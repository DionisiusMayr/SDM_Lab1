{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62450ace-a87c-44da-b4fa-bf1d06af15f8",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b563f-5673-4bce-ae3f-7850eaa3005e",
   "metadata": {},
   "source": [
    "- [ ] Fix the arrays in the data ingestion\n",
    "- [ ] Fix the datatypes in general\n",
    "- [X] Fix the connection pooling issue (ClientError: failed to obtain a connection from the pool within 60.0s (timeout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48febaa3-bc63-4060-a00a-1cce7e901aeb",
   "metadata": {},
   "source": [
    "# Libraries and contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54283889-0326-48be-9f02-fcd28a1fa070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "# !pip install spacy\n",
    "# !pip install git+https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4a90e1-dfba-4b44-a28b-5870e55360e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import neo4j\n",
    "import yake\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f418a294-c67e-4cf9-8415-285ccb27041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMANTIC_PATH = '../semanticscholar_raw_data'\n",
    "\n",
    "DEFAULT_JOURNAL_NAME = 'Unknown'\n",
    "\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4804b2-d40a-4c3d-8d31-86e5fe6e64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867774d-def4-4269-9ebd-76c3fb5b2d16",
   "metadata": {},
   "source": [
    "# Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7ccb56-a73e-4851-b8c0-97101096c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER = neo4j.GraphDatabase.driver(uri=\"neo4j://localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b884c55-8a15-4e07-84ee-8dcad18ba7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(query: str):\n",
    "    \"\"\"\n",
    "    Executes a Cypher @query and returns its result.\n",
    "    \"\"\"\n",
    "    result = DRIVER.execute_query(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f76e31e-bfd7-4684-8792-8aff2bdb781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_graph() -> None:\n",
    "    \"\"\"\n",
    "    Deletes every node and edge of the graph.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        MATCH (n)\n",
    "        DETACH DELETE n;\n",
    "    \"\"\"\n",
    "\n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea3448f-31e5-49ee-94cb-e07e2a5b3229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delete_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ccfe3-cf33-498c-acd7-b10ba696bc99",
   "metadata": {},
   "source": [
    "## Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677edcc1-28e8-41f0-9581-79cdc09e180a",
   "metadata": {},
   "source": [
    "Our dataset does not provide the keywords automatically extracted for us.\n",
    "Therefore, we will be trying to extract them from the abstract using an external library called [Yake](https://liaad.github.io/yake/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffb0d49-6ee2-4667-b10f-271c8f85f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_journal_name(paper) -> str:\n",
    "    \"\"\"\n",
    "    Not every file has a field 'journal' in the json.\n",
    "    This function treats those edge cases.\n",
    "    \"\"\"\n",
    "    if 'journal' not in paper or not paper['journal']:\n",
    "        return DEFAULT_JOURNAL_NAME\n",
    "    else:\n",
    "        return paper.get('journal', {'name': DEFAULT_JOURNAL_NAME}).get('name', DEFAULT_JOURNAL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4398209d-1d06-4352-beb7-2805ebd46ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_abstract(abstract: str) -> str:\n",
    "    if abstract:\n",
    "        return (\n",
    "            abstract\n",
    "            .replace('\"', \"'\")\n",
    "            .replace('\\\\', '\\\\\\\\')\n",
    "        )\n",
    "    else:\n",
    "        return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "037bc719-c73b-4f7b-9891-14dcaa076e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_papers():\n",
    "    \"\"\"\n",
    "    Create the nodes of label `Paper`.\n",
    "    \"\"\"\n",
    "    # This is used to extract the keywords from the abstract.\n",
    "    kw_extractor = yake.KeywordExtractor(\n",
    "        lan='en',\n",
    "        n=3,  # Max n-gram size\n",
    "        top=5  # Number of keywords\n",
    "    )\n",
    "    \n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Creating paper of {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        keywords = kw_extractor.extract_keywords(paper['abstract']) if paper['abstract'] else ''\n",
    "        keywords = list(map(lambda x: str.lower(x[0]) if x else '', keywords))\n",
    "\n",
    "        query = f\"\"\"\n",
    "        CREATE (n:Paper {{\n",
    "            paper_id: \"{paper['paperId']}\",\n",
    "            publication_venue: \"{paper['publicationVenue']}\",\n",
    "            title: \"{paper['title']}\",\n",
    "            venue: \"{paper['venue']}\",\n",
    "            year: \"{paper['year']}\",\n",
    "            fieldsOfStudy: \"{paper['fieldsOfStudy']}\",\n",
    "            publicationDate: \"{paper['publicationDate']}\",\n",
    "            abstract: \"{sanitize_abstract(paper['abstract'])}\",\n",
    "            keywords: \"{keywords}\"\n",
    "        }})\n",
    "        \"\"\"\n",
    "        # print(query)\n",
    "        try:\n",
    "            execute(query)\n",
    "        except:\n",
    "            print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db23829-32c9-4a7d-a8ff-015a47d30823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 244/244 [00:02<00:00, 89.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 53.7 ms, total: 2.13 s\n",
      "Wall time: 2.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b1b63d-35a1-4c20-ac42-7df037e2fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper__paper_id__range_index():\n",
    "    \"\"\"\n",
    "    Create indexes\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        CREATE RANGE INDEX paper__paper_id__range_index IF NOT EXISTS\n",
    "        FOR (n:Paper)\n",
    "        ON (n.paper_id)\n",
    "    \"\"\"\n",
    "\n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68253c3d-0774-4bcf-af31-009dc4704456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 ms, sys: 0 ns, total: 1.59 ms\n",
      "Wall time: 2.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_paper__paper_id__range_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207fe7b-2a92-4e98-a114-aa2cc5d90dcd",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eed0910-0e7f-4f7d-9f3e-28b6005645cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authors() -> None:\n",
    "    \"\"\"\n",
    "    For each paper, generate a node with label `Author` for that paper.\n",
    "    We are using the MERGE here since we don't want to duplicate authors.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Creating the authors of {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "    \n",
    "        for author in paper['authors']:\n",
    "            query = f\"\"\"\n",
    "            MERGE (n:Author {{\n",
    "                name: \"{author['name']}\",\n",
    "                author_id: \"{author['authorId']}\"\n",
    "            }})\n",
    "            \"\"\"\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0b397a-82c1-4a96-b40f-5e01184aa386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 244/244 [00:03<00:00, 64.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 172 ms, total: 1.19 s\n",
      "Wall time: 3.77 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899bd3c6-75cd-412d-9520-ad9e375c5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author__author_id__range_index():\n",
    "    \"\"\"\n",
    "    Create indexes\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        CREATE RANGE INDEX author__author_id__range_index IF NOT EXISTS\n",
    "        FOR (n:Author)\n",
    "        ON (n.author_id)\n",
    "    \"\"\"\n",
    "\n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61b8f13b-d73a-457d-b817-fd9c778ed5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.43 ms, sys: 0 ns, total: 2.43 ms\n",
      "Wall time: 4.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_author__author_id__range_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d01bc9-1de7-4d1a-9564-482c447f9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_author_to_paper() -> None:\n",
    "    \"\"\"\n",
    "    Create the edge `Wrote` and `IsCorrespondingAuthor`, linking Authors and Papers.\n",
    "    The first author is considered the corresponding author.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Linking authors of file {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "            is_first = True\n",
    "            for author in paper['authors']:\n",
    "                if is_first:\n",
    "                    # The first author is the main corresponding author.\n",
    "                    query = f\"\"\"\n",
    "                        MATCH (a:Author {{author_id: '{author['authorId']}'}})\n",
    "                        WITH a\n",
    "                        MATCH (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                        WITH a, p\n",
    "                        CREATE (a)-[e:IsCorrespondingAuthor]->(p);\n",
    "                    \"\"\"\n",
    "                    execute(query)\n",
    "                    is_first = False\n",
    "                \n",
    "                query = f\"\"\"\n",
    "                    MATCH (a:Author {{author_id: '{author['authorId']}'}})\n",
    "                    WITH a\n",
    "                    MATCH (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                    WITH a, p\n",
    "                    CREATE (a)-[e:Wrote]->(p);\n",
    "                \"\"\"\n",
    "    \n",
    "                execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c2269df-3603-4720-bc1b-b8b558d216f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 244/244 [00:08<00:00, 29.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 924 ms, sys: 173 ms, total: 1.1 s\n",
      "Wall time: 8.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_author_to_paper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b92fe6-2231-405c-9dbb-8e5c987bda99",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609eb7da-8a5f-497e-aa5a-ed8783e1d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_citations_between_papers() -> None:\n",
    "    \"\"\"\n",
    "    Generate the edge Cited linking a Paper to a Paper.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Linking citations of file {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        for citation in paper.get('citations', []):\n",
    "            query = f\"\"\"\n",
    "                MATCH (a:Paper {{paper_id: '{citation['paperId']}'}}), (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                CREATE (a)-[e:Cites]->(p);\n",
    "            \"\"\"\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fca91a16-15aa-40da-b486-e4b0334d7151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 244/244 [00:08<00:00, 27.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 s, sys: 185 ms, total: 1.66 s\n",
      "Wall time: 8.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_citations_between_papers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a25305-92c9-47fe-a0d8-c230b319d8bd",
   "metadata": {},
   "source": [
    "## Journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21418bb3-cd6d-4e80-91c1-4829e5c6006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_journals() -> None:\n",
    "    \"\"\"\n",
    "    Create the Journal nodes.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        journal_name = parse_journal_name(paper)\n",
    "         # or paper['journal'] == 'None'\n",
    "        if journal_name != DEFAULT_JOURNAL_NAME:\n",
    "            query = f\"\"\"\n",
    "                MERGE (n:Journal {{\n",
    "                    year: \"{paper['year']}\",\n",
    "                    journal_name: \"{journal_name}\"\n",
    "                    \n",
    "                }})\n",
    "            \"\"\"\n",
    "        # else:\n",
    "        #     query = f\"\"\"\n",
    "        #         MERGE (n:Journal {{\n",
    "        #             year: \"{paper['year']}\",\n",
    "        #             journal_name: \"{DEFAULT_JOURNAL_NAME}\"\n",
    "                    \n",
    "        #         }})\n",
    "        #     \"\"\"\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56f0df53-7d77-43e9-aa41-7a49cabce848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 244/244 [00:00<00:00, 280.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 269 ms, sys: 36.6 ms, total: 305 ms\n",
      "Wall time: 875 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_journals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d036d68-ee13-427a-804a-0c84b77e7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_journals()-> None:\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        query = f\"\"\"\n",
    "            MATCH (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                , (j:Journal {{journal_name: '{parse_journal_name(paper)}', year: '{paper['year']}'}})\n",
    "            WITH p, j\n",
    "            CREATE (p)-[e:PublishedIn]->(j);\n",
    "        \"\"\"\n",
    "        execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37a326b6-3898-4b5f-bb35-75c6f6e1f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 244/244 [00:01<00:00, 173.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 180 ms, sys: 41.7 ms, total: 222 ms\n",
      "Wall time: 1.41 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_journals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9bb43-13d4-41bf-b65f-e4c25b2298c1",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fac118-ed4b-4ae9-ab56-f5bbb51486e5",
   "metadata": {},
   "source": [
    "We will have to generate synthetic data here to represent the reviews.\n",
    "\n",
    "Typically, each paper has 3 reviewers, who are usually relevant authors.\n",
    "The author cannot review its own paper.\n",
    "\n",
    "The strategy that we will be using is to select up to 3 authors who:\n",
    "1. wrote papers cited by the paper in question; and\n",
    "2. didn't wrote the paper itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fbfc534-d873-4187-9a4f-777b47547642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_reviewers():\n",
    "    \"\"\"\n",
    "    Auxiliary function that returns an aggregation of all possible reviewers of a paper.\n",
    "    The logic of a \"possible reviewer\" is to select an author who:\n",
    "    1. wrote paper(s) cited by the paper in question; and who\n",
    "    2. didn't wrote the paper itself.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        MATCH (a:Author)-[w1:Wrote]->(mp:Paper)-[c:Cites]->(cp:Paper)\n",
    "        WITH mp, cp, a\n",
    "        MATCH (wcp:Author)-[w2:Wrote]->(cp)\n",
    "        WHERE NOT (wcp)-[:Wrote]->(mp)\n",
    "        RETURN mp.paper_id AS paper_id, collect(wcp.author_id) AS possible_reviewer_ids;\n",
    "    \"\"\"\n",
    "\n",
    "    return execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3faf49c7-f01b-46cf-81c3-cf0545721bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def link_reviewer_to_paper() -> None:\n",
    "    \"\"\"\n",
    "    This function generates synthetic data.\n",
    "    \"\"\"\n",
    "    result = get_possible_reviewers()\n",
    "    \n",
    "    for paper_id, possible_reviewers in tqdm(result[0]):\n",
    "        # Papers can have a different amount of reviewers, varying from 1 to 4, following the distribution specified by `p`.\n",
    "        # Edge case: If the paper doesn't cite any other paper, it will have 0 reviewers.\n",
    "        reviewer_qty = min(\n",
    "            np.random.choice(np.arange(1, 5), p=[0.1, 0.3, 0.5, 0.1]),\n",
    "            len(possible_reviewers)\n",
    "        )\n",
    "\n",
    "        reviewers = random.sample(possible_reviewers, reviewer_qty)\n",
    "        for reviewer in reviewers:\n",
    "            query = f\"\"\"\n",
    "                MATCH (a:Author {{author_id: '{reviewer}'}}), (p:Paper {{paper_id: '{paper_id}'}})\n",
    "                CREATE (a)-[e:Reviewed]->(p);\n",
    "            \"\"\"\n",
    "\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75b93fdf-8446-4efc-8ff6-08e435a6b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 243/243 [00:03<00:00, 74.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 533 ms, sys: 86.3 ms, total: 619 ms\n",
      "Wall time: 3.31 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_reviewer_to_paper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c65ced-2650-4bc8-ad33-a25cea0c84ee",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63f5d5-b828-40a6-bf76-2b10d3cbd799",
   "metadata": {},
   "source": [
    "Our dataset does not provide the keywords automatically extracted for us.\n",
    "Therefore, we will be trying to extract them from the abstract using an external library called [spacy](https://spacy.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ebe931-de58-41ec-bf37-3d2cd15bce3c",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0b356-8590-4af8-a1e6-8708b3a84c1b",
   "metadata": {},
   "source": [
    "<b>Query 1</b>\n",
    "\n",
    "Find the top 3 most cited papers of each conference.\n",
    "\n",
    "MATCH (p:Paper)-[:cited]->(cited:Paper) WITH p.journal_name AS journal, p.title AS title, COUNT(*) AS num_citations ORDER BY journal, num_citations DESC WITH journal, COLLECT({title: title, num_citations: num_citations}) AS papers WITH journal, papers, [i IN RANGE(1, SIZE(papers)) | i] AS ranks UNWIND ranks AS rank WITH journal, papers[rank - 1].title AS title, papers[rank - 1].num_citations AS num_citations, rank WHERE rank <= 3 RETURN journal, title, num_citations, rank ORDER BY journal, rank\n",
    "\n",
    "<b>Manually Test</b>\n",
    "\n",
    "MATCH (p:Paper)-[c:cited]->(cited:Paper) WITH p.journal_name AS journal, p.title AS title, COUNT(c) AS num_citations WHERE journal = '2014 IEEE International Conference on Big Data (Big Data)' RETURN journal, title, num_citations ORDER BY num_citations DESC\n",
    "\n",
    "<b>Query 4</b>\n",
    "\n",
    "Find the h-indexes of the authors in your graph\n",
    "\n",
    "MATCH (a:Author)-[:Wrote]->(p:Paper)-[:cited]->(cited:Paper) WITH a, p, COUNT(*) AS num_citations ORDER BY num_citations DESC WITH a, COLLECT(num_citations) AS citation_counts WITH a, [i IN RANGE(1, SIZE(citation_counts)) | CASE WHEN citation_counts[i - 1] >= i THEN i ELSE 0 END] AS h_values WITH a, MAX(h_values) AS h_index WITH a, MAX(REDUCE(s = 0, h IN h_index | CASE WHEN h > s THEN h ELSE s END)) AS max_h_index RETURN a.author_id AS author_id, a.name AS author_name, max_h_index\n",
    "\n",
    "<b>Manually test</b>\n",
    "\n",
    "MATCH (a:Author)-[:Wrote]->(p:Paper)-[:cited]->(cited:Paper) WITH a, p, COUNT(*) AS num_citations ORDER BY num_citations DESC WHERE a.name = 'M. Mokbel' return a.name, p.title, num_citations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938604e0-2137-4957-ab31-7b6587f2e7b1",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fb60b-9262-4899-a13a-de8fc29814e6",
   "metadata": {},
   "source": [
    "- [ ] Add the abstract of the paper;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa529fa-cc29-44ba-9b05-e8a95c74374c",
   "metadata": {},
   "source": [
    "# Known limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa18751-c78d-49e8-ab06-c9d7f56beb44",
   "metadata": {},
   "source": [
    "1. Our data source doesn't always provide the Journal name.\n",
    "When we don't have it, we are not creating a node for the journal where that paper was published.\n",
    "2. Papers without abstracts won't have their keywords extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfaa78-7832-4bc3-b8c0-18d4c486dfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62450ace-a87c-44da-b4fa-bf1d06af15f8",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b563f-5673-4bce-ae3f-7850eaa3005e",
   "metadata": {},
   "source": [
    "- [ ] Fix the arrays in the data ingestion\n",
    "- [ ] Fix the datatypes in general\n",
    "- [X] Fix the connection pooling issue (ClientError: failed to obtain a connection from the pool within 60.0s (timeout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48febaa3-bc63-4060-a00a-1cce7e901aeb",
   "metadata": {},
   "source": [
    "# Libraries and contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54283889-0326-48be-9f02-fcd28a1fa070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "# !pip install spacy\n",
    "# !pip install git+https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4a90e1-dfba-4b44-a28b-5870e55360e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import neo4j\n",
    "import yake\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f418a294-c67e-4cf9-8415-285ccb27041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMANTIC_PATH = '../semanticscholar_raw_data'\n",
    "\n",
    "DEFAULT_JOURNAL_NAME = 'Unknown'\n",
    "\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4804b2-d40a-4c3d-8d31-86e5fe6e64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867774d-def4-4269-9ebd-76c3fb5b2d16",
   "metadata": {},
   "source": [
    "# Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7ccb56-a73e-4851-b8c0-97101096c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER = neo4j.GraphDatabase.driver(uri=\"neo4j://localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b884c55-8a15-4e07-84ee-8dcad18ba7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(query: str):\n",
    "    \"\"\"\n",
    "    Executes a Cypher @query and returns its result.\n",
    "    \"\"\"\n",
    "    result = DRIVER.execute_query(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f76e31e-bfd7-4684-8792-8aff2bdb781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_graph() -> None:\n",
    "    \"\"\"\n",
    "    Deletes every node and edge of the graph.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        MATCH (n)\n",
    "        DETACH DELETE n;\n",
    "    \"\"\"\n",
    "\n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea3448f-31e5-49ee-94cb-e07e2a5b3229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delete_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ccfe3-cf33-498c-acd7-b10ba696bc99",
   "metadata": {},
   "source": [
    "## Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677edcc1-28e8-41f0-9581-79cdc09e180a",
   "metadata": {},
   "source": [
    "Our dataset does not provide the keywords automatically extracted for us.\n",
    "Therefore, we will be trying to extract them from the abstract using an external library called [Yake](https://liaad.github.io/yake/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffb0d49-6ee2-4667-b10f-271c8f85f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_journal_name(paper) -> str:\n",
    "    \"\"\"\n",
    "    Not every file has a field 'journal' in the json.\n",
    "    This function treats those edge cases.\n",
    "    \"\"\"\n",
    "    if 'journal' not in paper or not paper['journal']:\n",
    "        return DEFAULT_JOURNAL_NAME\n",
    "    else:\n",
    "        return paper.get('journal', {'name': DEFAULT_JOURNAL_NAME}).get('name', DEFAULT_JOURNAL_NAME).replace(\"'\", '').replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4398209d-1d06-4352-beb7-2805ebd46ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_abstract(abstract: str) -> str:\n",
    "    if abstract:\n",
    "        return (\n",
    "            abstract\n",
    "            .replace('\"', \"'\")\n",
    "            .replace('\\\\', '\\\\\\\\')\n",
    "        )\n",
    "    else:\n",
    "        return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "037bc719-c73b-4f7b-9891-14dcaa076e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_papers():\n",
    "    \"\"\"\n",
    "    Create the nodes of label `Paper`.\n",
    "    \"\"\"\n",
    "    # This is used to extract the keywords from the abstract.\n",
    "    kw_extractor = yake.KeywordExtractor(\n",
    "        lan='en',\n",
    "        n=3,  # Max n-gram size\n",
    "        top=5  # Number of keywords\n",
    "    )\n",
    "    \n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        title = paper['title'].replace('\\\\', '')\n",
    "        keywords = kw_extractor.extract_keywords(paper['abstract']) if paper['abstract'] else ''\n",
    "        keywords = list(map(lambda x: str.lower(x[0]) if x else '', keywords))\n",
    "\n",
    "        # publication_venue: \"{paper['publicationVenue']}\",\n",
    "        # venue: \"{paper['venue']}\",\n",
    "        query = f\"\"\"\n",
    "        CREATE (n:Paper {{\n",
    "            paper_id: \"{paper['paperId']}\",\n",
    "            title: \"{title}\",\n",
    "            \n",
    "            year: toInteger({paper['year'] if paper['year'] else -1}),\n",
    "            fieldsOfStudy: {paper['fieldsOfStudy'] if paper['fieldsOfStudy'] else '[]'},\n",
    "            publicationDate: date(\"{paper['publicationDate'] if paper['publicationDate'] else '1970-01-01'}\"),\n",
    "            abstract: \"{sanitize_abstract(paper['abstract'])}\",\n",
    "            keywords: {keywords}\n",
    "        }})\n",
    "        \"\"\"\n",
    "        try:\n",
    "            execute(query)\n",
    "        except:\n",
    "            print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db23829-32c9-4a7d-a8ff-015a47d30823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████▎                         | 1673/4919 [00:25<00:47, 68.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        CREATE (n:Paper {\n",
      "            paper_id: \"2703789238c80cc96e2a9d8dcc695d50316271ad\",\n",
      "            title: \"Datenbanksysteme für Business, Technologie und Web (BTW 2017), 17. Fachtagung des GI-Fachbereichs „Datenbanken und Informationssysteme\" (DBIS), 6.-10. März 2017, Stuttgart, Germany, Workshopband\",\n",
      "            \n",
      "            year: toInteger(2017),\n",
      "            fieldsOfStudy: ['Computer Science'],\n",
      "            publicationDate: date(\"1970-01-01\"),\n",
      "            abstract: \"The energy domain currently struggles with radical legal and technological changes, such as, smart meters. This results in new use cases which can be implemented based on business process technology. Understanding and automating business processes requires to model and test them. However, existing process testing approaches frequently struggle with the testing of process resources, such as ERP systems, and negative testing. Hence, this work presents a toolchain which tackles that limitations. The approach uses an open source process engine to generate event logs and applies process mining techniques in a novel way.\",\n",
      "            keywords: ['smart meters', 'energy domain', 'radical legal', 'legal and technological', 'struggles with radical']\n",
      "        })\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4919/4919 [01:15<00:00, 65.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45 s, sys: 1.24 s, total: 46.2 s\n",
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b1b63d-35a1-4c20-ac42-7df037e2fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper__paper_id__range_index():\n",
    "    \"\"\"\n",
    "    Create indexes\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        CREATE RANGE INDEX paper__paper_id__range_index IF NOT EXISTS\n",
    "        FOR (n:Paper)\n",
    "        ON (n.paper_id)\n",
    "    \"\"\"\n",
    "\n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68253c3d-0774-4bcf-af31-009dc4704456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 ms, sys: 86 µs, total: 1.99 ms\n",
      "Wall time: 5.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_paper__paper_id__range_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207fe7b-2a92-4e98-a114-aa2cc5d90dcd",
   "metadata": {},
   "source": [
    "## Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eed0910-0e7f-4f7d-9f3e-28b6005645cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authors() -> None:\n",
    "    \"\"\"\n",
    "    For each paper, generate a node with label `Author` for that paper.\n",
    "    We are using the MERGE here since we don't want to duplicate authors.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Creating the authors of {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "    \n",
    "        for author in paper['authors']:\n",
    "            query = f\"\"\"\n",
    "            MERGE (n:Author {{\n",
    "                name: \"{author['name']}\",\n",
    "                author_id: \"{author['authorId']}\"\n",
    "            }})\n",
    "            \"\"\"\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0b397a-82c1-4a96-b40f-5e01184aa386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4935/4935 [01:26<00:00, 56.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 3.56 s, total: 24.6 s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899bd3c6-75cd-412d-9520-ad9e375c5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author__author_id__range_index():\n",
    "    \"\"\"\n",
    "    Create indexes\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        CREATE RANGE INDEX author__author_id__range_index IF NOT EXISTS\n",
    "        FOR (n:Author)\n",
    "        ON (n.author_id)\n",
    "    \"\"\"\n",
    "\n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61b8f13b-d73a-457d-b817-fd9c778ed5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 ms, sys: 275 µs, total: 3.24 ms\n",
      "Wall time: 5.43 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_author__author_id__range_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d01bc9-1de7-4d1a-9564-482c447f9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_author_to_paper() -> None:\n",
    "    \"\"\"\n",
    "    Create the edge `Wrote` and `IsCorrespondingAuthor`, linking Authors and Papers.\n",
    "    The first author is considered the corresponding author.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Linking authors of file {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "            is_first = True\n",
    "            for author in paper['authors']:\n",
    "                if is_first:\n",
    "                    # The first author is the main corresponding author.\n",
    "                    query = f\"\"\"\n",
    "                        MATCH (a:Author {{author_id: '{author['authorId']}'}})\n",
    "                        WITH a\n",
    "                        MATCH (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                        WITH a, p\n",
    "                        CREATE (a)-[e:IsCorrespondingAuthor]->(p);\n",
    "                    \"\"\"\n",
    "                    execute(query)\n",
    "                    is_first = False\n",
    "                \n",
    "                query = f\"\"\"\n",
    "                    MATCH (a:Author {{author_id: '{author['authorId']}'}})\n",
    "                    WITH a\n",
    "                    MATCH (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                    WITH a, p\n",
    "                    CREATE (a)-[e:Wrote]->(p);\n",
    "                \"\"\"\n",
    "    \n",
    "                execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c2269df-3603-4720-bc1b-b8b558d216f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4962/4962 [03:18<00:00, 24.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 4.56 s, total: 27.4 s\n",
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_author_to_paper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b92fe6-2231-405c-9dbb-8e5c987bda99",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "609eb7da-8a5f-497e-aa5a-ed8783e1d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_citations_between_papers() -> None:\n",
    "    \"\"\"\n",
    "    Generate the edge Cited linking a Paper to a Paper.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        # print(f'Linking citations of file {fname}')\n",
    "\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        for citation in paper.get('citations', []):\n",
    "            query = f\"\"\"\n",
    "                MATCH (a:Paper {{paper_id: '{citation['paperId']}'}}), (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                CREATE (a)-[e:Cites]->(p);\n",
    "            \"\"\"\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fca91a16-15aa-40da-b486-e4b0334d7151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5050/5050 [05:09<00:00, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.6 s, sys: 7.96 s, total: 53.6 s\n",
      "Wall time: 5min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_citations_between_papers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a25305-92c9-47fe-a0d8-c230b319d8bd",
   "metadata": {},
   "source": [
    "## Journals and Conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21418bb3-cd6d-4e80-91c1-4829e5c6006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_journals() -> None:\n",
    "    \"\"\"\n",
    "    Create the Journal nodes.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        journal_name = parse_journal_name(paper)\n",
    "\n",
    "        if journal_name != DEFAULT_JOURNAL_NAME:\n",
    "            query = f\"\"\"\n",
    "                MERGE (n:Journal {{\n",
    "                    year: toInteger({paper['year']}),\n",
    "                    name: \"{journal_name}\"\n",
    "                    \n",
    "                }})\n",
    "            \"\"\"\n",
    "\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56f0df53-7d77-43e9-aa41-7a49cabce848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5192/5192 [00:25<00:00, 201.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.44 s, sys: 1.11 s, total: 6.55 s\n",
      "Wall time: 25.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_journals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d036d68-ee13-427a-804a-0c84b77e7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_journals()-> None:\n",
    "    \"\"\"\n",
    "    Link a Paper to a Journal creating the `PublishedIn` edge.\n",
    "    \"\"\"\n",
    "    for fname in tqdm(os.listdir(SEMANTIC_PATH)):\n",
    "        with open(f'{SEMANTIC_PATH}/{fname}') as f:\n",
    "            paper = json.loads(f.read())\n",
    "\n",
    "        query = f\"\"\"\n",
    "            MATCH (p:Paper {{paper_id: '{paper['paperId']}'}})\n",
    "                , (j:Journal {{name: '{parse_journal_name(paper)}', year: toInteger({paper['year'] if paper['year'] else -1})}})\n",
    "            WITH p, j\n",
    "            CREATE (p)-[e:PublishedIn]->(j);\n",
    "        \"\"\"\n",
    "        execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37a326b6-3898-4b5f-bb35-75c6f6e1f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5206/5206 [00:42<00:00, 123.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.9 s, sys: 853 ms, total: 5.75 s\n",
      "Wall time: 42.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_journals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef6e19bf-a9b9-43dc-9a0a-453b74a21fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_conference() -> None:\n",
    "    \"\"\"\n",
    "    Change the label from Journal to Conference if the \"Journal\" name contains 'conference' in it.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        MATCH (j:Journal)\n",
    "        WHERE toLower(j.name) =~ '.*conference.*' OR toLower(j.name) =~ '.*workshop.*'\n",
    "        REMOVE j:Journal\n",
    "        SET j:ConfWork\n",
    "    \"\"\"\n",
    "    \n",
    "    execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3188903a-1c41-4ba2-afc5-34cc45218417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.58 ms, sys: 365 µs, total: 2.94 ms\n",
      "Wall time: 29.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "change_to_conference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9bb43-13d4-41bf-b65f-e4c25b2298c1",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fac118-ed4b-4ae9-ab56-f5bbb51486e5",
   "metadata": {},
   "source": [
    "We will have to generate synthetic data here to represent the reviews.\n",
    "\n",
    "Typically, each paper has 3 reviewers, who are usually relevant authors.\n",
    "The author cannot review its own paper.\n",
    "\n",
    "The strategy that we will be using is to select up to 3 authors who:\n",
    "1. wrote papers cited by the paper in question; and\n",
    "2. didn't wrote the paper itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fbfc534-d873-4187-9a4f-777b47547642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_reviewers():\n",
    "    \"\"\"\n",
    "    Auxiliary function that returns an aggregation of all possible reviewers of a paper.\n",
    "    The logic of a \"possible reviewer\" is to select an author who:\n",
    "    1. wrote paper(s) cited by the paper in question; and who\n",
    "    2. didn't wrote the paper itself.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        MATCH (a:Author)-[w1:Wrote]->(mp:Paper)-[c:Cites]->(cp:Paper)\n",
    "        WITH mp, cp, a\n",
    "        MATCH (wcp:Author)-[w2:Wrote]->(cp)\n",
    "        WHERE NOT (wcp)-[:Wrote]->(mp)\n",
    "        RETURN mp.paper_id AS paper_id, collect(wcp.author_id) AS possible_reviewer_ids;\n",
    "    \"\"\"\n",
    "\n",
    "    return execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3faf49c7-f01b-46cf-81c3-cf0545721bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def link_reviewer_to_paper() -> None:\n",
    "    \"\"\"\n",
    "    This function generates synthetic data.\n",
    "    \"\"\"\n",
    "    result = get_possible_reviewers()\n",
    "    \n",
    "    for paper_id, possible_reviewers in tqdm(result[0]):\n",
    "        # Papers can have a different amount of reviewers, varying from 1 to 4, following the distribution specified by `p`.\n",
    "        # Edge case: If the paper doesn't cite any other paper, it will have 0 reviewers.\n",
    "        reviewer_qty = min(\n",
    "            np.random.choice(np.arange(1, 5), p=[0.1, 0.3, 0.5, 0.1]),\n",
    "            len(possible_reviewers)\n",
    "        )\n",
    "\n",
    "        reviewers = random.sample(possible_reviewers, reviewer_qty)\n",
    "        for reviewer in reviewers:\n",
    "            query = f\"\"\"\n",
    "                MATCH (a:Author {{author_id: '{reviewer}'}}), (p:Paper {{paper_id: '{paper_id}'}})\n",
    "                CREATE (a)-[e:Reviewed]->(p);\n",
    "            \"\"\"\n",
    "\n",
    "            execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75b93fdf-8446-4efc-8ff6-08e435a6b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 4880/4880 [00:52<00:00, 92.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.52 s, sys: 1.23 s, total: 9.75 s\n",
      "Wall time: 53.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_reviewer_to_paper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ebe931-de58-41ec-bf37-3d2cd15bce3c",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0b356-8590-4af8-a1e6-8708b3a84c1b",
   "metadata": {},
   "source": [
    "<b>Query 1</b>\n",
    "\n",
    "Find the top 3 most cited papers of each conference.\n",
    "\n",
    "```\n",
    "MATCH (p:Paper)-[:cited]->(cited:Paper) WITH p.name AS journal, p.title AS title, COUNT(*) AS num_citations ORDER BY journal, num_citations DESC WITH journal, COLLECT({title: title, num_citations: num_citations}) AS papers WITH journal, papers, [i IN RANGE(1, SIZE(papers)) | i] AS ranks UNWIND ranks AS rank WITH journal, papers[rank - 1].title AS title, papers[rank - 1].num_citations AS num_citations, rank WHERE rank <= 3 RETURN journal, title, num_citations, rank ORDER BY journal, rank\n",
    "```\n",
    "\n",
    "<b>Manually Test</b>\n",
    "\n",
    "```\n",
    "MATCH (p:Paper)-[c:cited]->(cited:Paper) WITH p.name AS journal, p.title AS title, COUNT(c) AS num_citations WHERE journal = '2014 IEEE International Conference on Big Data (Big Data)' RETURN journal, title, num_citations ORDER BY num_citations DESC\n",
    "```\n",
    "\n",
    "<b>Query 3</b>\n",
    "\n",
    "Find the impact factors of the journals in your graph (see https://en.wikipedia.org/wiki/Impact_factor, for the definition of the impact factor).\n",
    "\n",
    "```\n",
    "MATCH (citing_paper:Paper)-[:Cites]->(published_paper:Paper {year: j.year})-[:PublishedIn]->(j:Journal)\n",
    "WITH COUNT(DISTINCT citing_paper) AS total_citations, j.name AS journal_name, j AS j1\n",
    "MATCH (j2: Journal)<-[:PublishedIn]-(p:Paper)\n",
    "WHERE j2.year IN [j1.year - 1, j1.year - 2]\n",
    "      AND j1.name = j2.name\n",
    "WITH j1.year AS year,\n",
    "     COUNT(p.title) AS past_publications,\n",
    "     j1.name AS journal_name,\n",
    "     total_citations\n",
    "RETURN year, journal_name, total_citations, past_publications, 1.0 * total_citations / past_publications\n",
    "ORDER BY journal_name, year;\n",
    "```\n",
    "\n",
    "<b>Query 4</b>\n",
    "\n",
    "Find the h-indexes of the authors in your graph\n",
    "\n",
    "```\n",
    "MATCH (a:Author)-[:Wrote]->(p:Paper)-[:cited]->(cited:Paper) WITH a, p, COUNT(*) AS num_citations ORDER BY num_citations DESC WITH a, COLLECT(num_citations) AS citation_counts WITH a, [i IN RANGE(1, SIZE(citation_counts)) | CASE WHEN citation_counts[i - 1] >= i THEN i ELSE 0 END] AS h_values WITH a, MAX(h_values) AS h_index WITH a, MAX(REDUCE(s = 0, h IN h_index | CASE WHEN h > s THEN h ELSE s END)) AS max_h_index RETURN a.author_id AS author_id, a.name AS author_name, max_h_index\n",
    "```\n",
    "\n",
    "<b>Manually test</b>\n",
    "\n",
    "```\n",
    "MATCH (a:Author)-[:Wrote]->(p:Paper)-[:cited]->(cited:Paper) WITH a, p, COUNT(*) AS num_citations ORDER BY num_citations DESC WHERE a.name = 'M. Mokbel' return a.name, p.title, num_citations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb00ab24-df96-4d82-ba8f-b0e5f7f50185",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3593147951.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    MATCH (a:Author)-[:Wrote]->(p:Paper)-[:PublishedIn]->(c:Journal)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "MATCH (a:Author)-[:Wrote]->(p:Paper)-[:PublishedIn]->(c:Journal)\n",
    "// WITH a, c, size(collect(c.year)) AS s\n",
    "// WHERE s > 2\n",
    "// RETURN a.name, collect(c.year), c.name\n",
    "// ORDER BY a.name, c.name\n",
    "WITH a.name AS author, collect(DISTINCT c.year) AS years, c.name AS conference\n",
    "WHERE size(years) > 1\n",
    "RETURN author, years, conference\n",
    "// ORDER BY  DESC\n",
    "// RETURN a.name, size(collect(c.name)), collect(c.name)\n",
    "// ORDER BY size(collect(c.name)) DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e62949-94f6-4ba0-8c95-ade55e8aa9ca",
   "metadata": {},
   "source": [
    "# Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba4ec7c-107d-4a65-bd65-226783550e58",
   "metadata": {},
   "source": [
    "<b>Part 1</b>\n",
    "\n",
    "```\n",
    "// First we are looking for papers containing any of those keywords.\n",
    "MATCH (p:Paper)\n",
    "WHERE\n",
    "    // Could've been an array intersection, but APOC was giving us some setup issues.\n",
    "    'data management' IN p.keywords\n",
    "    OR 'indexing' IN p.keywords\n",
    "    OR 'data modeling' IN p.keywords\n",
    "    OR 'big data' IN p.keywords\n",
    "    OR 'data processing' IN p.keywords\n",
    "    OR 'data storage' IN p.keywords\n",
    "    OR 'data querying' IN p.keywords\n",
    "RETURN *\n",
    "```\n",
    "\n",
    "<b>Part 2</b>\n",
    "\n",
    "```\n",
    "// Now we want the conferences or journals with at least 90% of published papers being related to databases.\n",
    "MATCH (p:Paper)-[:PublishedIn]->(jc)\n",
    "WITH p, (\n",
    "        'data management' IN p.keywords\n",
    "        OR 'indexing' IN p.keywords\n",
    "        OR 'data modeling' IN p.keywords\n",
    "        OR 'big data' IN p.keywords\n",
    "        OR 'data processing' IN p.keywords\n",
    "        OR 'data storage' IN p.keywords\n",
    "        OR 'data querying' IN p.keywords\n",
    "    ) AS in_db_community,\n",
    "    jc\n",
    "WITH COUNT(p) AS total_published_papers, SUM(CASE in_db_community WHEN TRUE THEN 1 ELSE 0 END) AS db_comm_papers, jc.name AS jc_name\n",
    "WHERE 100.0 * db_comm_papers / total_published_papers > 90.0 \n",
    "RETURN total_published_papers, db_comm_papers, 100.0 * db_comm_papers / total_published_papers AS percentage_of_db_papers, jc_name\n",
    "LIMIT 50\n",
    "```\n",
    "\n",
    "<b>Part 3</b>\n",
    "\n",
    "```\n",
    "// Let's now grab the top 100 most cited papers in the Database community.\n",
    "MATCH (p:Paper)-[:PublishedIn]->(jc)\n",
    "WITH p, (\n",
    "        'data management' IN p.keywords\n",
    "        OR 'indexing' IN p.keywords\n",
    "        OR 'data modeling' IN p.keywords\n",
    "        OR 'big data' IN p.keywords\n",
    "        OR 'data processing' IN p.keywords\n",
    "        OR 'data storage' IN p.keywords\n",
    "        OR 'data querying' IN p.keywords\n",
    "    ) AS in_db_community,\n",
    "    jc\n",
    "WITH COUNT(p) AS total_published_papers, SUM(CASE in_db_community WHEN TRUE THEN 1 ELSE 0 END) AS db_comm_papers, jc.name AS jc_name, jc\n",
    "WHERE 100.0 * db_comm_papers / total_published_papers > 90.0\n",
    "WITH collect(jc.name) AS db_comm_conferences\n",
    "\n",
    "MATCH (citing_paper:Paper)-[:Cites]->(cited_paper:Paper)-[:PublishedIn]->(jc1), (citing_paper)-[:PublishedIn]->(jc2)\n",
    "WHERE jc1.name IN db_comm_conferences\n",
    "  AND jc2.name IN db_comm_conferences\n",
    "WITH cited_paper, jc1, COUNT(DISTINCT citing_paper) AS c\n",
    "RETURN c, jc1.name, cited_paper.title\n",
    "ORDER BY c DESC\n",
    "LIMIT 100\n",
    "```\n",
    "\n",
    "<b>Part 4</b>\n",
    "\n",
    "```\n",
    "// Now, we will find the gurus of the community.\n",
    "MATCH (p:Paper)-[:PublishedIn]->(jc)\n",
    "WITH p, (\n",
    "        'data management' IN p.keywords\n",
    "        OR 'indexing' IN p.keywords\n",
    "        OR 'data modeling' IN p.keywords\n",
    "        OR 'big data' IN p.keywords\n",
    "        OR 'data processing' IN p.keywords\n",
    "        OR 'data storage' IN p.keywords\n",
    "        OR 'data querying' IN p.keywords\n",
    "    ) AS in_db_community,\n",
    "    jc\n",
    "WITH COUNT(p) AS total_published_papers, SUM(CASE in_db_community WHEN TRUE THEN 1 ELSE 0 END) AS db_comm_papers, jc.name AS jc_name, jc\n",
    "WHERE 100.0 * db_comm_papers / total_published_papers > 90.0\n",
    "WITH collect(jc.name) AS db_comm_conferences\n",
    "\n",
    "MATCH (citing_paper:Paper)-[:Cites]->(cited_paper:Paper)-[:PublishedIn]->(jc1), (citing_paper)-[:PublishedIn]->(jc2)\n",
    "WHERE jc1.name IN db_comm_conferences\n",
    "  AND jc2.name IN db_comm_conferences\n",
    "WITH cited_paper, jc1, COUNT(DISTINCT citing_paper) AS c\n",
    "WITH COLLECT(cited_paper.paper_id)[1..100] AS most_cited_papers// UNWIND most_cited_papers AS most_cited_paper\n",
    "\n",
    "MATCH (p1:Paper)<-[:Wrote]-(a:Author)-[:Wrote]->(p2:Paper)\n",
    "WHERE p1 <> p2\n",
    "AND p1.paper_id IN most_cited_papers\n",
    "AND p2.paper_id IN most_cited_papers\n",
    "RETURN a\n",
    "\n",
    "// , collect() AS col UNWIND RANGE(0, SIZE(col) - 1) AS un\n",
    "// RETURN un AS rn, col[un][0] AS cited_paper_node//, col[un][1] AS jc_node\n",
    "\n",
    "// WITH , AS rank\n",
    "\n",
    "\n",
    "// MATCH (a:Author)-[:Wrote]->(cited_paper)\n",
    "\n",
    "// RETURN c, jc1.name, cited_paper.title\n",
    "// ORDER BY c ASC\n",
    "LIMIT 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa529fa-cc29-44ba-9b05-e8a95c74374c",
   "metadata": {},
   "source": [
    "# Known limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa18751-c78d-49e8-ab06-c9d7f56beb44",
   "metadata": {},
   "source": [
    "1. Our data source doesn't always provide the Journal name.\n",
    "When we don't have it, we are not creating a node for the journal where that paper was published.\n",
    "2. Papers without abstracts won't have their keywords extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53b43f-0c02-4250-a57e-aafbeff25ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (citing_paper:Paper)-[:Cites]->(published_paper:Paper {year: j.year})-[:PublishedIn]->(j:Journal)\n",
    "WITH COUNT(DISTINCT citing_paper) AS total_citations, j.name AS journal_name, j AS j1\n",
    "MATCH (j2: Journal)<-[:PublishedIn]-(p:Paper)\n",
    "WHERE j2.year IN [j1.year - 1, j1.year - 2]\n",
    "      AND j1.name = j2.name\n",
    "WITH j1.year AS year,\n",
    "     COUNT(p.title) AS past_publications,\n",
    "     j1.name AS journal_name,\n",
    "     total_citations\n",
    "RETURN year, journal_name, total_citations, past_publications, 1.0 * total_citations / past_publications\n",
    "ORDER BY journal_name, year\n",
    "LIMIT 50;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"paperId": "242dbbef9e7f624525c57645f193e0b13a90ad44", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions", "abstract": "The intersection of the Foundation Model (FM) and Federated Learning (FL) provides mutual benefits, presents a unique opportunity to unlock new possibilities in AI research, and address critical challenges in AI and real-world applications. FL expands the availability of data for FMs and enables computation sharing, distributing the training process and reducing the burden on FL participants. It promotes collaborative FM development, democratizing the process and fostering inclusivity and innovation. On the other hand, FM, with its enormous size, pre-trained knowledge, and exceptional performance, serves as a robust starting point for FL, facilitating faster convergence and better performance under non-iid data. Additionally, leveraging FM to generate synthetic data enriches data diversity, reduces overfitting, and preserves privacy. By examining the interplay between FL and FM, this paper aims to deepen the understanding of their synergistic relationship, highlighting the motivations, challenges, and future directions. Through an exploration of the challenges faced by FL and FM individually and their interconnections, we aim to inspire future research directions that can further enhance both fields, driving advancements and propelling the development of privacy-preserving and scalable AI systems.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-06-27", "journal": {"name": "ArXiv", "volume": "abs/2306.15546"}, "authors": [{"authorId": "1900312976", "name": "Weiming Zhuang"}, {"authorId": null, "name": "Chen Chen"}, {"authorId": "145225199", "name": "Lingjuan Lyu"}], "citations": [{"paperId": "eb051b9e1549039fbe82201eacb4e458d78edb1a", "title": "Mitigating Heterogeneity in Federated Multimodal Learning with Biomedical Vision-Language Pre-training"}, {"paperId": "60071051e176b6e2fadbededadbb08b05e125c13", "title": "Dual-Personalizing Adapter for Federated Foundation Models"}, {"paperId": "200740a8f8c6d56d507837e1ae9cbad46c51fa7b", "title": "An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning"}, {"paperId": "fc7254969b8b5dc0497ae53a9c9cf9120e0379e5", "title": "Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting"}, {"paperId": "64a2001747524a38d624c181b7ebf339745af999", "title": "Large Language Models are Few-shot Generators: Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples"}, {"paperId": "3588a9fbeb79e8fb04b8a148b1ad79beb52988d7", "title": "Exploring Federated Self-Supervised Learning for General Purpose Audio Understanding"}, {"paperId": "8b2daef609768cc030bfa26126bff97990b3b1aa", "title": "Federated Learning with New Knowledge: Fundamentals, Advances, and Futures"}, {"paperId": "23e507cef64d4119d1681a7b15f999ea8ba2777d", "title": "Parametric Feature Transfer: One-shot Federated Learning with Foundation Models"}, {"paperId": "8e1c0a78a26a59cbe4ac82f13d9d01017a9bcb73", "title": "Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models"}, {"paperId": "9268a445f779f908b768d955100e0ba1e172d889", "title": "Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats"}, {"paperId": "e6f480a7d45e2447fa5e9988064735b19433c301", "title": "Towards Integrated Fine-tuning and Inference when Generative AI meets Edge Intelligence"}, {"paperId": "2d6407c6cc4ec8458a2307c849ca23bb017075eb", "title": "GainNet: Coordinates the Odd Couple of Generative AI and 6G Networks"}, {"paperId": "9423b10238de6df6414a1f997bc6855b7e4082e5", "title": "Blended Learning for Machine Learning-based Image Classification"}, {"paperId": "9bf5c27696ecd7b96b8d1b6e62a7aee9bf485937", "title": "Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous Federated Learning"}, {"paperId": "f416c5574c9741e14f0fd728112178bcda382c21", "title": "Grounding Foundation Models through Federated Transfer Learning: A General Framework"}, {"paperId": "6dc8f09f3f39d41c21ec167b8a0ed9f12552f487", "title": "Trustworthy Large Models in Vision: A Survey"}, {"paperId": "1b6bec9ecc76de20a92ec37e4cd4b98845299f28", "title": "Backdoor Threats from Compromised Foundation Models to Federated Learning"}, {"paperId": "30f96d89567aa71d47a5d43bdf3ec47a3d389669", "title": "FedSplitX: Federated Split Learning for Computationally-Constrained Heterogeneous Clients"}, {"paperId": "c8d5c5ebc1aaada257141aa4f65e890bb8224b4d", "title": "ZooPFL: Exploring Black-box Foundation Models for Personalized Federated Learning"}, {"paperId": "053bdcbe3cf45c5f34a4e50b271a6016a960637a", "title": "Bridging the Gap Between Foundation Models and Heterogeneous Federated Learning"}, {"paperId": "2e677e9471d9f2654a1c3a378400d287c8f2e337", "title": "FwdLLM: Efficient FedLLM using Forward Gradient"}, {"paperId": "3cb399d96cd70f5e9aa4ffecf7d329d1b0910745", "title": "FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning"}, {"paperId": "2003dcf311ccab2426818113964e59ca0cfde2c9", "title": "FDAPT: Federated Domain-adaptive Pre-training for Language Models"}, {"paperId": "dac1541f9052ec74637cf8556d9fd7da05f8cf7c", "title": "A Pathway Towards Responsible AI Generated Content"}, {"paperId": "3218bec272fe1708c20b009440c011eabce94764", "title": "How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models"}, {"paperId": "20f92345229a7155d851bbccc65ad21942ee7640", "title": "B RIDGING THE G AP B ETWEEN F OUNDATION M ODELS AND H ETEROGENEOUS F EDERATED L EARNING"}]}

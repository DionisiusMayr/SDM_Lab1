{"paperId": "c57a16699228810f919d55ca02bfbdd42d97807a", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Grid-Centric Traffic Scenario Perception for Autonomous Driving: A Comprehensive Review", "abstract": "Grid-centric perception is a crucial field for mobile robot perception and navigation. Nonetheless, grid-centric perception is less prevalent than object-centric perception for autonomous driving as autonomous vehicles need to accurately perceive highly dynamic, large-scale outdoor traffic scenarios and the complexity and computational costs of grid-centric perception are high. The rapid development of deep learning techniques and hardware gives fresh insights into the evolution of grid-centric perception and enables the deployment of many real-time algorithms. Current industrial and academic research demonstrates the great advantages of grid-centric perception, such as comprehensive fine-grained environmental representation, greater robustness to occlusion, more efficient sensor fusion, and safer planning policies. Given the lack of current surveys for this rapidly expanding field, we present a hierarchically-structured review of grid-centric perception for autonomous vehicles. We organize previous and current knowledge of occupancy grid techniques and provide a systematic in-depth analysis of algorithms in terms of three aspects: feature representation, data utility, and applications in autonomous driving systems. Lastly, we present a summary of the current research trend and provide some probable future outlooks.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-03-02", "journal": {"name": "ArXiv", "volume": "abs/2303.01212"}, "authors": [{"authorId": "2118897651", "name": "Yining Shi"}, {"authorId": "48333611", "name": "Kun Jiang"}, {"authorId": "2208881740", "name": "Jiusi Li"}, {"authorId": "145024315", "name": "Jun Wen"}, {"authorId": "2210267138", "name": "Zelin Qian"}, {"authorId": "2111076804", "name": "Mengmeng Yang"}, {"authorId": "2208949317", "name": "Ke Wang"}, {"authorId": "2525550", "name": "Diange Yang"}], "citations": [{"paperId": "37a0796a8508eaf5edb7c9cd873a2efc1c61cbb9", "title": "Predictive Recruitment in Vehicular Crowdsensing Based on Spatial Sensing Strength Analysis Method"}, {"paperId": "6d2ab31aa75468f5458b9d96192c3f4a28f55d73", "title": "DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving"}, {"paperId": "cd1c95ee95fd7026bad1e115f26e4119678fdd83", "title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations"}, {"paperId": "6c0adffa4dc38dd3aa640e8d5e0bdc7af7801444", "title": "LiDAR-based 4D Occupancy Completion and Forecasting"}, {"paperId": "84d5e00d5961b24d48051885fb6a40b937ba145c", "title": "V2X Cooperative Perception for Autonomous Driving: Recent Advances and Challenges"}, {"paperId": "cc94245258a9e4106a845c541b6ab8948fa9c173", "title": "Risk-Aware Navigation for Mobile Robots in Unknown 3D Environments"}, {"paperId": "cbcdb85838ae0d6511c2f7c3e22e84134d308e39", "title": "SOGDet: Semantic-Occupancy Guided Multi-view 3D Object Detection"}, {"paperId": "e2e59f434940d03300ee0fac14d2c65ed0e2ae15", "title": "UniWorld: Autonomous Driving Pre-training via World Models"}, {"paperId": "528ca770243af9baacc9e59a6fc6588d8649dfe5", "title": "An Overview about Emerging Technologies of Autonomous Driving"}, {"paperId": "a99e551cb9326f071b01105bb115c5ca15209391", "title": "Multi-Camera Unified Pre-Training via 3D Scene Reconstruction"}, {"paperId": "43c13a0d9d132c5f4c8f03db039f730396ba92e0", "title": "Self-supervised Learning for Pre-Training 3D Point Clouds: A Survey"}, {"paperId": "55e2ab8f8051a35c535bad9b75b7ff4f91ca8e72", "title": "Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction"}]}

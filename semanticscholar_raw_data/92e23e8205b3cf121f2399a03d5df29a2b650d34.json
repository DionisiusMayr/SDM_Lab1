{"paperId": "92e23e8205b3cf121f2399a03d5df29a2b650d34", "publicationVenue": null, "title": "Transparent In-memory Cache for Hadoop-MapReduce", "abstract": "Transparent in-memory cache for Hadoop-MapReduce Venkatesh Nandakumar Master of Applied Science Graduate Department of Electrical and Computer Engineering University of Toronto 2014 Many analytic applications built on Hadoop ecosystem have a propensity to iteratively perform repetitive operations on same input data. To remove the burden of these repetitive operations, new frameworks for MapReduce have been introduced, which make users follow its programming model. We propose a solution to the problem of application rewriting that newer frameworks impose. We re-architected Hadoop core to add in-memory caching & cache-aware task-scheduling. We set out to match the performance of a state-of-the-art high speed, in-memory MapReduce architecture with caching (Spark). While Spark[1] reimplements the MapReduce paradigm, it comes with a new set of new API\u2019s and abstractions. We maintain the familiar Hadoop framework and API\u2019s, thus complete backward compatibility for any existing Hadoop-based software. This ensures no changes to existing applications code whatsoever. It guarantees no-pain installation over existing deployments while providing 4.5-12X performance improvement. We perform comparable to, and in some cases", "venue": "", "year": 2014, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2014-11-01", "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "2248257", "name": "Venkatesh Nandakumar"}], "citations": [{"paperId": "1b72d92318b4f6d2bcd831b099a889fc90fbe05a", "title": "CATS: cache-aware task scheduling for Hadoop-based systems"}]}

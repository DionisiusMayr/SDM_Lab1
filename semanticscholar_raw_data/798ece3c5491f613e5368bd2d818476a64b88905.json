{"paperId": "798ece3c5491f613e5368bd2d818476a64b88905", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers", "abstract": "The emergence of Large Language Models (LLMs) such as ChatGPT and LLaMA encounter limitations in domain-specific tasks, with these models often lacking depth and accuracy in specialized areas, and exhibiting a decrease in general capabilities when fine-tuned, particularly analysis ability in small sized models. To address these gaps, we introduce ICE-GRT, utilizing Reinforcement Learning from Human Feedback (RLHF) grounded in Proximal Policy Optimization (PPO), demonstrating remarkable ability in in-domain scenarios without compromising general task performance. Our exploration of ICE-GRT highlights its understanding and reasoning ability to not only generate robust answers but also to provide detailed analyses of the reasons behind the answer. This capability marks a significant progression beyond the scope of Supervised Fine-Tuning models. The success of ICE-GRT is dependent on several crucial factors, including Appropriate Data, Reward Size Scaling, KL-Control, Advantage Normalization, etc. The ICE-GRT model exhibits state-of-the-art performance in domain-specific tasks and across 12 general Language tasks against equivalent size and even larger size LLMs, highlighting the effectiveness of our approach. We provide a comprehensive analysis of the ICE-GRT, underscoring the significant advancements it brings to the field of LLM.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-01-04", "journal": {"name": "ArXiv", "volume": "abs/2401.02072"}, "authors": [{"authorId": "2267276054", "name": "Chen Zheng"}, {"authorId": "2257036596", "name": "Ke Sun"}, {"authorId": "2256980831", "name": "Da Tang"}, {"authorId": "2257348528", "name": "Yukun Ma"}, {"authorId": "2248087218", "name": "Yuyu Zhang"}, {"authorId": "2248188939", "name": "Chenguang Xi"}, {"authorId": "2257319328", "name": "Xun Zhou"}], "citations": [{"paperId": "9ddfb1583ce7f5370ace2751bb5f260fa4af1961", "title": "Balancing Enhancement, Harmlessness, and General Capabilities: Enhancing Conversational LLMs with Direct RLHF"}, {"paperId": "debcb86e9d230807b3967227342c9b3747c27f3b", "title": "Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective"}]}

{"paperId": "2f6db79cc6d762be8c7ef4643942c7ac89e0adce", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Optimal Placement of Cores, Caches and Memory Controllers in NoC", "abstract": "Multi-threaded programming is emerging very fast and memory-hungry programs need more resources so chip multiprocessors are widely used. Accessing L1 caches beside the cores are the fastest after registers but the size of private caches cannot increase because of design, cost and technology issues. Then split I-cache and D-cache are used with shared LLC (last level cache). For a unified shared LLC, bus interface is not scalable, and it seems that distributed shared LLC (DSLLC) is a better choice, so most of papers assume a distributed shared LLC beside each core in on-chip network. Many works assume that DSLLCs are placed in all cores; however we show that this design ignores the effect of traffic congestion in the on-chip network. In fact the problem is finding optimal placement of cores, DSLLCs and even memory controllers to minimize the expected latency based on traffic load in a mesh on-chip network with fixed number of cores and total cache capacity. We try to do some analytical modeling to derive the intended cost function and then optimize it for minimum mean delay. This work is supposed to be verified using some traffic patterns that are run on CSIM simulator.", "venue": "arXiv.org", "year": 2016, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2016-07-14", "journal": {"name": "ArXiv", "volume": "abs/1607.04298"}, "authors": [{"authorId": "2487483", "name": "D. Z. Tootaghaj"}, {"authorId": "35779995", "name": "F. Farhat"}], "citations": []}

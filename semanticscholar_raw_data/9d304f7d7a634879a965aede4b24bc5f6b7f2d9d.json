{"paperId": "9d304f7d7a634879a965aede4b24bc5f6b7f2d9d", "publicationVenue": null, "title": "BigDataBench: A Scalable and Unified Big Data and AI Benchmark Suite", "abstract": "Several fundamental changes in technology indicate domain-specific hardware and software co-design is the only path left. In this context, architecture, system, data management, and machine learning communities pay greater attention to innovative big data and AI algorithms, architecture, and systems. Unfortunately, complexity, diversity, frequently-changed workloads, and rapid evolution of big data and AI systems raise great challenges. First, the traditional benchmarking methodology that creates a new benchmark or proxy for every possible workload is not scalable, or even impossible for Big Data and AI benchmarking. Second, it is prohibitively expensive to tailor the architecture to characteristics of one or more application or even a domain of applications. We consider each big data and AI workload as a pipeline of one or more classes of units of computation performed on different initial or intermediate data inputs, each class of which we call a data motif. On the basis of our previous work that identifies eight data motifs taking up most of the run time of a wide variety of big data and AI workloads, we propose a scalable benchmarking methodology that uses the combination of one or more data motifs---to represent diversity of big data and AI workloads. Following this methodology, we present a unified big data and AI benchmark suite---BigDataBench 4.0, publicly available from~\\url{this http URL}. This unified benchmark suite sheds new light on domain-specific hardware and software co-design: tailoring the system and architecture to characteristics of the unified eight data motifs other than one or more application case by case. Also, for the first time, we comprehensively characterize the CPU pipeline efficiency using the benchmarks of seven workload types in BigDataBench 4.0.", "venue": "", "year": 2018, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2018-02-23", "journal": {"name": "arXiv: Distributed, Parallel, and Cluster Computing", "volume": ""}, "authors": [{"authorId": "46874006", "name": "Wanling Gao"}, {"authorId": "2062319", "name": "Jianfeng Zhan"}, {"authorId": "2152504122", "name": "Lei Wang"}, {"authorId": "34406813", "name": "Chunjie Luo"}, {"authorId": "29994319", "name": "Daoyi Zheng"}, {"authorId": "2023921094", "name": "Xu Wen"}, {"authorId": "1380311995", "name": "Rui Ren"}, {"authorId": "2113919016", "name": "Chen Zheng"}, {"authorId": "2111100269", "name": "Xiwen He"}, {"authorId": "2124247", "name": "Hainan Ye"}, {"authorId": "48176348", "name": "Haoning Tang"}, {"authorId": "1384468633", "name": "Zheng Cao"}, {"authorId": "2107944412", "name": "Shujie Zhang"}, {"authorId": "32054931", "name": "Jiahui Dai"}], "citations": [{"paperId": "0419ecbffde61adb01ad4d53895d1e475710d144", "title": "A Linear Combination-based Method to Construct Proxy Benchmarks for Big Data Workloads"}, {"paperId": "486854d2c90fae9e096a0c123350d675c8157226", "title": "TPCx-AI - An Industry Standard Benchmark for Artificial Intelligence and Machine Learning Systems"}, {"paperId": "054b419d2c22cf6d4bb420b51e2181a7f228f9f2", "title": "Does Big Data Require Complex Systems? A Performance Comparison Between Spark and Unicage Shell Scripts"}, {"paperId": "6fce773f7b5efcd3bb3f0852fcb3b8efe885d269", "title": "Splash-4: A Modern Benchmark Suite with Lock-Free Constructs"}, {"paperId": "d456a30f9d2f01d31cf81e41a1df56b9af4e35dc", "title": "Phronesis: Efficient Performance Modeling for High-dimensional Configuration Tuning"}, {"paperId": "c5a95ab744c336cbf0f82c1f8ca4fcbd9fa2db03", "title": "Impact of Map-Reduce framework on Hadoop and Spark MR Application Performance"}, {"paperId": "c86d6005f3fc3129d997199cab2660e48a0cab82", "title": "A Study on the Causes of Garbage Collection in Java for Big Data Workloads"}, {"paperId": "0dabd9986bb1a89a93419c95e42bbdc0d92617d9", "title": "TOPOSCH: Latency-Aware Scheduling Based on Critical Path Analysis on Shared YARN Clusters"}, {"paperId": "c0886957c05e5d1e61509bbadc52c0c67b66fc79", "title": "HPC AI500: The Methodology, Tools, Roofline Performance Models, and Metrics for Benchmarking HPC AI Systems"}, {"paperId": "453dc0bfce0b72cd70848d0ed4f3ac60683d906f", "title": "Analyzing Performance of Apache Spark MLlib with Multinode Clusters on Azure HDInsight: Spark-Perf Case Study"}, {"paperId": "eb2896246bdcd098838bc25e0def41d66ce550c9", "title": "AIBench Scenario: Scenario-Distilling AI Benchmarking"}, {"paperId": "498670bf17c93253ec23b40ac8f3ac6b8c58b49c", "title": "AIBench: Scenario-distilling AI Benchmarking"}, {"paperId": "64b58ecbf516c01e4d73bd74c92c7b3982aaab4f", "title": "Scenario-distilling AI Benchmarking"}, {"paperId": "e44b3799e7f06dffce95e16b68f558a3f2054d30", "title": "AIBench Training: Balanced Industry-Standard AI Training Benchmarking"}, {"paperId": "61d9307b4d0147d6c0f706c2ff93d29ef268a244", "title": "AIBench: An Industry Standard AI Benchmark Suite from Internet Services"}, {"paperId": "23853029700c9aa6f99002bb0b1ce6d88920d89f", "title": "Interference Analysis of Co-Located Container Workloads: A Perspective from Hardware Performance Counters"}, {"paperId": "750c09e27d1fa87996af0d1d5d5e3f1d62976343", "title": "AIBench: An Agile Domain-specific Benchmarking Methodology and an AI Benchmark Suite"}, {"paperId": "1478ea2d56566cc7c19c6f0358d04033c52e6da5", "title": "BenchCouncil's View on Benchmarking AI and Other Emerging Workloads"}, {"paperId": "58511640e60e9909d720d1df2670ea4c16899c39", "title": "Benchmarking for End-to-End QoS Sustainability in Cloud-Hosted Data Processing Pipelines"}, {"paperId": "4cc4a785997995cc03afd383407af6bc8ea588de", "title": "Benchmark Researches from the Perspective of Metrology"}, {"paperId": "6d8db61577a021981ccf58d0c5ced167674b389c", "title": "On-Device Machine Learning: An Algorithms and Learning Theory Perspective"}, {"paperId": "8559e2e8ade03a81aed6cec6646027a495a94797", "title": "SSD: Cache or Tier an Evaluation of SSD Cost and Efficiency using MapReduce"}, {"paperId": "91d9c85fc7b2f72079aa8cfdb5316825c93f37e3", "title": "Machine learning and big scientific data"}, {"paperId": "2b71e4053be465dcd68064a3a45dedc9fa368726", "title": "AIBench: An Industry Standard Internet Service AI Benchmark Suite"}, {"paperId": "4068c3303340ed9796463a2064a74f2dc6ea5795", "title": "Big data stream analysis: a systematic literature review"}, {"paperId": "661c7d2a74cda699458e32fb8b45778b32f834b8", "title": "DCMIX: Generating Mixed Workloads for the Cloud Data Center"}, {"paperId": "dd4e58f2300c2cf8040c8ae09cb363922401d324", "title": "AIBench: Towards Scalable and Comprehensive Datacenter AI Benchmarking"}, {"paperId": "91a74b9ff7425c427c17f0f670dd7fc0f1bef069", "title": "Data Motif-based Proxy Benchmarks for Big Data and AI Workloads"}, {"paperId": "fcb74a27ae8bf54ecce9aed765fa009103309254", "title": "Data motifs: a lens towards fully understanding big data and AI workloads"}, {"paperId": "fec60b9224e302d79cdf5c150edb15a841c4d6f1", "title": "BOPS, Not FLOPS! A New Metric, Measuring Tool, and Roofline Performance Model For Datacenter Computing"}, {"paperId": "f4d2abdba8bca9bf6ce40d93cc72f73c107b56ae", "title": "BOPS, Not FLOPS! A New Metric and Roofline Performance Model For Datacenter Computing"}, {"paperId": "de844933393619dd60f20dea3f097fe4f0beb81f", "title": "A Survey of Big Data, High Performance Computing, and Machine Learning Benchmarks"}]}

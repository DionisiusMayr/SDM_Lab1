{"paperId": "8c03332288c663ac80162dcccdd6ec4985ed44e2", "publicationVenue": {"id": "7c9d091e-015e-4e5d-a11f-9bc369fcf414", "name": "IEEE Transactions on Parallel and Distributed Systems", "type": "journal", "alternate_names": ["IEEE Trans Parallel Distrib Syst"], "issn": "1045-9219", "url": "http://www.computer.org/tpds", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=71"]}, "title": "Dependency-Aware Network Adaptive Scheduling of Data-Intensive Parallel Jobs", "abstract": "Datacenter clusters often run data-intensive jobs in parallel for improving resource utilization and cost efficiency. The performance of parallel jobs is often constrained by the cluster's hard-to-scale network bisection bandwidth. Various solutions have been proposed to address the issue, however, most of them do not consider inter-job data dependencies and schedule jobs independently from one another. In this work, we find that aggregating and co-locating the data and tasks of dependent jobs offer an extra opportunity for data locality improvement that can help to greatly enhance the performance of jobs. We propose and design Dawn, a dependency-aware network-adaptive scheduler that includes an online plan and an adaptive task scheduler. The online plan, taking job dependencies into consideration, determines where (i.e., preferred racks) to place tasks in order to proactively aggregate dependent data. The task scheduler, based on the output of online plan and dynamic network status, adaptively schedules tasks to co-locate with the dependent data in order to take advantage of data locality. We implement Dawn on Apache Yarn and evaluate it on physical and virtual clusters using various machine learning and query workloads. Results show that Dawn effectively improves cluster throughput by up to 73 and 38 percent compared to Fair Scheduler and ShuffleWatcher, respectively. Dawn not only significantly enhances the performance of jobs with dependency, but also works well for jobs without dependency.", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-03-01", "journal": {"name": "IEEE Transactions on Parallel and Distributed Systems", "pages": "515-529", "volume": "30"}, "authors": [{"authorId": "1891284", "name": "Shaoqi Wang"}, {"authorId": "2154941244", "name": "Wei Chen"}, {"authorId": "46224002", "name": "Xiaobo Zhou"}, {"authorId": "2108910966", "name": "Liqiang Zhang"}, {"authorId": "2125064232", "name": "Yin Wang"}], "citations": [{"paperId": "fd8fe50fd4e2709c4c6a83f1dde1d4c4534c83a1", "title": "Cost-Effective Scheduling for Dependent Tasks With Tight Deadline Constraints in Mobile Edge Computing"}, {"paperId": "e71da9f57d1ddd4304743e4e889f08390b148d17", "title": "New YARN sharing GPU based on graphics memory granularity scheduling"}, {"paperId": "eaf023efc0e165336e77627c0d085e2cf48bf618", "title": "A Network Load Perception Based Task Scheduler for Parallel Distributed Data Processing Systems"}, {"paperId": "eecc039a75d9b08e86b77479b51d419d6555d7df", "title": "GCSS: a global collaborative scheduling strategy for wide-area high-performance computing"}, {"paperId": "c170deb79a0df6579f1497234adcf901d993db0f", "title": "Overlapping Communication With Computation in Parameter Server for Scalable DL Training"}, {"paperId": "840f3d9064c631a0e37e94dc55a04b3bb0589be4", "title": "Performance Improvement of DAG-Aware Task Scheduling Algorithms with Efficient Cache Management in Spark"}, {"paperId": null, "title": "2020 Index IEEE Transactions on Parallel and Distributed Systems Vol. 31"}, {"paperId": "21bd6c6efd91cfa9773b1b9134d5b9afea757cd9", "title": "DAG-Aware Joint Task Scheduling and Cache Management in Spark Clusters"}, {"paperId": "9dbe1f92fb734298c9c700b36538b0317ceceda3", "title": "Resource management for moldable parallel tasks supporting slot time in the Cloud"}, {"paperId": "1fde8390b8796a9e237eb01facb6e56d365b3262", "title": "Scalable Distributed DL Training: Batching Communication and Computation"}, {"paperId": "fdf67c4029e48ffe601e7764226f59b0346cd83e", "title": "Addressing Skewness in Iterative ML Jobs with Parameter Partition"}, {"paperId": "2e39c07b6f22fda66ff79ba82def848ff2a93765", "title": "Aggressive Synchronization with Partial Processing for Iterative ML Jobs on Clusters"}]}

{"paperId": "29b7849eca377f115e67b80e8fa2840f26e0e842", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "An Empirical Evaluation of Columnar Storage Formats", "abstract": "Columnar storage is a core component of a modern data analytics system. Although many database management systems (DBMSs) have proprietary storage formats, most provide extensive support to open-source storage formats such as Parquet and ORC to facilitate cross-platform data sharing. But these formats were developed over a decade ago, in the early 2010s, for the Hadoop ecosystem. Since then, both the hardware and workload landscapes have changed.\n In this paper, we revisit the most widely adopted open-source columnar storage formats (Parquet and ORC) with a deep dive into their internals. We designed a benchmark to stress-test the formats' performance and space efficiency under different workload configurations. From our comprehensive evaluation of Parquet and ORC, we identify design decisions advantageous with modern hardware and real-world data distributions. These include using dictionary encoding by default, favoring decoding speed over compression ratio for integer encoding algorithms, making block compression optional, and embedding finer-grained auxiliary data structures. We also point out the inefficiencies in the format designs when handling common machine learning workloads and using GPUs for decoding. Our analysis identified important considerations that may guide future formats to better fit modern technology trends.", "venue": "Proceedings of the VLDB Endowment", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-04-11", "journal": {"name": "ArXiv", "volume": "abs/2304.05028"}, "authors": [{"authorId": "2947698", "name": "Xinyu Zeng"}, {"authorId": "2213908419", "name": "Yulong Hui"}, {"authorId": "22298896", "name": "Jiahong Shen"}, {"authorId": "1774210", "name": "Andrew Pavlo"}, {"authorId": "49018948", "name": "Wes McKinney"}, {"authorId": "2043439", "name": "Huanchen Zhang"}], "citations": [{"paperId": "b37005656748a114dd1083c71a7d4d90f9e65aea", "title": "Performance of Null Handling in Array Databases"}, {"paperId": "35e34ca58482b0307455b4539bf58bd6af5cc1bf", "title": "A Deep Dive into Common Open Formats for Analytical DBMSs"}, {"paperId": "849696f5195be4f5f63f1b7ef8bbb0f9f19ce8b4", "title": "LeCo: Lightweight Compression via Learning Serial Correlations"}]}

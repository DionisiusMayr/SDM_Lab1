{"paperId": "aa7f9c057804328d863244bf9c43d75cb00f5780", "publicationVenue": {"id": "289bfdda-eab3-4c9a-97be-ef1e0f9ddfc0", "name": "International Symposium on Software Testing and Analysis", "type": "conference", "alternate_names": ["ISSTA", "Int Symp Softw Test Anal"], "url": "https://dl.acm.org/conference/issta"}, "title": "Simple techniques work surprisingly well for neural network test prioritization and active learning (replicability study)", "abstract": "Test Input Prioritizers (TIP) for Deep Neural Networks (DNN) are an important technique to handle the typically very large test datasets efficiently, saving computation and labelling costs. This is particularly true for large scale, deployed systems, where inputs observed in production are recorded to serve as potential test or training data for next versions of the system. Feng et. al. propose DeepGini, a very fast and simple TIP and show that it outperforms more elaborate techniques such as neuron- and surprise coverage. In a large-scale study (4 case studies, 8 test datasets, 32\u2019200 trained models) we verify their findings. However, we also find that other comparable or even simpler baselines from the field of uncertainty quantification, such as the predicted softmax likelihood or the entropy of the predicted softmax likelihoods perform equally well as DeepGini", "venue": "International Symposium on Software Testing and Analysis", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2022-05-02", "journal": {"name": "Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis"}, "authors": [{"authorId": "2112681662", "name": "Michael Weiss"}, {"authorId": "1769017", "name": "P. Tonella"}], "citations": [{"paperId": "95cc2969f83a54295cf30dbe17b768c3cda6ee2b", "title": "Test Input Prioritization for Machine Learning Classifiers"}, {"paperId": "6b4aba6e6d4f86d6397198c61c70a5bc2f4f29c5", "title": "Dynamic Test Case Prioritization in Industrial Test Result Datasets"}, {"paperId": "0e4468ec45f98ed60b864dae272e018e30994a17", "title": "Inferring Data Preconditions from Deep Learning Models for Trustworthy Prediction in Deployment"}, {"paperId": "2c4d2bf233d6cec0558be2e0f0f81d965c26821d", "title": "Robust Test Selection for Deep Neural Networks"}, {"paperId": "5770476d5a6fd520cafa7bed48f19c33a6655254", "title": "How Do Deep Learning Faults Affect AI-Enabled Cyber-Physical Systems in Operation? A Preliminary Study Based on DeepCrime Mutation Operators"}, {"paperId": "8d3c27beb51f90b29ad734c383825cb64a02760c", "title": "Hazards in Deep Learning Testing: Prevalence, Impact and Recommendations"}, {"paperId": "aa1679987391908451d3c341c0a4fe0fb451b7d2", "title": "On-the-fly Improving Performance of Deep Code Models via Input Denoising"}, {"paperId": "e5fbf4307f265d65ec2a50b63359754aa93a5593", "title": "VisAlign: Dataset for Measuring the Degree of Alignment between AI and Humans in Visual Perception"}, {"paperId": "77b061b4ed1c0292741b20b213246facb0af08b5", "title": "Evaluating the Robustness of Test Selection Methods for Deep Neural Networks"}, {"paperId": "6690c14ed6a4af0d6ae16be7fce76793665315f2", "title": "In Defense of Simple Techniques for Neural Network Test Case Selection"}, {"paperId": "b55fa6a62d23186fce438ef65eae014336c61e3d", "title": "GraphPrior: Mutation-based Test Input Prioritization for Graph Neural Networks"}, {"paperId": "7abd72907caa217406da64bd3fad652f512f6707", "title": "Difficulty and Severity-Oriented Metrics for Test Prioritization in Deep Learning Systems"}, {"paperId": "bca031d72dc27e3d864d8359acd4a24752a8088f", "title": "Active Code Learning: Benchmarking Sample-Efficient Training of Code Models"}, {"paperId": "8159128c29c84aa9653fc1ca3085a4496446a4b4", "title": "Adopting Two Supervisors for Efficient Use of Large-Scale Remote Deep Neural Networks"}, {"paperId": "9c183ce5106801a048a9dc38dac19982eb8ad137", "title": "DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks"}, {"paperId": "5e6d201698da2808893131f34e4fb62caaf43f2f", "title": "Neuroevolutionary algorithms driven by neuron coverage metrics for semi-supervised classification"}, {"paperId": "f440301de23bf62c11bd3f4865e4165bf59e85f4", "title": "FedRC: Tackling Diverse Distribution Shifts Challenge in Federated Learning by Robust Clustering"}, {"paperId": "640b2bfdcf5083e25a9c8b305338bcc0a51f039c", "title": "ActGraph: prioritization of test cases based on deep neural network activation graph"}, {"paperId": "8267e6c9bf8d10013eae45916fc2861a9a09fffa", "title": "To Softmax, or not to Softmax: that is the question when applying Active Learning for Transformer Models"}, {"paperId": "03a8cd7b6aeda45547063cd3c35b1dd85827a003", "title": "CheapET-3: cost-efficient use of remote DNN models"}, {"paperId": "0859ab692f32f180f3ee6fc5bc6c1ce364f04d5f", "title": "Generating and detecting true ambiguity: a forgotten danger in DNN supervision testing"}, {"paperId": "b9a604e459a3ae46442c0a23a68c4f0772959988", "title": "Guiding the retraining of convolutional neural networks against adversarial inputs"}, {"paperId": "ff5ba3e889d934cd1168bf660aa6128416b6a939", "title": "Hierarchical Distribution-Aware Testing of Deep Learning"}, {"paperId": "3f31a913aee31997f347fe387e4978d68a0a462a", "title": "Mind the Gap! A Study on the Transferability of Virtual Versus Physical-World Testing of Autonomous Driving Systems"}, {"paperId": "f63ff3b9b2f5dee42cae91a86b4e414f531f7cec", "title": "FedConceptEM: Robust Federated Learning Under Diverse Distribution Shifts"}, {"paperId": "a74a5665b39267e640efa89ffea517ae407f085b", "title": "A Forgotten Danger in DNN Supervision Testing: Generating and Detecting True Ambiguity"}]}

{"paperId": "9056b3c83b9036db5c43b7e2603efa8c62907a07", "publicationVenue": null, "title": "Trends in Explanations: Understanding and Debugging Data-driven Systems", "abstract": "Humans reason about the world around them by seeking to understand why and how something occurs. The same principle extends to the technology that so many of human activities increasingly rely on. Issues of trust, transparency, and understandability are critical in promoting adoption and proper use of systems. However, with increasing complexity of the systems and technologies we use, it is hard or even impossible to comprehend their function and behavior, and justify surprising observations through manual investigation alone. Explanation support can ease humans\u2019 interactions with technology: explanations can help users understand a system\u2019s function, justify system results, and increase their trust in automated decisions. Our goal in this article is to provide an overview of existing work in explanation support for data-driven processes, through a lens that identifies commonalities across varied problem settings and solutions. We suggest a classification of explainability requirements across three dimensions: the target of the explanation (\u201cWhat\u201d), the audience of the Boris Glavic, Alexandra Meliou and Sudeepa Roy (2021), \u201cTrends in Explanations: Understanding and Debugging Data-driven Systems\u201d, Foundations and Trends\u00ae in Databases: Vol. 11, No. 3, pp 226\u2013318. DOI: 10.1561/1900000074. The version of record is available at: http://dx.doi.org/10.1561/1900000074", "venue": "Found. Trends Databases", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": null, "journal": {"name": "Found. Trends Databases", "pages": "226-318", "volume": "11"}, "authors": [{"authorId": "1798930", "name": "Boris Glavic"}, {"authorId": "2283085", "name": "A. Meliou"}, {"authorId": "31938009", "name": "Sudeepa Roy"}], "citations": [{"paperId": "c949d9c1b36c2aae09d3f65d86059d077f7f5c76", "title": "Explaining cube measures through Intentional Analytics"}, {"paperId": "9abffa8435a568b62546549fd6ada69d7d4936ca", "title": "Discovering Dichotomies for Problems in Database Theory"}, {"paperId": "489f76879f3795c029d28639580416bba43ff424", "title": "A Unified Approach for Resilience and Causal Responsibility with Integer Linear Programming (ILP) and LP Relaxations"}, {"paperId": "30d74ceaab5d5e0451c7ff9057792cb6464b8b57", "title": "Toward Interpretable and Actionable Data Analysis with Explanations and Causality"}, {"paperId": "0976bd8451b2d0281269b57f20d71734410bdc1d", "title": "XInsight: eXplainable Data Analysis Through The Lens of Causality"}, {"paperId": "b20c87e2925a81f57d9c913423e9e74c14de5341", "title": "A Survey on Trustworthy Recommender Systems"}, {"paperId": "272cf450ba9e83e7d534dff8726e8fd1cfd76be1", "title": "Human-GDPR Interaction: Practical Experiences of Accessing Personal Data"}, {"paperId": "abb97f7777d73ba0979a85857f39e09c5c4aa2a1", "title": "A dynamical spatial-temporal graph neural network for traffic demand prediction"}, {"paperId": "168a60545467b86eb2fa012afd01137c97e77275", "title": "Reptile: Aggregation-level Explanations for Hierarchical Data"}, {"paperId": "8a825654f0a7f33c8e3eac4cab0118623835d723", "title": "Towards an Objective Metric for Data Value Through Relevance"}, {"paperId": "bbddad7a89987e98877c054155a5beda715113ac", "title": "The Whys and Wherefores of Cubes"}, {"paperId": "76424e827058716a2705e13c5a1a3a33699157fe", "title": "Using Regression to Explain Cube Measures"}, {"paperId": "3b694dfa9df03823db0d765847a16f7cd21a8795", "title": "Data Errors: Symptoms, Causes and Origins"}, {"paperId": "87a741701c302bfc2120b3789e68ecefc06523db", "title": "The Right Tool for the Job: Data-Centric Workflows in Vizier"}]}

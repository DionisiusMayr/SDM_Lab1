{"paperId": "b3d8c5479d23c4492903cc6f02193bd43846d20b", "publicationVenue": null, "title": "DistME: A Fast and Elastic Distributed Matrix Computation Engine using GPUs", "abstract": "Matrix computation, in particular, matrix multiplication is time-consuming, but essentially and widely used in a large number of applications in science and industry. The existing distributed matrix multiplication methods only focus on either low communication cost (i.e., high performance) with the risk of out of memory or large-scale processing with high communication overhead. We propose a distributed elastic matrix multiplication method called CuboidMM that achieves both high performance and large-scale processing. We also propose a GPU acceleration method that can be combined with CuboidMM. CuboidMM partitions matrices into cuboids for optimizing the network communication cost with considering memory usage per task, and the GPU acceleration method partitions a cuboid into subcuboids for optimizing the PCI-E communication cost with considering GPU memory usage. We implement a fast and elastic matrix computation engine called DistME by integrating CuboidMM with GPU acceleration on top of Apache Spark. Through extensive experiments, we have demonstrated that CuboidMM and DistME significantly outperform the state-of-the-art methods and systems, respectively, in terms of both performance and data size.", "venue": "SIGMOD Conference", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2019-06-25", "journal": {"name": "Proceedings of the 2019 International Conference on Management of Data"}, "authors": [{"authorId": "9719871", "name": "Donghyoung Han"}, {"authorId": "9729092", "name": "Yoon-Min Nam"}, {"authorId": "2141631225", "name": "Jihye Lee"}, {"authorId": "144726469", "name": "Kyongseok Park"}, {"authorId": "2154858210", "name": "Hyunwoo Kim"}, {"authorId": "2116504190", "name": "Min-Soo Kim"}], "citations": [{"paperId": "9067b8cd182af53592be3a57d9e34d4af07b982a", "title": "Fast matrix multiplication via compiler\u2010only layered data reorganization and intrinsic lowering"}, {"paperId": "9ffa0d2a4042bdc8e991999c8c1df1348eb60ca5", "title": "Redundancy Elimination in Distributed Matrix Computation"}, {"paperId": "0c3c71075a0d932ef20ed76f3eca6e88872c828c", "title": "FuseME: Distributed Matrix Computation Engine based on Cuboid-based Fused Operator and Plan Generation"}, {"paperId": "94480f8108f84193018353fce2fb58e016cfc7e2", "title": "Hybrid Evaluation for Distributed Iterative Matrix Computation"}, {"paperId": "a564c147612bbd05661bd5885217f81d90c07e37", "title": "Distributed Numerical and Machine Learning Computations via Two-Phase Execution of Aggregated Join Trees"}, {"paperId": "79fe5f21a3efc0c21f4094a51c76862599f598aa", "title": "Tensor Relational Algebra for Distributed Machine Learning System Design"}, {"paperId": "2d70dfb2332c2de591572d7e37b198e7da26c797", "title": "Tensor Relational Algebra for Machine Learning System Design"}, {"paperId": "c245f4449d323640a53338af0d35cd3504b7e91c", "title": "(When) Do Multiple Passes Save Energy?"}]}

{"paperId": "7c6ed0ff29cb7298082527c4cba6f9869097a05b", "publicationVenue": {"id": "7c9d091e-015e-4e5d-a11f-9bc369fcf414", "name": "IEEE Transactions on Parallel and Distributed Systems", "type": "journal", "alternate_names": ["IEEE Trans Parallel Distrib Syst"], "issn": "1045-9219", "url": "http://www.computer.org/tpds", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=71"]}, "title": "Exploring Query Processing on CPU-GPU Integrated Edge Device", "abstract": "Huge amounts of data have been generated on edge devices every day, which requires efficient data analytics and management. However, due to the limited computing capacity of these edge devices, query processing at the edge faces tremendous pressure. Fortunately, in recent years, hardware vendors have integrated heterogeneous coprocessors, such as GPUs, into the edge device, which can provide much more computing power. Furthermore, the CPU-GPU integrated edge device has shown significant benefits in a variety of situations. Therefore, the exploration of query processing on such CPU-GPU integrated edge devices becomes an urgent need. In this paper, we develop a fine-grained query processing engine, called FineQuery, which can perform efficient query processing on CPU-GPU integrated edge devices. Particularly, FineQuery can take advantage of both architectural features of edge devices and query characteristics by performing fine-grained workload scheduling between the CPU and the GPU. Experiments show that on TPC-H workloads, FineQuery reduces 42.81% latency and improves 2.39\u00d7 bandwidth utilization on average compared to the implementation of using only GPU or CPU. Furthermore, query processing at the edge can bring significant performance-per-cost benefits and energy efficiency. On average, FineQuery at the edge brings a 21\u00d7 performance-per-cost ratio and 4\u00d7 energy efficiency compared with processing the data on a discrete GPU platform.", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal": {"name": "IEEE Transactions on Parallel and Distributed Systems", "pages": "1-1", "volume": "PP"}, "authors": [{"authorId": "2167513185", "name": "Jiesong Liu"}, {"authorId": "1884418505", "name": "Feng Zhang"}, {"authorId": "2135722022", "name": "Hourun Li"}, {"authorId": "2111226787", "name": "Dalin Wang"}, {"authorId": "47718901", "name": "Weitao Wan"}, {"authorId": "2166932090", "name": "Xiaokun Fang"}, {"authorId": "2467444", "name": "Jidong Zhai"}, {"authorId": "2152944669", "name": "Xiaoyong Du"}], "citations": [{"paperId": "97c842066203f838de9bdb8358ced9cdc81d4aa3", "title": "General-purpose data stream processing on heterogeneous architectures with WindFlow"}, {"paperId": "b86c75e2a1edabe452bd73b3afc29cec7f43e0d7", "title": "Accelerating network analytics with an on-NIC streaming engine"}, {"paperId": "13648e055c16b76822a8e9b53b6ee88ba94ab81e", "title": "SmartNIC-Accelerated Stream Processing Analytics"}, {"paperId": "97dcb6e6f57d18f2b0138672b0c0fcabd0678991", "title": "Arithmetic Study about Efficiency in Network Topologies for Data Centers"}, {"paperId": "314017988c6a7f274da65f7ce052af5e3c7342c0", "title": "HBMax: Optimizing Memory Efficiency for Parallel Influence Maximization on Multicore Architectures"}, {"paperId": "1d1d7d6bba6074db3820ed7a8692eddb43055097", "title": "Performance Analysis of Distributed GPU-Accelerated Task-Based Workflows"}, {"paperId": "8fb94151f043084f084c0a41e58eee124ae7b6d1", "title": "Evolutionary Game Theory-Based Optimal Scheduling Strategy for Heterogeneous Computing"}, {"paperId": "b037687e1a0b8f2a9b248ea66c8d96de98232696", "title": "Arithmetic Study about Ef\ufb01ciency in Network Topologies for Data Centers"}]}

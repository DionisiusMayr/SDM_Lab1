{"paperId": "7636c5734792a72583a66b727a4b64a8104d549e", "publicationVenue": {"id": "b7aa40ac-729b-49d6-9064-4d1a9480e9a9", "name": "International Symposium on High-Performance Computer Architecture", "type": "conference", "alternate_names": ["HPCA", "High Perform Comput Appl", "Int Symp High-performance Comput Archit", "High Performance Computing and Applications"], "url": "https://web.archive.org/web/*/http://www.hpcaconf.org/"}, "title": "Know Your Enemy To Save Cloud Energy: Energy-Performance Characterization of Machine Learning Serving", "abstract": "The proportion of machine learning (ML) inference in modern cloud workloads is rapidly increasing, and graphic processing units (GPUs) are the most preferred computational accelerators for it. The massively parallel computing capability of GPUs is well-suited to the inference workloads but consumes more power than conventional CPUs. Therefore, GPU servers contribute significantly to the total power consumption of a data center. However, despite their heavy power consumption, GPU power management in cloud-scale has not yet been actively researched. In this paper, we reveal three findings about energy efficiency of ML inference clusters in the cloud. \u2776 GPUs of different architectures have comparative advantages in energy efficiency to each other for a set of ML models. \u2777 The energy efficiency of a GPU set may significantly vary depending on the number of active GPUs and their clock frequencies even when producing the same level of throughput. \u2778 The service level objective(SLO)-blind dynamic voltage and frequency scaling (DVFS) driver of commercial GPUs maintain an immoderately high clock frequency. Based on these implications, we propose a hierarchical GPU resource management approach for cloud-scale inference services. The proposed approach consists of energy-aware cluster allocation, intra-cluster node scaling, intra-node GPU scaling and GPU clock scaling schemes considering the inference service architecture hierarchy. We evaluated our approach with its prototype implementation and cloud-scale simulation. The evaluation with real-world traces showed that the proposed schemes can save up to 28.3% of the cloud-scale energy consumption when serving five ML models with 105 servers having three different kinds of GPUs.", "venue": "International Symposium on High-Performance Computer Architecture", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-02-01", "journal": {"name": "2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)", "pages": "842-854"}, "authors": [{"authorId": "2153201762", "name": "Junyeol Yu"}, {"authorId": "2110099989", "name": "Jongseok Kim"}, {"authorId": "1920052", "name": "Euiseong Seo"}], "citations": [{"paperId": "0a4c04e95d460a3680ba0bc79e69d797126749ca", "title": "Part-time Power Measurements: nvidia-smi's Lack of Attention"}, {"paperId": "ebc4fcf5a402e0c3cae73e108e1efd8cd5145fdf", "title": "POLCA: Power Oversubscription in LLM Cloud Providers"}]}

{"paperId": "610d5740b6c335ffbe23c931da8ee8cca759e3d3", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Chimp: Efficient Lossless Floating Point Compression for Time Series Databases", "abstract": "\n Applications in diverse domains such as astronomy, economics and industrial monitoring, increasingly press the need for analyzing massive collections of\n time series\n data. The sheer size of the latter hinders our ability to efficiently store them and also yields significant storage costs. Applying general purpose compression algorithms would effectively reduce the size of the data, at the expense of introducing significant computational overhead. Time Series Management Systems that have emerged to address the challenge of handling this overwhelming amount of information, cannot suffer the ingestion rate restrictions that such compression algorithms would cause. Data points are usually encoded using faster, streaming compression approaches. However, the techniques that contemporary systems use do not fully utilize the compression potential of time series data, with implications in both storage requirements and access times. In this work, we propose a novel streaming compression algorithm, suitable for floating point time series data. We empirically establish properties exhibited by a diverse set of time series and harness these features in our proposed encodings. Our experimental evaluation demonstrates that our approach\n readily outperforms\n competing techniques, attaining compression ratios that are competitive with\n slower\n general purpose algorithms, and on average around 50% of the space required by state-of-the-art streaming approaches. Moreover, our algorithm outperforms all earlier techniques with regards to both\n compression and access time\n , offering a significantly\n improved trade-off\n between space and speed. The aforementioned benefits of our approach - in terms of\n all\n space requirements, compression time and read access - significantly improve the efficiency in which we can store and analyze time series data.\n", "venue": "Proceedings of the VLDB Endowment", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-07-01", "journal": {"name": "Proc. VLDB Endow.", "pages": "3058-3070", "volume": "15"}, "authors": [{"authorId": "144080475", "name": "Panagiotis Liakos"}, {"authorId": "2675684", "name": "Katia Papakonstantinopoulou"}, {"authorId": "1751420", "name": "Y. Kotidis"}], "citations": [{"paperId": "6ca65bd80b531d5ec2db7e7540d0a6e65929107a", "title": "Time series data encoding in Apache IoTDB: comparative analysis and recommendation"}, {"paperId": "5dba3b9244fae93e840efb66d2568039d7a7fc20", "title": "AFC: An adaptive lossless floating-point compression algorithm in time series database"}, {"paperId": "5d837ca27a7bc0882dcd6e6a4dd5d16e0d1f98c3", "title": "Homomorphic Compression: Making Text Processing on Compression Unlimited"}, {"paperId": "80426d73fa4a7d9e2c47477c1fc8430674afa28e", "title": "ALP: Adaptive Lossless floating-Point Compression"}, {"paperId": "68fdc992cf1b9e1b33110380a3f93e32027abd47", "title": "Khronos: A Real-Time Indexing Framework for Time Series Databases on Large-Scale Performance Monitoring Systems"}, {"paperId": "4cc4a9c36f5be75ad6b72c73f19e84ee3a76c8a7", "title": "Adaptive Encoding Strategies for Erasing-Based Lossless Floating-Point Compression"}, {"paperId": "c562c003bc0cf6928141e1f83156a48e3ee1a53d", "title": "DuckPGQ: Bringing SQL/PGQ to DuckDB"}, {"paperId": "f0c29d08360328b21f1a50ec71b3d51452d2e38e", "title": "Erasing-based lossless compression method for streaming floating-point time series"}, {"paperId": "742b584c6a15daff95198b56dafd3eeb75f33722", "title": "BtrBlocks: Efficient Columnar Compression for Data Lakes"}, {"paperId": "9ede4abf03af7693af397a5e0451f0b373760ed2", "title": "AWARE: Workload-aware, Redundancy-exploiting Linear Algebra"}, {"paperId": "29b7849eca377f115e67b80e8fa2840f26e0e842", "title": "An Empirical Evaluation of Columnar Storage Formats"}, {"paperId": "081ddd991440c51f614eb366581f40a3d366bc67", "title": "Stream Aggregation with Compressed Sliding Windows"}, {"paperId": "32612ead0f13b5042a1362be5a60ff2621326d35", "title": "Sim-Piece: Highly Accurate Piecewise Linear Approximation through Similar Segment Merging"}, {"paperId": "0b2f0506803af99751f28a0ab0a3a07bb8008b9f", "title": "Elf: Erasing-based Lossless Floating-Point Compression"}, {"paperId": "b77a705565304067d3cd1db53a7016566d4f45c3", "title": "ILX: Intelligent \"Location+X\" Data Systems (Vision Paper)"}, {"paperId": "7fce26fbf5967fb3935159273b7c2f1b90af4fe3", "title": "Sim-Piece+: Efficient Time Series Data Compression"}, {"paperId": "eccc230feb695ffdab0a86bd7bae98793cf5c800", "title": "CHimp: Efficient Lossless Compression of Floating Point Time Series Data"}, {"paperId": "1dc181d7c001a364f8b94781867d3d288239cc73", "title": "Sim-Piece against Lossless Compression Techniques"}]}

{"paperId": "6e170961dd7848b2571bdae23b8c5a9fe910b0c7", "publicationVenue": {"id": "c56116d3-225c-47c9-a4d9-f935e32f846c", "name": "IEEE Vehicular Technology Conference", "type": "conference", "alternate_names": ["IEEE Veh Technol Conf", "Veh Technol Conf", "VTC", "Vehicular Technology Conference"], "url": "http://vtsociety.org/"}, "title": "Federated Deep Reinforcement Learning-Based Task Allocation in Vehicular Fog Computing", "abstract": "The advancement of Internet of Vehicles has brought out various vehicular applications, and some of the applications are computation-intensive or delay-sensitive. Vehicular fog computing (VFC) can provide low-latency computing service, where vehicles can share their idle computing resource among each other. However, due to the high dynamic vehicular environment, both the vehicle-to-vehicle (V2V) communication link and onboard idle computing resource are time-variant. How to ensure the efficiency of V2V computation offloading under such environment is one main challenge. In this work, we design a multi-task offloading model that considers the dynamic of V2V communication link and the computing resource allocation in vehicles. In order to make the policy of task offloading adapt to the dynamic environment, we propose a deep reinforcement learning (DRL)-based V2V computation offloading algorithm. Moreover, the experiences of computation offloading in a single vehicle is generally limited, and the training process consumes much energy and time. To reduce the workload of model training in vehicles and protect the privacy of vehicles in terms of computation offloading, we further propose a federated DRL algorithm based on double deep Q-network (DDQN), where the DDQN model is trained cooperatively in multiple vehicles. The numerical simulation results validate the convergence of the proposed federated DDQN algorithm, and reveal that the proposed algorithm is more efficient in computation offloading compared with other baseline algorithms.", "venue": "IEEE Vehicular Technology Conference", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-06-01", "journal": {"name": "2022 IEEE 95th Vehicular Technology Conference: (VTC2022-Spring)", "pages": "1-6"}, "authors": [{"authorId": "1753655526", "name": "Jinming Shi"}, {"authorId": "1515709515", "name": "Jun Du"}, {"authorId": "2152765829", "name": "Jian Wang"}, {"authorId": "150167381", "name": "Jian Yuan"}], "citations": [{"paperId": "2cf8a86a702d9f6afe58f79c3d3477de61cf432f", "title": "A Game-Based Computing Resource Allocation Scheme of Edge Server in Vehicular Edge Computing Networks Considering Diverse Task Offloading Modes"}, {"paperId": "627e819a314367c3dd4876ede9bbc86f7b613d88", "title": "Fast Adaptive Task Offloading and Resource Allocation via Multiagent Reinforcement Learning in Heterogeneous Vehicular Fog Computing"}, {"paperId": "90c494fa3803971cfa5b1ef6c46847764665394c", "title": "Federated Deep Reinforcement Learning Based Task Offloading with Power Control in Vehicular Edge Computing"}, {"paperId": "aaab62dd1b7adf66288f9d72c81a805c63497e1c", "title": "Task Scheduling Mechanisms for Fog Computing: A Systematic Survey"}]}

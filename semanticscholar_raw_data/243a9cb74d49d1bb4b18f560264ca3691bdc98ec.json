{"paperId": "243a9cb74d49d1bb4b18f560264ca3691bdc98ec", "publicationVenue": {"id": "d5b215f3-f737-45b2-875b-df309ce14c43", "name": "Scientific Programming", "type": "journal", "alternate_names": ["Sci Program"], "issn": "1058-9244", "url": "https://www.hindawi.com/journals/sp/", "alternate_urls": ["https://www.iospress.nl/html/10589244.php", "https://www.wiley.com/legacy/compbooks/compjournals/sciprog.html", "http://content.iospress.com/journals/scientific-programming"]}, "title": "Improving I/O Efficiency in Hadoop-Based Massive Data Analysis Programs", "abstract": "Apache Hadoop has been a popular parallel processing tool in the era of big data. While practitioners have rewritten many conventional analysis algorithms to make them customized to Hadoop, the issue of inefficient I/O in Hadoop-based programs has been repeatedly reported in the literature. In this article, we address the problem of the I/O inefficiency in Hadoop-based massive data analysis by introducing our efficient modification of Hadoop. We first incorporate a columnar data layout into the conventional Hadoop framework, without any modification of the Hadoop internals. We also provide Hadoop with indexing capability to save a huge amount of I/O while processing not only selection predicates but also star-join queries that are often used in many analysis tasks.", "venue": "Scientific Programming", "year": 2018, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2018-12-02", "journal": {"name": "Sci. Program.", "pages": "2682085:1-2682085:9", "volume": "2018"}, "authors": [{"authorId": "2145186317", "name": "Kyong-Ha Lee"}, {"authorId": "3075157", "name": "Woo-Lam Kang"}, {"authorId": "33112185", "name": "Young-Kyoon Suh"}], "citations": [{"paperId": "469a68a2daa6c05227e69481709a165be4f41808", "title": "Bucket MapReduce: Relieving the Disk I/O Intensity of Data-Intensive Applications in MapReduce Frameworks"}]}

{"paperId": "04e9416c7496e8c2d72df7b7a03bf37080adb974", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection", "abstract": "We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We systematize literature on automated detection of misinformation across a corpus of 270 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. Our paper corpus includes published work in security, natural language processing, and computational social science. Across these disparate disciplines, we identify common errors in dataset and method design. In general, detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. Data and code availability is poor. We demonstrate the limitations of current detection methods in a series of three replication studies. Based on the results of these analyses and our literature survey, we offer recommendations for evaluating applications of machine learning to trust and safety problems in general. Our aim is for future work to avoid the pitfalls that we identify.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-08-23", "journal": {"name": "ArXiv", "volume": "abs/2308.12215"}, "authors": [{"authorId": "12833184", "name": "Madelyne Xiao"}, {"authorId": "79109521", "name": "Jonathan R. Mayer"}], "citations": [{"paperId": "3d9fc1f34929548577f387ddd7f16839a4be5986", "title": "Exploiting User Comments for Early Detection of Fake News Prior to Users' Commenting"}]}

{"paperId": "11ae18852a2f45782dccfc7e56af69d9efcd66ae", "publicationVenue": {"id": "65967e36-f7db-476f-9d00-fd080a5a8483", "name": "IEEE Transactions on Circuits and Systems Part 1: Regular Papers", "type": "journal", "alternate_names": ["IEEE Trans Circuit Syst Part 1 Regul Pap", "IEEE Trans Circuit Syst I-regular Pap", "IEEE Transactions on Circuits and Systems I-regular Papers"], "issn": "1549-8328", "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=8919", "alternate_urls": ["https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8919"]}, "title": "An Efficient CNN Inference Accelerator Based on Intra- and Inter-Channel Feature Map Compression", "abstract": "Deep convolutional neural networks (CNNs) generate intensive inter-layer data during inference, which results in substantial on- chip memory size and off-chip bandwidth. To solve the memory constraint, this paper proposes an accelerator adopting a compression technique that can reduce the inter-layer data by removing both intra- and inter-channel redundant information. Principal component analysis (PCA) is utilized in the compression process to concentrate inter-channel information. The spatial differences, truncation, and reconfigurable bit-width coding are implemented inside every feature map to eliminate the intra-channel data redundancy. Moreover, a particular data arrangement is introduced to enhance data continuity to optimize PCA analysis and improve compression performance. A CNN accelerator with the proposed compression technique is designed to support the on- the-fly compression process by pipelining the reconstruction, CNN computation, and compression operation. The prototype accelerator is implemented using 28-nm CMOS technology. It achieves 819.2GOPS peak throughput and 3.75TOPS/W energy efficiency with 218.5mW. Experiments show that the proposed compression technique achieves compression ratios of 21.5% $\\sim $ 43.0% (8-bit mode) and 9.8% $\\sim $ 19.3% (16-bit mode) on state-of-the-art CNNs with a negligible accuracy loss.", "venue": "IEEE Transactions on Circuits and Systems Part 1: Regular Papers", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-09-01", "journal": {"name": "IEEE Transactions on Circuits and Systems I: Regular Papers", "pages": "3625-3638", "volume": "70"}, "authors": [{"authorId": "2152297586", "name": "Chenjia Xie"}, {"authorId": "2071819833", "name": "Zhuang Shao"}, {"authorId": "2189433000", "name": "Ning Zhao"}, {"authorId": "145265931", "name": "Yuan Du"}, {"authorId": "153119765", "name": "Li Du"}], "citations": [{"paperId": "1fdc045a6e9432f8c453027bce67269d3011ac8b", "title": "A Dynamic Codec with Adaptive Quantization for Convolution Neural Network"}]}

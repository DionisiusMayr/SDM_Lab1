{"paperId": "d17f666085018f19f6ab8253979d0d727af43f00", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft", "abstract": "Many reinforcement learning environments (e.g., Minecraft) provide only sparse rewards that indicate task completion or failure with binary values. The challenge in exploration efficiency in such environments makes it difficult for reinforcement-learning-based agents to learn complex tasks. To address this, this paper introduces an advanced learning system, named Auto MC-Reward, that leverages Large Language Models (LLMs) to automatically design dense reward functions, thereby enhancing the learning efficiency. Auto MC-Reward consists of three important components: Reward Designer, Reward Critic, and Trajectory Analyzer. Given the environment information and task descriptions, the Reward Designer first design the reward function by coding an executable Python function with predefined observation inputs. Then, our Reward Critic will be responsible for verifying the code, checking whether the code is self-consistent and free of syntax and semantic errors. Further, the Trajectory Analyzer summarizes possible failure causes and provides refinement suggestions according to collected trajectories. In the next round, Reward Designer will further refine and iterate the dense reward function based on feedback. Experiments demonstrate a significant improvement in the success rate and learning efficiency of our agents in complex tasks in Minecraft, such as obtaining diamond with the efficient ability to avoid lava, and efficiently explore trees and animals that are sparse in the plains biome.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-12-14", "journal": {"name": "ArXiv", "volume": "abs/2312.09238"}, "authors": [{"authorId": "2274232642", "name": "Hao Li"}, {"authorId": "2274196438", "name": "Xue Yang"}, {"authorId": "2274198735", "name": "Zhaokai Wang"}, {"authorId": "2578924", "name": "Xizhou Zhu"}, {"authorId": "2141009492", "name": "Jie Zhou"}, {"authorId": "2258755556", "name": "Yu Qiao"}, {"authorId": "2137313794", "name": "Xiaogang Wang"}, {"authorId": "2266421952", "name": "Hongsheng Li"}, {"authorId": "152309485", "name": "Lewei Lu"}, {"authorId": "3304536", "name": "Jifeng Dai"}], "citations": [{"paperId": "c35b8dad08e11a77c249c0aed2b2f7f9ba853acd", "title": "A Survey on Large Language Model-Based Game Agents"}, {"paperId": "c44471e846846bde281779405a3b5c132fd60b00", "title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods"}, {"paperId": "6cd1b99ec6d399a682b01e6fe9096e2fcf450862", "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents"}, {"paperId": "1404b3cf9649ed6a933d06cb9ea3610ff8bc031c", "title": "A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges"}, {"paperId": "fa8fa745f58d362925dd44f02750bab1b30a1189", "title": "RL-GPT: Integrating Reinforcement Learning and Code-as-policy"}, {"paperId": "4ca78a93635aa6e41d695c78110699e04e5d5a5b", "title": "A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health"}]}

{"paperId": "11741b14d5b712c11624c65c9f14d2bbf9f9966c", "publicationVenue": {"id": "4c51a870-1809-485b-8c20-3c1326b3fe16", "name": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies", "alternate_names": ["Proc ACM Interact Mob Wearable Ubiquitous Technol"], "issn": "2474-9567", "url": "https://dl.acm.org/journal/imwut", "alternate_urls": ["http://imwut.acm.org/", "https://dl.acm.org/pub.cfm?id=J1566"]}, "title": "Technical Design Space Analysis for Unobtrusive Driver Emotion Assessment Using Multi-Domain Context", "abstract": "Driver emotions play a vital role in driving safety and performance. Consequently, regulating driver emotions through empathic interfaces have been investigated thoroughly. However, the prerequisite - driver emotion sensing - is a challenging endeavor: Body-worn physiological sensors are intrusive, while facial and speech recognition only capture overt emotions. In a user study (N=27), we investigate how emotions can be unobtrusively predicted by analyzing a rich set of contextual features captured by a smartphone, including road and traffic conditions, visual scene analysis, audio, weather information, and car speed. We derive a technical design space to inform practitioners and researchers about the most indicative sensing modalities, the corresponding impact on users' privacy, and the computational cost associated with processing this data. Our analysis shows that contextual emotion recognition is significantly more robust than facial recognition, leading to an overall improvement of 7% using a leave-one-participant-out cross-validation.", "venue": "Proceedings of the ACM on Interactive Mobile Wearable and Ubiquitous Technologies", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-12-21", "journal": {"name": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies", "pages": "1 - 30", "volume": "6"}, "authors": [{"authorId": "1720742756", "name": "David Bethge"}, {"authorId": "2136641539", "name": "Luis Falconeri Coelho"}, {"authorId": "40628906", "name": "T. Kosch"}, {"authorId": "2199946745", "name": "Satiyabooshan Murugaboopathy"}, {"authorId": "2457344", "name": "Ulrich von Zadow"}, {"authorId": "2116880767", "name": "Albrecht Schmidt"}, {"authorId": "1403429262", "name": "T. Gro\u00dfe-Puppendahl"}], "citations": [{"paperId": "fa66e956f17caede04ae6baec899004974f6dce7", "title": "Comprehensive study of driver behavior monitoring systems using computer vision and machine learning techniques"}, {"paperId": "1335db8eb4fb86ac0256eae392ea0b94ce7820f5", "title": "Pilots' Considerations Regarding Current Generation Mixed Reality Headset Use in General Aviation Cockpits"}, {"paperId": "8a9b291db93c3242088ea8f85ba99751599ba0e1", "title": "Affective Driver-Pedestrian Interaction: Exploring Driver Affective Responses toward Pedestrian Crossing Actions using Camera and Physiological Sensors"}, {"paperId": "2178a7748d42a822a7851b54256cf9a5398632c6", "title": "Advances in Emotion Recognition for Driving: A Review of Uni-Modal and Multi-Modal Methods"}, {"paperId": "e482af41a3f082856af7fdfdde4216d81753e85e", "title": "Interpretable Time-Dependent Convolutional Emotion Recognition with Contextual Data Streams"}, {"paperId": "d24b4930d93fb2e44d7258db55c215bb8019017c", "title": "Rethinking infrastructure design: evaluating pedestrians and VRUs\u2019 psychophysiological and behavioral responses to different roadway designs"}]}

{"paperId": "9ca72168aa9b9dad83d9020a4159152ba114314b", "publicationVenue": {"id": "47e4f61e-9b0e-431f-bd17-e534b53c655b", "name": "International Conference on Intelligent Computing", "type": "conference", "alternate_names": ["ICIC", "Int Conf Ind Instrum Control", "Int Conf Intell Comput", "International Conference on Industrial Instrumentation and Control"], "url": "http://www.wikicfp.com/cfp/program?id=1382"}, "title": "Basic Knowledge Construction Technique to Reduce The Volume of Low-Dimensional Big Data", "abstract": "Big-data has the characteristics of high volume, velocity, and variety (3v) and continues to grow exponentially following the development of the use of world information and communication technology. The main problem in the use of big data is data deluge. The need for technology and big-data storage and processing methods to offset the exponential data growth rate is potentially unlimited, giving rise to the problem of increasing exponential technology requirements as well. In this paper, we propose a new approach in the realm of big-data analysis, through separating the basic-knowledge construction process from the original data into knowledge with much smaller velocity and volume. There are three problems to be solved, such as formulating basic-knowledge, developing a method for constructing basic-knowledge from initial data, and developing a technique for analyzing basic-knowledge into final knowledge. In this study, the technique used to build basic-knowledge is clustering-based. Analysis of basic-knowledge into final-knowledge is limited to the clustering-based analysis process. The main contributions in this paper are basic-knowledge formulation, new big-data analytic architecture, basic-knowledge construction algorithms (DSC4BKC), and analysis algorithms from basic-knowledge (BDAfBK) to final-knowledge. To test our proposed method, we use the BIRCH clustering algorithm with O(n) complexity as the baseline. We also used the artificial test-data generated from WEKA, and the IRIS4D and Diabetes data from the UCI Machine Learning Data Set for validation. Our test shows that the proposed method much more efficient in using data storage (84.69% up to 99.80%), faster in processing (20.84% up to 86.91%, and produces final-knowledge that is similar to the baseline.", "venue": "International Conference on Intelligent Computing", "year": 2020, "fieldsOfStudy": null, "publicationTypes": ["Conference"], "publicationDate": "2020-11-03", "journal": {"name": "2020 Fifth International Conference on Informatics and Computing (ICIC)", "pages": "1-8"}, "authors": [{"authorId": "2084288107", "name": "G. Karya"}, {"authorId": "2209967", "name": "B. Sitohang"}, {"authorId": "144852462", "name": "Saiful Akbar"}, {"authorId": "50547063", "name": "Veronica S. Moertini"}], "citations": [{"paperId": "3ae1b0541b2d2bce8cae5db875e52dda1dce9bfc", "title": "MapReduce-based distributed tensor clustering algorithm"}, {"paperId": "6caee3f40cfe436093272bcccfc700abae72c291", "title": "Privacy-Preserving High-Order Possibilistic C-Means Algorithm For Big Data Clustering Performance"}]}

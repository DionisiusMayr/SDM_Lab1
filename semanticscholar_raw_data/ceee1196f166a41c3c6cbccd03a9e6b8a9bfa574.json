{"paperId": "ceee1196f166a41c3c6cbccd03a9e6b8a9bfa574", "publicationVenue": {"id": "deedf64a-dd5c-4b33-b345-ff83bfb93d71", "name": "International Symposium on Computer Architecture", "type": "conference", "alternate_names": ["Int Symp Comput Archit", "ISCA"], "url": "http://www.cs.wisc.edu/~arch/www/"}, "title": "Understanding data storage and ingestion for large-scale deep recommendation model training: industrial product", "abstract": "Datacenter-scale AI training clusters consisting of thousands of domain-specific accelerators (DSA) are used to train increasingly-complex deep learning models. These clusters rely on a data storage and ingestion (DSI) pipeline, responsible for storing exabytes of training data and serving it at tens of terabytes per second. As DSAs continue to push training efficiency and throughput, the DSI pipeline is becoming the dominating factor that constrains the overall training performance and capacity. Innovations that improve the efficiency and performance of DSI systems and hardware are urgent, demanding a deep understanding of DSI characteristics and infrastructure at scale. This paper presents Meta's end-to-end DSI pipeline, composed of a central data warehouse built on distributed storage and a Data PreProcessing Service that scales to eliminate data stalls. We characterize how hundreds of models are collaboratively trained across geo-distributed datacenters via diverse and continuous training jobs. These training jobs read and heavily filter massive and evolving datasets, resulting in popular features and samples used across training jobs. We measure the intense network, memory, and compute resources required by each training job to preprocess samples during training. Finally, we synthesize key takeaways based on our production infrastructure characterization. These include identifying hardware bottlenecks, discussing opportunities for heterogeneous DSI hardware, motivating research in datacenter scheduling and benchmark datasets, and assimilating lessons learned in optimizing DSI infrastructure.", "venue": "International Symposium on Computer Architecture", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2021-08-20", "journal": {"name": "Proceedings of the 49th Annual International Symposium on Computer Architecture"}, "authors": [{"authorId": "48886419", "name": "Mark Zhao"}, {"authorId": "2563569", "name": "Niket Agarwal"}, {"authorId": "2077604103", "name": "Aarti Basant"}, {"authorId": "1742813", "name": "B. Gedik"}, {"authorId": "3315729", "name": "Satadru Pan"}, {"authorId": "1736566", "name": "Muhammet Mustafa Ozdal"}, {"authorId": "1992006", "name": "Rakesh Komuravelli"}, {"authorId": "3337314", "name": "Jerry Y. Pan"}, {"authorId": "2124122927", "name": "Tianshu Bao"}, {"authorId": "2115608345", "name": "Haowei Lu"}, {"authorId": "2125028668", "name": "Sundaram Narayanan"}, {"authorId": "2123019002", "name": "Jack Langman"}, {"authorId": "2093755996", "name": "Kevin Wilfong"}, {"authorId": "20992128", "name": "Harsha Rastogi"}, {"authorId": "2797270", "name": "Carole-Jean Wu"}, {"authorId": "117272782", "name": "Christos Kozyrakis"}, {"authorId": "145816479", "name": "Parikshit Pol"}], "citations": [{"paperId": "438497a8fe2a387aeabf4c182a92a154aa480385", "title": "Data Motion Acceleration: Chaining Cross-Domain Multi Accelerators"}, {"paperId": "fa26bd7d8f217e3b93b5e0cae7f5b9a006e6e82e", "title": "HEAM : Hashed Embedding Acceleration using Processing-In-Memory"}, {"paperId": "398bb60aed5d51d2053349f4149c5f44257ff850", "title": "cedar: Composable and Optimized Machine Learning Input Data Pipelines"}, {"paperId": "5b7dfe4992d0b1f40a693e9265816ad2d59aeb40", "title": "Accuracy-enhanced E-commerce recommendation based on deep learning and locality-sensitive hashing"}, {"paperId": "99bcc0edbdeda56e79d23c83422256b522ed8fd2", "title": "Optimizing the Training of Co-Located Deep Learning Models Using Cache-Aware Staggering"}, {"paperId": "b7aaa82d10b31959e17ea6e8545865c347075cfc", "title": "Perseus: Removing Energy Bloat from Large Model Training"}, {"paperId": "a462a41e2794dbcddd4aba19d12413c9ce4fa673", "title": "Modyn: A Platform for Model Training on Dynamic Datasets With Sample-Level Data Selection"}, {"paperId": "df3e456ed971931a5840a777106d184481f94a3c", "title": "Efficiently Processing Large Relational Joins on GPUs"}, {"paperId": "203278b671b1894d603451b41017e2ad227a3bd3", "title": "FusionFlow: Accelerating Data Preprocessing for Machine Learning with CPU-GPU Cooperation"}, {"paperId": "8137c3bb7c1908d62addf07e0add90c0eca171e2", "title": "Data Acquisition: A New Frontier in Data-centric AI"}, {"paperId": "bd90c071bccf057496c2d198c61417ea2ad10aa7", "title": "Strega: An HTTP Server for FPGAs"}, {"paperId": "1978610dadb790fe56e9a07be245b5461d20914d", "title": "Inclusive-PIM: Hardware-Software Co-design for Broad Acceleration on Commercial PIM Architectures"}, {"paperId": "d2a8294f1aede0ca6a89920475dc780e918a79aa", "title": "InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models"}, {"paperId": "4b2f18cd4cec6b246f6bf14b9cac14a4ff232d16", "title": "The Difficult Balance Between Modern Hardware and Conventional CPUs"}, {"paperId": "53780b4eeb51f8cde06c7e76008d5c8b3260a88c", "title": "Accelerating Personalized Recommendation with Cross-level Near-Memory Processing"}, {"paperId": "694d7381e95cc7ffa83448658ec7abd430906cda", "title": "Optimizing CPU Performance for Recommendation Systems At-Scale"}, {"paperId": "fb016b2ccff8b5f75c630cf0a093137bd63495d9", "title": "GPU-initiated Fine-grained Overlap of Collective Communication with Computation"}, {"paperId": "cce1a0b71db567af283b056edb9ed5b5286fd0ba", "title": "Towards A Platform and Benchmark Suite for Model Training on Dynamic Datasets"}, {"paperId": "a8e32285ff09afaa3fcea50a06a421d5b9fe578d", "title": "SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters"}, {"paperId": "7c25adf2ddb35df05a61c697da97efb8583d77df", "title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings"}, {"paperId": "9a256ff6b335caacb95a3cffd1db855696bb2aec", "title": "An intelligent recommendation method based on multi-interest network and adversarial deep learning"}, {"paperId": "09aa3b34765d30e7b71939dc2030d1411e43c9fa", "title": "RECom: A Compiler Approach to Accelerating Recommendation Model Inference with Massive Embedding Columns"}, {"paperId": "2fdee183716352fe48494241e9249e8a6f7bd996", "title": "Realizing Strong Determinism Contract on Log-Structured Merge Key-Value Stores"}, {"paperId": "f86ce7221ee9f5c43de832be1abeaa6faace663d", "title": "iCache: An Importance-Sampling-Informed Cache for Accelerating I/O-Bound DNN Model Training"}, {"paperId": "e63bb59408deac7e1b4409502c3dd218b7685bf8", "title": "FlexShard: Flexible Sharding for Industry-Scale Sequence Recommendation Models"}, {"paperId": "efb8d99c903328f64bfbcaa10b59f3b807798c55", "title": "FastFlow: Accelerating Deep Learning Model Training with Smart Offloading of Input Data Pipeline"}, {"paperId": "c04f8eb01c3ef78d41b37f7c1964aa28989b5d6d", "title": "How Do Consumer Innovation Characteristics and Consumption Value Shape Users\u2019 Willingness to Buy Innovative Car Safety Seats?"}, {"paperId": "a9fdbc9d28c288efb24ba1d5e0886506cdc9f100", "title": "Mystique: Enabling Accurate and Scalable Generation of Production AI Benchmarks"}, {"paperId": "4656356eb018ede25315f134c622f405c0581604", "title": "Characterizing I/O in Machine Learning with MLPerf Storage"}, {"paperId": "3437212c42cc17e1bd0904601c79e3240cc44331", "title": "RecD: Deduplication for End-to-End Deep Learning Recommendation Model Training Infrastructure"}, {"paperId": "9c8399c92592f09071030af70611421d90923856", "title": "tf.data service: A Case for Disaggregating ML Input Data Processing"}, {"paperId": "93f9d29445a1236c0b1ab45026c2e308b9b74c15", "title": "Understanding Scaling Laws for Recommendation Models"}, {"paperId": "9e21453ffc3ef4567a2358c2a27f6b42fefbd0c9", "title": "Velox: Meta's Unified Execution Engine"}, {"paperId": "489f6c0e46fc72ee91a06e99cfb48d969acd654e", "title": "Amalur: Data Integration Meets Machine Learning"}, {"paperId": "236e378c41894c2a5b77cdc41d9fab246a4b72e5", "title": "Shared Foundations: Modernizing Meta's Data Lakehouse"}, {"paperId": "5d5bbcb7b6072f3cac430855449d16719f47cbfc", "title": "Leave Nothing Idle: Filling Datacenter Resource Utilization Gaps with Quicksand"}, {"paperId": "41d293f730da7e81448d3e75aec54d6ae0138c13", "title": "Cachew: Machine Learning Input Data Processing as a Service"}, {"paperId": "423d83256f500fa413da9d9d1af474078754ff05", "title": "Orion: Interference-aware, Fine-grained GPU Sharing for ML Applications"}, {"paperId": "cfe67cae58393210279b095ddbedf1b5099e9a56", "title": "This paper is included in the Proceedings of the 2022 USENIX Annual Technical Conference."}]}

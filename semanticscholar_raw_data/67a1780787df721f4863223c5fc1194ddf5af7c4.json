{"paperId": "67a1780787df721f4863223c5fc1194ddf5af7c4", "publicationVenue": {"id": "312ca99c-9149-490d-813e-c60d5e949f65", "name": "Concurrency and Computation", "type": "journal", "alternate_names": ["Concurr Comput Pract Exp", "Concurrency and Computation: Practice and Experience", "Concurr Comput"], "issn": "1532-0626", "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/77004395?CRETRY=1&SRETRY=0", "alternate_urls": ["http://www3.interscience.wiley.com/cgi-bin/jtoc?ID=77004395", "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1532-0634"]}, "title": "Towards optimizing the execution of spark scientific workflows using machine learning\u2010based parameter tuning", "abstract": "In the last few years, Apache Spark has become a de facto the standard framework for big data systems on both industry and academy projects. Spark is used to execute compute\u2010 and data\u2010intensive workflows in distinct areas like biology and astronomy. Although Spark is an easy\u2010to\u2010install framework, it has more than one hundred parameters to be set, besides domain\u2010specific parameters of each workflow. In this way, to execute Spark\u2010based workflows efficiently, the user has to fine\u2010tune a myriad of Spark and workflow parameters (eg, partitioning strategy, the average size of a DNA sequence, etc.). This configuration task cannot be manually performed in a trial\u2010and\u2010error manner since it is tedious and error\u2010prone. This article proposes an approach that focuses on generating interpretable predictive machine learning models (ie, decision trees), and then extract useful rules (ie, patterns) from these models that can be applied to configure parameters of future executions of the workflow and Spark for nonexperts users. In the experiments presented in this article, the proposed parameter configuration approach led to better performance in processing Spark workflows. Finally, the approach introduced here reduced the number of parameters to be configured by identifying the most relevant domain\u2010specific ones related to the workflow performance in the predictive model.", "venue": "Concurrency and Computation", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-09-05", "journal": {"name": "Concurrency and Computation: Practice and Experience", "volume": "33"}, "authors": [{"authorId": "3416982", "name": "D. Oliveira"}, {"authorId": "145179575", "name": "F. Porto"}, {"authorId": "1712651", "name": "Cristina Boeres"}, {"authorId": "33663874", "name": "Daniel de Oliveira"}], "citations": [{"paperId": "2c071a57bf69d8a665a3c1ee338c03ac1ed38838", "title": "Tuning parameters of Apache Spark with Gauss\u2013Pareto-based multi-objective optimization"}, {"paperId": "56d16cb01d24816507548437f3303c3f55007b71", "title": "Optimizing computational costs of Spark for SARS\u2010CoV\u20102 sequences comparisons on a commercial cloud"}, {"paperId": "2122c64be55d2b9a4ed07b587a9803911a3e9e8a", "title": "Runtime prediction of big data jobs: performance comparison of machine learning algorithms and analytical models"}, {"paperId": "c2cccdc71114ed2e140ffee1e8fbd18851dd6e27", "title": "Towards Analyzing Computational Costs of Spark for SARS-CoV-2 Sequences Comparisons on a Commercial Cloud"}, {"paperId": "c3ddae5cb7ad9473453765a657cdfc341d7bcf13", "title": "NoStop: A Novel Configuration Optimization Scheme for Spark Streaming"}, {"paperId": "d7f5990db3bfbea6ec063ccbb4449afb3c06c4e1", "title": "Defini\u00e7\u00e3o de Par\u00e2metros do Spark por meio de Aprendizado de M\u00e1quina: um Estudo com Dataflows de Astronomia"}, {"paperId": "7712f3398a99504e45ad50f2c82ec727d9832ddc", "title": "Scientific Workflows Management and Scheduling in Cloud Computing: Taxonomy, Prospects, and Challenges"}]}

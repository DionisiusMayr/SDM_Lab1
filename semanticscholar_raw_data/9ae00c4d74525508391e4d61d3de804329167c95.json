{"paperId": "9ae00c4d74525508391e4d61d3de804329167c95", "publicationVenue": null, "title": "Optimizaci\u00f3n y Procesamiento Inteligente de Grandes Vol\u00famenes de Datos Categ\u00f3ricos", "abstract": "In the last years, the volume of information is growing faster than ever, moving from small datasets to huge volumes of data. This data growth has forced researchers to look for a new alternatives to store and process this information, since traditional techniques have been limited by the size and structure of the data. There are many data types including numerical, categorical, text, images, audio, etc. Current methods that work with this type of data often convert them into numerical or categorical data. Categorical data (also known as nominal data) have been the subject of several studies and several methods have been developed to work with this type of data. The need to process data intelligently to infer useful knowledge for organizations and the computational complexity of machine learning algorithms becomes a critical factor when combined with large volumes of data as they base their operation on a progressive iteration on the data set. To get better performance, it is important to keep all the data in memory (local or distributed). Some specialized machine learning algorithms have been developed to work with categorical data, for exmample the fuzzykMeans was adapted to fuzzy k-Modes to work with categorical data. However, the performance of these algorithms has two important factors to consider: the processing technique (algorithm) and the representation of data. In many cases, prior to the application of an algorithm, it requieres that the information be stored in memory. Reducing the amount of memory used for data representation clearly reduce the number of operations required to process it. The kNN classification algorithm (k-nearest neighbors) is one of the most widely used non-parametric classification method, however it is limited due to memory consumption related to the size of the dataset which makes it impractical to apply to large volumnes of data. The research described in this thesis was motivated by the need for an optimal categorical data representation that can be easily incorporated in machine learning algorithms that allow a smart analisys and explotation of big data. This thesis proposes the use of bit-level compression schema to compress the training dataset prior to train a machine learning model. In order to use the dataset, an on-the-fly decompression was proposed that enable the use of the dataset without the need for a whole decompression. To facilitate the incorporation of the proposed compression method into existing machine learning frameworks, the proposed method is aligned with the Basic Linear Algebra Subprograms BLAS Level 1 which defines the basic construction blocks in form of algebraic functions. In particular, we proposes the use of kNN algorithm to work with categorical compressed data. The proposed method allows to keep the compressed data in memory, with drastically reduces the memory consuption. Finally, we proposed the use of Hamming metric to work with commpressed categorical data without decompressing each observation in order to avoid the on-the-fly decompression phase. This allows us to process the whole dataset without decompression.", "venue": "", "year": 2019, "fieldsOfStudy": ["Geography"], "publicationTypes": null, "publicationDate": null, "journal": null, "authors": [{"authorId": "153813942", "name": "J. Salvador"}], "citations": []}

{"paperId": "c5304b0a651a34e0b679be111a2c50892148e47f", "publicationVenue": {"id": "7c9d091e-015e-4e5d-a11f-9bc369fcf414", "name": "IEEE Transactions on Parallel and Distributed Systems", "type": "journal", "alternate_names": ["IEEE Trans Parallel Distrib Syst"], "issn": "1045-9219", "url": "http://www.computer.org/tpds", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=71"]}, "title": "Optimizing Streaming Parallelism on Heterogeneous Many-Core Architectures", "abstract": "As many-core accelerators keep integrating more processing units, it becomes increasingly more difficult for a parallel application to make effective use of all available resources. An effective way of improving hardware utilization is to exploit spatial and temporal sharing of the heterogeneous processing units by multiplexing computation and communication tasks \u2013 a strategy known as heterogeneous streaming. Achieving effective heterogeneous streaming requires carefully partitioning hardware among tasks, and matching the granularity of task parallelism to the resource partition. However, finding the right resource partitioning and task granularity is extremely challenging, because there is a large number of possible solutions and the optimal solution varies across programs and datasets. This article presents an automatic approach to quickly derive a good solution for hardware resource partition and task granularity for task-based parallel applications on heterogeneous many-core architectures. Our approach employs a performance model to estimate the resulting performance of the target application under a given resource partition and task granularity configuration. The model is used as a utility to quickly search for a good configuration at runtime. Instead of hand-crafting an analytical model that requires expert insights into low-level hardware details, we employ machine learning techniques to automatically learn it. We achieve this by first learning a predictive model offline using training programs. The learned model can then be used to predict the performance of any unseen program at runtime. We apply our approach to 39 representative parallel applications and evaluate it on two representative heterogeneous many-core platforms: a CPU-XeonPhi platform and a CPU-GPU platform. Compared to the single-stream version, our approach achieves, on average, a 1.6x and 1.1x speedup on the XeonPhi and the GPU platform, respectively. These results translate to over 93 percent of the performance delivered by a theoretically perfect predictor.", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-03-05", "journal": {"name": "IEEE Transactions on Parallel and Distributed Systems", "pages": "1878-1896", "volume": "31"}, "authors": [{"authorId": "2151329683", "name": "Peng Zhang"}, {"authorId": "144634544", "name": "Jianbin Fang"}, {"authorId": "1806026", "name": "Canqun Yang"}, {"authorId": "50419182", "name": "Chun Huang"}, {"authorId": "144543522", "name": "T. Tang"}, {"authorId": "50218803", "name": "Z. Wang"}], "citations": [{"paperId": "672da2bff20808998a5c4a3953612d2cdd60d891", "title": "JavaScript Performance Tuning as a Crowdsourced Service"}, {"paperId": "98dec13d0ce06ce1fa7641aa7ff293215dfaeb5a", "title": "Kernel-as-a-Service: A Serverless Programming Model for Heterogeneous Hardware Accelerators"}, {"paperId": "072da6d5dd5448d32ca6b92362aebef0f247a3a8", "title": "Adaptive Model Selection for Video Super Resolution"}, {"paperId": "d1e3f04fb2c6a84c35d1ee3be6cb5fbd2b029043", "title": "Dynamic GPU Energy Optimization for Machine Learning Training Workloads"}, {"paperId": "cb327eb23d59fbb85818756b35854ccf9b32c074", "title": "Libshalom: Optimizing Small and Irregular-Shaped Matrix Multiplications on ARMv8 Multi-Cores"}, {"paperId": "fa9091ded0a2f436c718e41bd0ddc8199d054f49", "title": "Optimizing Sparse Matrix Multiplications for Graph Neural Networks"}, {"paperId": "3087814d42f79c1637bb69aafd33f0c594230b00", "title": "Online Power Management for Multi-Cores: A Reinforcement Learning Based Approach"}, {"paperId": "fd8d00150e2473c83bc59942b84f7de11bf71af2", "title": "Compiler-directed scratchpad memory data transfer optimization for multithreaded applications on a heterogeneous many-core architecture"}, {"paperId": "72b260f36d193d064806b931660129e1be09eb78", "title": "Characterizing Small-Scale Matrix Multiplications on ARMv8-based Many-Core Architectures"}, {"paperId": "69f135317ab602550c587cd663e82ebd323e010c", "title": "Deep Program Structure Modeling Through Multi-Relational Graph-based Learning"}, {"paperId": "4cf8be8646c179e87e83966f553707f584936a0b", "title": "Parallel programming models for heterogeneous many-cores: a comprehensive survey"}, {"paperId": "725a7cc6f95e56c8339e0378de7835617ec2bbf0", "title": "Parallel Programming Models for Heterogeneous Many-Cores : A Survey"}, {"paperId": "533c9508dee744b383cbd5edc33ec82800654775", "title": "Camel: Smart, Adaptive Energy Optimization for Mobile Web Interactions"}]}

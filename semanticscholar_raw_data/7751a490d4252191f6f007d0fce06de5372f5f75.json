{"paperId": "7751a490d4252191f6f007d0fce06de5372f5f75", "publicationVenue": null, "title": "Optimizing end-to-end machine learning pipelines for model training", "abstract": "Modern data analysis programs often consist of complex operations. They combine multiple heterogeneous data sources, perform data cleaning and feature transformations, and apply machine learning algorithms to train models on the preprocessed data. Existing systems can execute such end-to-end training pipelines. However, they face unique challenges in their applicability to large scale data. In particular, current approaches either rely on in-memory execution (e.g., Python Pandas and scikit-learn) or they do not provide convenient programming abstractions for specifying data analysis programs (e.g., Apache Flink and Spark). Moreover, these systems do not support optimizations across operations in these pipelines, which also limits their e cient execution. In this thesis, we present our contributions towards a more e cient execution of end-to-end machine learning pipelines for model training. In particular, we discuss the following three contributions: In our rst contribution, we propose a programming abstraction in the dynamic language R on top of the distributed data ow engine Apache Flink. Our abstraction scales to large amounts of data but also hides system speci cs of the data ow engine. We integrate R and the system language Java in a shared runtime to alleviate the performance overhead of current solutions for language integration in case of complex user-de ned functions. In our second contribution, we introduce an intermediate representation for data analytics programs, which allows us to optimize the complete training pipeline. We base our approach on a low-level intermediate representation that provides access to the whole program and augments two abstractions on top of it: a layer that uni es the application of user-de ned functions enables operator fusion and pushdown; a high-level representation of the operations enables plan variant selection. In our third contribution, we propose a new context-aware operator for data ow engines, which directly creates an e cient partitioning schema for matrices from normalized data sources. The operator decouples the evaluation of the join predicate from the materialization of the result. This minimizes data shu ing in distributed settings and enables the operator to choose the materialization strategy depending on the shape of the input relations. In summary, we conclude that we need a holistic system design that covers all tiers \u2013 programming abstraction, intermediate representation, and execution backend \u2013 to overcome the scalability challenges of large-scale data analysis programs.", "venue": "", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "1902358", "name": "Andreas Kunft"}], "citations": [{"paperId": "3717842d7005e751510eaca1a62f65db9e94a1d7", "title": "The NebulaStream Platform for Data and Application Management in the Internet of Things"}, {"paperId": "f698de98ee6c438f4354090f712fbcdf128c74ee", "title": "End-to-End Data Pipeline in Games for Real-Time Data Analytics"}]}

{"paperId": "1b969c8317441edef4e1976ed7f27b36751c2c35", "publicationVenue": {"id": "5e1f6444-5d03-48c7-b202-7f47d492aeae", "name": "IEEE Transactions on Visualization and Computer Graphics", "type": "journal", "alternate_names": ["IEEE Trans Vis Comput Graph"], "issn": "1077-2626", "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=2945"}, "title": "Evaluating the Effects of Virtual Reality Environment Learning on Subsequent Robot Teleoperation in an Unfamiliar Building", "abstract": "Using a map in an unfamiliar environment requires identifying correspondences between elements of the map's allocentric representation and elements in egocentric views. Aligning the map with the environment can be challenging. Virtual reality (VR) allows learning about unfamiliar environments in a sequence of egocentric views that correspond closely to the perspectives and views that are experienced in the actual environment. We compared three methods to prepare for localization and navigation tasks performed by teleoperating a robot in an office building: studying a floor plan of the building and two forms of VR exploration. One group of participants studied a building plan, a second group explored a faithful VR reconstruction of the building from a normal-sized avatar's perspective, and a third group explored the VR from a giant-sized avatar's perspective. All methods contained marked checkpoints. The subsequent tasks were identical for all groups. The self-localization task required indication of the approximate location of the robot in the environment. The navigation task required navigation between checkpoints. Participants took less time to learn with the giant VR perspective and with the floorplan than with the normal VR perspective. Both VR learning methods significantly outperformed the floorplan in the orientation task. Navigation was performed quicker after learning in the giant perspective compared to the normal perspective and the building plan. We conclude that the normal perspective and especially the giant perspective in VR are viable options for preparing for teleoperation in unfamiliar environments when a virtual model of the environment is available.", "venue": "IEEE Transactions on Visualization and Computer Graphics", "year": 2023, "fieldsOfStudy": ["Computer Science", "Medicine"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-02-22", "journal": {"name": "IEEE Transactions on Visualization and Computer Graphics", "pages": "2220-2229", "volume": "29"}, "authors": [{"authorId": "2212911378", "name": "Karl Eisentr\u00e4ger"}, {"authorId": "2209561674", "name": "Judith Haubner"}, {"authorId": "34610633", "name": "Jennifer Brade"}, {"authorId": "1917767", "name": "W. Einh\u00e4user"}, {"authorId": "2572821", "name": "A. Bendixen"}, {"authorId": "2162977248", "name": "Sven Winkler"}, {"authorId": "1764260", "name": "Philipp Klimant"}, {"authorId": "2155741136", "name": "Georg Jahn"}], "citations": [{"paperId": "2503564609a31b42559583a0e5ccfad531c2b3a1", "title": "LGSDF: Continual Global Learning of Signed Distance Fields Aided by Local Updating"}, {"paperId": "41bd591f0007570805fa80f4e619999648b3d50c", "title": "Multi-Scale Interactions Between Augmented Reality and Virtual Reality Users in Mixed Reality Environment"}]}

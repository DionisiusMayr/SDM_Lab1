{"paperId": "cacc4b203f76292179385aa9c7320c5798cfa085", "publicationVenue": null, "title": "Visual Image Reconstruction from Human Brain Activity using Linear Image Decoders plus Nonlinear Noise Suppression", "abstract": "\u2014In recent years, substantial strides have been made in the field of visual image reconstruction, particularly in its capacity to generate high-quality visual representations from human brain activity. This advancement not only enables the recreation of visual content but also provides valuable insights into the intricate processes occurring within functional brain regions, contributing to a deeper understanding of brain function. However, linear decoding methods, which were once prominent in this field, have faced challenges due to their susceptibility to noise. As a result, they have gradually fallen out of favor. In response to this limitation, our study introduces a novel approach that combines linear mapping with nonlinear reconstruction techniques to recreate visual images perceived by research subjects based on their brain activity patterns. The primary challenge associated with linear mapping lies in its susceptibility to noise interference. To address this issue, we leverage a flexible denoised deep convolutional neural network, which surpasses the performance of traditional linear mapping. Our investigation encompasses three distinct linear mapping approaches, as well as the training of shallow and deep autoencoder denoised neural networks, including a pre-trained state-of-the-art denoised neural network. The outcome of our study reveals that the amalgamation of linear image decoding with nonlinear noise reduction significantly enhances the quality of reconstructed images from human brain activity. This suggests that our methodology holds promise for decoding intricate perceptual experiences directly from brain activity patterns. Moreover, our analysis highlights an interesting observation: during the encoder phases of the denoised autoencoder, color information emerges as the most crucial factor, while both color and texture information assume equal importance during the decoder phases. This observation underscores the distinct manner in which Alexnet neural networks represent feature information, setting the stage for further investigation and innovation in this domain.", "venue": "", "year": 2023, "fieldsOfStudy": null, "publicationTypes": null, "publicationDate": null, "journal": null, "authors": [{"authorId": "2285359622", "name": "Qiang Li"}], "citations": []}

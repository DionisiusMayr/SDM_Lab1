{"paperId": "553d85e202fdbdd4101673b9205135b8eb94811d", "publicationVenue": {"id": "0d6f7fba-7092-46b3-8039-93458dba736b", "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing", "type": "conference", "alternate_names": ["Int Conf Acoust Speech Signal Process", "IEEE Int Conf Acoust Speech Signal Process", "ICASSP", "International Conference on Acoustics, Speech, and Signal Processing"], "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"}, "title": "Recovering from Privacy-Preserving Masking with Large Language Models", "abstract": "Model adaptation is crucial to handle the discrepancy between proxy training data and actual users data received. To effectively perform adaptation, textual data of users is typically stored on servers or their local devices, where downstream natural language processing (NLP) models can be directly trained using such in-domain data. However, this might raise privacy and security concerns due to the extra risks of exposing user information to adversaries. Replacing identifying information in textual data with a generic marker has been recently explored. In this work, we leverage large language models (LLMs) to suggest substitutes of masked tokens and have their effectiveness evaluated on downstream language modeling tasks. Specifically, we propose multiple pre-trained and fine-tuned LLM-based approaches and perform empirical studies on various datasets for the comparison of these methods. Experimental results show that models trained on the obfuscation corpora are able to achieve comparable performance with the ones trained on the original data without privacy-preserving token masking.", "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-09-12", "journal": {"name": "ArXiv", "volume": "abs/2309.08628"}, "authors": [{"authorId": "13847026", "name": "A. Vats"}, {"authorId": "2116746698", "name": "Zhe Liu"}, {"authorId": "47527626", "name": "Peng Su"}, {"authorId": "2242882211", "name": "Debjyoti Paul"}, {"authorId": "2146275988", "name": "Yingyi Ma"}, {"authorId": "2057013888", "name": "Yutong Pang"}, {"authorId": "2237806751", "name": "Zeeshan Ahmed"}, {"authorId": "2237802124", "name": "Ozlem Kalinli"}], "citations": [{"paperId": "d624894c25478d32bbc399f4e8f9672fc37fe557", "title": "Can LLMs get help from other LLMs without revealing private information?"}, {"paperId": "383c598625110e0a4c60da4db10a838ef822fbcf", "title": "A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly"}]}

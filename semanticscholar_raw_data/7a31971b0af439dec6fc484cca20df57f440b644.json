{"paperId": "7a31971b0af439dec6fc484cca20df57f440b644", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "One Shot Learning as Instruction Data Prospector for Large Language Models", "abstract": "Aligning large language models(LLMs) with human is a critical step in effectively utilizing their pre-trained capabilities across a wide array of language tasks. Current instruction tuning practices often rely on expanding dataset size without a clear strategy for ensuring data quality, which can inadvertently introduce noise and degrade model performance. To address this challenge, we introduce Nuggets, a novel and efficient methodology that employs one shot learning to select high-quality instruction data from expansive datasets. Nuggets assesses the potential of individual instruction examples to act as effective one shot examples, thereby identifying those that can significantly enhance diverse task performance. Nuggets utilizes a scoring system based on the impact of candidate examples on the perplexity of a diverse anchor set, facilitating the selection of the most beneficial data for instruction tuning. Through rigorous testing on two benchmarks, including MT-Bench and Alpaca-Eval, we demonstrate that instruction tuning with the top 1% of Nuggets-curated examples substantially outperforms conventional methods that use the full dataset. These findings advocate for a data selection paradigm that prioritizes quality, offering a more efficient pathway to align LLMs with humans.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-12-16", "journal": {"name": "ArXiv", "volume": "abs/2312.10302"}, "authors": [{"authorId": "2204767592", "name": "Yunshui Li"}, {"authorId": "151471590", "name": "Binyuan Hui"}, {"authorId": "2077454998", "name": "Xiaobo Xia"}, {"authorId": "2135964855", "name": "Jiaxi Yang"}, {"authorId": "2275101569", "name": "Min Yang"}, {"authorId": "2274938171", "name": "Lei Zhang"}, {"authorId": "2053739525", "name": "Shuzheng Si"}, {"authorId": "2108373912", "name": "Junhao Liu"}, {"authorId": "2259846144", "name": "Tongliang Liu"}, {"authorId": "2256480062", "name": "Fei Huang"}, {"authorId": "2253881638", "name": "Yongbin Li"}], "citations": [{"paperId": "c00c3fd40e4ab89faa14c0d2d34e0ea5de8e3608", "title": "Exploring the Mystery of Influential Data for Mathematical Reasoning"}, {"paperId": "94db8a625418800c8ae7b48157a9cad1c8129051", "title": "A Survey on Knowledge Distillation of Large Language Models"}, {"paperId": "32370746059bc592106688f119110e7d54fc5848", "title": "Exploring Learning Complexity for Downstream Data Pruning"}, {"paperId": "c991dedacba67949a28640cd8755de4c8ae297b0", "title": "A Survey on Data Selection for LLM Instruction Tuning"}, {"paperId": "271ff9dbeacd05276f1f192453793e772ad91b69", "title": "IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models"}]}

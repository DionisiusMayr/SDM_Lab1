{"paperId": "c9e0826ec05763f6bb73908038d89e2afd38d67b", "publicationVenue": {"id": "312ca99c-9149-490d-813e-c60d5e949f65", "name": "Concurrency and Computation", "type": "journal", "alternate_names": ["Concurr Comput Pract Exp", "Concurrency and Computation: Practice and Experience", "Concurr Comput"], "issn": "1532-0626", "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/77004395?CRETRY=1&SRETRY=0", "alternate_urls": ["http://www3.interscience.wiley.com/cgi-bin/jtoc?ID=77004395", "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1532-0634"]}, "title": "(k, m, t)\u2010anonymity: Enhanced privacy for transactional data", "abstract": "Recent years have witnessed the wide availability of an array of transactional datasets for mining and other research activities. A primary concern related to the public sharing of transactional datasets is identifying individuals whose data is being published. Data anonymization is a commonly utilized privacy preservation method for preventing user identification. However, the existing anonymization models such as km$$ {k}^m $$ \u2010anonymity, \u03c1$$ \\rho $$ \u2010uncertainty, and (h, k, p)\u2010coherence for privacy preservation of transactional data do not provide complete protection from the various types of possible privacy attacks. Therefore, this article proposes a novel privacy model called (k, m, t)\u2010anonymity to effectively prevent identity and attribute disclosure as well as skewness attack on transactional data. A genetic algorithm\u2010based implementation of the model is also presented. The genetic algorithm clusters transactional data based on the similarity among the transactions for effective km$$ {k}^m $$ \u2010anonymization with low information loss. The clustering algorithm simultaneously aims to minimize the skewness of data distribution in the obtained clusters for preventing skewness attack on anonymized data. Experimental results have verified that the (k, m, t)\u2010anonymity model ensures transactional data anonymization without significant information loss. The proposed privacy model is implemented using the proposed approach on two real\u2010world datasets (health domain and click\u2010stream data) and an enormous dataset generated synthetically (health domain consisting of 5,00,000 records). The relative error is less as compared to the relative privacy and disassociation technique for all test case scenarios. Hence, the proposed anonymization model maintains the data utility.", "venue": "Concurrency and Computation", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-04-10", "journal": {"name": "Concurrency and Computation: Practice and Experience", "volume": "34"}, "authors": [{"authorId": "153425239", "name": "Vartika Puri"}, {"authorId": "2081215", "name": "Parmeet Kaur"}, {"authorId": "1855173", "name": "Shelly Sachdeva"}], "citations": [{"paperId": "db69ee52f101dc2a1c6f2244410be906b8d727d8", "title": "A New Approach for Anonymizing Transaction Data with Set Values"}]}

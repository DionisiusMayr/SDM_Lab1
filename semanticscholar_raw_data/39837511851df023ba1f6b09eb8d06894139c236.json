{"paperId": "39837511851df023ba1f6b09eb8d06894139c236", "publicationVenue": {"id": "c3e5f1c8-9ba7-47e5-acde-53063a69d483", "name": "Future Internet", "type": "journal", "issn": "1999-5903", "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-156830", "alternate_urls": ["http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-156830", "https://www.mdpi.com/journal/futureinternet"]}, "title": "Exploiting Machine Learning for Improving In-Memory Execution of Data-Intensive Workflows on Parallel Machines", "abstract": "Workflows are largely used to orchestrate complex sets of operations required to handle and process huge amounts of data. Parallel processing is often vital to reduce execution time when complex data-intensive workflows must be run efficiently, and at the same time, in-memory processing can bring important benefits to accelerate execution. However, optimization techniques are necessary to fully exploit in-memory processing, avoiding performance drops due to memory saturation events. This paper proposed a novel solution, called the Intelligent In-memory Workflow Manager (IIWM), for optimizing the in-memory execution of data-intensive workflows on parallel machines. IIWM is based on two complementary strategies: (1) a machine learning strategy for predicting the memory occupancy and execution time of workflow tasks; (2) a scheduling strategy that allocates tasks to a computing node, taking into account the (predicted) memory occupancy and execution time of each task and the memory available on that node. The effectiveness of the machine learning-based predictor and the scheduling strategy were demonstrated experimentally using as a testbed, Spark, a high-performance Big Data processing framework that exploits in-memory computing to speed up the execution of large-scale applications. In particular, two synthetic workflows were prepared for testing the robustness of the IIWM in scenarios characterized by a high level of parallelism and a limited amount of memory reserved for execution. Furthermore, a real data analysis workflow was used as a case study, for better assessing the benefits of the proposed approach. Thanks to high accuracy in predicting resources used at runtime, the IIWM was able to avoid disk writes caused by memory saturation, outperforming a traditional strategy in which only dependencies among tasks are taken into account. Specifically, the IIWM achieved up to a 31% and a 40% reduction of makespan and a performance improvement up to 1.45\u00d7 and 1.66\u00d7 on the synthetic workflows and the real case study, respectively.", "venue": "Future Internet", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2021-05-05", "journal": {"name": "Future Internet", "pages": "121", "volume": "13"}, "authors": [{"authorId": "1585232914", "name": "Riccardo Cantini"}, {"authorId": "1997738", "name": "Fabrizio Marozzo"}, {"authorId": "96934840", "name": "A. Orsino"}, {"authorId": "1760683", "name": "D. Talia"}, {"authorId": "1767138", "name": "Paolo Trunfio"}], "citations": [{"paperId": "251cd68d63fa174ae3f84ad78b226725942aede3", "title": "Block size estimation for data partitioning in HPC applications using machine learning techniques"}, {"paperId": "d2352109ea7eccbbd5b9a473f27ad082c3176150", "title": "Programming big data analysis: principles and solutions"}]}

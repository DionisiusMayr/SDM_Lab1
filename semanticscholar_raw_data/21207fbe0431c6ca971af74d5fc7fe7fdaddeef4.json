{"paperId": "21207fbe0431c6ca971af74d5fc7fe7fdaddeef4", "publicationVenue": null, "title": "Slice Tuner: A Selective Data Acquisition Framework for Accurate and Fair Machine Learning Models", "abstract": "As machine learning becomes democratized in the era of Software 2.0, a serious bottleneck is acquiring enough data to ensure accurate and fair models. Recent techniques including crowdsourcing provide cost-effective ways to gather such data. However, simply acquiring data as much as possible is not necessarily an effective strategy for optimizing accuracy and fairness. For example, if an online app store has enough training data for certain slices of data (say American customers), but not for others, obtaining more American customer data will only bias the model training. Instead, we contend that one needs to selectively acquire data and propose Slice Tuner, which acquires possibly-different amounts of data per slice such that the model accuracy and fairness on all slices are optimized. This problem is different than labeling existing data (as in active learning or weak supervision) because the goal is obtaining the right amounts of new data. At its core, Slice Tuner maintains learning curves of slices that estimate the model accuracies given more data and uses convex optimization to find the best data acquisition strategy. The key challenges of estimating learning curves are that they may be inaccurate if there is not enough data, and there may be dependencies among slices where acquiring data for one slice influences the learning curves of others. We solve these issues by iteratively and efficiently updating the learning curves as more data is acquired. We evaluate Slice Tuner on real datasets using crowdsourcing for data acquisition and show that Slice Tuner significantly outperforms baselines in terms of model accuracy and fairness, even when the learning curves cannot be reliably estimated.", "venue": "SIGMOD Conference", "year": 2020, "fieldsOfStudy": ["Computer Science", "Mathematics"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2020-03-10", "journal": {"name": "Proceedings of the 2021 International Conference on Management of Data"}, "authors": [{"authorId": "66438571", "name": "Ki Hyun Tae"}, {"authorId": "3288247", "name": "Steven Euijong Whang"}], "citations": [{"paperId": "1b97b6160936a667a71e3d51377eb0a2afcabdcf", "title": "Prioritizing Data Acquisition for end-to-end Speech Model Improvement"}, {"paperId": "d3db6d1348ca1925acd7c8ca7158c6edee9ec105", "title": "Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach"}, {"paperId": "b5cf2acd8952a46165e262e0ccf431345335f307", "title": "Data Collection Algorithms for Model Training in Internet of Vehicles"}, {"paperId": "8f9d880af2fab7d1666fe0548d5d871b4099110e", "title": "Falcon: Fair Active Learning using Multi-armed Bandits"}, {"paperId": "302bbba2f61082f63f99c8dd0269d047f7efb837", "title": "Advanced Dataset Discovery: When Multi-Query-Dataset Cardinality Estimation Matters"}, {"paperId": "4ce56b7ca0de6963b888e21d77dc6e7729af9ed0", "title": "Explainable Artificial Intelligence for Interpretable Data Minimization"}, {"paperId": "5cbbe911564117fc4ac7c53866c189fe60166cad", "title": "SAGA: A Scalable Framework for Optimizing Data Cleaning Pipelines for Machine Learning Applications"}, {"paperId": "1f79c96e061ca3a9310b2d54525ef0cce39417be", "title": "VLSlice: Interactive Vision-and-Language Slice Discovery"}, {"paperId": "371c5d0204193eeafafe471c83716cc6fb0a94c0", "title": "Data Coverage for Detecting Representation Bias in Image Datasets: A Crowdsourcing Approach"}, {"paperId": "c909aaf29267c8a4cd31d8de2a82dbfba351257a", "title": "Optimizing Tensor Computations: From Applications to Compilation and Runtime Techniques"}, {"paperId": "565080264fa0e795a77ffccf0acba85c67238594", "title": "Open-source tool for model performance analysis for subpopulations"}, {"paperId": "dd55ea06ede00589c9e08a7bd1a40f6d1aff8724", "title": "Non-Invasive Fairness in Learning through the Lens of Data Drift"}, {"paperId": "16664b2201b36100ff6090aadf8ce4081f4b153a", "title": "Next-generation Challenges of Responsible Data Integration"}, {"paperId": "b1ab0635586fc7677f9a54590e56dcb0717db664", "title": "Pushing the Accuracy-Group Robustness Frontier with Introspective Self-play"}, {"paperId": "308b6528d3578971705221d4e2fb4cadb729597b", "title": "[Data] Quality Lies In The Eyes Of The Beholder"}, {"paperId": "8ce65cd7fc3c5d2870cd58654e34fb7eaf3a1179", "title": "Responsible Data Integration: Next-generation Challenges"}, {"paperId": "892b1aabc0d5d92901dbedb6ab736a40239f38d3", "title": "Fairness-Aware Range Queries for Selecting Unbiased Data"}, {"paperId": "2e52bd43fec1a91aef5cf00c622ebe3d8dbd94e4", "title": "Reliability Evaluation of Individual Predictions: A Data-centric Approach"}, {"paperId": "a7a8ad822d6917e3950a4bd3d6fbf358d3a0de76", "title": "Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms"}, {"paperId": "0368102a9510ab93ab500322dbc7709b0a8a6e1b", "title": "Representation Bias in Data: A Survey on Identification and Resolution Techniques"}, {"paperId": "9a1f352ef21044700c180882038c28c3b2361914", "title": "Data collection and quality challenges in deep learning: a data-centric AI perspective"}, {"paperId": "6b827b800091fa7b1171b265846bf226cd92d3e2", "title": "Overview of Machine Learning Process Modelling"}, {"paperId": "c1816ce71d81cbcdc257661c5ff75f7004820f22", "title": "Mandoline: Model Evaluation under Distribution Shift"}, {"paperId": "0233cd95dd0bc327dd72a14d60216c98021250ab", "title": "Responsible AI Challenges in End-to-end Machine Learning"}, {"paperId": "d688594d2aac080f657b7be251e89cca6a7df165", "title": "FairBatch: Batch Selection for Model Fairness"}, {"paperId": "8bf51ba8963586ad35c83f2d3dd89f5e73dfd0eb", "title": "Blue Elephants Inspecting Pandas: Inspection and Execution of Machine Learning Pipelines in SQL"}, {"paperId": "f643a128d74328a04c37f408a5ba2a5e7dc107f2", "title": "A Survey on Techniques for Identifying and Resolving Representation Bias in Data"}, {"paperId": "bab43e9fb113570c36a17fc4dfd9cd61569ee5f9", "title": "Data-Centric Distrust Quantification for Responsible AI: When Data-driven Outcomes Are Not Reliable"}, {"paperId": "0b7be9a29d72e3217e33bf195ebaf1ee9513b91a", "title": "Data-centric Reliability Evaluation of Individual Predictions"}]}

{"paperId": "14407cec730dbdd19d01cccb9f03ca3fb682cdd7", "publicationVenue": {"id": "4e46790b-e240-4236-9b8d-a70ed74f900a", "name": "IEEE Transactions on Mobile Computing", "type": "journal", "alternate_names": ["IEEE Trans Mob Comput"], "issn": "1536-1233", "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=7755", "alternate_urls": ["http://www.computer.org/portal/web/tmc"]}, "title": "Computation and Communication Efficient Federated Learning With Adaptive Model Pruning", "abstract": "Federated learning (FL) has emerged as a promising distributed learning paradigm that enables a large number of mobile devices to cooperatively train a model without sharing their raw data. The iterative training process of FL incurs considerable computation and communication overhead. The workers participating in FL are usually heterogeneous and the workers with poor capabilities may become the bottleneck of model training. To address the challenges of resource overhead and system heterogeneity, this article proposes an efficient FL framework, called FedMP, that improves both computation and communication efficiency over heterogeneous workers through adaptive model pruning. We theoretically analyze the impact of pruning ratio on training performance, and employ a Multi-Armed Bandit based online learning algorithm to adaptively determine different pruning ratios for heterogeneous workers, even without any prior knowledge of their capabilities. As a result, each worker in FedMP can train and transmit the sub-model that fits its own capabilities, accelerating the training process without hurting model accuracy. To prevent the diverse structures of pruned models from affecting the training convergence, we further present a new parameter synchronization scheme, called Residual Recovery Synchronous Parallel (R2SP). Besides, our proposed framework can be extended to the peer-to-peer (P2P) setting. Extensive experiments on physical devices demonstrate that FedMP is effective for different heterogeneous scenarios and data distributions, and can provide up to 4.1\u00d7 speedup compared to the existing FL methods.", "venue": "IEEE Transactions on Mobile Computing", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-03-01", "journal": {"name": "IEEE Transactions on Mobile Computing", "pages": "2003-2021", "volume": "23"}, "authors": [{"authorId": "2143104467", "name": "Zhida Jiang"}, {"authorId": "2129093616", "name": "Yang Xu"}, {"authorId": "2155908613", "name": "Hong-Ze Xu"}, {"authorId": "2142008867", "name": "Zhiyuan Wang"}, {"authorId": "46700208", "name": "Jianchun Liu"}, {"authorId": "2210055296", "name": "Qian Chen"}, {"authorId": "2055528774", "name": "C. Qiao"}], "citations": [{"paperId": "2c859754f05887fc03765a893e39f231fa7912b8", "title": "Computation and Communication Efficient Lightweighting Vertical Federated Learning"}, {"paperId": "8eb0798c542015aec713969dd3b468a92bf53f4d", "title": "Knowledge Transfer via Compact Model in Federated Learning (Student Abstract)"}, {"paperId": "b8d1df7d98b2dc01a6a2c795f8cadfa2920dabfc", "title": "FedSPU: Personalized Federated Learning for Resource-constrained Devices with Stochastic Parameter Update"}, {"paperId": "3c185b5b318aaf036d15fce22c004ff397992a8f", "title": "Energy-Efficient Wireless Federated Learning via Doubly Adaptive Quantization"}, {"paperId": "31bb305eea7a5cb80fe6f3c5c8ef00ae701acb7c", "title": "Responsible and Effective Federated Learning in Financial Services: A Comprehensive Survey"}, {"paperId": "407d375249fe628ee350665a82f7aa1b455f3e7c", "title": "Heroes: Lightweight Federated Learning with Neural Composition and Adaptive Local Update in Heterogeneous Edge Networks"}, {"paperId": "88c7eda7ae8d6fc5d6df2c8fb7b42bedd525dcfd", "title": "MERGE: Meta Reinforcement Learning for Tunable RL Agents at the Edge"}, {"paperId": "5f7949093065d523aaa43036edbcdbedd061ba7b", "title": "TinyFL: A Lightweight Federated Learning Method with Efficient Memory-and-Communication"}, {"paperId": "dd9c530f7994d2f8d5ddc8684bef8ae8bd875774", "title": "Joint Model Pruning and Topology Construction for Accelerating Decentralized Machine Learning"}]}

{"paperId": "052fbae566b46bdb095d78aafa6b590489289ddc", "publicationVenue": {"id": "29df4b17-9a16-4a4c-94a6-002f52e628b4", "name": "International Conference on Parallel Processing", "type": "conference", "alternate_names": ["ICPP", "Int Conf Parallel Process", "IEEE Int Conf Pulsed Power", "IEEE International Conference on Pulsed Power"], "url": "http://www.wikicfp.com/cfp/program?id=1447"}, "title": "ROBOTune: High-Dimensional Configuration Tuning for Cluster-Based Data Analytics", "abstract": "Spark is popular for its ability to enable high-performance data analytics applications on diverse systems. Its great versatility is achieved through numerous user- and system-level options, resulting in an exponential configuration space that, ironically, hinders data analytics\u2019s optimal performance. The colossal complexity is caused by two main issues: the high dimensionality of configuration space and the expensive black-box configuration-performance relationship. In this paper, we design and develop a robust tuning framework called ROBOTune that can tackle both issues and tune Spark applications quickly for efficient data analytics. Specifically, it performs parameter selection through a Random Forests based model to reduce the dimensionality of analytics configuration space. In addition, ROBOTune employs Bayesian Optimization to overcome the complex nature of the configuration-performance relationship and balance exploration and exploitation to efficiently locate a globally optimal or near-optimal configuration. Furthermore, ROBOTune strengthens Latin Hypercube Sampling with caching and memoization to enhance the coverage and effectiveness in the generation of sample configurations. Our evaluation results demonstrate that ROBOTune finds similar or better performing configurations than contemporary tuning tools like BestConfig and Gunther while improving on search cost by 1.59 \u00d7 and 1.53 \u00d7 on average and up to 2.27 \u00d7 and 1.71 \u00d7 , respectively.", "venue": "International Conference on Parallel Processing", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2021-08-09", "journal": {"name": "Proceedings of the 50th International Conference on Parallel Processing"}, "authors": [{"authorId": "66145250", "name": "Md. Muhib Khan"}, {"authorId": "1709886", "name": "Weikuan Yu"}], "citations": [{"paperId": "c21546642283a980e780897061dc198d6632e9ca", "title": "EFTuner: A Bi-Objective Configuration Parameter Auto-Tuning Method Towards Energy-Efficient Big Data Processing"}, {"paperId": "96d3fac085b7f2396e4c99dc5f7db02eb9cb8588", "title": "TurBO: A cost-efficient configuration-based auto-tuning approach for cluster-based big data frameworks"}, {"paperId": "e0917b7f212261e01194b6eb6e190f1b66ce002b", "title": "ATConf: auto-tuning high dimensional configuration parameters for big data processing frameworks"}, {"paperId": "6e02f1dda7075f9a101d6557fd206c5ecf994377", "title": "DeepCAT: A Cost-Efficient Online Configuration Auto-Tuning Approach for Big Data Frameworks"}, {"paperId": "c00b4d2800e313a9b75fd6aa4ed1c3e6e3e9f909", "title": "JointConf: Jointly autotuning configuration parameters for modularized graph databases"}]}

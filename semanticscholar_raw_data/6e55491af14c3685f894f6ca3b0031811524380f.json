{"paperId": "6e55491af14c3685f894f6ca3b0031811524380f", "publicationVenue": {"id": "d13e941e-4cac-4f1d-bdca-77d927e31f1b", "name": "ACM Symposium on Cloud Computing", "type": "conference", "alternate_names": ["System-on-Chip Conference", "ACM Symp Cloud Comput", "Syst Conf", "Symp Cloud Comput", "Annual IEEE International System-on-Chip Conference", "Symposium on Cloud Computing", "Annu IEEE Int Syst Conf", "SoCC"], "url": "http://www.ieee-socc.org/"}, "title": "\u03bcConAdapter: Reinforcement Learning-based Fast Concurrency Adaptation for Microservices in Cloud", "abstract": "Modern web-facing applications such as e-commerce comprise tens or hundreds of distributed and loosely coupled microservices that promise to facilitate high scalability. While hardware resource scaling approaches [28] have been proposed to address response time fluctuations in critical microservices, little attention has been given to the scaling of soft resources (e.g., threads or database connections), which control hardware resource concurrency. This paper demonstrates that optimal soft resource allocation for critical microservices significantly impacts overall system performance, particularly response time. This suggests the need for fast and intelligent runtime reallocation of soft resources as part of microservices scaling management. We introduce \u03bcConAdapter, an intelligent and efficient framework for managing concurrency adaptation. It quickly identifies optimal soft resource allocations for critical microservices and adjusts them to mitigate violations of service-level objectives (SLOs). \u03bcConAdapter utilizes fine-grained online monitoring metrics from both the system and application levels and a Deep Q-Network (DQN) to quickly and adaptively provide optimal concurrency settings for critical microservices. Using six realistic bursty workload traces and two representative microservices-based benchmarks (SockShop and SocialNetwork), our experimental results show that \u03bcConAdapter can effectively mitigate large response time fluctuation and reduce the tail latency at the 99th percentile by 3\u00d7 on average when compared to the hardware-only scaling strategies like Kubernetes Autoscaling and FIRM [28], and by 1.6\u00d7 to the state-of-the-art concurrency-aware system scaling strategy like ConScale [21].", "venue": "ACM Symposium on Cloud Computing", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2023-10-30", "journal": {"name": "Proceedings of the 2023 ACM Symposium on Cloud Computing"}, "authors": [{"authorId": "48210810", "name": "Jianshu Liu"}, {"authorId": "21197444", "name": "Shungeng Zhang"}, {"authorId": "2264149424", "name": "Qingyang Wang"}], "citations": []}

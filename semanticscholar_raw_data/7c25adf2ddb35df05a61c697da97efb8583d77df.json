{"paperId": "7c25adf2ddb35df05a61c697da97efb8583d77df", "publicationVenue": {"id": "deedf64a-dd5c-4b33-b345-ff83bfb93d71", "name": "International Symposium on Computer Architecture", "type": "conference", "alternate_names": ["Int Symp Comput Archit", "ISCA"], "url": "http://www.cs.wisc.edu/~arch/www/"}, "title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings", "abstract": "In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x--7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus nearly 10x faster overall, which along with OCS flexibility and availability allows a large language model to train at an average of ~60% of peak FLOPS/second. For similar sized systems, it is ~4.3x--4.5x faster than the Graphcore IPU Bow and is 1.2x--1.7x faster and uses 1.3x--1.9x less power than the Nvidia A100. TPU v4s inside the energy-optimized warehouse scale computers of Google Cloud use ~2--6x less energy and produce ~20x less CO2e than contemporary DSAs in typical on-premise data centers.", "venue": "International Symposium on Computer Architecture", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2023-04-04", "journal": {"name": "Proceedings of the 50th Annual International Symposium on Computer Architecture"}, "authors": [{"authorId": "1715454", "name": "N. Jouppi"}, {"authorId": "1753079661", "name": "George Kurian"}, {"authorId": "2153701529", "name": "Sheng Li"}, {"authorId": "49735130", "name": "Peter C. Ma"}, {"authorId": "1395811464", "name": "R. Nagarajan"}, {"authorId": "2144577", "name": "Lifeng Nai"}, {"authorId": "2056800684", "name": "Nishant Patil"}, {"authorId": "1929462", "name": "Suvinay Subramanian"}, {"authorId": "1394189636", "name": "Andy Swing"}, {"authorId": "1762455", "name": "Brian Towles"}, {"authorId": "39660914", "name": "C. Young"}, {"authorId": "50177639", "name": "Xiaoping Zhou"}, {"authorId": "2109465503", "name": "Zongwei Zhou"}, {"authorId": "2052996328", "name": "David A. Patterson"}], "citations": [{"paperId": "99f40e5e8f8611bbcc6be796420ed1135a4377c3", "title": "Optical Circuit Switching Using REC-DFB Laser Array"}, {"paperId": "dbb89e29f18cbf011cc31d748503a3070cf1d544", "title": "Allo: A Programming Model for Composable Accelerator Design"}, {"paperId": "5a5db66b0077db5afc1190fc937c8154e9cbefc3", "title": "CUTE: A scalable CPU-centric and Ultra-utilized Tensor Engine for convolutions"}, {"paperId": "5addc092e4e2ccc9e04673762194db8075dde7cc", "title": "Bigger is not Always Better: Scaling Properties of Latent Diffusion Models"}, {"paperId": "46566ef7e51987cd101bf2b275c650cb3be21995", "title": "Human Alignment of Large Language Models through Online Preference Optimisation"}, {"paperId": "ad00723294c4c2b2e10eb3fc93591d2a54601ad7", "title": "Communication Optimization for Distributed Training: Architecture, Advances, and Opportunities"}, {"paperId": "7b4ca4d27c630fa4ed339eea116f9ba70a991f73", "title": "Reconfigurable inverse designed phase-change photonics"}, {"paperId": "93e6637d2a2a4dd126078d840133d6e0d7f5dd3f", "title": "Beyond Inference: Performance Analysis of DNN Server Overheads for Computer Vision"}, {"paperId": "704b8448c588dc0f15daf132b25e50d05635efee", "title": "LUTein: Dense-Sparse Bit-Slice Architecture With Radix-4 LUT-Based Slice-Tensor Processing Units"}, {"paperId": "505641490f56e0a0b67757a1f3a157bf5a62e97d", "title": "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing"}, {"paperId": "566bcda80a95c91e709dac12e34d042171b21d4a", "title": "Enabling Artificial Intelligence Supercomputers With Domain-Specific Networks"}, {"paperId": "d53fe76bd2795a19ddf52d012917782f6f6f2c1e", "title": "Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models"}, {"paperId": "4b033843e86a5746e486b5c26ed35a407d4d00e5", "title": "TeMPO: Efficient Time-Multiplexed Dynamic Photonic Tensor Core for Edge AI with Compact Slow-Light Electro-Optic Modulator"}, {"paperId": "20c1ddb08ea9a017b19bf014ef0ec0bf44927f0f", "title": "ForestColl: Efficient Collective Communications on Heterogeneous Network Fabrics"}, {"paperId": "4dd683e937acf12ddad5e4ac55f8ca8ce9b90b9a", "title": "Navigating the security landscape of large language models in enterprise information systems"}, {"paperId": "6d4a6e833a9852fa5e515727e0b5829a164669ea", "title": "Fast classical simulation of Harvard/QuEra IQP circuits"}, {"paperId": "fe2e81571e5b9021f6165433f90dc9a3a69f9368", "title": "Hypermultiplexed Integrated Tensor Optical Processor"}, {"paperId": "cf766291d3c534c7ef972af0ae22e6ca68449faa", "title": "ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters"}, {"paperId": "b12775806f607aa2415680630037f4ede509bc95", "title": "PartIR: Composing SPMD Partitioning Strategies for Machine Learning"}, {"paperId": "716cf8139313697caab4797ee8f8bf0c0494b0dd", "title": "Mathematical Algorithm Design for Deep Learning under Societal and Judicial Constraints: The Algorithmic Transparency Requirement"}, {"paperId": "ab6430312fb471b559ee4a388ac9c6a2397f445a", "title": "Flexible Systolic Array Platform on Virtual 2-D Multi-FPGA Plane"}, {"paperId": "398bb60aed5d51d2053349f4149c5f44257ff850", "title": "cedar: Composable and Optimized Machine Learning Input Data Pipelines"}, {"paperId": "a1ed287f3cea8aefe3964ab1eaa4ad0e0456a13e", "title": "High-speed emerging memories for AI hardware accelerators"}, {"paperId": "f9649d9eaec791118f12ba694134f72f6796b023", "title": "Neural Rendering and Its Hardware Acceleration: A Review"}, {"paperId": "930531445da6cb4b5056e39c5215964d6a2ddde1", "title": "Analysis of the Designs and Applications of AI Chip"}, {"paperId": "3e525c72d29c0f6a86dc4ebab673f5b3db069a0c", "title": "Gemini Pro Defeated by GPT-4V: Evidence from Education"}, {"paperId": "f6e7e8b96b8ce1f32973318b3b88bc54f6eb4ab7", "title": "GenCast: Diffusion-based ensemble forecasting for medium-range weather"}, {"paperId": "2385b5263646954287a2a2baf04bae5b969a45e1", "title": "DEAP: Design Space Exploration for DNN Accelerator Parallelism"}, {"paperId": "13261129251c9e8891cff02c3aee15c4df6a5630", "title": "Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems"}, {"paperId": "0a693f0355e4f6bd6cbc59fc1519e1de8b7fed53", "title": "A Trade-off Analysis of Replacing Proprietary LLMs with Open Source SLMs in Production"}, {"paperId": "fdbcf2db9fe5207716389407a211413d297c4536", "title": "Gemini: A Family of Highly Capable Multimodal Models"}, {"paperId": "ebe79e8347b5ad4f7497b0e110fcf8304ade4755", "title": "Energy-efficient Computation-In-Memory Architecture using Emerging Technologies"}, {"paperId": "97e1ee758069915f28cb3779e4ada73c477040b2", "title": "ESPN: Memory-Efficient Multi-Vector Information Retrieval"}, {"paperId": "848a3885a5a47fa47b05912d41f5c0cc9fe3a8c3", "title": "Benchmarking GPU Tensor Cores on General Matrix Multiplication Kernels through CUTLASS"}, {"paperId": "94e3badba15476a0f4058ab9066426e14fb06bf9", "title": "Training Chain-of-Thought via Latent-Variable Inference"}, {"paperId": "cc2099784e9b36cec19a1f43d8531d098288f4bf", "title": "Increased Compute Efficiency and the Diffusion of AI Capabilities"}, {"paperId": "996aeba5d6f66a33042f8c0a46204e5f7b3de657", "title": "An Efficient 3D Gaussian Representation for Monocular/Multi-view Dynamic Scenes"}, {"paperId": "78b2c84e4ead63c6b9488e7e8a5f0c8dc2fbb34b", "title": "GreenFPGA: Evaluating FPGAs as Environmentally Sustainable Computing Solutions"}, {"paperId": "75d71bd1aabfad39b6b0c46dd8c1a7d38ad0b37b", "title": "Fast Inner-Product Algorithms and Architectures for Deep Neural Network Accelerators"}, {"paperId": "8897958f289b70e15733fabd8c53b943ffadf94b", "title": "ReuseSense: With Great Reuse Comes Greater Efficiency; Effectively Employing Computation Reuse on General-Purpose CPUs"}, {"paperId": "59d705d702af640a178897f34397ab9aa026d0b1", "title": "Flexible silicon photonic architecture for accelerating distributed deep learning"}, {"paperId": "76d1781c8ae8c28841e4ba8ed226384eb6f77fd0", "title": "Sparsity-Preserving Differentially Private Training of Large Embedding Models"}, {"paperId": "3d13935886627982fc98971baa33d2f9f3115bff", "title": "Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small Scorer"}, {"paperId": "5c104f905fcacf390270f619f232a2ba4eb873f2", "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"}, {"paperId": "cba3ce5f66de25bc0cef94266cd1f6f3991ebf19", "title": "Exploring the benefits of using co-packaged optics in data center and AI supercomputer networks: a simulation-based analysis [Invited]"}, {"paperId": "1cd9910e1e67803e2b260ea388722985fbeb1c61", "title": "Two Watts is All You Need: Enabling In-Detector Real-Time Machine Learning for Neutrino Telescopes Via Edge Computing"}, {"paperId": "73d31d886ccf72a3a0de0fb343af8eced42a3616", "title": "Pipeline Parallelism for DNN Inference with Practical Performance Guarantees"}, {"paperId": "1ff01607323da0553eb4f125c19ee6c3cf8afb4e", "title": "On Graphs with Finite-Time Consensus and Their Use in Gradient Tracking"}, {"paperId": "f860de1c504d886f1fd22848459f08b56a35a30e", "title": "Klotski: DNN Model Orchestration Framework for Dataflow Architecture Accelerators"}, {"paperId": "a7712aae416914a31046e748027edf307be3ee45", "title": "Simultaneous and Heterogenous Multithreading"}, {"paperId": "d847c5b56335bb24ae585963b1ed02edea5cdac0", "title": "Heterogeneous Die-to-Die Interfaces: Enabling More Flexible Chiplet Interconnection Systems"}, {"paperId": "7d5bed3d0687489e48eff0d684d3489acb2eb219", "title": "Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges"}, {"paperId": "8385a3b3829c068afa0bbd2815d60bb15026e5fa", "title": "Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse Multi-DNN Workloads"}, {"paperId": "a6d4dcb3cf087c3dcfb3edf3665cd287b59fae80", "title": "Memory-Based Computing for Energy-Efficient AI: Grand Challenges"}, {"paperId": "be6e0f747c462c5195331f2ba1f00a8ec3c0542c", "title": "Exponential Quantum Communication Advantage in Distributed Learning"}, {"paperId": "3825a3e33ea64452a47ab0e62ed069e947ee23c6", "title": "Ingestion of Google Cloud Platform Data using Dataflow"}, {"paperId": "a399c4c0353cd05c81c25881d9e60cad9dc25721", "title": "MAD Max Beyond Single-Node: Enabling Large Machine Learning Model Acceleration on Distributed Systems"}, {"paperId": "b1e2abc63630f26be54a1931041e0f4eeb0434e0", "title": "Enabling Language Models to Implicitly Learn Self-Improvement"}, {"paperId": "97b79d1ea59890cc3b76b45ec3afc7f759f3f5c6", "title": "3D photonics for ultra-low energy, high bandwidth-density chip data links"}, {"paperId": "48322ec58f0042e1c71e20a63438d0a8f4681d38", "title": "TripLe: Revisiting Pretrained Model Reuse and Progressive Learning for Efficient Vision Transformer Scaling and Searching"}, {"paperId": "6d99a203b2d9105e94c0a5d6c23dfa904507b16d", "title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks"}, {"paperId": "3d70601902de3178e515f5d770869cea6e38a85c", "title": "Efficient All-to-All Collective Communication Schedules for Direct-Connect Topologies"}, {"paperId": "f5f68b15ac7d62b63f667a66a095a342b6866b3c", "title": "Efficient Data Representation Learning in Google-scale Systems"}, {"paperId": "ebbac9ff9454f55d836960b2f5c625cac8e7d6ca", "title": "Lightwave Fabrics: At-Scale Optical Circuit Switching for Datacenter and Machine Learning Systems"}, {"paperId": "a37d5620210276e47cf0c9dd2898c2a82c9d0422", "title": "Simple synthetic data reduces sycophancy in large language models"}, {"paperId": "30429a16068ac0328011dcec823ce1f20a2ee6f9", "title": "The Case for Domain-Specific Networks"}, {"paperId": "a5264aebd61fb9224fdc6e64132b3de072c119a6", "title": "HUGE: Huge Unsupervised Graph Embeddings with TPUs"}, {"paperId": "e5b20a75bceca92b46f683aad22c825451cdda3a", "title": "New trends in photonic switching and optical networking architectures for data centers and computing systems [Invited]"}, {"paperId": "7d2be483318eb68a3d0d130075e2ca809102fbaa", "title": "TPU as Cryptographic Accelerator"}, {"paperId": "8203fa3dad9a908785ccbf8738c73a7e83f80769", "title": "End-to-end differentiability and tensor processing unit computing to accelerate materials\u2019 inverse design"}, {"paperId": "d278692e07e0d13f88e199f451723d37209b10e5", "title": "EnergAt: Fine-Grained Energy Attribution for Multi-Tenancy"}, {"paperId": "f7928dc84176f4f48669b13b22adb88b87d49fc5", "title": "When Does Saving Power Save the Planet?"}, {"paperId": "fd6a61ced540fe543585a4db3ae0ccae8e3a4ced", "title": "Towards a Methodology and Framework for AI Sustainability Metrics"}, {"paperId": "88075bf281a2cec2a0af24af7197657ed5240ca7", "title": "Heterogeneous Reconfigurable Accelerators: Trends and Perspectives"}, {"paperId": "9a7a09a1884b1b76aa606918d879253277a4d448", "title": "Retrospective: A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing"}, {"paperId": "1079b2a414cd6349fb26b60fab9ae96e84c65280", "title": "Skadi: Building a Distributed Runtime for Data Systems in Disaggregated Data Centers"}, {"paperId": "2be406284aa18b6e0ff1a094f7707388c1bdd679", "title": "DGEMM on Integer Matrix Multiplication Unit"}, {"paperId": "18015df70c22f4771b0955b01eaf8921a46f976c", "title": "GRAP: Group-level Resource Allocation Policy for Reconfigurable Dragonfly Network in HPC"}, {"paperId": "01ba9e0be47e688aa36b759745bd32ba688d43c3", "title": "ArchGym: An Open-Source Gymnasium for Machine Learning Assisted Architecture Design"}, {"paperId": "b88f67e6a21a0e59405f25cf02b30991c64f3f24", "title": "DORSal: Diffusion for Object-centric Representations of Scenes et al"}, {"paperId": "83d1b5337b9c810e193587a432eb04bd6016ae8e", "title": "Augmenting Hessians with Inter-Layer Dependencies for Mixed-Precision Post-Training Quantization"}, {"paperId": "004abdbefd8b89f866728802f9c659ab2bdd3b63", "title": "M3ICRO: Machine Learning-Enabled Compact Photonic Tensor Core based on PRogrammable Multi-Operand Multimode Interference"}, {"paperId": "0d5469be6d35fb5819471bdfe231cb075971a8c3", "title": "Translatotron 3: Speech to Speech Translation with Monolingual Data"}, {"paperId": "d154833ad5b4b1853cfa3681a291e201b82a0c2e", "title": "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM"}, {"paperId": "874160247612834ef40e3e1302323173b5213f3a", "title": "Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems"}, {"paperId": "2183c88e9056e931b07d48f1dc44360785952073", "title": "SoundStorm: Efficient Parallel Audio Generation"}, {"paperId": "3db1219429c3f04e88347d41269bdc83c457fbf9", "title": "Symbol tuning improves in-context learning in language models"}, {"paperId": "5d76533f1503793067573dc8bd25b1e8d48f53af", "title": "TACOS: Topology-Aware Collective Algorithm Synthesizer for Distributed Machine Learning"}, {"paperId": "f4a62db4dd86129561a16b0a18cc09985580554c", "title": "FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead"}, {"paperId": "51e4602f9bdec3f0245bfe7979cac2028722fd29", "title": "Supporting Energy-Based Learning with an Ising Machine Substrate: A Case Study on RBM"}, {"paperId": "071d021ef9dcd83686d7b12bec2e13283b2f048f", "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision"}, {"paperId": "140d1b27effabea80d59d96776c309e16a2c65e6", "title": "GPU-based Private Information Retrieval for On-Device Machine Learning Inference"}, {"paperId": "60b49ed1fede7d4b8a6ef626dd00042249ccf8cf", "title": "COMET: A Comprehensive Cluster Design Methodology for Distributed Deep Learning Training"}, {"paperId": "9c8399c92592f09071030af70611421d90923856", "title": "tf.data service: A Case for Disaggregating ML Input Data Processing"}, {"paperId": "a16005cbea461ee0e31a6c7631bd136a43d40e82", "title": "Efficient Direct-Connect Topologies for Collective Communications"}, {"paperId": "e8baba95df964119eaa3ed16015e6be2c4c02936", "title": "Reliability evaluation for bijection-connected networks based on the super Pk-connectivity"}, {"paperId": "2b591e458d661c8fa7f8e5bca78fbc8666e2216e", "title": "Genetic Improvement of Last Level Cache"}, {"paperId": "e113fefcaff291dc5eef57d949a6dea9d0cb33ee", "title": "Reliable and Energy-Efficient Diabetic Retinopathy Screening Using Memristor-Based Neural Networks"}, {"paperId": "de7f2731370b97a1a1ba5f43092b2d01b7158765", "title": "RETROSPECTIVE: Energy Proportional Datacenter Networking"}, {"paperId": "c00696545d88f8d7411cf6eedcbcf5174941a1ec", "title": "Improve Model Inference Cost with Image Gridding"}, {"paperId": "7b72dab2d1a8a1d91b6b8ad5f9ddef71a0c29a0e", "title": "AlGhafa Evaluation Benchmark for Arabic Language Models"}, {"paperId": "c24c3606c0c581dc4512525a5ef41786fe43c29f", "title": "Scaling Down to Scale Up: A Cost-Benefit Analysis of Replacing OpenAI's GPT-4 with Self-Hosted Open Source SLMs in Production"}, {"paperId": "92a411a85e7d42e1f297f8495451f1f4b561ebc7", "title": "Leveraging Foundation Models for Scientific Research Productivity"}]}

{"paperId": "d6354e91d8dcf73bff50097b76a81de874f7bd7a", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "OceanGPT: A Large Language Model for Ocean Science Tasks", "abstract": "Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though comprehensive experiments, OceanGPT not only shows a higher level of knowledge expertise for oceans science tasks but also gains preliminary embodied intelligence capabilities in ocean technology. Codes, data and checkpoints will soon be available at https://github.com/zjunlp/KnowLM.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-03", "journal": {"name": "ArXiv", "volume": "abs/2310.02031"}, "authors": [{"authorId": "2059276046", "name": "Zhen Bi"}, {"authorId": "2153010067", "name": "Ningyu Zhang"}, {"authorId": "2256174722", "name": "Yida Xue"}, {"authorId": "2196928874", "name": "Yixin Ou"}, {"authorId": "2253464545", "name": "Daxiong Ji"}, {"authorId": "1706307", "name": "Guozhou Zheng"}, {"authorId": "2144200945", "name": "Huajun Chen"}], "citations": [{"paperId": "e31fc3fe4c838881682b9d155b1efb8c5a166a01", "title": "Interpretable Machine Learning for Weather and Climate Prediction: A Survey"}, {"paperId": "94db8a625418800c8ae7b48157a9cad1c8129051", "title": "A Survey on Knowledge Distillation of Large Language Models"}, {"paperId": "a1bbce2f5c62cb4a14998ea92a3d95e899eb48ac", "title": "BreakGPT: A Large Language Model with Multi-stage Structure for Financial Breakout Detection"}, {"paperId": "d839519477bd2f2055ec189f796bce578c578102", "title": "Foundation Models for Weather and Climate Data Understanding: A Comprehensive Survey"}, {"paperId": "777bf0028ca91b8a82df6042eeb3662341a21205", "title": "Enabling Large Language Models to Think Twice When Its Answer Is Unreliable: A Case Study In Cancer Screening"}, {"paperId": "59f319a326df236679fa012811aecef3eff7c37f", "title": "Bioinfo-Bench: A Simple Benchmark Framework for LLM Bioinformatics Skills Evaluation"}, {"paperId": "953ffb99bc943f7e983b5b413ba000d194256127", "title": "When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System"}]}

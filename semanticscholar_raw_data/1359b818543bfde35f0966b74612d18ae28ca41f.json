{"paperId": "1359b818543bfde35f0966b74612d18ae28ca41f", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "On Protecting the Data Privacy of Large Language Models (LLMs): A Survey", "abstract": "Large language models (LLMs) are complex artificial intelligence systems capable of understanding, generating and translating human language. They learn language patterns by analyzing large amounts of text data, allowing them to perform writing, conversation, summarizing and other language tasks. When LLMs process and generate large amounts of data, there is a risk of leaking sensitive information, which may threaten data privacy. This paper concentrates on elucidating the data privacy concerns associated with LLMs to foster a comprehensive understanding. Specifically, a thorough investigation is undertaken to delineate the spectrum of data privacy threats, encompassing both passive privacy leakage and active privacy attacks within LLMs. Subsequently, we conduct an assessment of the privacy protection mechanisms employed by LLMs at various stages, followed by a detailed examination of their efficacy and constraints. Finally, the discourse extends to delineate the challenges encountered and outline prospective directions for advancement in the realm of LLM privacy protection.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2024-03-08", "journal": {"name": "ArXiv", "volume": "abs/2403.05156"}, "authors": [{"authorId": "2279547784", "name": "Biwei Yan"}, {"authorId": "2260465411", "name": "Kun Li"}, {"authorId": "1959579140", "name": "Minghui Xu"}, {"authorId": "2290991648", "name": "Yueyan Dong"}, {"authorId": "2290728039", "name": "Yue Zhang"}, {"authorId": "2290872727", "name": "Zhaochun Ren"}, {"authorId": "2284865484", "name": "Xiuzhen Cheng"}], "citations": []}

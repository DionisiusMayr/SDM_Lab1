{"paperId": "af2bb3a28f95bb4ff5c6f26321a45c39be2b94ed", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Ginex: SSD-enabled Billion-scale Graph Neural Network Training on a Single Machine via Provably Optimal In-memory Caching", "abstract": "\n Graph Neural Networks (GNNs) are receiving a spotlight as a powerful tool that can effectively serve various inference tasks on graph structured data. As the size of real-world graphs continues to scale, the GNN training system faces a scalability challenge. Distributed training is a popular approach to address this challenge by scaling out CPU nodes. However, not much attention has been paid to\n disk-based\n GNN training, which can scale up the single-node system in a more cost-effective manner by leveraging high-performance storage devices like NVMe SSDs. We observe that the data movement between the main memory and the disk is the primary bottleneck in the SSD-based training system, and that the conventional GNN training pipeline is sub-optimal without taking this overhead into account. Thus, we propose Ginex, the first SSD-based GNN training system that can process billion-scale graph datasets on a single machine. Inspired by the inspector-executor execution model in compiler optimization, Ginex restructures the GNN training pipeline by separating\n sample\n and\n gather\n stages. This separation enables Ginex to realize a provably optimal replacement algorithm, known as\n Belady's algorithm\n , for caching feature vectors in memory, which account for the dominant portion of I/O accesses. According to our evaluation with four billion-scale graph datasets and two GNN models, Ginex achieves 2.11X higher training throughput on average (2.67X at maximum) than the SSD-extended PyTorch Geometric.\n", "venue": "Proceedings of the VLDB Endowment", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-07-01", "journal": {"name": "ArXiv", "volume": "abs/2208.09151"}, "authors": [{"authorId": "1504704369", "name": "Yeonhong Park"}, {"authorId": "2165576754", "name": "Sunhong Min"}, {"authorId": "66152513", "name": "Jae W. Lee"}], "citations": [{"paperId": "5a0a03d020e18b2e44f1f39db046119420d7037d", "title": "FlashGNN: An In-SSD Accelerator for GNN Training"}, {"paperId": "48c35e8cfa7ac7e24c448fb21154151097e4f184", "title": "Celeritas: Out-of-Core Based Unsupervised Graph Neural Network via Cross-Layer Computing 2024"}, {"paperId": "ffb06f4691b2e3f841e698df09d2237705efa262", "title": "BeaconGNN: Large-Scale GNN Acceleration with Out-of-Order Streaming In-Storage Computing"}, {"paperId": "549d440dd1a8f54fb9022b47118685c1c4885f17", "title": "ADGNN: Towards Scalable GNN Training with Aggregation-Difference Aware Sampling"}, {"paperId": "fe363b831be5132454ec358421496fb072747aae", "title": "NeutronStream: A Dynamic GNN Training Framework with Sliding Window for Graph Streams"}, {"paperId": "1cc2fb8f359e266bf232380ef09195a6f537dae8", "title": "TT-GNN: Efficient On-Chip Graph Neural Network Training via Embedding Reformation and Hardware Optimization"}, {"paperId": "2a72d9a7f8a3c4740fc75b8e62a6648189fb8f19", "title": "Barad-dur: Near-Storage Accelerator for Training Large Graph Neural Networks"}, {"paperId": "51cde01d005f61c7f545c8789d0b407fbde72d2e", "title": "Cooperative Minibatching in Graph Neural Networks"}, {"paperId": "c07cf05a0fa90fa6207aa07912131646198066e0", "title": "Helios: An Efficient Out-of-core GNN Training System on Terabyte-scale Graphs with In-memory Performance"}, {"paperId": "b07deb1cadf89d3b578f4ff78d718bb01bf2d315", "title": "Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses"}, {"paperId": "fcfbad2a3df0bea145cede61299ca361e1b2140c", "title": "BatchGNN: Efficient CPU-Based Distributed GNN Training on Very Large Graphs"}, {"paperId": "5b36dfc37ae7149936ad05e6575800dece051630", "title": "Design and Implementation of External Storage Large-Scale Graph Computing System"}, {"paperId": "4503f23afe2e6c38a0953e1baa40c2ea040db3d0", "title": "Performance Characterization of Modern Storage Stacks: POSIX I/O, libaio, SPDK, and io_uring"}, {"paperId": "a89f2cb72006e9ddc3a1cec6486a82c923777798", "title": "Distributed Graph Embedding with Information-Oriented Random Walks"}]}

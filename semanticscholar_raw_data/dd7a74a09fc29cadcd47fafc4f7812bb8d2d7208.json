{"paperId": "dd7a74a09fc29cadcd47fafc4f7812bb8d2d7208", "publicationVenue": {"id": "41bf9ed3-85b3-4c90-b015-150e31690253", "name": "Conference on Empirical Methods in Natural Language Processing", "type": "conference", "alternate_names": ["Empir Method Nat Lang Process", "Empirical Methods in Natural Language Processing", "Conf Empir Method Nat Lang Process", "EMNLP"], "url": "https://www.aclweb.org/portal/emnlp"}, "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values", "abstract": "Human feedback is increasingly used to steer the behaviours of Large Language Models (LLMs). However, it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values. In this paper, we survey existing approaches for learning from human feedback, drawing on 95 papers primarily from the ACL and arXiv repositories.First, we summarise the past, pre-LLM trends for integrating human feedback into language models. Second, we give an overview of present techniques and practices, as well as the motivations for using feedback; conceptual frameworks for defining values and preferences; and how feedback is collected and from whom. Finally, we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference", "Review"], "publicationDate": "2023-10-11", "journal": {"name": "ArXiv", "volume": "abs/2310.07629"}, "authors": [{"authorId": "90729626", "name": "Hannah Rose Kirk"}, {"authorId": "2242554313", "name": "Andrew M. Bean"}, {"authorId": "2737827", "name": "Bertie Vidgen"}, {"authorId": "2043232919", "name": "Paul R\u00f6ttger"}, {"authorId": "1741886127", "name": "Scott A. Hale"}], "citations": [{"paperId": "5bd44a34457d3f323eea4d961dd762003be3961d", "title": "Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models"}, {"paperId": "f6bd2c1f111eee0f6c6ddd90a87606d350f96f2f", "title": "LLMs with Industrial Lens: Deciphering the Challenges and Prospects - A Survey"}, {"paperId": "7ae48b24cbf955bf9b9498fb287bf4c5cd3b73d4", "title": "OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning"}, {"paperId": "b90abcfbc391c606206b4d32c3887292f0fd3226", "title": "Professional Agents - Evolving Large Language Models into Autonomous Experts with Human-Level Competencies"}, {"paperId": "bff3dc34477ac2d10477cdd37c8e71d5688c40dd", "title": "The Empty Signifier Problem: Towards Clearer Paradigms for Operationalising \"Alignment\" in Large Language Models"}, {"paperId": "daa5df014ad89aebc0dfcec507eccbbf3934224e", "title": "Decolonial AI Alignment: Openness, Vi\\'{s}e\\d{s}a-Dharma, and Including Excluded Knowledges"}]}

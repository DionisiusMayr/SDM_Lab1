{"paperId": "80c1bceba2932fa8f73d7dd64be6225a5c19287c", "publicationVenue": null, "title": "Integration of the Big Data Environment in a Financial Sector Entity to Optimize Products, Services and Decision-Making", "abstract": "- This article describes the integration from big data environment in the management of products and services from a banking entity with optimizing financial products and decision-making. Actually, there are many financial entities where their different business areas have isolated databases, causing greater consumption of computer resources, maintainability and, in many cases, process delays. This problem becomes critical specially if there is a transnational company because data needs can vary geographically despite being the same functional area. The Data Architecture area proposed guidelines such as centralizing information in a big data environment, ensuring progressive accessibility from users for new financial analytics initiatives and thereby reducing isolated data. The agile, Scrum framework supported the advanced analytics pilot which comprising developments in the data ingestion layer (data lake) through the distributed processing from Apache Spark; and information consumption through Sandboxes, which one, users performing the analysis, visualization and prediction from data. Abstract- This article describes the integration from big data environment in the management of products and services from a banking entity with optimizing financial products and decision-making. Actually, there are many financial entities where their different business areas have isolated databases, causing greater consumption of computer resources, maintainability and, in many cases, process delays. This problem becomes critical specially if there is a transnational company because data needs can vary geographically despite being the same functional area. The Data Architecture area proposed guidelines such as centralizing information in a big data environment, ensuring progressive accessibility from users for new financial analytics initiatives and thereby reducing isolated data. The agile, Scrum framework supported the advanced analytics pilot which comprising developments in the data ingestion layer (data lake) through the distributed processing from Apache Spark; and information consumption through Sandboxes, which one, users performing the analysis, visualization and prediction from data. All this framed in stages such as: Geographical Diagnosis, Platform Validation, Design and Development of the Pilot.", "venue": "", "year": 2022, "fieldsOfStudy": null, "publicationTypes": null, "publicationDate": null, "journal": null, "authors": [{"authorId": "2104924310", "name": "Ulises Rom\u00e1n Concha"}, {"authorId": "2176892078", "name": "Jos\u00e9 Huapaya V\u00e1squez"}, {"authorId": "2288930062", "name": "Guilllermo Pastor"}, {"authorId": "2289822817", "name": "Morales Romero"}, {"authorId": "2254074880", "name": "Dominga M. Cano"}, {"authorId": "2289078398", "name": "Ccoa. This"}, {"authorId": "2176892197", "name": "Dominga Cano Ccoa"}], "citations": []}

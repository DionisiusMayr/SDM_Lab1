{"paperId": "2df8ebae18c223e4fef965f8eecaa10d2544c3e2", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Flare & Lantern: Efficiently Swapping Horses Midstream", "abstract": "Running machine learning (ML) workloads at scale is as much a data management problem as a model engineering problem. Big performance challenges exist when data management systems invoke ML classi \ufb01 ers as user-de \ufb01 ned functions (UDFs) or when stand-alone ML frameworks interact with data stores for data loading and pre-processing (ETL). In particular, UDFs can be precompiled or simply a black box for the data management system and the data layout may be completely di \ufb00 erent from the native layout, thus adding overheads at the boundaries. In this demo, we will show how bottlenecks between existing systems can be eliminated when their engines are designed around runtime compilation and native code generation, which is the case for many state-of-the-art relational engines as well as ML frameworks. We demonstrate an integration of Flare (an accelerator for Spark SQL), and Lantern (an accelerator for TensorFlow and PyTorch) that results in a highly optimized end-to-end compiled data path, switching between SQL and ML processing with negligible overhead.", "venue": "Proceedings of the VLDB Endowment", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-08-01", "journal": {"name": "Proc. VLDB Endow.", "pages": "1910-1913", "volume": "12"}, "authors": [{"authorId": "9931980", "name": "Gr\u00e9gory M. Essertel"}, {"authorId": "21527679", "name": "Ruby Y. Tahboub"}, {"authorId": "2148955949", "name": "Fei Wang"}, {"authorId": "117235241", "name": "James M. Decker"}, {"authorId": "1712987", "name": "Tiark Rompf"}], "citations": [{"paperId": "a72c5ff8bb28397049dfd49831d3208ed94fe4c2", "title": "Architecting Intermediate Layers for Efficient Composition of Data Management and Machine Learning Systems"}, {"paperId": "f00691e0fc7a8cda9d89937dd52f1c290229f855", "title": "Towards A Polyglot Framework for Factorized ML"}, {"paperId": "1200c9ecb97a84ab136290f69c6f6294f6f51aee", "title": "Architecting a Query Compiler for Spatial Workloads"}, {"paperId": "6c73be8cb4b89699afc94d7f5e79b023ae7b6809", "title": "Modularis: Modular Relational Analytics over Heterogeneous Distributed Platforms"}, {"paperId": "5c573e77829a606008bcb2bd0737b93cef3a5a5b", "title": "Modularis: Modular Data Analytics for Hardware, Software, and Platform Heterogeneity"}]}

{"paperId": "82613be05470a0afdbd267907aea130e5b7335b1", "publicationVenue": {"id": "146869d7-bc08-4ccf-89c8-2aba81d32bde", "name": "ACM Journal of Data and Information Quality", "type": "journal", "alternate_names": ["Journal of Data and Information Quality", "J Data Inf Qual", "ACM J Data Inf Qual"], "issn": "1936-1963", "url": "https://dl.acm.org/citation.cfm?id=J1191&picked=prox", "alternate_urls": ["https://dl.acm.org/loi/jdiq", "https://jdiq.acm.org/", "http://portal.acm.org/jdiq"]}, "title": "Pipeline Design for Data Preparation for Social Media Analysis", "abstract": "In a data-driven culture, in which analytics applications are the main resources for supporting decision-making, the use of high-quality datasets is mandatory to minimize errors and risks. For this reason, data analysis tasks need to be preceded by a data preparation pipeline. The design of such a pipeline is not trivial: the data analyst must carefully choose the appropriate operations considering several aspects. This is often performed by adopting a trial-and-error approach that does not always lead to the most effective solution. In addition, extracting information from social media poses specific problems due to the need to consider only posts relevant for the analysis, for its dependence from the context being considered, for its multimedia contents, and for the risk of filtering out informative posts with automatic filters. In this article, we propose a systematic approach to support the design of pipelines that are able to effectively extract a relevant dataset for the goal of the analysis of data from social media. We provide a conceptual model for designing and annotating the data preparation pipeline with quality and performance information, thus providing the data analyst preliminary information on the expected quality of the resulting dataset in a context-aware manner. The generation of metadata related to the processing tasks has been recognized as essential for enabling data sharing and reusability. To this aim, the dataset resulting from the pipeline application is automatically annotated with provenance metadata to get a detailed description of all the activities performed by the pipeline on them. As a case study, we consider the design of a pipeline for creating datasets of images extracted from social media in order to analyze behavioural aspects during COVID-19.", "venue": "ACM Journal of Data and Information Quality", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-05-20", "journal": {"name": "ACM Journal of Data and Information Quality", "pages": "1 - 25", "volume": "15"}, "authors": [{"authorId": "2089560502", "name": "C. Bono"}, {"authorId": "1723724", "name": "C. Cappiello"}, {"authorId": "1747714", "name": "B. Pernici"}, {"authorId": "1404443962", "name": "Edoardo Ramalli"}, {"authorId": "143686989", "name": "Monica Vitali"}], "citations": []}

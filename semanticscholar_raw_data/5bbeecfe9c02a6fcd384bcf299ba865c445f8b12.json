{"paperId": "5bbeecfe9c02a6fcd384bcf299ba865c445f8b12", "publicationVenue": {"id": "c2abee38-d372-4e2a-ac1e-2cd22999a564", "name": "Conference on Automated Knowledge Base Construction", "type": "conference", "alternate_names": ["AKBC", "Conf Autom Knowl Base Constr", "Automated Knowledge Base Construction", "Autom Knowl Base Constr"], "url": "https://www.akbc.ws/"}, "title": "Scalable Rule Learning in Probabilistic Knowledge Bases", "abstract": "Knowledge Bases (KBs) are becoming increasingly large, sparse and probabilistic. These KBs are typically used to perform query inferences and rule mining. But their efficacy is only as high as their completeness. Efficiently utilizing incomplete KBs remains a major challenge as the current KB completion techniques either do not take into account the inherent uncertainty associated with each KB tuple or do not scale to large KBs. Probabilistic rule learning not only considers the probability of every KB tuple but also tackles the problem of KB completion in an explainable way. For any given probabilistic KB, it learns probabilistic first-order rules from its relations to identify interesting patterns. But, the current probabilistic rule learning techniques perform grounding to do probabilistic inference for evaluation of candidate rules. It does not scale well to large KBs as the time complexity of inference using grounding is exponential over the size of the KB. In this paper, we present SafeLearner -- a scalable solution to probabilistic KB completion that performs probabilistic rule learning using lifted probabilistic inference -- as faster approach instead of grounding. We compared SafeLearner to the state-of-the-art probabilistic rule learner ProbFOIL+ and to its deterministic contemporary AMIE+ on standard probabilistic KBs of NELL (Never-Ending Language Learner) and Yago. Our results demonstrate that SafeLearner scales as good as AMIE+ when learning simple rules and is also significantly faster than ProbFOIL+.", "venue": "Conference on Automated Knowledge Base Construction", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-05-02", "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "118046681", "name": "Arcchit Jain"}, {"authorId": "47009206", "name": "Tal Friedman"}, {"authorId": "1798442", "name": "Ond\u0159ej Ku\u017eelka"}, {"authorId": "1749506", "name": "Guy Van den Broeck"}, {"authorId": "1740042", "name": "L. D. Raedt"}], "citations": [{"paperId": "4a29b831e16871526592119aad4a590649572a41", "title": "Logical Entity Representation in Knowledge-Graphs for Differentiable Rule Learning"}, {"paperId": "bb3810f6d11ef22baa7574bb4b552f60d9deb92b", "title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding"}, {"paperId": "2bc668bd1eb505c7a6d5370224371f6a7230ca54", "title": "Probabilistic Rule Learning Systems"}, {"paperId": "9761fe88bcfcbafdb6869182444be4bf2b6c6420", "title": "A Generative Symbolic Model for More General Natural Language Understanding and Reasoning"}]}

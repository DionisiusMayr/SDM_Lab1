{"paperId": "f200d3d74e27aca508cc0a264998396d3d961841", "publicationVenue": {"id": "fbbafe0e-5e14-431f-9456-f569300a37cb", "name": "IEEE Open Journal of the Communications Society", "type": "journal", "alternate_names": ["IEEE Open J Commun Soc"], "issn": "2644-125X", "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8782661"}, "title": "Intelligent Resource Management Using Multiagent Double Deep Q-Networks to Guarantee Strict Reliability and Low Latency in IoT Network", "abstract": "With the rapid adoption of the Internet of Things, it is necessary to go beyond fifth-generation applications and apply stringent high reliability and low latency requirements, closely related to strict delay demands. These requirements support massive network connectivity for multiple Internet of Things devices. Hence, in this paper, we optimize energy efficiency and achieve quality-of-service requirements by mitigating co-channel interference, performing efficient power control of transmitters, and harvesting energy using time-slot exchanges. Due to a nonconvex optimization problem, we propose an iterative algorithm for power allocation and time slot interchange to reduce the computational complexity. To achieve a high degree of ultra-reliability and low latency with quality-of-service-aware instantaneous reward under massive connectivity, we efficiently employ multiagent reinforcement learning by addressing the intelligent resource management problem via a novel Double Deep Q Network. The network prioritizes experience replay to exploit the best policy and maximize accumulative rewards. It also learns the optimal policy and enhances learning efficiency by maximizing its reward function to make decisions with high intelligence and guarantee strict ultra-reliability and low latency. The simulation result shows that the Double Deep Q Network with prioritized experience replay can guarantee stringent ultra-reliability and low latency. As a result, the co-channel interference between transmission links and the high-power consumption density associated with the massive connectivity of the Internet of Things devices are mitigated.", "venue": "IEEE Open Journal of the Communications Society", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal": {"name": "IEEE Open Journal of the Communications Society", "pages": "2245-2257", "volume": "3"}, "authors": [{"authorId": "2087062609", "name": "A. Salh"}, {"authorId": "2086245", "name": "R. Ngah"}, {"authorId": "66892901", "name": "G. Hussain"}, {"authorId": "1874985", "name": "L. Audah"}, {"authorId": "9287356", "name": "Mohammed A. Alhartomi"}, {"authorId": "123456218", "name": "Qazwan Abdullah  (\u063a\u0632\u0648\u0627\u0646 \u0639\u0628\u062f \u0627\u0644\u0644\u0647 \u0645\u062d\u0645\u062f \u0637\u0631\u0628\u0648\u0634)"}, {"authorId": "9744391", "name": "Ruwaybih Alsulami"}, {"authorId": "2191828964", "name": "Saeed Alzahrani"}, {"authorId": "31519499", "name": "Ahmed Alzahmi"}], "citations": [{"paperId": "718b20c958691fa86cde23cf157ed2d5600ea17f", "title": "Spectrum Efficiency Enhancement for Cell-Free Massive MIMO Through Large-Scale Fading"}, {"paperId": "5628698baa616cbf1c7efefc4acb1a1096474be2", "title": "Mutated Deep Reinforcement Learning Scheduling in Cloud for Resource-Intensive IoT Systems"}, {"paperId": "fb7216f743dceef4cc699ac45b81d9240fd6a492", "title": "New Reward-Clipping Mechanism in Deep -Learning Enabled Internet of Things in 6G to Improve Intelligent Transmission Scheduling"}, {"paperId": "68d206ae53d7db2e24d53d2b5a91571dccd47416", "title": "One-Bit Massive MIMO Precoding Using Unsupervised Deep Learning"}, {"paperId": "bf1c888efa4726f045492ccceff489b5209c38e8", "title": "D2D Cooperative Communication Network Resource Allocation Algorithm Based on Improved Monte Carlo Tree Search"}]}

{"paperId": "4f55b94b6cd7b8fa20908b6941f493ded8e844be", "publicationVenue": null, "title": "BoPF: Mitigating the Burstiness-Fairness Tradeoff in Multi-Resource Clusters", "abstract": "Even though batch, interactive, and streaming applications all care about performance, their notions of performance are different. For instance, while the average completion time can suffciently capture the performance of a throughout-sensitive batch-job queue (TQ) [5], interactive sessions and streaming applications form latencysensitive queues (LQ): each LQ is a sequence of small jobs following an ON-OFF pattern. For these jobs [7], individual completion times or latencies are far more important than the average completion time or the throughput of the LQ.\n Indeed, existing \"fair\" schedulers are inherently unfair to LQ jobs: when LQ jobs are present (ON state), they must share the resources equally with TQ jobs, but when they are absent (OFF state), batch jobs get all the resources. In the long run, TQs receive more resources than their fair shares because today's schedulers such as Dominant Resource Fairness [4] make instantaneous decisions\n Clearly, it is impossible to achieve the best response time for LQ jobs under instantaneous fairness. In other words, there is a hard tradeoff between providing instantaneous fairness for TQs and minimizing the response time of LQs. However, instantaneous fairness is not necessary for TQs because average-completion time over a relatively long time horizon is their most important metric. This sheds light on the following question: how well can we simultaneously accommodate multiple classes of workloads with performance guarantees, in particular, isolation protection for TQs in terms of long-term fairness and low response times for LQs?\n This work serves as our first step in answering the question by designing BoPF: the first multi-resource scheduler that achieves both isolation protection for TQs and response time guarantees for LQs in a strategyproof way. The key idea is \"bounded\" priority for LQs: as long as the burst is not too large to hurt the long-term fair share of TQs and other LQs, they are given higher priority so jobs can be completed as quickly as possible.", "venue": "PERV", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-01-18", "journal": {"name": "ArXiv", "volume": "abs/1912.03523"}, "authors": [{"authorId": "2171919", "name": "T. Le"}, {"authorId": "2112349803", "name": "Xiao Sun"}, {"authorId": "2288980934", "name": "Mosharaf Chowdhury"}, {"authorId": "2109071234", "name": "Zhenhua Liu"}], "citations": [{"paperId": "ba30893b6489a4b4d8e972e0e45c807e36f23555", "title": "Adaptive Performance Modeling of Data-intensive Workloads for Resource Provisioning in Virtualized Environment"}, {"paperId": "25baa24a18d8cb38cf7e0ff0647985fc16167030", "title": "Flex: Closing the Gaps between Usage and Allocation"}, {"paperId": "6ca5fd549f84c92778cc0b2832b46295d97e2bab", "title": "AlloX: compute allocation in hybrid clusters"}]}

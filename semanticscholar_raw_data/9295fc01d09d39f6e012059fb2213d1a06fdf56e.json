{"paperId": "9295fc01d09d39f6e012059fb2213d1a06fdf56e", "publicationVenue": {"id": "42ad1c65-dc2f-448c-bbbf-483b016441b3", "name": "USENIX Workshop on Hot Topics in Cloud Computing", "type": "conference", "alternate_names": ["USENIX conference on Hot Topics in Cloud Ccomputing", "USENIX Workshop Hot Top Cloud Comput", "HotCloud", "USENIX conf Hot Top Cloud Ccomputing"]}, "title": "DLion: Decentralized Distributed Deep Learning in Micro-Clouds", "abstract": "Deep learning (DL) is a popular technique for building models from large quantities of data such as pictures, videos, messages generated from edges devices at rapid pace all over the world. It is often infeasible to migrate large quantities of data from the edges to centralized data center(s) over WANs for training due to privacy, cost, and performance reasons. At the same time, training large DL models on edge devices is infeasible due to their limited resources. An attractive alternative for DL training distributed data is to use micro-clouds---small-scale clouds deployed near edge devices in multiple locations. However, micro-clouds present the challenges of both computation and network resource heterogeneity as well as dynamism. In this paper, we introduce DLion, a new and generic decentralized distributed DL system designed to address the key challenges in micro-cloud environments, in order to reduce overall training time and improve model accuracy. We present three key techniques in DLion: (1) Weighted dynamic batching to maximize data parallelism for dealing with heterogeneous and dynamic compute capacity, (2) Per-link prioritized gradient exchange to reduce communication overhead for model updates based on available network capacity, and (3) Direct knowledge transfer to improve model accuracy by merging the best performing model parameters. We build a prototype of DLion on top of TensorFlow and show that DLion achieves up to 4.2X speedup in an Amazon GPU cluster, and up to 2X speed up and 26% higher model accuracy in a CPU cluster over four state-of-the-art distributed DL systems.", "venue": "USENIX Workshop on Hot Topics in Cloud Computing", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle"], "publicationDate": "2020-06-21", "journal": {"name": "Proceedings of the 30th International Symposium on High-Performance Parallel and Distributed Computing"}, "authors": [{"authorId": "50875719", "name": "Rankyung Hong"}, {"authorId": "144114650", "name": "A. Chandra"}], "citations": [{"paperId": "5fd1ba8e9b9350772551539fee557cff3d9f0bcf", "title": "H-EYE: Holistic Resource Modeling and Management for Diversely Scaled Edge-Cloud Systems"}, {"paperId": "80eb1e5c00dfad529364cf254f2a4022ca8464ad", "title": "NBSync: Parallelism of Local Computing and Global Synchronization for Fast Distributed Machine Learning in WANs"}, {"paperId": "ce573c7fa7f01d16c873f494e5c1140518b9b4f2", "title": "CLUE: Systems Support for Knowledge Transfer in Collaborative Learning With Neural Nets"}, {"paperId": "ba6261f420bff7ae659ac56d797f014fc2061669", "title": "FedGSync: Jointly Optimized Weak Synchronization and Gradient Transmission for Fast Distributed Machine Learning in Heterogeneous WAN"}, {"paperId": "f436f4186fc2dd14e803470c621618af849f1e30", "title": "Collaborative Learning-Based Scheduling for Kubernetes-Oriented Edge-Cloud Network"}, {"paperId": "fe81557cb5e2d67303528f0139f75daf300334ba", "title": "AggFirstJoin: Optimizing Geo-Distributed Joins using Aggregation-Based Transformations"}, {"paperId": "e87e6f758f765cdcbbc25766206f77de3e4ca4b1", "title": "Security Issues and Mitigation Mechanisms in Distributed Systems"}, {"paperId": "bb7bdcf77515d1d80e78a16f595a366914f238df", "title": "Cost-Efficient Scheduling of Multicast Transfers With Deadline Guarantees Across Edge Datacenters"}, {"paperId": "e72eee3fe4163c7191b79079ce8e1f583f781892", "title": "Accelerating model synchronization for distributed machine learning in an optical wide area network"}, {"paperId": "0fd63ff4cf47335b6d3d47969f9d9c393bb4fa1a", "title": "Making distributed edge machine learning for resource-constrained communities and environments smarter: contexts and challenges"}, {"paperId": "3f8b640be2b897774819775f86117895051a02c9", "title": "HACCS: Heterogeneity-Aware Clustered Client Selection for Accelerated Federated Learning"}, {"paperId": "c6002247dee39ff91db2b646d8f2dd375cbb0a43", "title": "Towards WAN-aware join sampling over geo-distributed data"}, {"paperId": "af2b4938c5e2233ee510ce972c4c7c3733656cef", "title": "Distributed intelligence on the Edge-to-Cloud Continuum: A systematic literature review"}, {"paperId": "fa80e5a26bbbdf422259bb516cefeab535c383da", "title": "Canoe : A System for Collaborative Learning for Neural Nets"}, {"paperId": "8c68ba842187073049e5f81001f65725ca5383a2", "title": "On the Future of Cloud Engineering"}, {"paperId": "24a153faeaf432efef1efc4e238b015d9cf716dd", "title": "Investigations on optimizing performance of the distributed computing in heterogeneous environment using machine learning technique for large scale data set"}, {"paperId": "3aa42091f9080c1583343f75e9262a237afcaa6b", "title": "Recommender System for Optimal Distributed Deep Learning in Cloud Datacenters"}, {"paperId": "c3455699f6c05400237b6e1bf1c96fa002969cae", "title": "Job scheduling for distributed machine learning in optical WAN"}, {"paperId": "1dcd3ce2221eff4213487249978f7ec844f1c611", "title": "Communication-efficient Decentralized Machine Learning over Heterogeneous Networks"}, {"paperId": "c8fed8830caf52edea31a2ba040b86516cdaa4ec", "title": "Extending reference architecture of big data systems towards machine learning in edge computing environments"}, {"paperId": "58683a69809cf1eec4e2a379b7f01b71a8809dff", "title": "Cost-Efficient and Skew-Aware Data Scheduling for Incremental Learning in 5G Networks"}, {"paperId": "e7dd73e84efa11f0b0bc7654c93f7fc19058f5d0", "title": "Prague: High-Performance Heterogeneity-Aware Asynchronous Decentralized Training"}, {"paperId": "a5be61badb1bf38b020872d5603c0681aee3aad3", "title": "Beyond Edge Cloud: Distributed Edge Computing"}, {"paperId": "73bf2ea6986511cc7282a2f01ec213063dd257be", "title": "Heterogeneity-Aware Asynchronous Decentralized Training"}]}

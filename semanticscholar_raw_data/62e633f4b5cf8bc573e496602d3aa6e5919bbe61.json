{"paperId": "62e633f4b5cf8bc573e496602d3aa6e5919bbe61", "publicationVenue": {"id": "bdc2e585-4e48-4e36-8af1-6d859763d405", "name": "AAAI Conference on Artificial Intelligence", "type": "conference", "alternate_names": ["National Conference on Artificial Intelligence", "National Conf Artif Intell", "AAAI Conf Artif Intell", "AAAI"], "url": "http://www.aaai.org/"}, "title": "Improving Automatic VQA Evaluation Using Large Language Models", "abstract": "8 years after the visual question answering (VQA) task was proposed, accuracy remains the primary metric for automatic evaluation. VQA Accuracy has been effective so far in the IID evaluation setting. However, our community is undergoing a shift towards open-ended generative models and OOD evaluation. In this new paradigm, the existing VQA Accuracy metric is overly stringent and underestimates the performance of VQA systems. Thus, there is a need to develop more robust automatic VQA metrics that serve as a proxy for human judgment. In this work, we propose to leverage the in-context learning capabilities of instruction-tuned large language models (LLMs) to build a better VQA metric. We formulate VQA evaluation as an answer-rating task where the LLM is instructed to score the accuracy of a candidate answer given a set of reference answers. We demonstrate the proposed metric better correlates with human judgment compared to existing metrics across several VQA models and benchmarks. We hope wide adoption of our metric will contribute to better estimating the research progress on the VQA task. We plan to release the evaluation code and collected human judgments.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-10-04", "journal": {"pages": "4171-4179"}, "authors": [{"authorId": "1796269096", "name": "Oscar Ma\u00f1as"}, {"authorId": "1994697809", "name": "Benno Krojer"}, {"authorId": "2801949", "name": "Aishwarya Agrawal"}], "citations": [{"paperId": "63de69245502d9a22de04581a4b5c0168d596aa3", "title": "Generalizing Visual Question Answering from Synthetic to Human-Written Questions via a Chain of QA with a Large Language Model"}, {"paperId": "8efc20988021ce3b4b05dd44b13e27260ee9b99b", "title": "Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering"}]}

{"paperId": "b3474a0bfddd48d46abe2214f42e660b569cc4aa", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "FactCHD: Benchmarking Fact-Conflicting Hallucination Detection", "abstract": "Despite their impressive generative capabilities, LLMs are hindered by fact-conflicting hallucinations in real-world applications. The accurate identification of hallucinations in texts generated by LLMs, especially in complex inferential scenarios, is a relatively unexplored area. To address this gap, we present FactCHD, a dedicated benchmark designed for the detection of fact-conflicting hallucinations from LLMs. FactCHD features a diverse dataset that spans various factuality patterns, including vanilla, multi-hop, comparison, and set operation. A distinctive element of FactCHD is its integration of fact-based evidence chains, significantly enhancing the depth of evaluating the detectors' explanations. Experiments on different LLMs expose the shortcomings of current approaches in detecting factual errors accurately. Furthermore, we introduce Truth-Triangulator that synthesizes reflective considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming to yield more credible detection through the amalgamation of predictive results and evidence. The benchmark dataset is available at https://github.com/zjunlp/FactCHD.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-18", "journal": {"name": "ArXiv", "volume": "abs/2310.12086"}, "authors": [{"authorId": "2143735911", "name": "Xiang Chen"}, {"authorId": "2260035133", "name": "Duanzheng Song"}, {"authorId": "2217228727", "name": "Honghao Gui"}, {"authorId": "2279862515", "name": "Chenxi Wang"}, {"authorId": "2153010067", "name": "Ningyu Zhang"}, {"authorId": "2279789241", "name": "Jiang Yong"}, {"authorId": "2256480060", "name": "Fei Huang"}, {"authorId": "2259919791", "name": "Chengfei Lv"}, {"authorId": "2259947118", "name": "Dan Zhang"}, {"authorId": "2144200945", "name": "Huajun Chen"}], "citations": [{"paperId": "79f9dac419693bb065e9ef0077389f24ae2207e6", "title": "AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for hallucination detection and analysis"}, {"paperId": "3f915aab835cbfe69e7b2ea1c73b74ac8a2d384e", "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations"}, {"paperId": "d6b42d3042877f3e27420878fc26b9adfc91b5bf", "title": "RJUA-QA: A Comprehensive QA Dataset for Urology"}]}

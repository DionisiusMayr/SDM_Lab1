{"paperId": "465a768ffbf42834d07168e40bf6f657ed7e3e0d", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "EMOGI: Efficient Memory-access for Out-of-memory Graph-traversal In GPUs", "abstract": "Modern analytics and recommendation systems are increasingly based on graph data that capture the relations between entities being analyzed. Practical graphs come in huge sizes, offer massive parallelism, and are stored in sparse-matrix formats such as compressed sparse row (CSR). To exploit the massive parallelism, developers are increasingly interested in using GPUs for graph traversal. However, due to their sizes, graphs often do not fit into the GPU memory. Prior works have either used input data pre-processing/partitioning or unified virtual memory (UVM) to migrate chunks of data from the host memory to the GPU memory. However, the large, multi-dimensional, and sparse nature of graph data presents a major challenge to these schemes and results in significant amplification of data movement and reduced effective data throughput. In this work, we propose EMOGI, an alternative approach to traverse graphs that do not fit in GPU memory using direct cache-line-sized access to data stored in host memory.\n This paper addresses the open question of whether a sufficiently large number of overlapping cache-line-sized accesses can be sustained to 1) tolerate the long latency to host memory, 2) fully utilize the available bandwidth, and 3) achieve favorable execution performance. We analyze the data access patterns of several graph traversal applications in GPU over PCIe using an FPGA to understand the cause of poor external bandwidth utilization. By carefully coalescing and aligning external memory requests, we show that we can minimize the number of PCIe transactions and nearly fully utilize the PCIe bandwidth with direct cache-line accesses to the host memory. EMOGI achieves 2.60X speedup on average compared to the optimized UVM implementations in various graph traversal applications. We also show that EMOGI scales better than a UVM-based solution when the system uses higher bandwidth interconnects such as PCIe 4.0.", "venue": "Proceedings of the VLDB Endowment", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-06-12", "journal": {"name": "Proc. VLDB Endow.", "pages": "114-127", "volume": "14"}, "authors": [{"authorId": "66889780", "name": "S. Min"}, {"authorId": "52205400", "name": "Vikram Sharma Mailthody"}, {"authorId": "1443779225", "name": "Zaid Qureshi"}, {"authorId": "46590281", "name": "Jinjun Xiong"}, {"authorId": "3149281", "name": "Eiman Ebrahimi"}, {"authorId": "143668320", "name": "Wen-mei W. Hwu"}], "citations": [{"paperId": "6e419d87084f8cc153f79f6c399e48092ba237b0", "title": "HongTu: Scalable Full-Graph GNN Training on Multiple GPUs"}, {"paperId": "de7d453f25d241fe89e0c5fdac97fd038846fbd0", "title": "Fine-Grain Quantitative Analysis of Demand Paging in Unified Virtual Memory"}, {"paperId": "e52a7a8b6fe27420749af97dc983e1dadab3afea", "title": "GPU Graph Processing on CXL-Based Microsecond-Latency External Memory"}, {"paperId": "6c3421144d3d6d6401fe52cfe56c660c786959a0", "title": "MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching"}, {"paperId": "a818c337a115d9b19da6a582d6cfc55310a8805e", "title": "SaGraph: A Similarity-aware Hardware Accelerator for Temporal Graph Processing"}, {"paperId": "7edb1633f3fe53c7b0a384307fda75a720682e05", "title": "Closeness Centrality on Uncertain Graphs"}, {"paperId": "be2f8368f414c4806b37bcf2d2283391d3680ca3", "title": "Liberator: A Data Reuse Framework for Out-of-Memory Graph Computing on GPUs"}, {"paperId": "29e31ccdd03a264ec793fc2aaac46c19ae28207d", "title": "GTraclus: a novel algorithm for local trajectory clustering on GPUs"}, {"paperId": "a4959bdd6780f1c801cd5a63ea60f23fd77d3665", "title": "Traversing Large Compressed Graphs on GPUs"}, {"paperId": "44775b43d0f55d0d8b94beb1fe8b76ad64270cbb", "title": "LightTraffic: On Optimizing CPU-GPU Data Traffic for Efficient Large-scale Random Walks"}, {"paperId": "79af8667ea55f0bf63462ee807d001d900754b27", "title": "GAMMA: A Graph Pattern Mining Framework for Large Graphs on GPU"}, {"paperId": "6155e94e5174e4c615f890c185acbe4b635dba16", "title": "IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research"}, {"paperId": "5b671f29e7830283d983a7f18f745b12abd490f8", "title": "DSP: Efficient GNN Training with Multiple GPUs"}, {"paperId": "364c5f6e04079a55503cf04b6e38c9e26f4df37e", "title": "Scoped Buffered Persistency Model for GPUs"}, {"paperId": "cdaa30519029d0e0d7c545dbfefe94dc4e333ef3", "title": "BARM: A Batch-Aware Resource Manager for Boosting Multiple Neural Networks Inference on GPUs With Memory Oversubscription"}, {"paperId": "3b9e59e91d99a49122124b25d58e8a1a887e448b", "title": "HyTGraph: GPU-Accelerated Graph Processing with Hybrid Transfer Management"}, {"paperId": "b6faa858b8ec91e52b21ff81c72ef60f1aacab64", "title": "Triton Join: Efficiently Scaling to a Large Join State on GPUs with Fast Interconnects"}, {"paperId": "6032374bdbe6a6b74cb606bb00aa096229f4f7c5", "title": "GPU-Initiated On-Demand High-Throughput Storage Access in the BaM System Architecture"}, {"paperId": "0e6f0e1d0a0e934a2720edd7e4d0253c75c05626", "title": "GPM: leveraging persistent memory from a GPU"}, {"paperId": "ca28d25b11347507412295f69e0e46a059928ca3", "title": "RecShard: statistical feature-based memory optimization for industry-scale neural recommendation"}, {"paperId": "2235896b7851d92c46f5baefafedde600500ed13", "title": "In-Depth Analyses of Unified Virtual Memory System for GPU Accelerated Computing"}, {"paperId": "9d4b2da6e25326ceb89d372cf4e35fe8e0e82765", "title": "TOD: GPU-accelerated Outlier Detection via Tensor Operations"}, {"paperId": "f2259b785c76fdd285ae574ba38dd56ca6900865", "title": "Unified-memory-based hybrid processing for partition-oriented subgraph matching on GPU"}, {"paperId": "e5d878e57f4ffff999abe5a69a0abd7a6c418dbb", "title": "Self-adaptive Graph Traversal on GPUs"}, {"paperId": "956c18664f37fb7853f5274e2bc6d7d099802d35", "title": "Demystifying GPU UVM Cost with Deep Runtime and Workload Analysis"}, {"paperId": "3eabdfc1e8ebc3c3a5b40676ad6cc55dad2469ef", "title": "Large Graph Convolutional Network Training with GPU-Oriented Data Communication Architecture"}, {"paperId": "4b798d2886e1f3fc214676b731e6e306eb1cfa74", "title": "PyTorch-Direct: Enabling GPU Centric Data Access for Very Large Graph Neural Network Training with Irregular Accesses"}, {"paperId": "36c3a377ea91937c7f91ae8f822a65c1ca072e7e", "title": "Tearing Down the Memory Wall"}, {"paperId": "ecc64b4c8f5ccc7576aeb0c01b25f149334db6b6", "title": "Graph Processing Scheme Using GPU With Value-Driven Differential Scheduling"}, {"paperId": "c5269518351196e2d6a653b60fa7b024d329b95d", "title": "Fast and Efficient Update Handling for Graph H2TAP"}, {"paperId": "9795deb0aec23c3e1fa7175bcf935317a197212d", "title": "BaM: A Case for Enabling Fine-grain High Throughput GPU-Orchestrated Access to Storage"}, {"paperId": "4b30d6d47152c171ee4f3544f375bf9cb4e5cf75", "title": "Memory Harvesting in Multi-GPU Systems with Hierarchical Unified Virtual Memory"}]}

{"paperId": "8296eef3797afd1515021ff568a694412c38101b", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives", "abstract": "Large language models (LLMs) have undergone significant expansion and have been increasingly integrated across various domains. Notably, in the realm of robot task planning, LLMs harness their advanced reasoning and language comprehension capabilities to formulate precise and efficient action plans based on natural language instructions. However, for embodied tasks, where robots interact with complex environments, text-only LLMs often face challenges due to a lack of compatibility with robotic visual perception. This study provides a comprehensive overview of the emerging integration of LLMs and multimodal LLMs into various robotic tasks. Additionally, we propose a framework that utilizes multimodal GPT-4V to enhance embodied task planning through the combination of natural language instructions and robot visual perceptions. Our results, based on diverse datasets, indicate that GPT-4V effectively enhances robot performance in embodied tasks. This extensive survey and evaluation of LLMs and multimodal LLMs across a variety of robotic tasks enriches the understanding of LLM-centric embodied intelligence and provides forward-looking insights toward bridging the gap in Human-Robot-Environment interaction.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2024-01-09", "journal": {"name": "ArXiv", "volume": "abs/2401.04334"}, "authors": [{"authorId": "2221022947", "name": "Jiaqi Wang"}, {"authorId": "2263593041", "name": "Zihao Wu"}, {"authorId": "2257102397", "name": "Yiwei Li"}, {"authorId": "2273631049", "name": "Hanqi Jiang"}, {"authorId": "2220096705", "name": "Peng Shu"}, {"authorId": "2131108859", "name": "Enze Shi"}, {"authorId": "2215809245", "name": "Huawen Hu"}, {"authorId": "120688117", "name": "Chong-Yi Ma"}, {"authorId": "2116426849", "name": "Yi-Hsueh Liu"}, {"authorId": "2278782711", "name": "Xuhui Wang"}, {"authorId": "2278797305", "name": "Yincheng Yao"}, {"authorId": "2278801747", "name": "Xuan Liu"}, {"authorId": "2276747984", "name": "Huaqin Zhao"}, {"authorId": "2145977326", "name": "Zheng Liu"}, {"authorId": "29944950", "name": "Haixing Dai"}, {"authorId": "2111641126", "name": "Lin Zhao"}, {"authorId": "144691205", "name": "Bao Ge"}, {"authorId": "2250835054", "name": "Xiang Li"}, {"authorId": "2254792886", "name": "Tianming Liu"}, {"authorId": "2256586513", "name": "Shu Zhang"}], "citations": [{"paperId": "33c744a6749cc7b6a8b68922fec925c4ead69c0c", "title": "Large language models can help boost food production, but be mindful of their risks"}, {"paperId": "f1f47af44677c6e076172b7e43ff295242308f47", "title": "Collage Prompting: Budget-Friendly Visual Recognition with GPT-4V"}, {"paperId": "fed3376de52d70ba83050182e79466dddde45746", "title": "On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities"}, {"paperId": "f66e54be2f5ce603ee59d8a2341747a27c580577", "title": "LLMs for Coding and Robotics Education"}, {"paperId": "59f3cf13401b9cc45d0e5ad7ea525e1eec84cce1", "title": "Real-World Robot Applications of Foundation Models: A Review"}, {"paperId": "3d6197e4ab55a3a2785ce5934e48cfbe9fe9bf04", "title": "Revolutionizing Finance with LLMs: An Overview of Applications and Insights"}, {"paperId": "bca0bbd01ea917b7a9fe369288ea3ba03d3b1ff3", "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge"}]}

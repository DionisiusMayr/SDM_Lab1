{"paperId": "bac54736112098616f0e1c90435888ef3e119d32", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey", "abstract": "With the rapid development of online services, recommender systems (RS) have become increasingly indispensable for mitigating information overload. Despite remarkable progress, conventional recommendation models (CRM) still have some limitations, e.g., lacking open-world knowledge, and difficulties in comprehending users' underlying preferences and motivations. Meanwhile, large language models (LLM) have shown impressive general intelligence and human-like capabilities, which mainly stem from their extensive open-world knowledge, reasoning ability, as well as their comprehension of human culture and society. Consequently, the emergence of LLM is inspiring the design of recommender systems and pointing out a promising research direction, i.e., whether we can incorporate LLM and benefit from their knowledge and capabilities to compensate for the limitations of CRM. In this paper, we conduct a comprehensive survey on this research direction from the perspective of the whole pipeline in real-world recommender systems. Specifically, we summarize existing works from two orthogonal aspects: where and how to adapt LLM to RS. For the WHERE question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, user interaction, and pipeline controller. For the HOW question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLM or not, and whether to involve conventional recommendation models for inference. Then, we highlight key challenges in adapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and ethics. Finally, we summarize the survey and discuss the future prospects. We actively maintain a GitHub repository for papers and other related resources: https://github.com/CHIANGEL/Awesome-LLM-for-RecSys/.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-06-09", "journal": {"name": "ArXiv", "volume": "abs/2306.05817"}, "authors": [{"authorId": "2144908858", "name": "Jianghao Lin"}, {"authorId": "2105646417", "name": "Xinyi Dai"}, {"authorId": "2056826850", "name": "Yunjia Xi"}, {"authorId": "2130051800", "name": "Weiwen Liu"}, {"authorId": "92633145", "name": "Bo Chen"}, {"authorId": "2181637944", "name": "Xiangyang Li"}, {"authorId": "2115802321", "name": "Chenxu Zhu"}, {"authorId": "3339005", "name": "Huifeng Guo"}, {"authorId": "2156098229", "name": "Yong Yu"}, {"authorId": "2824766", "name": "Ruiming Tang"}, {"authorId": "2108309275", "name": "Weinan Zhang"}], "citations": [{"paperId": "bf64e04ad6015fd623e64784f728eeb4cc8104b6", "title": "Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation"}, {"paperId": "ac457964969cdf99650acacb65cd84985eb84863", "title": "Tired of Plugins? Large Language Models Can Be End-To-End Recommenders"}, {"paperId": "f6b373b7a4b9fb31052df0f35987edabd2f93ce6", "title": "Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling"}, {"paperId": "d066f8b59565f9cb6713ece87afc3f3268f45474", "title": "Play to Your Strengths: Collaborative Intelligence of Conventional Recommender Models and Large Language Models"}, {"paperId": "8767dcddfb856db4bfa1e150470fc99f51f43835", "title": "KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation"}, {"paperId": "d552ca135ea18a688b385984f8aab983d2098dc7", "title": "Can Small Language Models be Good Reasoners for Sequential Recommendation?"}, {"paperId": "8a439444d888202a711b8b8a195934cdb138342e", "title": "Towards Efficient and Effective Unlearning of Large Language Models for Recommendation"}, {"paperId": "009f64d890d8402cae8739b63bc0c3d06d62ed06", "title": "NoteLLM: A Retrievable Large Language Model for Note Recommendation"}, {"paperId": "203574cdbb7ae35a44c40abeed414093a58b74bf", "title": "Prospect Personalized Recommendation on Large Language Model-based Agent Platform"}, {"paperId": "81571f64e0b4b75fedae6a4279290e59e4143976", "title": "Item-side Fairness of Large Language Model-based Recommendation System"}, {"paperId": "c7bcb723db3ee516f6d3f73084a1baa5adb93b04", "title": "GCOF: Self-iterative Text Generation for Copywriting Using Large Language Model"}, {"paperId": "f15086f851680e1c05f1eb871436ff66c838b907", "title": "Foundation Models for Recommender Systems: A Survey and New Perspectives"}, {"paperId": "3b10497e5609d593b6a7035d7ed65890a3e6d13d", "title": "Cognitive Personalized Search Integrating Large Language Models with an Efficient Memory Mechanism"}, {"paperId": "650c056b360eef91bee1d287ce0d859c56e5debc", "title": "Large Language Model Interaction Simulator for Cold-Start Item Recommendation"}, {"paperId": "691fc6c4f13ee87e56341592594cd8f3445ea1e2", "title": "LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations"}, {"paperId": "bad12cb32faee21eafadbed03c6eec7e23e88ac9", "title": "Improving Sequential Recommendations with LLMs"}, {"paperId": "3dd86949c4028ac5d29428acd9e9439e7fc29fa0", "title": "PAP-REC: Personalized Automatic Prompt for Recommendation Language Model"}, {"paperId": "f0f5cf9d0a2dc4e6effd260d4d1d6509e7996c68", "title": "Parameter-Efficient Conversational Recommender System as a Language Processing Task"}, {"paperId": "9aa4d8461f9d6169e54e10baf3164212c252c80a", "title": "Enhancing Recommendation Diversity by Re-ranking with Large Language Models"}, {"paperId": "96aa0327c9faeecf8d520286a1b1999b541becb1", "title": "LLM-Guided Multi-View Hypergraph Learning for Human-Centric Explainable Recommendation"}, {"paperId": "156af81de93f840df39c0973ef1343629427a7db", "title": "Prompting Large Language Models for Recommender Systems: A Comprehensive Framework and Empirical Analysis"}, {"paperId": "60123a0542c4ae85f9c1d902526bb51626177242", "title": "Distillation is All You Need for Practically Using Different Pre-trained Recommendation Models"}, {"paperId": "fee61c03fd5ad4a8d8bcdec5bcdfacfe25b361d9", "title": "Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges"}, {"paperId": "bbf159cfafbb37108bafdf9dcf4767643ae5d23d", "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation"}, {"paperId": "dd5fcb0b5fdbd31281626157387cda115c1305f7", "title": "Preliminary Study on Incremental Learning for Large Language Model-based Recommender Systems"}, {"paperId": "46282f90bceadea07675648c4aacbce1ceba6002", "title": "LLANIME: Large Language Models for Anime Recommendations"}, {"paperId": "b6bc1590ae632fd8325fab23edf5c333a9a7723c", "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models"}, {"paperId": "74b0976a3a7b7013fd468a043a940dcf401e66f1", "title": "User Modeling in the Era of Large Language Models: Current Research and Future Directions"}, {"paperId": "0e8dec431a62dea147139d7805ab3a0a97bf3857", "title": "LLaRA: Aligning Large Language Models with Sequential Recommenders"}, {"paperId": "7c5a39096e80c86fc0e160e574a4db60b64540f4", "title": "Towards Generative Search and Recommendation: A keynote at RecSys 2023"}, {"paperId": "5a1b80a91df91a14d01772aa40e0193ac481533e", "title": "UFIN: Universal Feature Interaction Network for Multi-Domain Click-Through Rate Prediction"}, {"paperId": "6b395e45a8c54064ca1f68116912170e146e8506", "title": "Large Language Models for Recommendation: Progresses and Future Directions"}, {"paperId": "32f65dd751e5c491d83c2f46e41f50afa1c6d2bb", "title": "Scaling Law of Large Sequential Recommendation Models"}, {"paperId": "3dda5dcd75f6add679a20db854989523a02f32fa", "title": "Modeling User Viewing Flow using Large Language Models for Article Recommendation"}, {"paperId": "6531e6b6b8e43901a804fe3f03dd941c4e781718", "title": "Collaborative Large Language Model for Recommender Systems"}, {"paperId": "984583e8380fc8af8e20f32ed6ad9d7bc4888c6c", "title": "Large Language Model Can Interpret Latent Space of Sequential Recommender"}, {"paperId": "8f3b6a299098eb2e615e344b2f76a23dfca4d9ca", "title": "CoLLM: Integrating Collaborative Embeddings into Large Language Models for Recommendation"}, {"paperId": "9426ed538470ad98b881a20fd9725bf8536a674f", "title": "FLIP: Towards Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction"}, {"paperId": "28b35bf817ec07e27cf5512c14a553436b202852", "title": "LightLM: A Lightweight Deep and Narrow Language Model for Generative Recommendation"}, {"paperId": "27425bed026321bf5f9e290eff519719a1bb8ea5", "title": "Multiple Key-value Strategy in Recommendation Systems Incorporating Large Language Model"}, {"paperId": "4829b73a47be18f73e9e8d90f3c23c8f84d0fccb", "title": "Representation Learning with Large Language Models for Recommendation"}, {"paperId": "e96be7c55d139965b15bc0527d6d528b225f9a61", "title": "ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction"}, {"paperId": "44576a2c6337f41019f29b055d8c7f7f5891be92", "title": "AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems"}, {"paperId": "30abad6b21175a993d5723c368f8ae6c0c0494a8", "title": "Ten Challenges in Industrial Recommender Systems"}, {"paperId": "41c3745b834cb3147cc956d9d39e86028649b1e9", "title": "Leveraging Large Language Models for Sequential Recommendation"}, {"paperId": "9618ac49822a8d0d9924b6e7d9a0bb0847649fdb", "title": "CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models"}, {"paperId": "a1081c6fc6921d6b76d9ebda4d712333fd7bbbf5", "title": "Large Language Models for Generative Recommendation: A Survey and Visionary Discussions"}, {"paperId": "cb2dea3be40b9c26397e03c273e744adeac33d74", "title": "Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging"}, {"paperId": "26059f871eea2ef9aeeda228ebd40a69b61ab65c", "title": "RecMind: Large Language Model Powered Agent For Recommendation"}, {"paperId": "429e6c09eeadf54e2b245b8f2cddfbf157f9da4c", "title": "ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation"}, {"paperId": "6a8ef5e410da32958d0cba56e8d4c3f6302f02a4", "title": "Leveraging Large Language Models for Pre-trained Recommender Systems"}, {"paperId": "b946f3ee813aa671aff7db0a0c840049acb83662", "title": "The Costly Dilemma: Generalization, Evaluation and Cost-Optimal Deployment of Large Language Models"}, {"paperId": "62253f0dc5f6c210d56cef3e7231e7e033997620", "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction"}, {"paperId": "7d46a13a1edd02dd6ae2b9f713e6f91ea001dfb4", "title": "When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities"}, {"paperId": "57e85f4f0df264fa813714d7f12dc13aa2c422a5", "title": "LLM-Rec: Personalized Recommendation via Prompting Large Language Models"}, {"paperId": "001c35feef59c01394707b29fd95e4c7374b284d", "title": "Recommendation Unlearning via Influence Function"}, {"paperId": "a35f1315e91513ff0bec0c488fe175214fd9636c", "title": "Recommender Systems in the Era of Large Language Models (LLMs)"}, {"paperId": "4ce44526dfca878c76bdadd5c0a2ac4d6a192323", "title": "Could Small Language Models Serve as Recommenders? Towards Data-centric Cold-start Recommendations"}, {"paperId": "c5481668f78ab0c8ef2de9230f2fc1ce27eea6e4", "title": "Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models"}, {"paperId": "f454b3b3feb4abae67b62abc617d5adf871c86d3", "title": "UP5: Unbiased Foundation Model for Fairness-aware Recommendation"}, {"paperId": "ef0679f8b3114c339bdf5a0c202403a08d160a88", "title": "ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models"}, {"paperId": "6e8168ac08194ebe51bc9616abdbf9cb636b3215", "title": "RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models"}, {"paperId": "3d2fd5d3be7ccbad738a0787d96e6fe4123f20cf", "title": "ALT: Towards Fine-grained Alignment between Language and CTR Models for Click-Through Rate Prediction"}, {"paperId": "3863d46a26340d7ed428a120c40507784b959868", "title": "Large Language Model Powered Agents in the Web"}]}

{"paperId": "4e9e247c32edffe85adf53c8ec760be940183ee4", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Machine-Made Media: Monitoring the Mobilization of Machine-Generated Articles on Misinformation and Mainstream News Websites", "abstract": "As large language models (LLMs) like ChatGPT have gained traction, an increasing number of news websites have begun utilizing them to generate articles. However, not only can these language models produce factually inaccurate articles on reputable websites but disreputable news sites can utilize LLMs to mass produce misinformation. To begin to understand this phenomenon, we present one of the first large-scale studies of the prevalence of synthetic articles within online news media. To do this, we train a DeBERTa-based synthetic news detector and classify over 15.46 million articles from 3,074 misinformation and mainstream news websites. We find that between January 1, 2022, and May 1, 2023, the relative number of synthetic news articles increased by 57.3% on mainstream websites while increasing by 474% on misinformation sites. We find that this increase is largely driven by smaller less popular websites. Analyzing the impact of the release of ChatGPT using an interrupted-time-series, we show that while its release resulted in a marked increase in synthetic articles on small sites as well as misinformation news websites, there was not a corresponding increase on large mainstream news websites.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-05-16", "journal": {"name": "ArXiv", "volume": "abs/2305.09820"}, "authors": [{"authorId": "120376563", "name": "Hans W. A. Hanley"}, {"authorId": "3137133", "name": "Z. Durumeric"}], "citations": [{"paperId": "5246d53c5abd4f3d5f5682460bac5e0887f04f93", "title": "Farsight: Fostering Responsible AI Awareness During AI Application Prototyping"}, {"paperId": "74b0976a3a7b7013fd468a043a940dcf401e66f1", "title": "User Modeling in the Era of Large Language Models: Current Research and Future Directions"}, {"paperId": "ee5e79a83b019d5a7e3ad55e6e39696aff67a5f2", "title": "Combating Misinformation in the Age of LLMs: Opportunities and Challenges"}, {"paperId": "893960d503f3f182ddb6b15fb61032a488de87bc", "title": "Adapting Fake News Detection to the Era of Large Language Models"}, {"paperId": "60bd26bdb23ba353e5d79f161542dd074bc8391c", "title": "A Survey on Detection of LLMs-Generated Content"}, {"paperId": "69f4786769cad31d8ce2775161495153f261da3f", "title": "TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings"}, {"paperId": "aeddde96937507fb04104017ff5cdf3e29f90fa1", "title": "Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown"}, {"paperId": "39a01a360e014c2a7b8efa9b2e40aa0ec06e893b", "title": "Zero-Shot Detection of Machine-Generated Codes"}, {"paperId": "6f75e8b61f13562237851d8119cb2f9d49e073fb", "title": "Can LLM-Generated Misinformation Be Detected?"}, {"paperId": "8e5353c3e5bdb11f2df318ebd23faa65697ba929", "title": "Fake News Detectors are Biased against Texts Generated by Large Language Models"}, {"paperId": "e2cc232ad999164f1bf340996bb5db62b6602d31", "title": "Robustness Over Time: Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of Large Language Models"}, {"paperId": "dd1a17ca0406a1e02d85fa6c106060de8275607d", "title": "Anatomy of an AI-powered malicious social botnet"}]}

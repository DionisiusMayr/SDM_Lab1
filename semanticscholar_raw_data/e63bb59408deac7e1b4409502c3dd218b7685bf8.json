{"paperId": "e63bb59408deac7e1b4409502c3dd218b7685bf8", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "FlexShard: Flexible Sharding for Industry-Scale Sequence Recommendation Models", "abstract": "Sequence-based deep learning recommendation models (DLRMs) are an emerging class of DLRMs showing great improvements over their prior sum-pooling based counterparts at capturing users' long term interests. These improvements come at immense system cost however, with sequence-based DLRMs requiring substantial amounts of data to be dynamically materialized and communicated by each accelerator during a single iteration. To address this rapidly growing bottleneck, we present FlexShard, a new tiered sequence embedding table sharding algorithm which operates at a per-row granularity by exploiting the insight that not every row is equal. Through precise replication of embedding rows based on their underlying probability distribution, along with the introduction of a new sharding strategy adapted to the heterogeneous, skewed performance of real-world cluster network topologies, FlexShard is able to significantly reduce communication demand while using no additional memory compared to the prior state-of-the-art. When evaluated on production-scale sequence DLRMs, FlexShard was able to reduce overall global all-to-all communication traffic by over 85%, resulting in end-to-end training communication latency improvements of almost 6x over the prior state-of-the-art approach.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-01-08", "journal": {"name": "ArXiv", "volume": "abs/2301.02959"}, "authors": [{"authorId": "3382094", "name": "Geet Sethi"}, {"authorId": "2128345314", "name": "Pallab Bhattacharya"}, {"authorId": "9728430", "name": "Dhruv Choudhary"}, {"authorId": "2797270", "name": "Carole-Jean Wu"}, {"authorId": "117272782", "name": "Christos Kozyrakis"}], "citations": [{"paperId": "a490addae6ac4f0559a532d26f9cb1cd6bb94d29", "title": "Pre-train and Search: Efficient Embedding Table Sharding with Pre-trained Neural Cost Models"}, {"paperId": "7c25adf2ddb35df05a61c697da97efb8583d77df", "title": "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings"}, {"paperId": "701a8f6d5012ac0f5a38b146acb26d80b4a88e81", "title": "MP-Rec: Hardware-Software Co-design to Enable Multi-path Recommendation"}]}

{"paperId": "639d1227583d7e1ea9855971909afda3dbfd9eed", "publicationVenue": {"id": "322bf662-0263-48b5-bf26-03b114a182dc", "name": "Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis", "type": "conference", "alternate_names": ["WASSA", "Workshop Comput Approach Subj Sentim Soc Media Anal"]}, "title": "On the Complementarity of Images and Text for the Expression of Emotions in Social Media", "abstract": "Authors of posts in social media communicate their emotions and what causes them with text and images. While there is work on emotion and stimulus detection for each modality separately, it is yet unknown if the modalities contain complementary emotion information in social media. We aim at filling this research gap and contribute a novel, annotated corpus of English multimodal Reddit posts. On this resource, we develop models to automatically detect the relation between image and text, an emotion stimulus category and the emotion class. We evaluate if these tasks require both modalities and find for the image\u2013text relations, that text alone is sufficient for most categories (complementary, illustrative, opposing): the information in the text allows to predict if an image is required for emotion understanding. The emotions of anger and sadness are best predicted with a multimodal model, while text alone is sufficient for disgust, joy, and surprise. Stimuli depicted by objects, animals, food, or a person are best predicted by image-only models, while multimodal mod- els are most effective on art, events, memes, places, or screenshots.", "venue": "Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-02-11", "journal": {"pages": "1-15"}, "authors": [{"authorId": "2154575862", "name": "Anna Khlyzova"}, {"authorId": "2490430", "name": "Carina Silberer"}, {"authorId": "66339110", "name": "Roman Klinger"}], "citations": [{"paperId": "1bb17558b0bc067bf11445e1f1f1e8caa647f97e", "title": "Image and Text Aspect Level Multimodal Sentiment Classification Model Using Transformer and Multilayer Attention Interaction"}, {"paperId": "1dbc35042ce7aa4653c24e847a6cc42555f96007", "title": "Where are We in Event-centric Emotion Analysis? Bridging Emotion Role Labeling and Appraisal-based Approaches"}, {"paperId": "74eebf852659c3c2d2f1d5cdd7c9329d0c31c976", "title": "Exploring the Potential of Pre-trained DCNN Models for Facial Emotion Detection: A Comparative Analysis"}]}

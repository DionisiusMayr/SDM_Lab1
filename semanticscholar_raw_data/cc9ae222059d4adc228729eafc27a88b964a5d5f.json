{"paperId": "cc9ae222059d4adc228729eafc27a88b964a5d5f", "publicationVenue": null, "title": "A Ranked Bandit Approach for Multi-stakeholder Recommender Systems", "abstract": "Recommender systems traditionally find the most relevant products or services for users tailored to their needs or interests but they ignore the interests of the other sides of the market (aka stakeholders). In this paper, we propose to use a Ranked Bandit approach for an online multi-stakeholder recommender system that sequentially selects top \ud835\udc58 items according to the relevance and priority of all the involved stakeholders. We presented three different criteria to consider the priority of each stakeholder when evaluating our approach. Our extensive experimental results on a movie dataset showed that the contextual multi-armed bandits with a relevance function make a higher level of satisfaction for all involved stakeholders in the long term.", "venue": "MORS@RecSys", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal": null, "authors": [{"authorId": "23551855", "name": "Tahereh Arabghalizi"}, {"authorId": "1716685", "name": "Alexandros Labrinidis"}], "citations": [{"paperId": "1e3bfcc55c134152a7258dd84f32139f1b74eb37", "title": "MORS 2022: The Second Workshop on Multi-Objective Recommender Systems"}]}

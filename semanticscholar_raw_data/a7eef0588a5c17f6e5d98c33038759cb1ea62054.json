{"paperId": "a7eef0588a5c17f6e5d98c33038759cb1ea62054", "publicationVenue": null, "title": "1 E cient Execution of Large-Scale Scienti c Computation on CPUs and GPUs", "abstract": "Large scale computing applications are an integral part of everyday life. Web search, speech recognition, recommendation systems, and many other applications are powered by machine learning models containing billions of parameters. \u0091ese large models run on distributed systems with hundreds of Central Processing Units (CPUs) and Graphics Processing Units (GPUs). Similarly, computer simulation models for weather prediction, image processing, \u0083uid dynamics, and others run on supercomputers. However, it is di\u0081cult and error-prone to write scalable code for simulations and distributed machine learning. Programmers today must grapple with low-level issues like synchronization, deadlocks, and data locality. \u0091e goal of my research is to enable domain experts, like computational science and machine learning practitioners, to easily and e\u0081ciently use high performance hardware. I have designed novel abstractions and languages to describe domain applications naturally without sacri\u0080cing on performance. In many cases, my abstractions have outperformed low-level, hand-wri\u008ben code. My work allows domain experts to completely focus on their applications, and still achieve maximal performance on sophisticated, high-performance computing hardware. \u0091e major takeaway from my research is that new abstractions can make programming easy and expose new optimizations for be\u008ber performance. \u0091e major contributions of my research are: \u2022 New optimization and code generation algorithms that generate e\u0081cient image processing and scienti\u0080c computations for CPUs and GPUs while still providing a high level abstraction [15, 16, 17]. \u2022 A programming language and runtime system for expressing distributed machine learning workloads that accelerate the performance of distributed training and inference for widely-used, large machine learning models [12]. \u2022 A system to accelerate graph machine learning applications, that is the \u0080rst to implement GPU-based graph sampling [18]. \u2022 A foundational semantics for so-called \u201cserverless computing\u201d, which is a new approach to cloud computing [13]. \u0091e semantics models subtle bugs that arise and presents ways for programmers to write e\u0081cient and correct serverless programs. \u2022 \u0091e \u0080rst large-scale performance analysis of WebAssembly using signi\u0080cant real-world benchmarks [14].", "venue": "", "year": 2021, "fieldsOfStudy": null, "publicationTypes": null, "publicationDate": null, "journal": null, "authors": [{"authorId": "3258214", "name": "Abhinav Jangda"}], "citations": []}

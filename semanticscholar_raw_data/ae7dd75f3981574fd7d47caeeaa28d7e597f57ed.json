{"paperId": "ae7dd75f3981574fd7d47caeeaa28d7e597f57ed", "publicationVenue": {"id": "7c9d091e-015e-4e5d-a11f-9bc369fcf414", "name": "IEEE Transactions on Parallel and Distributed Systems", "type": "journal", "alternate_names": ["IEEE Trans Parallel Distrib Syst"], "issn": "1045-9219", "url": "http://www.computer.org/tpds", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=71"]}, "title": "GML: Efficiently Auto-Tuning Flink's Configurations Via Guided Machine Learning", "abstract": "The increasingly popular fused batch-streaming big data framework, Apache Flink, has many performance-critical as well as untamed configuration parameters. However, how to tune them for optimal performance has not yet been explored. Machine learning (ML) has been chosen to tune the configurations for other big data frameworks (e.g., Apache Spark), showing significant performance improvements. However, it needs a long time to collect a large amount of training data by nature. In this article, we propose a guided machine learning (GML) approach to tune the configurations of Flink with significantly shorter time for collecting training data compared to traditional ML approaches. GML innovates two techniques. First, it leverages generative adversarial networks (GANs) to generate a part of training data, reducing the time needed for training data collection. Second, GML guides a ML algorithm to select configurations that the corresponding performance is higher than the average performance of random configurations. We evaluate GML on a lab cluster with 4 servers and a real production cluster in an internet company. The results show that GML significantly outperforms the state-of-the-art, DAC (Datasize-Aware-Configuration) (Z. Yu et al. 2018) for tuning the configurations of Spark, with 2.4\u00d7 of reduced data collection time but with 30 percent reduced 99th percentile latency. When GML is used in the internet company, it reduces the latency by up to 57.8\u00d7 compared to the configurations made by the company.", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2021-12-01", "journal": {"name": "IEEE Transactions on Parallel and Distributed Systems", "pages": "2921-2935", "volume": "32"}, "authors": [{"authorId": "2118270114", "name": "Yijin Guo"}, {"authorId": "7938294", "name": "Huasong Shan"}, {"authorId": "2044656678", "name": "Shixin Huang"}, {"authorId": "2067461044", "name": "Kai Hwang"}, {"authorId": "48203700", "name": "Jianping Fan"}, {"authorId": "145202330", "name": "Zhibin Yu"}], "citations": [{"paperId": "4eb61ac220459437c909b2a6e93c45684bc93ebd", "title": "Mfrlmo: Model-Free Reinforcement Learning for Multi-Objective Optimization of Apache Spark"}, {"paperId": "e2f2f3fec7ecad567ccb1a4a864a171922496055", "title": "Studying the Energy Consumption of Stream Processing Engines in the Cloud"}, {"paperId": "c21546642283a980e780897061dc198d6632e9ca", "title": "EFTuner: A Bi-Objective Configuration Parameter Auto-Tuning Method Towards Energy-Efficient Big Data Processing"}, {"paperId": "e0917b7f212261e01194b6eb6e190f1b66ce002b", "title": "ATConf: auto-tuning high dimensional configuration parameters for big data processing frameworks"}, {"paperId": "6e02f1dda7075f9a101d6557fd206c5ecf994377", "title": "DeepCAT: A Cost-Efficient Online Configuration Auto-Tuning Approach for Big Data Frameworks"}, {"paperId": "c00b4d2800e313a9b75fd6aa4ed1c3e6e3e9f909", "title": "JointConf: Jointly autotuning configuration parameters for modularized graph databases"}, {"paperId": "f42c55162c4c00aa1e8561792504c133c0054d5c", "title": "Performance benchmarking and auto-tuning for scientific applications on virtual cluster"}, {"paperId": "b1f3a0a6e73da401a52cb2ce15131c1182d5ad0f", "title": "A literature review of parameter tuning within the context of big data processing frameworks"}]}

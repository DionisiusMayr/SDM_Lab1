{"paperId": "a4e32021908ae088839878a94513c2202e4bf084", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Harnessing Scalable Transactional Stream Processing for Managing Large Language Models [Vision]", "abstract": "Large Language Models (LLMs) have demonstrated extraordinary performance across a broad array of applications, from traditional language processing tasks to interpreting structured sequences like time-series data. Yet, their effectiveness in fast-paced, online decision-making environments requiring swift, accurate, and concurrent responses poses a significant challenge. This paper introduces TStreamLLM, a revolutionary framework integrating Transactional Stream Processing (TSP) with LLM management to achieve remarkable scalability and low latency. By harnessing the scalability, consistency, and fault tolerance inherent in TSP, TStreamLLM aims to manage continuous&concurrent LLM updates and usages efficiently. We showcase its potential through practical use cases like real-time patient monitoring and intelligent traffic management. The exploration of synergies between TSP and LLM management can stimulate groundbreaking developments in AI and database research. This paper provides a comprehensive overview of challenges and opportunities in this emerging field, setting forth a roadmap for future exploration and development.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-07-17", "journal": {"name": "ArXiv", "volume": "abs/2307.08225"}, "authors": [{"authorId": "2188004", "name": "Shuhao Zhang"}, {"authorId": "2111551824", "name": "Xianzhi Zeng"}, {"authorId": "2223670108", "name": "Yuhao Wu"}, {"authorId": "2111737301", "name": "Zhonghao Yang"}], "citations": []}

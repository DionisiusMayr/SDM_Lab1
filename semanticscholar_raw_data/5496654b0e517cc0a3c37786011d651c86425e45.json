{"paperId": "5496654b0e517cc0a3c37786011d651c86425e45", "publicationVenue": {"id": "0c1420a4-aa9b-44f9-b264-ba3ac5c37050", "name": "International Conference for High Performance Computing, Networking, Storage and Analysis", "alternate_names": ["Int Conf High Perform Comput Netw Storage Anal"], "issn": "2167-4337", "alternate_issns": ["2167-4329"], "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000729"}, "title": "C-SAW: A Framework for Graph Sampling and Random Walk on GPUs", "abstract": "Many applications require to learn, mine, analyze and visualize large-scale graphs. These graphs are often too large to be addressed efficiently using conventional graph processing technologies. Fortunately, recent research efforts find out graph sampling and random walk, which significantly reduce the size of original graphs, can benefit the tasks of learning, mining, analyzing and visualizing large graphs by capturing the desirable graph properties. This paper introduces C-SAW, the first framework that accelerates Sampling and Random Walk framework on GPUs. Particularly, C-SAW makes three contributions: First, our framework provides a generic API which allows users to implement a wide range of sampling and random walk algorithms with ease. Second, offloading this framework on GPU, we introduce warp-centric parallel selection, and two novel optimizations for collision migration. Third, towards supporting graphs that exceed the GPU memory capacity, we introduce efficient data transfer optimizations for out-of-memory and multi-GPU sampling, such as workload-aware scheduling and batched multi-instance sampling. Taken together, our framework constantly outperforms the state of the art projects in addition to the capability of supporting a wide range of sampling and random walk algorithms.", "venue": "International Conference for High Performance Computing, Networking, Storage and Analysis", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-09-18", "journal": {"name": "SC20: International Conference for High Performance Computing, Networking, Storage and Analysis", "pages": "1-15"}, "authors": [{"authorId": "2062217774", "name": "Santosh Pandey"}, {"authorId": "2635740", "name": "Lingda Li"}, {"authorId": "1753153", "name": "A. Hoisie"}, {"authorId": "10685934", "name": "X. Li"}, {"authorId": "1390915579", "name": "Hang Liu"}], "citations": [{"paperId": "69ee8f1f98da4847b3d7ffc9f04a68492873588b", "title": "Enhancing Graph Random Walk Acceleration via Efficient Dataflow and Hybrid Memory Architecture"}, {"paperId": "7e55d5b5630ea4e90cb6187a58a9e67465242aec", "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning"}, {"paperId": "180d5df74b7ea3799ae0018a2dbf6189fe5d0fcd", "title": "GraphScope Flex: LEGO-like Graph Computing Stack"}, {"paperId": "d10cabff491718f2b5a94b8e2d9c2a6d44aebe24", "title": "GNNFlow: A Distributed Framework for Continuous Temporal GNN Learning on Dynamic Graphs"}, {"paperId": "2f3049d3dfa761c94a54168388d9364f6e1a70ab", "title": "Distributed Matrix-Based Sampling for Graph Neural Network Training"}, {"paperId": "96a88170729021e553648a2b17c73602a3171d2f", "title": "gSampler: General and Efficient GPU-based Graph Sampling for Graph Learning"}, {"paperId": "8c200d77636b659a1c949f148f157701283cbb5f", "title": "Optimizing a Distributed Graph Data Structure for K - Path Centrality Estimation on HPC"}, {"paperId": "e52549fdb6be6d36071143764b8d8862aabb930c", "title": "Optimizing GPU-Based Graph Sampling and Random Walk for Efficiency and Scalability"}, {"paperId": "c1928f42ad6293562df6078b83adef1e78bd224e", "title": "Tango: Rethinking Quantization for Graph Neural Network Training on GPUs"}, {"paperId": "db63bd49a343b0b61c8617fca29b4b5ae00403d5", "title": "ClipSim: A GPU-friendly Parallel Framework for Single-Source SimRank with Accuracy Guarantee"}, {"paperId": "430c1151c3f58149a256fb2c21544031805ed86d", "title": "TEA: A General-Purpose Temporal Graph Random Walk Engine"}, {"paperId": "35f4fb2bbaa1139c077fcdaff76de945297bb47a", "title": "LightRW: FPGA Accelerated Graph Dynamic Random Walks"}, {"paperId": "44775b43d0f55d0d8b94beb1fe8b76ad64270cbb", "title": "LightTraffic: On Optimizing CPU-GPU Data Traffic for Efficient Large-scale Random Walks"}, {"paperId": "58d8de4a46396edfe771f30722b9476a30ad22d8", "title": "FastRW: A Dataflow-Efficient and Memory-Aware Accelerator for Graph Random Walk on FPGAs"}, {"paperId": "231b88e974b3117fbbeade9fa4f758ed4f15369b", "title": "NosWalker: A Decoupled Architecture for Out-of-Core Random Walk Processing"}, {"paperId": "81d9cd7fd934f218d3428fc70fc5b8940c0a1107", "title": "GSplit: Scaling Graph Neural Network Training on Large Graphs via Split-Parallelism"}, {"paperId": "5b671f29e7830283d983a7f18f745b12abd490f8", "title": "DSP: Efficient GNN Training with Multiple GPUs"}, {"paperId": "64be7eeb65be5d24ed75129fb051824cf914ecb2", "title": "Mining User-aware Multi-relations for Fake News Detection in Large Scale Online Social Networks"}, {"paperId": "1e79e33c77b2d8eaf643af0e1f5003057d7356b2", "title": "Distributed Graph Neural Network Training: A Survey"}, {"paperId": "6359ddaf1aef3379bd95a5a61948e2f2cbd758f5", "title": "Scalable Deep Learning-Based Microarchitecture Simulation on GPUs"}, {"paperId": "be5ae5f98ae4b16d14b99d5c3db2b86173382f28", "title": "Scalable Graph Sampling on GPUs with Compressed Graph"}, {"paperId": "a1162fa7e6e09872341001175c39a8662d41162b", "title": "T-GCN: A Sampling Based Streaming Graph Neural Network System with Hybrid Architecture"}, {"paperId": "305348db7a5b27a8dfcaf756053c194b6c9a99f0", "title": "Space-Efficient Random Walks on Streaming Graphs"}, {"paperId": "c8ae9b653bbb58b474735032128b113a24cf37f1", "title": "Bring orders into uncertainty: enabling efficient uncertain graph processing via novel path sampling on multi-accelerator systems"}, {"paperId": "893150f171bd7656d86a56c1026e6129d265a957", "title": "TeGraph: A Novel General-Purpose Temporal Graph Computing Engine"}, {"paperId": "740b9d4414a955a74c16f5f3617d2b5dde2e9adf", "title": "GNNLab: a factored system for sample-based GNN training over GPUs"}, {"paperId": "20dc2612c0296952a363f2aa5d78d2178503553f", "title": "Rethinking graph data placement for graph neural network training on multiple GPUs"}, {"paperId": "94f0823f8db5360972a7a68b453e28ddf9c4e992", "title": "BGL: GPU-Efficient GNN Training by Optimizing Graph Data I/O and Preprocessing"}, {"paperId": "1d4610d26bf9e5354d4afcd94db5539187389ae4", "title": "Parallel Global Edge Switching for the Uniform Sampling of Simple Graphs with Prescribed Degrees"}, {"paperId": "b588110ee9e30a1b1ee130c3323f8eef308a59dc", "title": "Efficient Data Loader for Fast Sampling-Based GNN Training on Large Graphs"}, {"paperId": "d68beb54431476edf2fa90f621887baa31591826", "title": "Dr. Top-k: Delegate-Centric Top-k on GPUs"}, {"paperId": "dfcd4cbd47b17eb60392ff918e2b5191921b503e", "title": "Skywalker: Efficient Alias-Method-Based Graph Sampling and Random Walk on GPUs"}, {"paperId": "0d71fb95ac805eb6141b93791ba3999cd7643277", "title": "ThunderRW: An In-Memory Graph Random Walk Engine"}, {"paperId": "674819a81b1f27e65a4ea3de86bfdafb52612223", "title": "Scalable Graph Neural Network Training"}, {"paperId": "ed6ce714b65aca1272ec8af9db74076ecb5605d5", "title": "Trust: Triangle Counting Reloaded on GPUs"}, {"paperId": "7de453008a7fdd426ee8e1f50424f7bf784d6811", "title": "gIM: GPU Accelerated RIS-Based Influence Maximization Algorithm"}, {"paperId": "fe3d6c9a7e76a175ca90f7ce05beb9965f148f26", "title": "the Proceedings of the 20th USENIX Symposium on Networked Systems Design and Implementation."}, {"paperId": "99e568d08ad43f1dc9e9ad3fe138e90e6d5bcefe", "title": "Wukong+G: Fast and Concurrent RDF Query Processing Using RDMA-assisted GPU Graph Exploration"}, {"paperId": "096819782ce34058faa7ad3d81c9b3d49a5cf527", "title": "Core Graph: Exploiting Edge Centrality to Speedup the Evaluation of Iterative Graph Queries"}, {"paperId": "febbe50d95e27e99c46a0d431dffd371203e57a4", "title": "This paper is included in the Proceedings of the 2023 USENIX Annual Technical Conference."}]}

{"paperId": "57436ee01e1e6facdafeede28636804ca11f7f02", "publicationVenue": {"id": "ffe5bb5c-04ed-488e-985d-d3a7b39542cf", "name": "IEEE International Conference on Distributed Computing Systems", "type": "conference", "alternate_names": ["International Conference on Distributed Computing Systems", "IEEE Int Conf Distrib Comput Syst", "Int Conf Device Circuit Syst", "ICDCS", "Int Conf Distrib Comput Syst", "International Conference on Devices, Circuits and Systems"], "url": "https://ieeexplore.ieee.org/xpl/conhome/1000213/all-proceedings"}, "title": "The Best of Both Worlds: Challenges in Linking Provenance and Explainability in Distributed Machine Learning", "abstract": "Machine learning experts prefer to think of their input as a single, homogeneous, and consistent data set. However, when analyzing large volumes of data, the entire data set may not be manageable on a single server, but must be stored on a distributed file system instead. Moreover, with the pressing demand to deliver explainable models, the experts may no longer focus on the machine learning algorithms in isolation, but must take into account the distributed nature of the data stored, as well as the impact of any data pre-processing steps upstream in their data analysis pipeline. In this paper, we make the point that even basic transformations during data preparation can impact the model learned, and that this is exacerbated in a distributed setting. We then sketch our vision of end-to-end explainability of the model learned, taking the pre-processing into account. In particular, we point out the potentials of linking the contributions of research on data provenance with the efforts on explainability in machine learning. In doing so, we highlight pitfalls we may experience in a distributed system on the way to generating more holistic explanations for our machine learning models.", "venue": "IEEE International Conference on Distributed Computing Systems", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-07-01", "journal": {"name": "2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)", "pages": "1620-1629"}, "authors": [{"authorId": "1703312", "name": "Stefanie Scherzinger"}, {"authorId": "145566115", "name": "C. Seifert"}, {"authorId": "1970342", "name": "L. Wiese"}], "citations": [{"paperId": "79a8e513ac136cc91175b99dead2306e6edd36af", "title": "Supporting Better Insights of Data Science Pipelines with Fine-grained Provenance"}, {"paperId": "82613be05470a0afdbd267907aea130e5b7335b1", "title": "Pipeline Design for Data Preparation for Social Media Analysis"}, {"paperId": "fa2de32ec7b1ffc83b597c769a2fb6a4ee59d0b4", "title": "LLVM code optimisation for automatic differentiation: when forward and reverse mode lead in the same direction"}, {"paperId": "d35e6ad6f3778efd965c1282170befc87bab25b0", "title": "Scaling distributed artificial intelligence/machine learning for decision dominance in all-domain operations"}, {"paperId": "40a00f81abe547bade17afad93816b41ed26ff51", "title": "NNCompare: a framework for dataset selection, data augmentation and comparison of different neural networks for medical image analysis"}, {"paperId": "a318e9e21595bbcbc21c5bde9c177734c4b36544", "title": "Distributed Machine Learning for Wireless Communication Networks: Techniques, Architectures, and Applications"}, {"paperId": "54a63ebccbbdf38a07cb3437fef66d34fabd6208", "title": "Capturing and querying fine-grained provenance of preprocessing pipelines in data science"}, {"paperId": "7efc1fadfec6e37f826cd06786a8027a1f5318c3", "title": "Provenance Supporting Hyperparameter Analysis in Deep Neural Networks"}]}

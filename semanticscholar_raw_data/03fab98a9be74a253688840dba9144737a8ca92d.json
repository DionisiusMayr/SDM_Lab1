{"paperId": "03fab98a9be74a253688840dba9144737a8ca92d", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity", "abstract": "This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-10-11", "journal": {"name": "ArXiv", "volume": "abs/2310.07521"}, "authors": [{"authorId": "35504092", "name": "Cunxiang Wang"}, {"authorId": "2109052548", "name": "Xiaoze Liu"}, {"authorId": "2257038841", "name": "Yuanhao Yue"}, {"authorId": "47274259", "name": "Xiangru Tang"}, {"authorId": "2257868315", "name": "Tianhang Zhang"}, {"authorId": "2109077713", "name": "Cheng Jiayang"}, {"authorId": "4841460", "name": "Yunzhi Yao"}, {"authorId": "2257122746", "name": "Wenyang Gao"}, {"authorId": "2257129624", "name": "Xuming Hu"}, {"authorId": "2257044451", "name": "Zehan Qi"}, {"authorId": "2108024273", "name": "Yidong Wang"}, {"authorId": "2145500840", "name": "Linyi Yang"}, {"authorId": "2145270616", "name": "Jindong Wang"}, {"authorId": "2249681654", "name": "Xing Xie"}, {"authorId": "2260691874", "name": "Zheng Zhang"}, {"authorId": "2250437942", "name": "Yue Zhang"}], "citations": [{"paperId": "5bd151095a06398bc4c8d34f2a64c5461af8235b", "title": "Concept -- An Evaluation Protocol on Conversation Recommender Systems with System-centric and User-centric Factors"}, {"paperId": "6aad880b9ba29bae7b9d10dfe275fa8caa6f459e", "title": "Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit"}, {"paperId": "866234cef500959cc85f948e00b770255b482246", "title": "Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs"}, {"paperId": "8d89d38fedfa4a5374c726eb7926510016671441", "title": "EventGround: Narrative Reasoning by Grounding to Eventuality-centric Knowledge Graphs"}, {"paperId": "8f0c4a91b5b7389bdd0ede1d5352212f8664e4cc", "title": "Is Factuality Decoding a Free Lunch for LLMs? Evaluation on Knowledge Editing Benchmark"}, {"paperId": "184753b614b35cde3f2e221cea3bc60fe016d29e", "title": "Editing Conceptual Knowledge for Large Language Models"}, {"paperId": "03cfdde24c6b9837ad8933cb535a2c4a7c0fd971", "title": "HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild"}, {"paperId": "3414be052766667fe375221804e48f4a9c815ba5", "title": "Multimodal Large Language Models to Support Real-World Fact-Checking"}, {"paperId": "ed8f46f493abce9498851e647d900a4628f6ff7f", "title": "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"}, {"paperId": "83d81e31f5c32f6989d98be1133adfc08db094ce", "title": "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models"}, {"paperId": "f05e64c2a096e3762939dfdb7f475724c04a46bd", "title": "Collaborative decoding of critical tokens for boosting factuality of large language models"}, {"paperId": "0c57cb87fcfb345ddc13bab3f20e9c203bac52e9", "title": "JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability"}, {"paperId": "8c15b79160031580fdf4012e18535ea7bc318da5", "title": "Exploring the Impact of Table-to-Text Methods on Augmenting LLM-based Question Answering with Domain Hybrid Data"}, {"paperId": "08436b3ddafd2edc798753ebc87f6ceffed6e8df", "title": "KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"}, {"paperId": "2495700b4303512784fbdbfccc58c6c4f7771ac2", "title": "Language Models with Conformal Factuality Guarantees"}, {"paperId": "19e909f88b8b9b0635bd6e441094e1738c3bba9a", "title": "Unified Hallucination Detection for Multimodal Large Language Models"}, {"paperId": "2fb593ca4b6d2631832d6424e238c32db3db5434", "title": "Factuality of Large Language Models in the Year 2024"}, {"paperId": "bad12cb32faee21eafadbed03c6eec7e23e88ac9", "title": "Improving Sequential Recommendations with LLMs"}, {"paperId": "2b28e170adf5cc68adcd158f0ba6dc8f810394d4", "title": "ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation"}, {"paperId": "5ec774c39f1ef4315ad40c578bae12d5a37ec6fa", "title": "Prospects for inconsistency detection using large language models and sheaves"}, {"paperId": "5f2618d7c743b1e0f8584b1b58126dd678ebb160", "title": "LLaMandement: Large Language Models for Summarization of French Legislative Proposals"}, {"paperId": "541958c384c3356c2da798344600b2a07482e035", "title": "Can AI Assistants Know What They Don't Know?"}, {"paperId": "810b3f4475f22f6ca0f1bded3b8523f3cdebee8d", "title": "UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems"}, {"paperId": "5cd671efa2af8456c615c5faf54d1be4950f3819", "title": "Hallucination is Inevitable: An Innate Limitation of Large Language Models"}, {"paperId": "3f915aab835cbfe69e7b2ea1c73b74ac8a2d384e", "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations"}, {"paperId": "4016fe2e7916b349f58d53f2e8a756bccb9c147a", "title": "From Turing to Transformers: A Comprehensive Review and Tutorial on the Evolution and Applications of Generative Transformer Models"}, {"paperId": "b512451d431df9e411bea4c99f7135d010275445", "title": "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"}, {"paperId": "9924ea41fb84be4ef29b7b5b574a68f1e54a6892", "title": "Technology-Enhanced Student Success Program Short Report"}, {"paperId": "ef7097244ee0cc2d54649e7bec121abf7c628947", "title": "A Survey of the Evolution of Language Model-Based Dialogue Systems"}, {"paperId": "edbfa8e27cf1065a30e6386a7a6313607503ea7e", "title": "RELIC: Investigating Large Language Model Responses using Self-Consistency"}, {"paperId": "1146d40d3d01427a008a20530269667b8989750c", "title": "UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation"}, {"paperId": "6fa0677731184444df0e1fc8070938419cd6da47", "title": "Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents"}, {"paperId": "6aa6003c7d7b3d275ae981aa6200014968c32430", "title": "A Survey of Confidence Estimation and Calibration in Large Language Models"}, {"paperId": "3bddd0073728e6ebd8a139a93c85e1618187f58d", "title": "LLatrieval: LLM-Verified Retrieval for Verifiable Generation"}, {"paperId": "1e909e2a8cdacdcdff125ebcc566f37cb869a1c8", "title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions"}, {"paperId": "abf1ddd4f48b2cee7e5c71ee4609f07209189c75", "title": "Large Language Model based Long-tail Query Rewriting in Taobao Search"}, {"paperId": "234dad3daec8db281882c25bb704eefa8970bdc7", "title": "Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs"}, {"paperId": "64410909714f421c153ac123f975f86cc15c1fec", "title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding"}, {"paperId": "b3474a0bfddd48d46abe2214f42e660b569cc4aa", "title": "FactCHD: Benchmarking Fact-Conflicting Hallucination Detection"}, {"paperId": "3bddda884c5264d2d3ae7087c2d570243dbe1db4", "title": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities"}, {"paperId": "186e96fe036927182ec963b63f9dd7f8ff650158", "title": "ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations"}, {"paperId": "7678a2dc22e74f06c74c5868fba5103fc95454ab", "title": "Exploring the Potential of ChatGPT on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations"}, {"paperId": "bb83db3f3183c847b2394ee3a8c13670bf34620f", "title": "GPT-Neo-CRV: Elevating Information Accuracy in GPT-Neo with Cross-Referential Validation"}, {"paperId": "ebda8d187f83876e37922c4105b171e6d7f99b05", "title": "DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention"}, {"paperId": "529b911da40fa9df598cfbb589e84af5b7c18f0d", "title": "Evaluation of Transfer Learning and Adaptability in Large Language Models with the GLUE Benchmark"}]}

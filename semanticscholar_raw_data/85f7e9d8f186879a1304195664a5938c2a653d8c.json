{"paperId": "85f7e9d8f186879a1304195664a5938c2a653d8c", "publicationVenue": {"id": "136edf8d-0f88-4c2c-830f-461c6a9b842e", "name": "Applied Sciences", "type": "journal", "alternate_names": ["Appl Sci"], "issn": "2076-3417", "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814", "alternate_urls": ["http://www.mathem.pub.ro/apps/", "https://www.mdpi.com/journal/applsci", "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217814"]}, "title": "Real-Time Physical Activity Recognition on Smart Mobile Devices Using Convolutional Neural Networks", "abstract": "Given the ubiquity of mobile devices, understanding the context of human activity with non-intrusive solutions is of great value. A novel deep neural network model is proposed, which combines feature extraction and convolutional layers, able to recognize human physical activity in real-time from tri-axial accelerometer data when run on a mobile device. It uses a two-layer convolutional neural network to extract local features, which are combined with 40 statistical features and are fed to a fully-connected layer. It improves the classification performance, while it takes up 5\u20138 times less storage space and outputs more than double the throughput of the current state-of-the-art user-independent implementation on the Wireless Sensor Data Mining (WISDM) dataset. It achieves 94.18% classification accuracy on a 10-fold user-independent cross-validation of the WISDM dataset. The model is further tested on the Actitracker dataset, achieving 79.12% accuracy, while the size and throughput of the model are evaluated on a mobile device.", "venue": "Applied Sciences", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2020-11-27", "journal": {"name": "Applied Sciences"}, "authors": [{"authorId": "104429528", "name": "Konstantinos Peppas"}, {"authorId": "40141046", "name": "A. Tsolakis"}, {"authorId": "2764130", "name": "S. Krinidis"}, {"authorId": "143636644", "name": "D. Tzovaras"}], "citations": [{"paperId": "387cf1dd4eb72bc707372152b683b201741b42b1", "title": "Novel human activity recognition by graph engineered ensemble deep learning model"}, {"paperId": "ba89f23254a8d5a184630d9ba9ed484960d70302", "title": "Smart-Wearable Sensors and CNN-BiGRU Model: A Powerful Combination for Human Activity Recognition"}, {"paperId": "54325106beb654099b0d184385ea0d58c8e97676", "title": "Enhancing Class Monitoring Through Video Analytics and Deep Learning Models"}, {"paperId": "9419a475f76cc40d0ebd2d76a3335cc1bc08871e", "title": "Building Lightweight Deep learning Models with TensorFlow Lite for Human Activity Recognition on Mobile Devices"}, {"paperId": "f85d2e4a08592fbd7ac27583ae68277359959ce9", "title": "FPGA Implementation of Novel Lossless ECG Compression Algorithm for Low Power Devices"}, {"paperId": "fc3b073f89ff190065f4c72444e3acaf86dbf7ab", "title": "Conditional Human Activity Signal Generation and Generative Classification with a GPT-2 Model"}, {"paperId": "5eb105d4d333eaeab925e0bbe53f183785111698", "title": "A Hybrid Deep Learning Model for Human Activity Recognition and Fall Detection for the Elderly"}, {"paperId": "ca66830cf6f5ec9bde516d8778829788e006be6a", "title": "Human Activity Recognition Using Attention-Mechanism-Based Deep Learning Feature Combination"}, {"paperId": "36324e760df8a4c3502cc4138adcaa5157d4b0d8", "title": "Convolutional Neural Network-Based Low-Powered Wearable Smart Device for Gait Abnormality Detection"}, {"paperId": "d382ebd278c6d7b2eba8eda384cdb709bf0f6fa9", "title": "A Framework for Daily Living Activity Recognition using Fusion of Smartphone Inertial Sensors Data"}, {"paperId": "2d06b3ea245ebe8f2e5cb976c8d9829311db152b", "title": "Design of cuckoo search optimization with deep belief network for human activity recognition and classification"}, {"paperId": "d24d6d1c978ea4e82265ab302eaa18864e0778f3", "title": "On-Device Deep Learning for Mobile and Wearable Sensing Applications: A Review"}, {"paperId": "f687e2ba10388de0007e02833a8737fe3830548d", "title": "Human Activity Recognition Based on a Modified Capsule Network"}, {"paperId": "6a0183e6c68f747110b4adb31b27bb095e7ca3f3", "title": "Improving the Performance and Explainability of Indoor Human Activity Recognition in the Internet of Things Environment"}, {"paperId": "76f1d9fff140657eb9d7860e6a5bf1c5f78d0c0b", "title": "HGCNN: Deep Graph Convolutional Network for Sensor-Based Human Activity Recognition"}, {"paperId": "bc04cee47c9dc955920a7037f360802d3c478051", "title": "Lightweight Multireceptive Field CNN for 12-Lead ECG Signal Classification"}, {"paperId": "16318df5de8ef02c05e5b363f0f3d19189db13d2", "title": "Context-Aware Edge-Based AI Models for Wireless Sensor Networks\u2014An Overview"}, {"paperId": "4f248f2ea8dacce53045e5f46ff5f0fbf1eb06e0", "title": "Human activity recognition: suitability of a neuromorphic approach for on-edge AIoT applications"}, {"paperId": "9f5b8649ea8be41e0a219e475018c6aa4ae160ec", "title": "Human activity recognition by combining external features with accelerometer sensor data using deep learning network model"}, {"paperId": "d107c90cd0d0f8343c5bd3ac48aeaa8ac6cbcae3", "title": "Human Activity Recognition of Exoskeleton Robot with Supervised Learning Techniques"}, {"paperId": "1a36b4b0849c0526e437a82e3600f522a5f8a493", "title": "MSTCN: A multiscale temporal convolutional network for user independent human activity recognition"}, {"paperId": "8f2108cb4ea21ec807ecaf4431b23cb0bcf53ef5", "title": "VLSI based Lossless ECG Compression Algorithm Implementation for Low Power Devices"}, {"paperId": "df2809f522f16047e0c31d37304075a14151c736", "title": "Enhancing COVID-19 tracking apps with human activity recognition using a deep convolutional neural network and HAR-images"}, {"paperId": "e8710c35339531e4913e4e5ef39bd0ba651a0a83", "title": "A Recommendation Specific Human Activity Recognition Dataset with Mobile Device's Sensor Data"}, {"paperId": "199f81d5f15aeae576131478deeb60cded512316", "title": "Improving Energy Efficiency in Tertiary Buildings Through User-Driven Recommendations Delivered on Optimal Micro-moments"}]}

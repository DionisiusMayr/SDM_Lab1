{"paperId": "1b733fddb370e38f89e17dddefb015c61fa2459d", "publicationVenue": {"id": "38e1b942-a62d-4d74-8e5d-677db6ed425f", "name": "Symposium on Networked Systems Design and Implementation", "type": "conference", "alternate_names": ["NSDI", "Symp Networked Syst Des Implement", "Networked Systems Design and Implementation", "Networked Syst Des Implement"]}, "title": "SelfTune: Tuning Cluster Managers", "abstract": "Large-scale cloud providers rely on cluster managers for container allocation and load balancing (e.g., Kubernetes), VM provisioning (e.g., Protean), and other management tasks. These cluster managers use algorithms or heuristics whose behavior depends upon multiple configuration parameters. Currently, operators manually set these parameters using a combination of domain knowledge and limited testing. In very large-scale and dynamic environments, these manually-set parameters may lead to sub-optimal cluster states, adversely affecting important metrics such as latency and throughput. In this paper we describe SelfTune , a framework that automatically tunes such parameters in deployment. SelfTune piggybacks on the iterative nature of cluster managers which, through multiple iterations, drives a cluster to a desired state. Using a simple interface, developers integrate SelfTune into the cluster manager code, which then uses a principled reinforcement learning algorithm to tune important parameters over time. We have deployed SelfTune on tens of thousands of machines that run a large-scale background task scheduler at Microsoft. SelfTune has improved throughput by as much as 20% in this deployment by continuously tuning a key configuration parameter that determines the number of jobs concurrently accessing CPU and disk on every machine. We also evaluate SelfTune with two Azure FaaS workloads, the Kubernetes Vertical Pod Autoscaler, and the DeathStar microservice benchmark. In all cases, SelfTune significantly improves cluster performance.", "venue": "Symposium on Networked Systems Design and Implementation", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "journal": {"pages": "1097-1114"}, "authors": [{"authorId": "1814418467", "name": "Ajaykrishna Karthikeyan"}, {"authorId": "145328735", "name": "Nagarajan Natarajan"}, {"authorId": "1454029001", "name": "Gagan Somashekar"}, {"authorId": "2111488803", "name": "Lei Zhao"}, {"authorId": "2252388", "name": "Ranjita Bhagwan"}, {"authorId": "2058660494", "name": "Rodrigo Fonseca"}, {"authorId": "2190833000", "name": "Tatiana Racheva"}, {"authorId": "2067170657", "name": "Y. Bansal"}], "citations": [{"paperId": "81a9f77a1ba35e3b71bb464515dee728de459e1c", "title": "Towards providing reliable job completion time predictions using PCS"}, {"paperId": "5779eac4a474d50b987c1143a37dc3009c7768fa", "title": "Chroma: Learning and Using Network Contexts to Reinforce Performance Improving Configurations"}, {"paperId": "8844062fc954dd5f0fa326ee756947eeece87e76", "title": "Learning to Score: Tuning Cluster Schedulers through Reinforcement Learning"}, {"paperId": "d09037b3bd6eb44098bbd2b9255cc9afa721fc64", "title": "Towards Performance Management of Large-Scale Microservices Applications"}, {"paperId": "55e4e159a593ea29840e0a8bcf1cb7268bd1e8ab", "title": "Towards OS Heterogeneity Aware Cluster Management for HPC"}, {"paperId": "b09753fd583687e0cdc9170d550f1c69414a42f2", "title": "Enhancing the Configuration Tuning Pipeline of Large-Scale Distributed Applications Using Large Language Models (Idea Paper)"}, {"paperId": "4d1c255fc35427b355c5f964bd5f063821749182", "title": "OPPerTune : Post-Deployment Configuration Tuning of Services Made Easy"}]}

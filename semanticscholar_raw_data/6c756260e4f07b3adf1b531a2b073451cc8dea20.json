{"paperId": "6c756260e4f07b3adf1b531a2b073451cc8dea20", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Accelerating Large Scale Real-Time GNN Inference using Channel Pruning", "abstract": "Graph Neural Networks (GNNs) are proven to be powerful models to generate node embedding for downstream applications. However, due to the high computation complexity of GNN inference, it is hard to deploy GNNs for large-scale or real-time applications. In this paper, we propose to accelerate GNN inference by pruning the dimensions in each layer with negligible accuracy loss. Our pruning framework uses a novel LASSO regression formulation for GNNs to identify feature dimensions (channels) that have high influence on the output activation. We identify two inference scenarios and design pruning schemes based on their computation and memory usage for each. To further reduce the inference complexity, we effectively store and reuse hidden features of visited nodes, which significantly reduces the number of supporting nodes needed to compute the target embedding. We evaluate the proposed method with the node classification problem on five popular datasets and a real-time spam detection application. We demonstrate that the pruned GNN models greatly reduce computation and memory usage with little accuracy loss. For full inference, the proposed method achieves an average of 3.27x speedup with only 0.002 drop in F1-Micro on GPU. For batched inference, the proposed method achieves an average of 6.67x speedup with only 0.003 drop in F1-Micro on CPU. To the best of our knowledge, we are the first to accelerate large scale real-time GNN inference through channel pruning.", "venue": "Proceedings of the VLDB Endowment", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2021-05-10", "journal": {"name": "ArXiv", "volume": "abs/2105.04528"}, "authors": [{"authorId": "1443735039", "name": "Hongkuan Zhou"}, {"authorId": "2215594", "name": "Ajitesh Srivastava"}, {"authorId": "1750905107", "name": "Hanqing Zeng"}, {"authorId": "2286832947", "name": "R. Kannan"}, {"authorId": "1728271", "name": "V. Prasanna"}], "citations": [{"paperId": "74ba57b693b67506c6eae81b30cda1b28022e925", "title": "Unifews: Unified Entry-Wise Sparsification for Efficient Graph Neural Network"}, {"paperId": "0a980180974561d3861ee298503426ddf1c3aa65", "title": "PruneGNN: Algorithm-Architecture Pruning Framework for Graph Neural Network Acceleration"}, {"paperId": "a25a73e09e603c73510bab61a78fb1fa66f04888", "title": "Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework"}, {"paperId": "60961d2d07e5163300d581691d63427ddfe7cd6e", "title": "Graph Inference Acceleration by Learning MLPs on Graphs without Supervision"}, {"paperId": "3edb1cebaeadc16c666d63886d3d252c54bd5953", "title": "Localization in 3D Wireless Sensor Networks with Obstacle Consideration"}, {"paperId": "2b1e64e590d3c4cb6e9c0ccd57acbe5be7b3b7fa", "title": "View-based Explanations for Graph Neural Networks"}, {"paperId": "35fcae7cdf6e24a64f9d6700bb468d0b4f1f1ed6", "title": "Double Wins: Boosting Accuracy and Efficiency of Graph Neural Networks by Reliable Knowledge Distillation"}, {"paperId": "20c687e4557afc303015eae8cbc37372209865a1", "title": "Equivariance Is Not All You Need: Characterizing the Utility of Equivariant Graph Neural Networks for Particle Physics Tasks"}, {"paperId": "3d841faa4b16234ae56ff15ef32f85915c29a0a9", "title": "ABKD: Graph Neural Network Compression with Attention-Based Knowledge Distillation"}, {"paperId": "94cb46a2657bf13a0480e794e347c2586d0cbaab", "title": "Accelerating Scalable Graph Neural Network Inference with Node-Adaptive Propagation"}, {"paperId": "3f88b30c63cb50478fa45c25629f60314f69b89c", "title": "Enabling Efficient Random Access to Hierarchically Compressed Text Data on Diverse GPU Platforms"}, {"paperId": "3f57f297eb80171f9c2a900d087cfcac943c4c1e", "title": "DGI: An Easy and Efficient Framework for GNN Model Evaluation"}, {"paperId": "d1dbbcb486e4133a874d6f080871468642f777ad", "title": "VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs"}, {"paperId": "5965a485cd26bb8840cf5b602c396e845530d1d1", "title": "Frameless Graph Knowledge Distillation"}, {"paperId": "894d61c709ec6f61899703458d90b09c663d7b11", "title": "A Survey on Graph Neural Network Acceleration: Algorithms, Systems, and Customized Hardware"}, {"paperId": "d334f5fc3050c9fd3b989249b228e7c64c77bdf7", "title": "Graph Entropy Minimization for Semi-supervised Node Classification"}, {"paperId": "fa1e8a10ec22c5177a0290d4877d150a9b36dafe", "title": "The Evolution of Distributed Systems for Graph Neural Networks and Their Origin in Graph Processing and Deep Learning: A Survey"}, {"paperId": "384d2f2f5b6441e1a3f334d9649cf3f546987e28", "title": "Less Can Be More: Unsupervised Graph Pruning for Large-scale Dynamic Graphs"}, {"paperId": "448b8bcf9edfa236e9906fca91e99abde2ae4238", "title": "Graph Neural Network for Accurate and Low-complexity SAR ATR"}, {"paperId": "772d3c8a9a8962210939df6fa5cedd0939d365de", "title": "Graph2Feat: Inductive Link Prediction via Knowledge Distillation"}, {"paperId": "8bc40c2ea8a526b296041450c73fd6784108bf76", "title": "InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs"}, {"paperId": "e18093d0e0c21580426d2fc2024547ab1af77af4", "title": "EdgeNN: Efficient Neural Network Inference for CPU-GPU Integrated Edge Devices"}, {"paperId": "444766f77e2109fe17fded1363f3dbbe5719dfa9", "title": "Graph Explicit Neural Networks: Explicitly Encoding Graphs for Efficient and Accurate Inference"}, {"paperId": "6155e94e5174e4c615f890c185acbe4b635dba16", "title": "IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research"}, {"paperId": "fd529dc803b31987f543a5d6de389e52315abaeb", "title": "IGRP: Iterative Gradient Rank Pruning for Finding Graph Lottery Ticket"}, {"paperId": "5205f96c6894b1b1fed6683d0c67f4b1f3b25b45", "title": "Scalable Graph Convolutional Network Training on Distributed-Memory Systems"}, {"paperId": "bf7e4d4d761c4da29e5410d962195aa5b64bee4a", "title": "Input Feature Pruning for Accelerating GNN Inference on Heterogeneous Platforms"}, {"paperId": "17eecd2973983b87dafc409b85c6358a1f1fd687", "title": "Topology-Aware Quantization Strategy via Personalized PageRank for Graph Neural Networks"}, {"paperId": "d4cdadb0355e7c8bad2a6040687ae4f9a9233937", "title": "DGI: Easy and Efficient Inference for GNNs"}, {"paperId": "d59b174547769aac7ef6916c3744bc60622aadb5", "title": "Accelerating GNN Inference by Soft Channel Pruning"}, {"paperId": "1e79e33c77b2d8eaf643af0e1f5003057d7356b2", "title": "Distributed Graph Neural Network Training: A Survey"}, {"paperId": "a2addad8bf58c76c4ad55c2e82c2d332cc576bc3", "title": "Efficient Graph Neural Network Inference at Large Scale"}, {"paperId": "4004a6304d4e576671d73b4eb44400728396c32f", "title": "SA-MLP: Distilling Graph Knowledge from GNNs into Structure-Aware MLP"}, {"paperId": "2be6804469b99d9c336ef0fe146f9a9ffaa75282", "title": "Linkless Link Prediction via Relational Distillation"}, {"paperId": "0cde51d846952f5b5e6811313e2257fff9642dad", "title": "Comprehensive Graph Gradual Pruning for Sparse Training in Graph Neural Networks"}, {"paperId": "ce15263abe9a3481da9f6c4cf99b8e8baf449a84", "title": "BRIGHT - Graph Neural Networks in Real-time Fraud Detection"}, {"paperId": "21913eb287f8fc33db8f6274fd2a07072c4e11eb", "title": "Trustworthy Graph Neural Networks: Aspects, Methods and Trends"}, {"paperId": "39271db2458f6fb635e40372049cb1e203c7e05c", "title": "SANCUS: Staleness-Aware Communication-Avoiding Full-Graph Decentralized Training in Large-Scale Graph Neural Networks"}, {"paperId": "f3e5ae436cee14b2db53e84d789b1170a244cff8", "title": "Distributed Cooperative Localization with Optimized Constraints for 3D WSNs"}, {"paperId": "e9cf7d2502402541edca17fd10aa76f9d86951d2", "title": "Model-Architecture Co-Design for High Performance Temporal GNN Inference on FPGA"}, {"paperId": "a0458ab2806967a0cec04bfc810c5c702a0da665", "title": "Algorithm and System Co-design for Efficient Subgraph-based Graph Representation Learning"}, {"paperId": "8994fd8dc3a4e18e93013b8aa8a79c732bf81572", "title": "Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation"}, {"paperId": "f87ab24bca90dc062b7ba73dc355a41625c0652a", "title": "Searching Lottery Tickets in Graph Neural Networks: A Dual Perspective"}, {"paperId": "791e318c1a6ebd43f70edb66822b51eadfe3e00f", "title": "ORB: Empowering Graph Queries through Inference"}, {"paperId": "c020dc77e2abc6ee1bcc043b21eb8786706d8328", "title": "VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs"}]}

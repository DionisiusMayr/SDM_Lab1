{"paperId": "3bdd3d56ef9054aba47f83879b531a4842640295", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Learning or Self-aligning? Rethinking Instruction Fine-tuning", "abstract": "Instruction Fine-tuning~(IFT) is a critical phase in building large language models~(LLMs). Previous works mainly focus on the IFT's role in the transfer of behavioral norms and the learning of additional world knowledge. However, the understanding of the underlying mechanisms of IFT remains significantly limited. In this paper, we design a knowledge intervention framework to decouple the potential underlying factors of IFT, thereby enabling individual analysis of different factors. Surprisingly, our experiments reveal that attempting to learn additional world knowledge through IFT often struggles to yield positive impacts and can even lead to markedly negative effects. Further, we discover that maintaining internal knowledge consistency before and after IFT is a critical factor for achieving successful IFT. Our findings reveal the underlying mechanisms of IFT and provide robust support for some very recent and potential future works.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-02-28", "journal": {"name": "ArXiv", "volume": "abs/2402.18243"}, "authors": [{"authorId": "2280137459", "name": "Mengjie Ren"}, {"authorId": "2113252896", "name": "Boxi Cao"}, {"authorId": "2116455765", "name": "Hongyu Lin"}, {"authorId": "2288206462", "name": "Liu Cao"}, {"authorId": "2118233348", "name": "Xianpei Han"}, {"authorId": "2287932496", "name": "Ke Zeng"}, {"authorId": "2249757099", "name": "Guanglu Wan"}, {"authorId": "2290035990", "name": "Xunliang Cai"}, {"authorId": "2110832778", "name": "Le Sun"}], "citations": []}

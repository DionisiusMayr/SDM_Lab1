{"paperId": "249869ad503dbae9774bb340909b8a5a4911b406", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Mondrian: On-Device High-Performance Video Analytics with Compressive Packed Inference", "abstract": "In this paper, we present Mondrian, an edge system that enables high-performance object detection on high-resolution video streams. Many lightweight models and system optimization techniques have been proposed for resource-constrained devices, but they do not fully utilize the potential of the accelerators over dynamic, high-resolution videos. To enable such capability, we devise a novel Compressive Packed Inference to minimize per-pixel processing costs by selectively determining the necessary pixels to process and combining them to maximize processing parallelism. In particular, our system quickly extracts ROIs and dynamically shrinks them, reflecting the effect of the fast-changing characteristics of objects and scenes. It then intelligently combines such scaled ROIs into large canvases to maximize the utilization of inference accelerators such as GPU. Evaluation across various datasets, models, and devices shows Mondrian outperforms state-of-the-art baselines (e.g., input rescaling, ROI extractions, ROI extractions+batching) by 15.0-19.7% higher accuracy, leading to $\\times$6.65 higher throughput than frame-wise inference for processing various 1080p video streams. We will release the code after the paper review.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2024-03-12", "journal": {"name": "ArXiv", "volume": "abs/2403.07598"}, "authors": [{"authorId": "2290905969", "name": "Changmin Jeon"}, {"authorId": "2249154428", "name": "Seonjun Kim"}, {"authorId": "26959426", "name": "Juheon Yi"}, {"authorId": "2290946767", "name": "Youngki Lee"}], "citations": []}

{"paperId": "daa2171619a5a00d478798f400dcece231b1706e", "publicationVenue": {"id": "2dc4386c-f418-4a62-a2c3-6b89b06981be", "name": "Journal of Intelligent & Fuzzy Systems", "type": "journal", "alternate_names": ["Journal of Intelligent and Fuzzy Systems", "J Intell  Fuzzy Syst", "J Intell Fuzzy Syst"], "issn": "1064-1246", "url": "http://content.iospress.com/journals/journal-of-intelligent-and-fuzzy-systems/", "alternate_urls": ["http://www.iospress.nl/journal-of-intelligent-fuzzy-systems/", "https://www.iospress.nl/html/10641246.php"]}, "title": "A comprehensive study and review of tuning the performance on database scalability in big data analytics", "abstract": "In the modern era, digital data processing with a huge volume of data from the repository is challenging due to various data formats and the extraction techniques available. The accuracy levels and speed of the data processing on larger networks using modern tools have limitations for getting quick results. The major problem of data extraction on the repository is finding the data location and the dynamic changes in the existing data. Even though many researchers created different tools with algorithms for processing those data from the warehouse, it has not given accurate results and gives low latency. This output is due to a larger network of batch processing. The performance of the database scalability has to be tuned with the powerful distributed framework and programming languages for the latest real-time applications to process the huge datasets over the network. Data processing has been done in big data analytics using the modern tools HADOOP and SPARK effectively. Moreover, a recent programming language such as Python will provide solutions with the concepts of map reduction and erasure coding. But it has some challenges and limitations on a huge dataset at network clusters. This review paper deals with Hadoop and Spark features also their challenges and limitations over different criteria such as file size, file formats, and scheduling techniques. In this paper, a detailed survey of the challenges and limitations that occurred during the processing phase in big data analytics was discussed and provided solutions to that by selecting the languages and techniques using modern tools. This paper gives solutions to the research people who are working in big data analytics, for improving the speed of data processing with a proper algorithm over digital data in huge repositories.", "venue": "Journal of Intelligent & Fuzzy Systems", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2022-12-28", "journal": {"name": "J. Intell. Fuzzy Syst.", "pages": "5231-5255", "volume": "44"}, "authors": [{"authorId": "88912341", "name": "M. Sundarakumar"}, {"authorId": "143811319", "name": "G. Mahadevan"}, {"authorId": "2280679438", "name": "R. Natchadalingam"}, {"authorId": "2162251312", "name": "G. Karthikeyan"}, {"authorId": "116175631", "name": "J. Ashok"}, {"authorId": "21456740", "name": "J. Manoharan"}, {"authorId": "2191904466", "name": "V. Sathya"}, {"authorId": "2036810836", "name": "P. Velmurugadass"}], "citations": [{"paperId": "f39e47a0b6c31801ec7970c989ee6c45ecdc4de0", "title": "Performance Analysis and Improvement for CRUD Operations in Relational Databases from Java Programs Using JPA, Hibernate, Spring Data JPA"}, {"paperId": "bd4d625877a9fd0d1ac1069a3915dc0ec033aede", "title": "Improving big data analytics data processing speed through map reduce scheduling and replica placement with HDFS using genetic optimization techniques"}, {"paperId": "d9dd70ab5580904a3c2a0bce9c743e1825e8b8e8", "title": "An Efficient Approach with Modified Butterfly Optimization Algorithm for Task Scheduling and DLAT Based Cloud Data Security"}, {"paperId": "2684f01fedc2a32500883cb3db51e08c03041a9e", "title": "An Efficient Data Recognition and Classification in Cloud-IoT System using Optimized K-Means Algorithm and Hybrid CNN-SVM Deep Learning Model"}, {"paperId": "664aa5982cfdf572792d0135b9ca30a2acdbd87a", "title": "Improving Data Processing Speed on Large Datasets in a Hadoop Multi-node Cluster using Enhanced Apriori Algorithm"}, {"paperId": "4b652529d0d3aed1ac0c8dfee72b18c3d9d667bc", "title": "A HDCP-Fuzzy Model for Securing Data Integrity of Medical Records against Attacks"}, {"paperId": "f218d65618174ba549de50f63743fdb5b8605a3a", "title": "Computational Overhead Analysis for Mitigation of Content Poisoning Attack in NDN-based IoT Body Area Networks"}]}

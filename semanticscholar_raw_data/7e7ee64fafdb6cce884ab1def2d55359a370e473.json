{"paperId": "7e7ee64fafdb6cce884ab1def2d55359a370e473", "publicationVenue": {"id": "43893b55-fde6-4e2b-9d2e-c15a669a1f94", "name": "ACM Symposium on Parallelism in Algorithms and Architectures", "type": "conference", "alternate_names": ["SPAA", "ACM Symposium on Parallel Algorithms and Architectures", "ACM Symp Parallelism Algorithm Archit", "ACM Symp Parallel Algorithm Archit"], "url": "http://www.spaa-conference.org/"}, "title": "High-Performance and Flexible Parallel Algorithms for Semisort and Related Problems", "abstract": "Semisort is a fundamental algorithmic primitive widely used in the design and analysis of efficient parallel algorithms. It takes input as an array of records and a function extracting a key per record, and reorders them so that records with equal keys are contiguous. Since many applications only require collecting equal values, but not fully sorting the input, semisort is broadly applicable, e.g., in string algorithms, graph analytics, and geometry processing, among many other domains. However, despite dozens of recent papers that use semisort in their theoretical analysis and the existence of an asymptotically optimal parallel semisort algorithm, most implementations of these parallel algorithms choose to implement semisort by using comparison or integer sorting in practice, due to potential performance issues in existing semisort implementations. In this paper, we revisit the semisort problem, with the goal of achieving a high-performance parallel semisort implementation with a flexible interface. Our approach can easily be extended to two related problems, histogram and collect-reduce. Our algorithms achieve strong speedups in practice, and importantly, outperform state-of-the-art parallel sorting and semisorting methods for almost all settings we tested, with varying input sizes, distribution, and key types. On average (geometric means), our semisort implementation is at least 1.27x faster the best of the tested baselines. We also test two important applications with real-world data, and show that our algorithms improve the performance (up to 2.13x) over existing approaches. We believe that many other parallel algorithm implementations can be accelerated using our results.", "venue": "ACM Symposium on Parallelism in Algorithms and Architectures", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2023-04-20", "journal": {"name": "Proceedings of the 35th ACM Symposium on Parallelism in Algorithms and Architectures"}, "authors": [{"authorId": "2118186408", "name": "Xiaojun Dong"}, {"authorId": "1712213830", "name": "Yunshu Wu"}, {"authorId": "2135362315", "name": "Zhongqi Wang"}, {"authorId": "35221280", "name": "Laxman Dhulipala"}, {"authorId": "46964402", "name": "Yan Gu"}, {"authorId": "2108541101", "name": "Yihan Sun"}], "citations": []}

{"paperId": "b85206105603a65b3108f84ca92067f928951aca", "publicationVenue": {"id": "29df4b17-9a16-4a4c-94a6-002f52e628b4", "name": "International Conference on Parallel Processing", "type": "conference", "alternate_names": ["ICPP", "Int Conf Parallel Process", "IEEE Int Conf Pulsed Power", "IEEE International Conference on Pulsed Power"], "url": "http://www.wikicfp.com/cfp/program?id=1447"}, "title": "Reference-distance Eviction and Prefetching for Cache Management in Spark", "abstract": "Optimizing memory cache usage is vital for performance of in-memory data-parallel frameworks such as Spark. Current data-analytic frameworks utilize the popular Least Recently Used (LRU) policy, which does not take advantage of data dependency information available in the application's directed acyclic graph (DAG). Recent research in dependency-aware caching, notably MemTune and Least Reference Count (LRC), have made important improvements to close this gap. But they do not fully leverage the DAG structure, which imparts information such as the time-spatial distribution of data references across the workflow, to further improve cache hit ratio and application runtime. In this paper, we propose and develop a new cache management policy, Most Reference Distance (MRD) that utilizes DAG information to optimize both eviction and prefetching of data to improve cache management. MRD takes into account the relative stage distance of each data block reference in the application workflow, effectively evicting the furthest and least likely data in the cache to be used, while aggressively prefetching the nearest and most likely data that will be needed, and in doing so, better overlapping computation with I/O time. Our experiments with a Spark implementation, utilizing popular benchmarking workloads show that, MRD has low overhead and improves performance by an average of 53% compared to LRU, and up to 68% and 45% when compared to MemTune and LRC respectively. It works best for I/O-intensive workloads.", "venue": "International Conference on Parallel Processing", "year": 2018, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2018-08-13", "journal": {"name": "Proceedings of the 47th International Conference on Parallel Processing"}, "authors": [{"authorId": "51166057", "name": "T. B. G. Perez"}, {"authorId": "46224002", "name": "Xiaobo Zhou"}, {"authorId": "1778706", "name": "Dazhao Cheng"}], "citations": [{"paperId": "12f33fce9a1c5c4c102fbe7685dac34cc1ccd0e6", "title": "DAG-aware harmonizing job scheduling and data caching for disaggregated analytics frameworks"}, {"paperId": "bea73f051ae6b5779468c9481d9f9ddcc2e443f5", "title": "SAC: Dynamic Caching upon Sketch for In-Memory Big Data Analytics"}, {"paperId": "56d16cb01d24816507548437f3303c3f55007b71", "title": "Optimizing computational costs of Spark for SARS\u2010CoV\u20102 sequences comparisons on a commercial cloud"}, {"paperId": "4b8a096069c3ae9601733874ac7aaa40a7c91442", "title": "LPW: an efficient data-aware cache replacement strategy for Apache Spark"}, {"paperId": "a05189ed010a2d7bebcf8382e41783814538701a", "title": "Tripod: Harmonizing Job Scheduling and Data Caching for Analytics Frameworks"}, {"paperId": "a31dffc8d8a3099eb357f429d1bc9cdfbd609377", "title": "SparkCAD: Caching Anomalies Detector for Spark Applications"}, {"paperId": "a630e2526b37242864f8995c77f8af9bc86c9895", "title": "Blink: Lightweight Sample Runs for Cost Optimization of Big Data Applications"}, {"paperId": "dee8afd8dfa6c3c161542e337236dd41caa1f256", "title": "Juggler: Autonomous Cost Optimization and Performance Prediction of Big Data Applications"}, {"paperId": "840f3d9064c631a0e37e94dc55a04b3bb0589be4", "title": "Performance Improvement of DAG-Aware Task Scheduling Algorithms with Efficient Cache Management in Spark"}, {"paperId": "def13e123abeea4ecc210eee02cf141ce0646567", "title": "SODA: A Semantics-Aware Optimization Framework for Data-Intensive Applications Using Hybrid Program Analysis"}, {"paperId": "c99b72519236e9124a59033108cde08ee389b3f9", "title": "CCA: Cost-Capacity-Aware Caching for In-Memory Data Analytics Frameworks"}, {"paperId": "3b33394b696b8854625ab6519121cec14629cf7b", "title": "Memory Management Approaches in Apache Spark: A Review"}, {"paperId": "21bd6c6efd91cfa9773b1b9134d5b9afea757cd9", "title": "DAG-Aware Joint Task Scheduling and Cache Management in Spark Clusters"}, {"paperId": "c9cc08acdb95a51f3e4831021d36234947e29836", "title": "Resource-Aware Cache Management for In-Memory Data Analytics Frameworks"}, {"paperId": "0897a997966b3ee4c1a461d81e93a04f9120747c", "title": "ATuMm: Auto-tuning Memory Manager in Apache Spark"}, {"paperId": "6d7ae61c36b4a81bbd84d2fb9b7bb0c3645cd981", "title": "Bottleneck-Aware Task Scheduling Based on Per-Stage and Multi-ML Profiling"}, {"paperId": "f17c1aa4c9330e2c1a2fb7f8bdfaeaec898df9dd", "title": "Execution Repair for Spark Programs by Active Maintenance of Partition Dependency"}, {"paperId": "39fc8e3f74da38e5f0041148ce2bba7aa4490120", "title": "SMConf: One-Size-Fit-Bunch, Automated Memory Capacity Configuration for In-memory Data Analytic Platform"}, {"paperId": "1b8d6aad1256d867b194e14962497690f0a98b6e", "title": "Caching in the Multiverse Mania"}, {"paperId": "22dd0ef9029102211f1da95edf4c9ba528529d03", "title": "This paper is included in the Proceedings of the 19th USENIX Conference on File and Storage Technologies."}, {"paperId": "c05af9286bd306bf148818428f7502edcdaa1aa7", "title": "Blaze: Holistic Caching for Iterative Data Processing"}]}

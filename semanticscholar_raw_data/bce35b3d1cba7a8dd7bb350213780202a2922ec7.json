{"paperId": "bce35b3d1cba7a8dd7bb350213780202a2922ec7", "publicationVenue": {"id": "bdc2e585-4e48-4e36-8af1-6d859763d405", "name": "AAAI Conference on Artificial Intelligence", "type": "conference", "alternate_names": ["National Conference on Artificial Intelligence", "National Conf Artif Intell", "AAAI Conf Artif Intell", "AAAI"], "url": "http://www.aaai.org/"}, "title": "VAST: The Valence-Assessing Semantics Test for Contextualizing Language Models", "abstract": "We introduce VAST, the Valence-Assessing Semantics Test, a novel intrinsic evaluation task for contextualized word embeddings (CWEs). Despite the widespread use of contextualizing language models (LMs), researchers have no intrinsic evaluation task for understanding the semantic quality of CWEs and their unique properties as related to contextualization, the change in the vector representation of a word based on surrounding words; tokenization, the breaking of uncommon words into subcomponents; and LM-specific geometry learned during training. VAST uses valence, the association of a word with pleasantness, to measure the correspondence of word-level LM semantics with widely used human judgments, and examines the effects of contextualization, tokenization, and LM-specific geometry. Because prior research has found that CWEs from OpenAI's 2019 English-language causal LM GPT-2 perform poorly on other intrinsic evaluations, we select GPT-2 as our primary subject, and include results showing that VAST is useful for 7 other LMs, and can be used in 7 languages. GPT-2 results show that the semantics of a word are more similar to the semantics of context in layers closer to model output, such that VAST scores diverge between our contextual settings, ranging from Pearson\u2019s rho of .55 to .77 in layer 11. We also show that multiply tokenized words are not semantically encoded until layer 8, where they achieve Pearson\u2019s rho of .46, indicating the presence of an encoding process for multiply tokenized words which differs from that of singly tokenized words, for which rho is highest in layer 0. We find that a few neurons with values having greater magnitude than the rest mask word-level semantics in GPT-2\u2019s top layer, but that word-level semantics can be recovered by nullifying non-semantic principal components: Pearson\u2019s rho in the top layer improves from .32 to .76. Downstream POS tagging and sentence classification experiments indicate that the GPT-2 uses these principal components for non-semantic purposes, such as to represent sentence-level syntax relevant to next-word prediction. After isolating semantics, we show the utility of VAST for understanding LM semantics via improvements over related work on four word similarity tasks, with a score of .50 on SimLex-999, better than the previous best of .45 for GPT-2. Finally, we show that 8 of 10 WEAT bias tests, which compare differences in word embedding associations between groups of words, exhibit more stereotype-congruent biases after isolating semantics, indicating that non-semantic structures in LMs also mask social biases.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-03-14", "journal": {"name": "ArXiv", "volume": "abs/2203.07504"}, "authors": [{"authorId": "100508901", "name": "R. Wolfe"}, {"authorId": "144537437", "name": "Aylin Caliskan"}], "citations": [{"paperId": "8755ec891c539838e21c9c4631410a1f7a9a0989", "title": "What\u2019s in a Name? Experimental Evidence of Gender Bias in Recommendation Letters Generated by ChatGPT"}, {"paperId": "0a0e2015084e68127dd6750d5d0aaa297e5b2f0d", "title": "Artificial Intelligence, Bias, and Ethics"}, {"paperId": "949842a2531ccbd47e650980ceebc5e0a9a90b1f", "title": "Evaluating Biased Attitude Associations of Language Models in an Intersectional Context"}, {"paperId": "b04493c0865c166d00f65bb78f6476b466bbe512", "title": "American == White in Multimodal Language-and-Image AI"}, {"paperId": "0f72e329d3b0f1cfe388d102ef5fec0677ac7558", "title": "Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics"}, {"paperId": "3cfea2a4291ea4e5e0061d8a626e414e27ec5ac5", "title": "Evidence for Hypodescent in Visual Semantic AI"}, {"paperId": "5dd7bc394e032eb0e982699a5f0c781fab9e3111", "title": "Contrastive Visual Semantic Pretraining Magnifies the Semantics of Natural Language Representations"}]}

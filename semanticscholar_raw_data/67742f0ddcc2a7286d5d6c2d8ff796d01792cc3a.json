{"paperId": "67742f0ddcc2a7286d5d6c2d8ff796d01792cc3a", "publicationVenue": {"id": "7c9d091e-015e-4e5d-a11f-9bc369fcf414", "name": "IEEE Transactions on Parallel and Distributed Systems", "type": "journal", "alternate_names": ["IEEE Trans Parallel Distrib Syst"], "issn": "1045-9219", "url": "http://www.computer.org/tpds", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=71"]}, "title": "Privacy vs. Efficiency: Achieving Both Through Adaptive Hierarchical Federated Learning", "abstract": "As a decentralized training paradigm, Federated learning (FL) promises data privacy by exchanging model parameters instead of raw local data. However, it is still impeded by the resource limitations of end devices and privacy risks from the \u2018curious\u2019 cloud. Yet, existing work predominately ignores that these two issues are non-orthogonal in nature. In this article, we propose a joint design (i.e., AHFL) that accommodates both the efficiency expectation and privacy protection of clients towards high inference accuracy. Based on a cloud-edge-end hierarchical FL framework, we carefully offload the training burden of devices to one proximate edge for enhanced efficiency and apply a two-level differential privacy mechanism for privacy protection. To resolve the conflicts of dynamical resource consumption and privacy risk accumulation, we formulate an optimization problem for choosing configurations under correlated learning parameters (e.g., iterations) and privacy control factors (e.g., noise intensity). An adaptive algorithmic solution is presented based on performance-oriented resource scheduling, budget-aware device selection, and adaptive local noise injection. Extensive evaluations are performed on three different data distribution cases of two real-world datasets, using both a networked prototype and large-scale simulations. Experimental results show that AHFL relieves the end's resource burden (w.r.t. computation time 8.58% <inline-formula><tex-math notation=\"LaTeX\">$\\downarrow$</tex-math><alternatives><mml:math><mml:mo>\u2193</mml:mo></mml:math><inline-graphic xlink:href=\"guo-ieq1-3244198.gif\"/></alternatives></inline-formula>, communication time 59.35%<inline-formula><tex-math notation=\"LaTeX\">$\\downarrow$</tex-math><alternatives><mml:math><mml:mo>\u2193</mml:mo></mml:math><inline-graphic xlink:href=\"guo-ieq2-3244198.gif\"/></alternatives></inline-formula> and memory consumption 43.61%<inline-formula><tex-math notation=\"LaTeX\">$\\downarrow$</tex-math><alternatives><mml:math><mml:mo>\u2193</mml:mo></mml:math><inline-graphic xlink:href=\"guo-ieq3-3244198.gif\"/></alternatives></inline-formula>) and has better accuracy (6.34%<inline-formula><tex-math notation=\"LaTeX\">$\\uparrow$</tex-math><alternatives><mml:math><mml:mo>\u2191</mml:mo></mml:math><inline-graphic xlink:href=\"guo-ieq4-3244198.gif\"/></alternatives></inline-formula>) than 3 typical baselines under the limited resource and privacy budgets. The code for our implementation is available at <uri>https://github.com/Guoyeting/AHFL</uri>.", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-04-01", "journal": {"name": "IEEE Transactions on Parallel and Distributed Systems", "pages": "1331-1342", "volume": "34"}, "authors": [{"authorId": "6507224", "name": "Yeting Guo"}, {"authorId": "70448703", "name": "F. Liu"}, {"authorId": "2053854565", "name": "Tongqing Zhou"}, {"authorId": "143942560", "name": "Zhiping Cai"}, {"authorId": "1730284", "name": "Nong Xiao"}], "citations": [{"paperId": "91142b6ff67ff2ab0b1f3a3bd9a834a00854fe6b", "title": "US-Byte: An Efficient Communication Framework for Scheduling Unequal-Sized Tensor Blocks in Distributed Deep Learning"}, {"paperId": "6242d1e97a59c7b8bd4882aaa857e3351e06aa5b", "title": "A Survey on Bias Mitigation in Federated Learning"}, {"paperId": "a60a3b1188adfe6476a7785ab03032679e5f0665", "title": "A Survey on Trustworthy Edge Intelligence: From Security and Reliability To Transparency and Sustainability"}]}

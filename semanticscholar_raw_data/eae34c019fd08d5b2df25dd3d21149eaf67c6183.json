{"paperId": "eae34c019fd08d5b2df25dd3d21149eaf67c6183", "publicationVenue": {"id": "c3e5f1c8-9ba7-47e5-acde-53063a69d483", "name": "Future Internet", "type": "journal", "issn": "1999-5903", "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-156830", "alternate_urls": ["http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-156830", "https://www.mdpi.com/journal/futureinternet"]}, "title": "ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3)", "abstract": "Historically, mastery of writing was deemed essential to human progress. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI-generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness in a manner similar to grading students, while qualitative precision gauged the scientific contribution similar to reviewing a scientific article. In the quantitative test, ChatGPT-4 scored near the passing grade (\u22125) whereas ChatGPT-3.5 (\u221218), Bing (\u221221) and Bard (\u221231) were not far behind. Claude 2 (\u221275) and Aria (\u221280) scored much lower. In the qualitative test, all AI chatbots, but especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, but all failed to generate original scientific content. As a side note, our results suggest that with ChatGPT-4, the size of large language models has reached a plateau. Furthermore, this paper underscores the intricate and recursive nature of human research. This process of transforming raw data into refined knowledge is computationally irreducible, highlighting the challenges AI chatbots face in emulating human originality in scientific writing. Our results apply to the state of affairs in the third quarter of 2023. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect this to change in the near future as current large language model-based AI chatbots evolve into large language model-powered software.", "venue": "Future Internet", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-09-14", "journal": {"name": "Future Internet", "pages": "336", "volume": "15"}, "authors": [{"authorId": "120330902", "name": "Edisa Lozi\u0107"}, {"authorId": "83193967", "name": "Benjamin \u0160tular"}], "citations": [{"paperId": "a8a0e0574b18787f03bd25e99124d0f4421922e6", "title": "AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks"}, {"paperId": "5ac2ab34db962032d9d6be4af09d53a1b61caf30", "title": "How good are large language models for automated data extraction from randomized trials?"}, {"paperId": "4a02605e8122243bbf3ca3021a2ef793be83da5c", "title": "Using large language models to generate silicon samples in consumer and marketing research: Challenges, opportunities, and guidelines"}, {"paperId": "083ee92e11f9da6ed7069d95b4bf1c7e7dc81c04", "title": "Directions for the Development of Social Sciences and Humanities in the Context of Creating Artificial General Intelligence"}, {"paperId": "6ae06f2bf66f19637adc695bc47256eeb1635b10", "title": "A Structured Narrative Prompt for Prompting Narratives from Large Language Models: Sentiment Assessment of ChatGPT-Generated Narratives and Real Tweets"}, {"paperId": "aec88b1ce8c6b9254abba65e94496265ba646d1d", "title": "Evaluating ChatGPT\u2019s Consciousness and Its Capability to Pass the Turing Test: A Comprehensive Analysis"}]}

{"paperId": "61345c4a629e6d7ab5ba21cf8b35aa5e808fe6dc", "publicationVenue": {"id": "b7478691-8468-4053-b828-4b261de2bf96", "name": "IEEE International Symposium on Real-Time Distributed Computing", "type": "conference", "alternate_names": ["Int Symp Object/component/service-oriented Real-time Distrib Comput", "ISORC", "International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing", "IEEE Int Symp Real-time Distrib Comput"], "url": "https://ieeexplore.ieee.org/xpl/conhome/1000514/all-proceedings"}, "title": "Pareto-Based Scheduling of MapReduce Workloads", "abstract": "In recent years we are observing an increased demand for processing large amounts of data. The MapReduce programming model has been utilized by major computing companies in order to perform large-scale data processing. However, the problem of efficiently scheduling MapReduce workloads in cluster environments, like Amazon's EC2, can be challenging due to the observed tradeoff between the need for performance and the corresponding monetary cost. The problem is exacerbated by the fact that cloud providers tend to charge users based on their I/O operations increasing dramatically the spending budget. In this paper we describe our approach for scheduling MapReduce workloads in cluster environments taking into consideration the performance/budget tradeoff. Our approach makes the following contributions: (i) a novel Pareto-based scheduler for identifying near-optimal resource allocations for user's workloads with respect to performance and monetary cost, and (ii) automatic configuration of tasks' buffer sizes to minimize the I/Os impact on the users' budget. Our detailed experimental evaluation using both real and synthetic datasets illustrate that our approach can improve the performance of the workloads as much as 50%, compared to its competitors.", "venue": "IEEE International Symposium on Real-Time Distributed Computing", "year": 2016, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2016-05-17", "journal": {"name": "2016 IEEE 19th International Symposium on Real-Time Distributed Computing (ISORC)", "pages": "174-181"}, "authors": [{"authorId": "2125879", "name": "Nikos Zacheilas"}, {"authorId": "1685532", "name": "V. Kalogeraki"}], "citations": [{"paperId": "c0f66451d28149a571d79dc37a55265f85678b0e", "title": "Optimising Cloud-Based Hadoop 2.x Applications"}, {"paperId": "73ab01d885a42fb766787a659c27829876cef988", "title": "Towards Multi-Objective Optimisation of Hadoop 2.x Application Deployment on Public Clouds"}, {"paperId": "6392fb1b23696a23cc817a7bce2f4d1787114719", "title": "A Study on Big Data Hadoop Map Reduce Job Scheduling"}]}

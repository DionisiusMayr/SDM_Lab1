{"paperId": "bfeda6c7aa7899a80adb01894555b09d24756a59", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration", "abstract": "Large Language Models (LLMs) are evolving at an unprecedented pace and have exhibited considerable capability in the realm of natural language processing (NLP) with world knowledge. Benefiting from ultra-large-scale training corpora, a single LLM can manage typical NLP tasks competently. However, its performance in executing reasoning tasks is still confined by the limitations of its internal representations. To push this boundary further, we introduce Corex in this paper, a suite of novel general-purpose strategies that transform LLMs into autonomous agents pioneering multi-model collaborations for complex task-solving. Inspired by human behaviors, Corex is constituted by diverse collaboration paradigms including Debate, Review, and Retrieve modes, which collectively work towards enhancing the factuality, faithfulness, and reliability of the reasoning process. These paradigms foster task-agnostic approaches that enable LLMs to ''think outside the box,'' thereby overcoming hallucinations and providing better solutions. Through extensive experiments across four different types of reasoning tasks, we demonstrate that orchestrating multiple LLMs to work in concert yields substantially better performance compared to existing methods. Further results and in-depth analysis demonstrate the cost-effectiveness of our method, facilitating collaboration among different LLMs and promoting annotation efficiency.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-09-30", "journal": {"name": "ArXiv", "volume": "abs/2310.00280"}, "authors": [{"authorId": "2112455065", "name": "Qiushi Sun"}, {"authorId": "2155273086", "name": "Zhangyue Yin"}, {"authorId": "2144440743", "name": "Xiang Li"}, {"authorId": "150358371", "name": "Zhiyong Wu"}, {"authorId": "2256661882", "name": "Xipeng Qiu"}, {"authorId": "2249986569", "name": "Lingpeng Kong"}], "citations": [{"paperId": "966ba2acfe0700c2410efe15ed1b6c25340b7a95", "title": "Learning to Use Tools via Cooperative and Interactive Agents"}, {"paperId": "8acdc5c7cb5913dab1ceed71c4750838f5cd8cca", "title": "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement"}, {"paperId": "f395f022548d1d1f11e231f42d4852dbff5e9376", "title": "On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference"}, {"paperId": "ed9db2081f375e338b1e170fb7089a292553db29", "title": "DefInt: A Default-interventionist Framework for Efficient Reasoning with Hybrid Large Language Models"}, {"paperId": "f9b39a6a7e40986b46f7796f3a805d70d7e3931a", "title": "SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents"}, {"paperId": "f4e8e66557005af41e101caf9d16d63bf7fe6f9a", "title": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"}, {"paperId": "bf11f01929afed0ad3ccfe1b5e0fd34d90ef2b4f", "title": "Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models"}, {"paperId": "4014253368133c01bfc0383660c518d11afccad2", "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration"}]}

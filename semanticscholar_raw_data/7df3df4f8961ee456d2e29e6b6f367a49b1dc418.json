{"paperId": "7df3df4f8961ee456d2e29e6b6f367a49b1dc418", "publicationVenue": null, "title": "Uma Proposta de Implementa\u00e7\u00e3o de \u00c1lgebra de Workflows em Apache Spark no Apoio a Processos de An\u00e1lise de Dados", "abstract": "The typical activity of a Data Scientist involves the implementation of various processes that characterize data analysis experiments. In these analyzes there is a need to execute several codes in different programming languages (Python, R, C, Java, and Scala) in different parallel and distributed processing environments. Depending on the complexity of the process and the numerous possibilities for distributed execution of these solutions, it may be necessary to spend a lot of energy on different implementations that take the Data Scientist away from his ultimate goal of producing knowledge from large volumes of data. In this context, this paper aims to support this difficulty by proposing the construction of a framework conceived from an algebraic approach that isolates the process modeling from the difficulty of optimally executing such workflows. The proposal presents a typical Extract Transform Load (ETL) workflow for performing data analysis and points to promising results in terms of representation and abstraction/isolation potential of the execution environment. Resumo. A atividade t\u0131\u0301pica de um Cientista de Dados envolve a implementa\u00e7\u00e3o de diversos processos que caracterizam experimentos de an\u00e1lise de dados. Nestas an\u00e1lises h\u00e1 a necessidade de executar diversos c\u00f3digos em diferentes linguagens de programa\u00e7\u00e3o (Python, R, C, Java e Scala) em diferentes ambientes de processamento paralelo e distribu\u0131\u0301do. Dependendo da complexidade do processo e das in\u00fameras possibilidades para execu\u00e7\u00e3o distribu\u0131\u0301da destas solu\u00e7\u00f5es, pode ser necess\u00e1rio gastar muito energia em diferentes implementa\u00e7\u00f5es que afastam o Cientista de Dados do seu objetivo final, que \u00e9 produzir conhecimento a partir dos grandes volumes de dados. Dentro deste contexto, este trabalho visa apoiar na solu\u00e7\u00e3o de tal dificuldade ao propor a constru\u00e7\u00e3o de um framework concebido a partir de uma abordagem alg\u00e9brica que isola a modelagem do processo da dificuldade de executar, de modo otimizado, tais workflows. A proposta apresenta um workflow t\u0131\u0301pico de Extract Transform Load (ETL) para realiza\u00e7\u00e3o de an\u00e1lise de dados e aponta para resultados promissores em termos de representa\u00e7\u00e3o e potencial de abstra\u00e7\u00e3o/isolamento do ambiente de execu\u00e7\u00e3o.", "venue": "", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2020-02-18", "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "145873565", "name": "J. A. Ferreira"}, {"authorId": "82717050", "name": "D. Gaspar"}, {"authorId": "2073618117", "name": "Bernardo Monteiro"}, {"authorId": "143821689", "name": "Ana Beatriz Cruz"}, {"authorId": "2064319003", "name": "F\u00e1bio Porto"}, {"authorId": "2083080838", "name": "Eduardo S. Ogasawara"}], "citations": [{"paperId": "0050eea2c464e06d019bce218aaacb72a9123efa", "title": "Rumo \u00e0 Otimiza\u00e7\u00e3o de Operadores sobre UDF no Spark"}]}

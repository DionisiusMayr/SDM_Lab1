{"paperId": "95c11cc5820ba32c60d5f2671f6567b9914a4978", "publicationVenue": {"id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44", "name": "Annual Meeting of the Association for Computational Linguistics", "type": "conference", "alternate_names": ["Annu Meet Assoc Comput Linguistics", "Meeting of the Association for Computational Linguistics", "ACL", "Meet Assoc Comput Linguistics"], "url": "https://www.aclweb.org/anthology/venues/acl/"}, "title": "ALERT: Adapt Language Models to Reasoning Tasks", "abstract": "Recent advancements in large language models have enabled them to perform well on complex tasks that require step-by-step reasoning with few-shot learning. However, it is unclear whether these models are applying reasoning skills they have learnt during pre-training , or if they are simply memorizing their training corpus at finer granularity and have learnt to better understand their context.To address this question, we introduce {pasted macro \u2018OUR\u2019}model, a benchmark and suite of analyses for evaluating reasoning skills of language models. {pasted macro \u2018OUR\u2019}model enables comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. Our benchmark provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. By using {pasted macro \u2018OUR\u2019}model we further investigate the role of finetuning. Our extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage. However, we also find that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-12-16", "journal": {"name": "ArXiv", "volume": "abs/2212.08286"}, "authors": [{"authorId": "2114104308", "name": "Ping Yu"}, {"authorId": "1785372925", "name": "Tianlu Wang"}, {"authorId": "100664938", "name": "O. Yu. Golovneva"}, {"authorId": "2006905770", "name": "Badr AlKhamissi"}, {"authorId": "134007132", "name": "Gargi Ghosh"}, {"authorId": "2138579860", "name": "Mona T. Diab"}, {"authorId": "1709797", "name": "Asli Celikyilmaz"}], "citations": [{"paperId": "40f3aaf33ffd2c6687e405cffdb08f2dcc1f8ce4", "title": "ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?"}, {"paperId": "13dc9eb9cf36c5bb287671a41cb31b7de2a4cee7", "title": "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"}, {"paperId": "98de0a73fc32e04b58d76579aef964cf686b25da", "title": "Reason2Drive: Towards Interpretable and Chain-based Reasoning for Autonomous Driving"}, {"paperId": "12a4c41b087629548b07d0dadb9da05147fa4f81", "title": "Towards Better Chain-of-Thought Prompting Strategies: A Survey"}, {"paperId": "1d8472bbf71ccf60550126d136b53699a2f4f685", "title": "DOMINO: A Dual-System for Multi-step Visual Language Reasoning"}, {"paperId": "c29dbfbc17fa190b787a2662d49f08a38c8bd166", "title": "ARB: Advanced Reasoning Benchmark for Large Language Models"}, {"paperId": "d7a3f5c612930a3c08f1632b88934252edc66d67", "title": "Minding Language Models\u2019 (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker"}, {"paperId": "9383e05fbeef79240721a51353f011618f80c142", "title": "Measuring the Robustness of NLP Models to Domain Shifts"}, {"paperId": "5dbffedcabe3fa43060ebbe2b1789500edfd871f", "title": "Reasoning with Language Model is Planning with World Model"}, {"paperId": "c218cd1772999517b137bbbc9872c4f67e540b7f", "title": "OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models"}, {"paperId": "55bcbd16f05e8a5639b2a7d29a489bf47de5d3ea", "title": "Domain Mastery Benchmark: An Ever-Updating Benchmark for Evaluating Holistic Domain Knowledge of Large Language Model-A Preliminary Release"}, {"paperId": "5eab810cc5d90de1c52127d1a5824f0817f46c30", "title": "Natural Language Reasoning, A Survey"}, {"paperId": "2029349c55c1dba3493c5b3bd25152f18ba21ae2", "title": "Augmented Language Models: a Survey"}, {"paperId": "db4ab91d5675c37795e719e997a2827d3d83cd45", "title": "Towards Reasoning in Large Language Models: A Survey"}, {"paperId": "6845bea94b2fb17d4377b3bb2bd10f73a959f9cc", "title": "Reasoning with Language Model Prompting: A Survey"}, {"paperId": "6f130cde30b91b5deaf5c57dc2b2b33c245ed79b", "title": "Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models"}]}

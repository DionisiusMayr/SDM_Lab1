{"paperId": "426f449a52d0ecf0cdd87ca99450a6a9ab8cfb58", "publicationVenue": null, "title": "GIN : High-Performance, Scalable Inference for Graph Neural Networks", "abstract": ". Deep learning models have enjoyed tremendous success when applying to low-dimensional regular grid data such as image, video, and speech. Recently, graph neural networks (GNNs) have been proposed to learn from high-dimensional graph-structured data (e.g., social networks, molecular structures, and protein networks). Unfortunately, existing systems that are developed for the construction, training, and deployment of GNN models su\ufb00er from poor performance, especially when running on big graphs that exceed the size of the on-board DRAMs of computation accelerators such as GPUs. In this paper, we present Gin , a new computational framework that is able to generate highly e\ufb03cient compute kernels for GNN inference. Speci\ufb01cally, Gin enables a user to continue to use a familiar deep learning framework (e.g., TensorFlow) as the front end, while utilizing a translator to translate the high-level representation of a GNN model into low-level codes. The back end in Gin will compile the translated code and create the optimized kernels on CPU. Our evaluation shows that Gin outperforms the state-of-art systems by up to three orders of magnitude, signi\ufb01cantly accelerating the inference on billion-edge graphs.", "venue": "", "year": 2020, "fieldsOfStudy": null, "publicationTypes": null, "publicationDate": null, "journal": null, "authors": [{"authorId": "2113771602", "name": "Qiang Fu"}, {"authorId": "48186750", "name": "Huimin Huang"}], "citations": [{"paperId": "8bc40c2ea8a526b296041450c73fd6784108bf76", "title": "InferTurbo: A Scalable System for Boosting Full-graph Inference of Graph Neural Network over Huge Graphs"}]}

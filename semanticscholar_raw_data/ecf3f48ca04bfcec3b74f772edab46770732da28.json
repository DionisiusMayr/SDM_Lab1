{"paperId": "ecf3f48ca04bfcec3b74f772edab46770732da28", "publicationVenue": {"id": "4f854c65-f7ce-4588-a3ca-d96a1c00fc6d", "name": "IEEE Symposium on Field-Programmable Custom Computing Machines", "type": "conference", "alternate_names": ["IEEE Symp Field-programmable Cust Comput Mach", "Field-programmable Cust Comput Mach", "FCCM", "Field-Programmable Custom Computing Machines"], "url": "http://www.fccm.org/"}, "title": "Modular and Lean Architecture with Elasticity for Sparse Matrix Vector Multiplication on FPGAs", "abstract": "The use of domain-specific accelerators is becoming prominent for a variety of emerging domains such as graph analytics and HPC, where most of the computations revolve around Sparse Matrix-Vector (SpMV) Multiplication. Many of the existing SpMV accelerators do not scale well on FPGA fabric and exhibit significant performance and area overheads [1]\u2013[3]. With the increased external memory bandwidths supported by FPGA platforms, SpMV accelerator design sizes are growing rapidly and exhibit timing closure challenges in physical implementation [4], [5]. To utilize all the High Bandwidth Memory (HBM) channels on the FPGA device, accelerator designers rely on the reuse and replication of the processing elements (PEs). As the number of PEs in a design grows, the achieved frequency of these large designs is often much lower than a single PE design [4], [5]. In this paper, we present a modular and lean architecture for the SpMV workload enabling elastic communication between building blocks. The proposed SpMV accelerator uses single-precision floating-point arithmetic (FP32) and achieves a frequency of 465 MHz for single-instance implementation. The lean nature of the design enables the scaling of the accelerator to sixteen instances, which utilizes all of the 32 HBM pseudo-channels available on the Alveo U280 FPGA platform. The accelerator design with sixteen SpMV instances, spanning multiple FPGA dies, can close timing at 310 MHz which is 80% higher than GraphLily [4] and 40% higher than HiSparse [5]. We demonstrate up to 50 GFLOPS performance on the Alveo U280 FPGA Platform which is 2.5\u00d7 of GraphLily [4].", "venue": "IEEE Symposium on Field-Programmable Custom Computing Machines", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-05-01", "journal": {"name": "2023 IEEE 31st Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)", "pages": "133-143"}, "authors": [{"authorId": "14463929", "name": "A. Jain"}, {"authorId": "73578358", "name": "C. Ravishankar"}, {"authorId": "144715077", "name": "Hossein Omidian"}, {"authorId": "2109682870", "name": "Sharan Kumar"}, {"authorId": "1576956623", "name": "Maithilee Kulkarni"}, {"authorId": "2146650385", "name": "Aashish Tripathi"}, {"authorId": "41019150", "name": "D. Gaitonde"}], "citations": [{"paperId": "7168a682f519bb2e5e59e3b1af5c850657cd9e2e", "title": "A High-Frequency Load-Store Queue with Speculative Allocations for High-Level Synthesis"}]}

{"paperId": "65b63322cac4f4fd1b2dbc7155be69aed5f95b68", "publicationVenue": null, "title": "Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with Spatial Relation Matching", "abstract": "Navigating drones through natural language commands remains challenging due to the dearth of accessible multi-modal datasets and the stringent precision requirements for aligning visual and textual data. To address this pressing need, we introduce GeoText-1652, a new natural language-guided geo-localization benchmark. This dataset is systematically constructed through an interactive human-computer process leveraging Large Language Model (LLM) driven annotation techniques in conjunction with pre-trained vision models. GeoText-1652 extends the established University-1652 image dataset with spatial-aware text annotations, thereby establishing one-to-one correspondences between image, text, and bounding box elements. We further introduce a new optimization objective to leverage fine-grained spatial associations, called blending spatial matching, for region-level spatial relation matching. Extensive experiments reveal that our approach maintains a competitive recall rate comparing other prevailing cross-modality methods. This underscores the promising potential of our approach in elevating drone control and navigation through the seamless integration of natural language commands in real-world scenarios.", "venue": "", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2023-11-21", "journal": null, "authors": [{"authorId": "2267489075", "name": "Meng Chu"}, {"authorId": "2187311001", "name": "Zhedong Zheng"}, {"authorId": "2072613978", "name": "Wei Ji"}, {"authorId": "2261789655", "name": "Tingyu Wang"}, {"authorId": "2281747744", "name": "Tat-Seng Chua"}], "citations": []}

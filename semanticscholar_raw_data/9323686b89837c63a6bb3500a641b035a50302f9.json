{"paperId": "9323686b89837c63a6bb3500a641b035a50302f9", "publicationVenue": {"id": "d13e941e-4cac-4f1d-bdca-77d927e31f1b", "name": "ACM Symposium on Cloud Computing", "type": "conference", "alternate_names": ["System-on-Chip Conference", "ACM Symp Cloud Comput", "Syst Conf", "Symp Cloud Comput", "Annual IEEE International System-on-Chip Conference", "Symposium on Cloud Computing", "Annu IEEE Int Syst Conf", "SoCC"], "url": "http://www.ieee-socc.org/"}, "title": "Sayer: Using Implicit Feedback to Optimize System Policies", "abstract": "We observe that many system policies that make threshold decisions involving a resource (e.g., time, memory, cores) naturally reveal additional, or implicit feedback. For example, if a system waits X min for an event to occur, then it automatically learns what would have happened if it waited < X min, because time has a cumulative property. This feedback tells us about alternative decisions, and can be used to improve the system policy. However, leveraging implicit feedback is difficult because it tends to be one-sided or incomplete, and may depend on the outcome of the event. As a result, existing practices for using feedback, such as simply incorporating it into a data-driven model, suffer from bias. We develop a methodology, called Sayer, that leverages implicit feedback to evaluate and train new system policies. Sayer builds on two ideas from reinforcement learning---randomized exploration and unbiased counterfactual estimators---to leverage data collected by an existing policy to estimate the performance of new candidate policies, without actually deploying those policies. Sayer uses implicit exploration and implicit data augmentation to generate implicit feedback in an unbiased form, which is then used by an implicit counterfactual estimator to evaluate and train new policies. The key idea underlying these techniques is to assign implicit probabilities to decisions that are not actually taken but whose feedback can be inferred; these probabilities are carefully calculated to ensure statistical unbiasedness. We apply Sayer to two production scenarios in Azure, and show that it can evaluate arbitrary policies accurately, and train new policies that outperform the production policies.", "venue": "ACM Symposium on Cloud Computing", "year": 2021, "fieldsOfStudy": ["Computer Science", "Mathematics"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2021-10-28", "journal": {"name": "Proceedings of the ACM Symposium on Cloud Computing"}, "authors": [{"authorId": "2574478", "name": "Mathias L\u00e9cuyer"}, {"authorId": "2141972103", "name": "Sang Hoon Kim"}, {"authorId": "2649174", "name": "Mihir Nanavati"}, {"authorId": "1727978", "name": "Junchen Jiang"}, {"authorId": "30721371", "name": "S. Sen"}, {"authorId": "2158559", "name": "Aleksandrs Slivkins"}, {"authorId": "2143678747", "name": "Amit Sharma"}], "citations": [{"paperId": "b7854ec84b88ea279907d4fa362792f59ec32d08", "title": "Veritas: Answering Causal Queries from Video Streaming Traces"}]}

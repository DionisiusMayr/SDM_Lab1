{"paperId": "92b48adfddd6177618c4f7451c8ea593a794a1a1", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding", "abstract": "3D visual grounding is the ability to localize objects in 3D scenes conditioned by utterances. Most existing methods devote the referring head to localize the referred object directly, causing failure in complex scenarios. In addition, it does not illustrate how and why the network reaches the final decision. In this paper, we address this question Can we design an interpretable 3D visual grounding framework that has the potential to mimic the human perception system?. To this end, we formulate the 3D visual grounding problem as a sequence-to-sequence task by first predicting a chain of anchors and then the final target. Interpretability not only improves the overall performance but also helps us identify failure cases. Following the chain of thoughts approach enables us to decompose the referring task into interpretable intermediate steps, boosting the performance and making our framework extremely data-efficient. Moreover, our proposed framework can be easily integrated into any existing architecture. We validate our approach through comprehensive experiments on the Nr3D, Sr3D, and Scanrefer benchmarks and show consistent performance gains compared to existing methods without requiring manually annotated data. Furthermore, our proposed framework, dubbed CoT3DRef, is significantly data-efficient, whereas on the Sr3D dataset, when trained only on 10% of the data, we match the SOTA performance that trained on the entire data.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-10", "journal": {"name": "ArXiv", "volume": "abs/2310.06214"}, "authors": [{"authorId": "2184841876", "name": "Eslam Mohamed Bakr"}, {"authorId": "2256997275", "name": "Mohamed Ayman"}, {"authorId": "2258300261", "name": "Mahmoud Ahmed"}, {"authorId": "2256997317", "name": "Habib Slim"}, {"authorId": "2256988814", "name": "Mohamed Elhoseiny"}], "citations": [{"paperId": "6a4dceda0b7a9fb2a43c1ea6fa36ecec1774a03d", "title": "DOrA: 3D Visual Grounding with Order-Aware Referring"}]}

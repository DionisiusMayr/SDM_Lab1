{"paperId": "6b19c76286b6894c276da4f9aa002bda086833cb", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Hyper Dimension Shuffle: Efficient Data Repartition at Petabyte Scale in Scope", "abstract": "\n In distributed query processing, data shuffle is one of the most costly operations. We examined scaling limitations to data shuffle that current systems and the research literature do not solve. As the number of input and output partitions increases, na\u00efve shuffling will result in high\n fan-out\n and\n fan-in.\n There are practical limits to\n fan-out,\n as a consequence of limits on memory buffers, network ports and I/O handles. There are practical limits to\n fan-in\n because it multiplies the communication errors due to faults in commodity clusters impeding progress. Existing solutions that limit\n fan-out\n and\n fan-in\n do so at the cost of scaling quadratically in the number of nodes in the data flow graph. This dominates the costs of shuffling large datasets.\n \n \n We propose a novel algorithm called Hyper Dimension Shuffle that we have introduced in production in SCOPE, Microsoft's internal big data analytics system. Hyper Dimension Shuffle is inspired by the divide and conquer concept, and utilizes a recursive partitioner with intermediate aggregations. It yields\n quasilinear\n complexity of the shuffling graph with tight guarantees on\n fan-out\n and\n fan-in.\n We demonstrate how it avoids the shuffling graph blow-up of previous algorithms to shuffle at petabyte-scale efficiently on both synthetic benchmarks and real applications.\n", "venue": "Proceedings of the VLDB Endowment", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-06-01", "journal": {"name": "Proc. VLDB Endow.", "pages": "1113-1125", "volume": "12"}, "authors": [{"authorId": "49830907", "name": "S. Qiao"}, {"authorId": "153299796", "name": "Adrian Nicoara"}, {"authorId": "8456870", "name": "Jin Sun"}, {"authorId": "143634544", "name": "Marc T. Friedman"}, {"authorId": "1471618633", "name": "Hiren Patel"}, {"authorId": "34388379", "name": "Jaliya Ekanayake"}], "citations": [{"paperId": "99fbad8d8c46be75fa2d0c326e8f7ae491dfe582", "title": "Towards Accelerating Data Intensive Application's Shuffle Process Using SmartNICs"}, {"paperId": "03ff19954a57b692fa8f99f463fe9baeacade52f", "title": "Runtime Variation in Big Data Analytics"}, {"paperId": "42398f605f3f4d3b6a2014baddf08308e5b5958c", "title": "Efficient. Scalable and Robust Data Shuffle Service for Distributed MapReduce Computing on Cloud"}, {"paperId": "3cedaed934111750b36ce5ee1441ebb39e7ab620", "title": "New Query Optimization Techniques in the Spark Engine of Azure Synapse"}, {"paperId": "03fe5309d8ea349ed1aba77ba1e66ba5900856b8", "title": "The Cosmos Big Data Platform at Microsoft: Over a Decade of Progress and a Decade to Look Forward"}, {"paperId": "3957d638e7ad2c26b32ac6a12e4c6662431ebaff", "title": "Hyperspace: The Indexing Subsystem of Azure Synapse"}, {"paperId": "d5c2a4c5904a999b4c8a2f848ae91f4525c179d0", "title": "KEA: Tuning an Exabyte-Scale Data Infrastructure"}, {"paperId": "8d0dd632c9da4740df4aa729821109169fd82805", "title": "Microlearner: A fine-grained Learning Optimizer for Big Data Workloads at Microsoft"}, {"paperId": "5787eb70a1b67a7d3af815fdfe2bbb63ca12e225", "title": "Generalized Sub-Query Fusion for Eliminating Redundant I/O from Big-Data Queries"}, {"paperId": "52343ceb35afc31198b788cf895b136f0180055b", "title": "Magnet"}, {"paperId": "468cb935d04d2cb3e1d60e827e9c87a7b31e0b23", "title": "Dremel"}, {"paperId": "f59b41128b3c68db3b66076d703a70dc4efcf6a7", "title": "Big Data Processing at Microsoft: Hyper Scale, Massive Complexity, and Minimal Cost"}, {"paperId": "d137cda092b57e8e7477fafc745c712a99120f80", "title": "Incorporating Super-Operators in Big-Data Query Optimizers"}]}

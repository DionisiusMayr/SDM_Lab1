{"paperId": "809be5d73ac7696242f2d6ec4394f54f680c5ff7", "publicationVenue": {"id": "d59689ad-d699-44d3-872b-3df8df58db7a", "name": "Journal of Science and Technology Policy Management", "type": "journal", "alternate_names": ["J Sci Technol Policy Manag"], "issn": "2053-4620", "url": "https://www.emerald.com/insight/publication/issn/2053-4620", "alternate_urls": ["http://www.emeraldgrouppublishing.com/products/journals/journals.htm?id=jstpm"]}, "title": "Cloud-based big data framework towards strengthening disaster risk reduction: systematic mapping", "abstract": "\nPurpose\nCloud computing promises dependable services offered through next-generation data centres based on virtualization technologies for computation, network and storage. Big Data Applications have been made viable by cloud computing technologies due to the tremendous expansion of data. Disaster management is one of the areas where big data applications are rapidly being deployed. This study looks at how big data is being used in conjunction with cloud computing to increase disaster risk reduction (DRR). This paper aims to explore and review the existing framework for big data used in disaster management and to provide an insightful view of how cloud-based big data platform toward DRR is applied.\n\n\nDesign/methodology/approach\nA systematic mapping study is conducted to answer four research questions with papers related to Big Data Analytics, cloud computing and disaster management ranging from the year 2013 to 2019. A total of 26 papers were finalised after going through five steps of systematic mapping.\n\n\nFindings\nFindings are based on each research question.\n\n\nResearch limitations/implications\nA specific study on big data platforms on the application of disaster management, in general is still limited. The lack of study in this field is opened for further research sources.\n\n\nPractical implications\nIn terms of technology, research in DRR leverage on existing big data platform is still lacking. In terms of data, many disaster data are available, but scientists still struggle to learn and listen to the data and take more proactive disaster preparedness.\n\n\nOriginality/value\nThis study shows that a very famous platform selected by researchers is central processing unit based processing, namely, Apache Hadoop. Apache Spark which uses memory processing requires a big capacity of memory, therefore this is less preferred in the world of research.\n", "venue": "Journal of Science and Technology Policy Management", "year": 2023, "fieldsOfStudy": null, "publicationTypes": ["Review"], "publicationDate": "2023-03-23", "journal": {"name": "Journal of Science and Technology Policy Management"}, "authors": [{"authorId": "74036338", "name": "M. N. Mahrin"}, {"authorId": "10600751", "name": "A. Subbarao"}, {"authorId": "144205275", "name": "S. Chuprat"}, {"authorId": "114380254", "name": "N. A. Abu Bakar"}], "citations": []}

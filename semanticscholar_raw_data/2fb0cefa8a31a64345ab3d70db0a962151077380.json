{"paperId": "2fb0cefa8a31a64345ab3d70db0a962151077380", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Implications of the Convergence of Language and Vision Model Geometries", "abstract": "Large-scale pretrained language models (LMs) are said to ``lack the ability to connect [their] utterances to the world'' (Bender and Koller, 2020). If so, we would expect LM representations to be unrelated to representations in computer vision models. To investigate this, we present an empirical evaluation across three different LMs (BERT, GPT2, and OPT) and three computer vision models (VMs, including ResNet, SegFormer, and MAE). Our experiments show that LMs converge towards representations that are partially isomorphic to those of VMs, with dispersion, and polysemy both factoring into the alignability of vision and language spaces. We discuss the implications of this finding.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-02-13", "journal": {"name": "ArXiv", "volume": "abs/2302.06555"}, "authors": [{"authorId": "2261336713", "name": "Jiaang Li"}, {"authorId": "51208524", "name": "Yova Kementchedjhieva"}, {"authorId": "1700187", "name": "Anders S\u00f8gaard"}], "citations": [{"paperId": "9b2d422225142abef905433173d3307a3fb2bb3a", "title": "Large language models converge toward human-like concept organization"}, {"paperId": "f8e99be4f9a01761fab74bade2c3c18de9fc686b", "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"}, {"paperId": "be831248bfda5dfb604ea1676f767e5af6be500f", "title": "Structural Similarities Between Language Models and Neural Response Measurements"}, {"paperId": "ad29ced9603a5909fce89dbf919a9cad926eda67", "title": "The Vector Grounding Problem"}]}

{"paperId": "ae8aabebad0c3ecae165ec05c18a2072ed360d1e", "publicationVenue": {"id": "41bf9ed3-85b3-4c90-b015-150e31690253", "name": "Conference on Empirical Methods in Natural Language Processing", "type": "conference", "alternate_names": ["Empir Method Nat Lang Process", "Empirical Methods in Natural Language Processing", "Conf Empir Method Nat Lang Process", "EMNLP"], "url": "https://www.aclweb.org/portal/emnlp"}, "title": "NEWTON: Are Large Language Models Capable of Physical Reasoning?", "abstract": "Large Language Models (LLMs), through their contextualized representations, have been empirically proven to encapsulate syntactic, semantic, word sense, and common-sense knowledge. However, there has been limited exploration of their physical reasoning abilities, specifically concerning the crucial attributes for comprehending everyday objects. To address this gap, we introduce NEWTON, a repository and benchmark for evaluating the physics reasoning skills of LLMs. Further, to enable domain-specific adaptation of this benchmark, we present a pipeline to enable researchers to generate a variant of this benchmark that has been customized to the objects and attributes relevant for their application. The NEWTON repository comprises a collection of 2800 object-attribute pairs, providing the foundation for generating infinite-scale assessment templates. The NEWTON benchmark consists of 160K QA questions, curated using the NEWTON repository to investigate the physical reasoning capabilities of several mainstream language models across foundational, explicit, and implicit reasoning tasks. Through extensive empirical analysis, our results highlight the capabilities of LLMs for physical reasoning. We find that LLMs like GPT-4 demonstrate strong reasoning capabilities in scenario-based tasks but exhibit less consistency in object-attribute reasoning compared to humans (50% vs. 84%). Furthermore, the NEWTON platform demonstrates its potential for evaluating and enhancing language models, paving the way for their integration into physically grounded settings, such as robotic manipulation. Project site: https://newtonreasoning.github.io", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-10-11", "journal": {"pages": "9743-9758"}, "authors": [{"authorId": "2257315331", "name": "Yi Ru Wang"}, {"authorId": "2257047727", "name": "Jiafei Duan"}, {"authorId": "2257042516", "name": "Dieter Fox"}, {"authorId": "1752197", "name": "S. Srinivasa"}], "citations": [{"paperId": "6f0a233ea070a5e260617a9caa495aa227006eeb", "title": "DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies"}, {"paperId": "437cbaee4eaee0bf84abbe11750b86b091b9b756", "title": "MacGyver: Are Large Language Models Creative Problem Solvers?"}, {"paperId": "c18fbc7441e393e551c4df6a164bcca9cc7df1e4", "title": "DeliGrasp: Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies"}]}

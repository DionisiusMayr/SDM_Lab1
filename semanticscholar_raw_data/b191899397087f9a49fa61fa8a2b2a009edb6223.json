{"paperId": "b191899397087f9a49fa61fa8a2b2a009edb6223", "publicationVenue": {"id": "a36dc29e-4ea1-4567-b0fe-1c06daf8bee8", "name": "International Conference on Software Engineering", "type": "conference", "alternate_names": ["Int Conf Softw Eng", "ICSE"], "url": "http://www.icse-conferences.org/"}, "title": "Diversity-Driven Automated Formal Verification", "abstract": "Formally verified correctness is one of the most desirable properties of software systems. But despite great progress made via interactive theorem provers, such as Coq, writing proof scripts for verification remains one of the most effort-intensive (and often prohibitively difficult) software development activities. Recent work has created tools that automatically synthesize proofs or proof scripts. For example, CoqHammer can prove 26.6% of theorems completely automatically by reasoning using precomputed facts, while TacTok and ASTactic, which use machine learning to model proof scripts and then perform biased search through the proof-script space, can prove 12.9% and 12.3% of the theorems, respectively. Further, these three tools are highly complementary; together, they can prove 30.4% of the theorems fully automatically. Our key insight is that control over the learning process can produce a diverse set of models, and that, due to the unique nature of proof synthesis (the existence of the theorem prover, an oracle that infallibly judges a proof's correctness), this diversity can significantly improve these tools' proving power. Accordingly, we develop Diva, which uses a diverse set of models with TacTok's and ASTactic's search mech-anism to prove 21.7% of the theorems. That is, Diva proves 68% more theorems than TacTok and 77% more than ASTactic. Complementary to CoqHammer, Diva proves 781 theorems (27% added value) that CoqHammer does not, and 364 theorems no existing tool has proved automatically. Together with CoqHammer, Diva proves 33.8% of the theorems, the largest fraction to date. We explore nine dimensions for learning diverse models, and identify which dimensions lead to the most useful diversity. Further, we develop an optimization to speed up Diva's execution by 40\u00d7. Our study introduces a completely new idea for using diversity in machine learning to improve the power of state-of-the-art proof-script synthesis techniques, and empirically demonstrates that the improvement is significant on a dataset of 68K theorems from 122 open-source software projects.", "venue": "International Conference on Software Engineering", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2022-05-01", "journal": {"name": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)", "pages": "01-13"}, "authors": [{"authorId": "104884254", "name": "E. First"}, {"authorId": "2932798", "name": "Yuriy Brun"}], "citations": [{"paperId": "edd3e9d9347a3866e1a5a913733f1d9477ec7a2c", "title": "Learning Guided Automated Reasoning: A Brief Survey"}, {"paperId": "16daf858baef5ff2a698596bf26999a618fa521e", "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion"}, {"paperId": "30c20c59a9af0c97f10f7108641c19f0d76c417b", "title": "LLM4PLC: Harnessing Large Language Models for Verifiable Programming of PLCs in Industrial Control Systems"}, {"paperId": "af451aa3ba4138d789d5276b874d2167aa525bbd", "title": "Graph2Tac: Learning Hierarchical Representations of Math Concepts in Theorem proving"}, {"paperId": "45c196d28d16b2a8c0a078e8b79bcb39887a8a9f", "title": "Can Transformers Learn to Solve Problems Recursively?"}, {"paperId": "cf7f00e636080617fb2f57debb6292c82c03d031", "title": "Getting More out of Large Language Models for Proofs"}, {"paperId": "1c42b6c3dd048f4141ac0841589b711c14748491", "title": "PRoofster: Automated Formal Verification"}, {"paperId": "f0f60b1a381db0a54b9877d5bb410ea98b2bc540", "title": "Seldonian Toolkit: Building Software with Safe and Fair Machine Learning"}, {"paperId": "9f8ac6ee3760ab202e492c733362e5bfc6763934", "title": "Baldur: Whole-Proof Generation and Repair with Large Language Models"}, {"paperId": "dbf9f58779eb554c7be22113bf78e9df78853519", "title": "The promise and perils of using machine learning when engineering software (keynote paper)"}, {"paperId": "455dcc6d88fac843c0717f60af2a065feaa7f248", "title": "Passport: Improving Automated Formal Verification Using Identifiers"}, {"paperId": "22ea3cd56bfbad81e7a7f8d024e710d06f2a2e5d", "title": "Blindspots in Python and Java APIs Result in Vulnerable Code"}, {"paperId": "ac6cc408ebd7b1e842edc9597a24d7d738927404", "title": "Better Automatic Program Repair by Using Bug Reports and Tests Together"}, {"paperId": "a8034aa680bda26ac63364ebbb13d75552a7db3f", "title": "Proof Repair Infrastructure for Supervised Models: Building a Large Proof Repair Dataset"}, {"paperId": "ceed82aea14a42a001c6bb5f0d7a24393d661225", "title": "Automated Program Repair, What Is It Good For? Not Absolutely Nothing!"}]}

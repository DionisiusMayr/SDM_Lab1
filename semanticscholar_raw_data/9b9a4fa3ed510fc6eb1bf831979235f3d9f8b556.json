{"paperId": "9b9a4fa3ed510fc6eb1bf831979235f3d9f8b556", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions", "abstract": "With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe SafetyBench will enable fast and comprehensive evaluation of LLMs' safety, and foster the development of safer LLMs. Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench. Submission entrance and leaderboard are available at https://llmbench.ai/safety.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-09-13", "journal": {"name": "ArXiv", "volume": "abs/2309.07045"}, "authors": [{"authorId": "101371510", "name": "Zhexin Zhang"}, {"authorId": "2239889447", "name": "Leqi Lei"}, {"authorId": "2239424207", "name": "Lindong Wu"}, {"authorId": "2239238861", "name": "Rui Sun"}, {"authorId": "2239394827", "name": "Yongkang Huang"}, {"authorId": "2239299334", "name": "Chong Long"}, {"authorId": "2111312892", "name": "Xiao Liu"}, {"authorId": "2181283109", "name": "Xuanyu Lei"}, {"authorId": "2260595820", "name": "Jie Tang"}, {"authorId": "1730108", "name": "Minlie Huang"}], "citations": [{"paperId": "9fd65c623d319dd21b99d67fcca2b4b4f2717ec5", "title": "Risks from Language Models for Automated Mental Healthcare: Ethics and Structure for Implementation"}, {"paperId": "6fd5dbea7588ee6bca703aa3fea9a487006dba29", "title": "Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order"}, {"paperId": "3cf3f50cb5379099f8fc98c9dd429944fef47f94", "title": "RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain"}, {"paperId": "a6f7485dfdf45320e82d84bcfdc51bcd52dff18b", "title": "Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models"}, {"paperId": "f88bb3f172633a83d1a4c51c3e10c29166ceb734", "title": "Safety of Multimodal Large Language Models on Images and Text"}, {"paperId": "0251bb95be75d472c8d5b873751615e7fe2feb1d", "title": "A Comprehensive Study of Knowledge Editing for Large Language Models"}, {"paperId": "b137709522bc70b42b026cae192de2a45000b22e", "title": "MetaAID 2.5: A Secure Framework for Developing Metaverse Applications via Large Language Models"}, {"paperId": "9bce4959082f9c133d9721bdb177dcb25d1d6b33", "title": "Control Risk for Potential Misuse of Artificial Intelligence in Science"}, {"paperId": "7c5a39096e80c86fc0e160e574a4db60b64540f4", "title": "Towards Generative Search and Recommendation: A keynote at RecSys 2023"}, {"paperId": "936f7f0fa77efcd322805b93a8d74c48a4108290", "title": "ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?"}, {"paperId": "6fa0677731184444df0e1fc8070938419cd6da47", "title": "Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents"}, {"paperId": "8d2709ed1788a67e64425fb410bb49f3ee49e088", "title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review"}, {"paperId": "a224705317c2c749865949e920752ea3740602f4", "title": "SC-Safety: A Multi-round Open-ended Question Adversarial Safety Benchmark for Large Language Models in Chinese"}, {"paperId": "84b7c486c56bd3880cb8eb01de9ae90ba3ebdaed", "title": "Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models"}, {"paperId": "6f75e8b61f13562237851d8119cb2f9d49e073fb", "title": "Can LLM-Generated Misinformation Be Detected?"}, {"paperId": "888728745dbb769e29ed475d4f7661eebe1a71cf", "title": "A Survey on Evaluation of Large Language Models"}]}

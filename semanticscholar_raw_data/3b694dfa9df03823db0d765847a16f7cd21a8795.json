{"paperId": "3b694dfa9df03823db0d765847a16f7cd21a8795", "publicationVenue": {"id": "7bf8fd30-543b-48f6-bb8a-8c518006bdd2", "name": "IEEE Data Engineering Bulletin", "type": "journal", "alternate_names": ["IEEE Data Eng Bull"], "url": "https://tc.computer.org/tcde/tcde-bulletin-issues/"}, "title": "Data Errors: Symptoms, Causes and Origins", "abstract": "The \ufb02ood of data that has enabled breakthroughs in medicine, commerce, transportation, science and society also threatens to overwhelm our storage capacities and our privacy. Due to the volume of data and growth of regulations governing its maintenance and use, it is essential to develop automatic disposal techniques to manage this \ufb02ood. We present a vision for automating data disposal \u2013 disposal by design \u2013 which takes into account processing constraints, regulatory constraints as well as storage constraints, and give three concrete examples which address aspects of this vision. Two of the examples address current needs in e-commerce, while the third suggests how to use machine learning to \ufb01nd summaries of relational data. We then discuss the research challenges that remain to provide a holistic solution to disposal by design. Abstract Most modern data systems have been designed with two goals in mind \u2013 fast ingestion and low-latency query processing. The \ufb01rst goal has led to the development of a plethora of write-optimized data stores that employ the out-of-place paradigm. Due to their write-optimized design, out-of-place data systems perform deletes logically via invalidation, and retain the invalid data for arbitrarily long. However, due to the recent enactment of new data privacy regulations, the requirement of timely deletion of user data has become central. The right to be forgotten (in EU\u2019s GDPR), right to delete (in California\u2019s CCPA and CPRA), or deletion right (in Virginia\u2019s VCDPA) mandates that service providers persistently delete a user\u2019s data within a pre-set time duration. Logical deletion in out-of-place data systems, however, does not offer guarantees for timely and persistent deletion, and attempting to enforce it using existing tools leads to poor performance and increased operational costs. In this paper, we present a new framework for building deletion-compliant data systems from a holistic perspective. We analyze the new regulations and the requirements derived from the new policies, and we propose changes in the application and the system layer of data management. We outline the new types of deletion requests that need to be supported, the query language modi\ufb01cations needed to be able to request for timely persistent data deletion, and the system-level changes needed to realize timely and persistent deletes. The proposed framework for deletion compliance lays the groundwork for a new class of data systems that can offer system-level guarantees for user data privacy. We present recent results spanning all layers of the framework: the requirements and the application layer target any database system, while the system layer discussion is geared towards out-of-place systems. Finally, we conclude with a discussion on next steps and open challenges on building deletion-compliant data systems. Abstract With the increasing need for Machine-learning-as-a-service (MaaS) online systems, effectively maintaining and reusing machine learning models in light of changes to the underlying data has become a big concern. In particular, it is extremely challenging to refresh existing models after the removal of training samples, which is called \u201cmachine unlearning\u201d. Addressing this challenge not only requires an ef\ufb01cient solution, but must comply with emerging privacy issues, e.g. GDPR, which implies that the removed samples must be fully erased from the models so that they cannot be leaked to an adversary. We review two provenance-based solutions, PrIU and DeltaGrad, and show how they can guard against \u201cmodel inversion attacks\", which reconstruct the removed training samples from the updated models after the unlearning process. Since PrIU and DeltaGrad support a limited class of models, we envision a system that can unlearn general models in an ef\ufb01cient and secure manner and outline possible technical challenges for building this system. Abstract In an increasingly digital world, compliance with data regulations play an important role. More and more individuals are rapidly getting concerned with the way their data is being stored and processed by organizations. Therefore, it is crucial that data processing be subjected to regulatory obligations at its core. Yet, achieving compliance with data regulations requires the entire data processing pipeline to be revisited to embrace data policies as \ufb01rst-class citizens. In this paper, we present our work on novel systems and methods for federated data processing, where the processing of geo-distributed data is subjected to data transfer regulations. We showcase our work on compliant geo-distributed data processing and present research challenges and opportunities for a federated data processing system to make compliance truly its \ufb01rst-class citizens. Abstract Both societal and regulatory pressure (GDPR) increasingly challenge organizations and engineering teams to balance privacy and innovation. Striking this balance can be costly in terms of effort, data utility and computation costs. Moreover, current approaches in scalable data systems often treat privacy as an access problem, which is at odds with important legal and design principles. A plethora of privacy preserving- and enhancing- technologies are available, yet their adoption in production data systems still faces challenges. In particular, their focus is often on narrow use cases such as external data sharing, on mostly existing data sets, rendering them unusable in real-time data architectures. In this paper we argue engineering teams should \u201cshift left\u201c with their data privacy efforts, to the point of data collection. We show how privacy challenges in production architectures can be addressed without compromising speed, data quality or privacy. We provide a detailed yet practical explanation of an architectural set-up that allows users to launch privacy streams in seconds.", "venue": "IEEE Data Engineering Bulletin", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": null, "journal": {"name": "IEEE Data Eng. Bull.", "pages": "4-9", "volume": "45"}, "authors": [{"authorId": "2180399", "name": "Sebastian Schelter"}, {"authorId": "1683688", "name": "Felix Naumann"}, {"authorId": "134207254", "name": "Jorge Quian\u00e9"}, {"authorId": "1733290", "name": "V. Markl"}], "citations": [{"paperId": "5884cf5dec737945e7bf0995f7a2652579e3854d", "title": "Sparcle: Boosting the Accuracy of Data Cleaning Systems through Spatial Awareness"}, {"paperId": "b3aa43c5cba7595877aa679718e18353a030d7ee", "title": "VerifAI: Verified Generative AI"}, {"paperId": "d5b3d774d605188f584fd92a8bc715d95b24ced2", "title": "AutoCure: Automated Tabular Data Curation Technique for ML Pipelines"}, {"paperId": "333d6631e0f0ad2e96903e8f28fd43d28f189735", "title": "Automated Data Cleaning Can Hurt Fairness in Machine Learning-based Decision Making"}]}

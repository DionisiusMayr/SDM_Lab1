{"paperId": "895e252bfc0c2aa39ddeb148e1c3ac2784bd4b0e", "publicationVenue": null, "title": "Reproducible Model Sharing for AI Practitioners", "abstract": "The rapid advancements in AI and Machine Learning (ML) technology, from both industry and academia lead to the need of large-scale, efficient and safe model sharing. With recent models, reproducibility has gained tremendous complexity both on the execution and the resource consumption level. Although sharing source-code and access to data is becoming common practice, the training process is limited by software dependencies, (sometimes large-scale) computation power, specialized hardware, and is time-sensitive. Next to these limitations, trained models are gaining financial value and organizations are reluctant to release models for public access. All these severely hinder the timely dissemination and the scientific sharing and reviewing process, limiting reproducibility. In this work we make the case for transparent and seamless model sharing to enable the ease of reviewing and reproducibility for ML practitioners. We design and implement a platform to enable practitioners to deploy trained models and create easy-to-use inference environments, which can be easily shared with peers, conference reviewers, and/or made publicly available. Our solution follows a provider agnostic practice and can be used internally in institutional infrastructures or public/private cloud providers.", "venue": "DIDL@Middleware", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Review"], "publicationDate": "2021-12-06", "journal": {"name": "Proceedings of the Fifth Workshop on Distributed Infrastructures for Deep Learning (DIDL) 2021"}, "authors": [{"authorId": "2055074001", "name": "Amin Moradi"}, {"authorId": "2860260", "name": "Alexandru Uta"}], "citations": [{"paperId": "4c40d9598b44599d5d8d681fb16fbbac7610b14f", "title": "A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping Attacks"}]}

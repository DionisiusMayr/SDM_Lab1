{"paperId": "217cfdd01d964a1b0b1f7b7e1ecc30d76bdd5e33", "publicationVenue": {"id": "1944b6e1-2c1d-4f42-88e3-9f8a52f57e47", "name": "Diagnostics", "issn": "2075-4418", "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217965", "alternate_urls": ["https://www.mdpi.com/journal/diagnostics", "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217965"]}, "title": "Optimizing Inference Distribution for Efficient Kidney Tumor Segmentation Using a UNet-PWP Deep-Learning Model with XAI on CT Scan Images", "abstract": "Kidney tumors represent a significant medical challenge, characterized by their often-asymptomatic nature and the need for early detection to facilitate timely and effective intervention. Although neural networks have shown great promise in disease prediction, their computational demands have limited their practicality in clinical settings. This study introduces a novel methodology, the UNet-PWP architecture, tailored explicitly for kidney tumor segmentation, designed to optimize resource utilization and overcome computational complexity constraints. A key novelty in our approach is the application of adaptive partitioning, which deconstructs the intricate UNet architecture into smaller submodels. This partitioning strategy reduces computational requirements and enhances the model\u2019s efficiency in processing kidney tumor images. Additionally, we augment the UNet\u2019s depth by incorporating pre-trained weights, therefore significantly boosting its capacity to handle intricate and detailed segmentation tasks. Furthermore, we employ weight-pruning techniques to eliminate redundant zero-weighted parameters, further streamlining the UNet-PWP model without compromising its performance. To rigorously assess the effectiveness of our proposed UNet-PWP model, we conducted a comparative evaluation alongside the DeepLab V3+ model, both trained on the \u201cKiTs 19, 21, and 23\u201d kidney tumor dataset. Our results are optimistic, with the UNet-PWP model achieving an exceptional accuracy rate of 97.01% on both the training and test datasets, surpassing the DeepLab V3+ model in performance. Furthermore, to ensure our model\u2019s results are easily understandable and explainable. We included a fusion of the attention and Grad-CAM XAI methods. This approach provides valuable insights into the decision-making process of our model and the regions of interest that affect its predictions. In the medical field, this interpretability aspect is crucial for healthcare professionals to trust and comprehend the model\u2019s reasoning.", "venue": "Diagnostics", "year": 2023, "fieldsOfStudy": ["Medicine"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-01", "journal": {"name": "Diagnostics", "volume": "13"}, "authors": [{"authorId": "2150453098", "name": "P. K. Rao"}, {"authorId": "2260553443", "name": "Subarna Chatterjee"}, {"authorId": "2260562801", "name": "M. Janardhan"}, {"authorId": "1717554033", "name": "K. Nagaraju"}, {"authorId": "2218006768", "name": "S. B. Khan"}, {"authorId": "3018630", "name": "Ahlam Almusharraf"}, {"authorId": "2260564750", "name": "Abdullah I. Alharbe"}], "citations": [{"paperId": "e1c3eb3e4ee55bc41ef353846871897c87cc4117", "title": "Joint Expedition: Exploring Clinical Medical Imaging and Artificial Intelligence as a Team Integration"}]}

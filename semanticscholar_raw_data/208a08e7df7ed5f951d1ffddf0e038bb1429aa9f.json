{"paperId": "208a08e7df7ed5f951d1ffddf0e038bb1429aa9f", "publicationVenue": {"id": "036e4843-9039-4bf3-a12d-2ee5b12cdee8", "name": "International Conference on Trust, Privacy and Security in Intelligent Systems and Applications", "type": "conference", "alternate_names": ["TPS-ISA", "Int Conf Trust Priv Secur Intell Syst Appl"]}, "title": "Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives", "abstract": "This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing Large Language Models (LLMs) such as GPT-4 to dig out vulnerabilities within smart contracts based on our ongoing research. For the task of smart contract vulnerability detection, achieving practical usability hinges on identifying as many true vulnerabilities as possible while minimizing the number of false positives. Nonetheless, our empirical study reveals contradictory yet interesting findings: generating more answers with higher randomness largely boosts the likelihood of producing a correct answer but inevitably leads to a higher number of false positives. To mitigate this tension, we propose an adversarial framework dubbed GPTLENS that breaks the conventional one-stage detection into two synergistic stages - generation and discrimination, for progressive detection and refinement, wherein the LLM plays dual roles, i.e., AUDITOR and CRITIC, respectively. The goal of AUDITOR is to yield a broad spectrum of vulnerabilities with the hope of encompassing the correct answer, whereas the goal of CRITIC that evaluates the validity of identified vulnerabilities is to minimize the number of false positives. Experimental results and illustrative examples demonstrate that AUDITOR and CRITIC work together harmoniously to yield pronounced improvements over the conventional one-stage detection. GPTLENS is intuitive, strategic, and entirely LLM-driven without relying on specialist expertise in smart contracts, showcasing its methodical generality and potential to detect a broad spectrum of vulnerabilities. Our code is available at: https://github.com/git-disl/GPTLens.", "venue": "International Conference on Trust, Privacy and Security in Intelligent Systems and Applications", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-10-02", "journal": {"name": "2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)", "pages": "297-306"}, "authors": [{"authorId": "2254156032", "name": "Sihao Hu"}, {"authorId": "2253860508", "name": "Tiansheng Huang"}, {"authorId": "2046866873", "name": "Fatih Ilhan"}, {"authorId": "2066601176", "name": "S. Tekin"}, {"authorId": "2254270304", "name": "Ling Liu"}], "citations": [{"paperId": "c35b8dad08e11a77c249c0aed2b2f7f9ba853acd", "title": "A Survey on Large Language Model-Based Game Agents"}, {"paperId": "43ad3f33c8b4196ee61ae6cbf596c17df5755501", "title": "Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications"}, {"paperId": "cb744211cfc25c476167ee545883151266d9c223", "title": "Large Language Models for Blockchain Security: A Systematic Literature Review"}, {"paperId": "a08b031275376d183281f6cddbc8d07c7f91daa3", "title": "Evaluation of ChatGPT's Smart Contract Auditing Capabilities Based on Chain of Thought"}, {"paperId": "5cb8fc293567f4f2930712a3bf7dec97b4dd1776", "title": "PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models"}, {"paperId": "84fb54c43d9513689848cecf06e3fd127e610a48", "title": "LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning"}, {"paperId": "383c598625110e0a4c60da4db10a838ef822fbcf", "title": "A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly"}]}

{"paperId": "e70c61818bb8c74c451e630948e1ea1ae576283f", "publicationVenue": {"id": "d13e941e-4cac-4f1d-bdca-77d927e31f1b", "name": "ACM Symposium on Cloud Computing", "type": "conference", "alternate_names": ["System-on-Chip Conference", "ACM Symp Cloud Comput", "Syst Conf", "Symp Cloud Comput", "Annual IEEE International System-on-Chip Conference", "Symposium on Cloud Computing", "Annu IEEE Int Syst Conf", "SoCC"], "url": "http://www.ieee-socc.org/"}, "title": "Optimizing Interactive Development of Data-Intensive Applications", "abstract": "Modern Data-Intensive Scalable Computing (DISC) systems are designed to process data through batch jobs that execute programs (e.g., queries) compiled from a high-level language. These programs are often developed interactively by posing ad-hoc queries over the base data until a desired result is generated. We observe that there can be significant overlap in the structure of these queries used to derive the final program. Yet, each successive execution of a slightly modified query is performed anew, which can significantly increase the development cycle. Vega is an Apache Spark framework that we have implemented for optimizing a series of similar Spark programs, likely originating from a development or exploratory data analysis session. Spark developers (e.g., data scientists) can leverage Vega to significantly reduce the amount of time it takes to re-execute a modified Spark program, reducing the overall time to market for their Big Data applications.", "venue": "ACM Symposium on Cloud Computing", "year": 2016, "fieldsOfStudy": ["Medicine", "Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2016-10-05", "journal": {"name": "Proceedings of the Seventh ACM Symposium on Cloud Computing"}, "authors": [{"authorId": "2192580", "name": "Matteo Interlandi"}, {"authorId": "3193674", "name": "S. Tetali"}, {"authorId": "33828413", "name": "Muhammad Ali Gulzar"}, {"authorId": "40202217", "name": "Joseph Noor"}, {"authorId": "3269316", "name": "Tyson Condie"}, {"authorId": "35710133", "name": "Miryung Kim"}, {"authorId": "3105241", "name": "T. Millstein"}], "citations": [{"paperId": "72ed1896db4ae21a53b6f46d5bfa0b250713adbf", "title": "PRISPARK: Differential Privacy Enforcement for Big Data Computing in Apache Spark"}, {"paperId": "d0e5eec744ae2735333373e1af0ea6d93f1ba53f", "title": "Software Engineering for Data Intensive Scalable Computing and Heterogeneous Computing"}, {"paperId": "def13e123abeea4ecc210eee02cf141ce0646567", "title": "SODA: A Semantics-Aware Optimization Framework for Data-Intensive Applications Using Hybrid Program Analysis"}, {"paperId": "c4a2e4e5544aefcf8151484dc7b24632014e4de6", "title": "Software Engineering for Data Analytics"}, {"paperId": "6f6123de857180e38941d59d4f89701d8a2a7d07", "title": "A rewrite-based optimizer for Spark"}, {"paperId": "e46e574f97cfac90fd9bafd3730f42d26dc735fb", "title": "Chi squared feature selection over Apache Spark"}, {"paperId": "fc1c4794e9e3d395d13b13561fd342c9c7d4d53c", "title": "Optimizing distributed data stream processing by tracing"}, {"paperId": "aa51b0c3b7c5389b887d3375c1b5b14be5fb0e69", "title": "Automated debugging in data-intensive scalable computing"}, {"paperId": "714853c4b3e5d3b90845f9f44ab824dbde546ced", "title": "Adding data provenance support to Apache Spark"}, {"paperId": "0acc28f8e6a20b19d05e31abb257c08c7f08ebf9", "title": "Cleaning MapReduce Workflows"}, {"paperId": "743fe78387808b919051b0f4d18c0519ea577090", "title": "Debugging Big Data Analytics in Spark with BigDebug"}, {"paperId": "1e78ef928dfab5a05ddb131979e32b12c267bab9", "title": "Optimizing Timeliness, Accuracy, and Cost in Geo-Distributed Data-Intensive Computing Systems"}, {"paperId": "67c108097001dd17bfc0d78dd1e6fd39e0c4cfdf", "title": "Interactive Debugging for Big Data Analytics"}, {"paperId": "2d740eea6caf338a5a5a069b9074c313b034b322", "title": "Supporting Data Provenance in Data-Intensive Scalable Computing Systems"}, {"paperId": "bbe65b8f070d538200610dbec1058b8a3a2e97d1", "title": "Map ( b ) Delta Debugging ( c ) Data Provenance"}]}

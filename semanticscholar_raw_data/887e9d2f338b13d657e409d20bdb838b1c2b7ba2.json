{"paperId": "887e9d2f338b13d657e409d20bdb838b1c2b7ba2", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Cross Subspace Alignment Codes for Coded Distributed Batch Matrix Multiplication", "abstract": "The goal of coded distributed matrix multiplication (CDMM) is to efficiently multiply matrices A \u2208 F\u03bb\u00d7\u03ba and B \u2208 F\u03ba\u00d7\u03bc by distributing the computation task across S servers (through a coding scheme), such that the response from any R servers (R is called the recovery threshold) is sufficient for the user to compute AB. CDMM algorithms seek to optimize the tradeoff between six quantities of interest: recovery threshold, upload cost, download cost, encoding complexity, decoding complexity, and server computation complexity. Existing CDMM codes such as Polynomial codes, MatDot codes, PolyDot codes, Generalized PolyDot codes and Entangled Polynomial codes, all focus on multiplying one A matrix with one B matrix. Batch matrix multiplication of A1,A2, \u00b7 \u00b7 \u00b7 ,AL with B1,B2, \u00b7 \u00b7 \u00b7 ,BL to compute A1B1,A2B2, \u00b7 \u00b7 \u00b7 ,ALBL can be naturally accomplished with CDMM codes by separately computing the AlBl products for each l \u2208 [L]. But is it possible to do significantly better? Somewhat surprisingly, this work shows that joint coding of the batch of matrices offers significant advantages over separate coding. To this end, Cross Subspace Alignment (CSA) codes are introduced, that code across the matrices in a batch instead of partitioning each of the individual matrices as done in existing CDMM codes. Given a recovery thresholdR, CSA codes have the same server computation complexity per matrix multiplication as existing CDMM codes, but CSA codes show a significant improvement over all existing CDMM codes in the tradeoff between upload-download costs. A corresponding improvement in the tradeoff between encoding and decoding complexity is also observed. The gain from batch processing is reminiscent of gains from multiletterization in information theory, vector codes in network coding, and symbol extensions in interference alignment schemes. 1 ar X iv :1 90 9. 13 87 3v 1 [ cs .I T ] 3 0 Se p 20 19", "venue": "arXiv.org", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-09-30", "journal": {"name": "ArXiv", "volume": "abs/1909.13873"}, "authors": [{"authorId": "2072782908", "name": "Zhuqing Jia"}, {"authorId": "145486824", "name": "S. Jafar"}], "citations": [{"paperId": "f3c3a2ac7f7e0e216ccb9aeb0cc88a885d338773", "title": "Coded Distributed Multiplication for Matrices of Different Sparsity Levels"}, {"paperId": "a4fc29e8e4ad70dfd233b4d3baec3916e33b2ca0", "title": "Sparse Random Khatri-Rao Product Codes for Distributed Matrix Multiplication"}, {"paperId": "1c490a9b04432ba561eb533d78fd5b3fbbb18ee3", "title": "Locally Random Alloy Codes with Channel Coding Theorems for Distributed Matrix Multiplication"}, {"paperId": "534a19bb1d8313b8db3c456c36c28dbdbc874820", "title": "Lightweight Projective Derivative Codes for Compressed Asynchronous Gradient Descent"}, {"paperId": "eb454e96b241a8a3997c93836f01c95043b7f9e0", "title": "Secure Private and Adaptive Matrix Multiplication Beyond the Singleton Bound"}, {"paperId": "10deb795f1c25e492214339c87a32e31d1378012", "title": "Adaptive Private Distributed Matrix Multiplication"}, {"paperId": "0b6774dcc108a5464a177c856c168bf612972138", "title": "Uplink Cost Adjustable Schemes in Secure Distributed Matrix Multiplication"}, {"paperId": "62e58dc0551b51b8e0a9195f7408c96fd033a6f1", "title": "Entangled Polynomial Codes for Secure, Private, and Batch Distributed Matrix Multiplication: Breaking the \"Cubic\" Barrier"}, {"paperId": "81b4328273f3468c9fdf3ff24159a072efb6bc9a", "title": "Uplink-Downlink Tradeoff in Secure Distributed Matrix Multiplication"}, {"paperId": "155205b8e288fd49bf203135871d66de879c8c04", "title": "Minimizing Latency for Secure Coded Computing Using Secret Sharing via Staircase Codes"}, {"paperId": "bc87eb48e33b457f1a5bec1a919f0a2ad4d41d18", "title": "Straggler Mitigation in Distributed Matrix Multiplication: Fundamental Limits and Optimal Coding"}]}

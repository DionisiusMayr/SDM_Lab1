{"paperId": "00688ba8108385566716559000a35ebfa1362c5e", "publicationVenue": {"id": "74f47cf8-2839-4a56-959a-524dd0ed9e3e", "name": "International Conference on Extending Database Technology", "type": "conference", "alternate_names": ["Int Conf Extending Database Technol", "Extending Database Technology", "Extending Database Technol", "EDBT"], "url": "http://www.edbt.org/"}, "title": "Evaluating the Impact of Error-Bounded Lossy Compression on Time Series Forecasting", "abstract": "Time series data is widely used for decision-making and advanced analytics such as forecasting. However, the vast data volumes make storage challenging. Using lossy compression can save more space compared to lossless methods, but it can affect the forecasting accuracy. Understanding the impact of lossy compression on forecasting accuracy is a multifaceted challenge, necessitating experimental evaluation across various forecasting models, compression methods, and time series. This paper conducts such experimental evaluation by combining seven forecasting models, three lossy compression algorithms, and six datasets. By simulating a real-life scenario where forecasting models use lossy compressed data for prediction, we address three main research questions related to compression error and its effects on the time series characteristics and the forecasting models. The results show that the Poor Man\u2019s Compression and Swing Filterlossycompressionalgorithmsaddlesserrorthanthe Squeeze method as the error bound increases. Poor Man\u2019s Compression provides the best balance between compression ratio and forecasting accuracy. Specifically, we obtained an average compression ratio of 13.65, 5.56, and 14.97 for PMC, SWING, and SZ with an average impact on forecasting accuracy of 5.56%, 3.3%, and 8.5%, respectively. An analysis of several time series characteristics shows that the maximum Kullback-Leibler divergence between consecutive windows in the time series is the best indicator of the impact of lossy compression on forecasting accuracy. Finally, our results indicate that simple models like Arima, are more resilient to lossy compression than complex deep learning models. The source code and data", "venue": "International Conference on Extending Database Technology", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": null, "journal": {"pages": "650-663"}, "authors": [{"authorId": "1409905310", "name": "C. E. Mu\u00f1iz-Cuza"}, {"authorId": "145180502", "name": "S. K. Jensen"}, {"authorId": "1420420500", "name": "Jonas Brusokas"}, {"authorId": "40540244", "name": "N. Ho"}, {"authorId": "2056515858", "name": "T. Pedersen"}], "citations": [{"paperId": "a36d8260cf749a361935ab3a140f8a6d52aa162c", "title": "Scalable Model-Based Management of Massive High Frequency Wind Turbine Data with ModelarDB"}]}

{"paperId": "ec10ea170ebcfdbaf1384ca132ea7ff424f4a1f4", "publicationVenue": {"id": "228761ec-c40a-479b-8309-9dcbe9851bcd", "name": "IEEE Internet of Things Journal", "type": "journal", "alternate_names": ["IEEE Internet Thing J"], "issn": "2327-4662", "url": "https://www.ieee.org/membership-catalog/productdetail/showProductDetailPage.html?product=PER288-ELE", "alternate_urls": ["https://ieeexplore.ieee.org/servlet/opac?punumber=6488907", "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6488907", "http://ieee-iotj.org/#"]}, "title": "Reinforcement Learning for Optimizing Delay-Sensitive Task Offloading in Vehicular Edge\u2013Cloud Computing", "abstract": "With the appearance of more and more devices connected to the Internet, the world has witnessed an ever-growing number of data to be processed. Among those, many tasks require swift execution time, while the storage and computation capability of Internet of Things (IoT) devices are limited. To address the demands of delay-sensitive tasks, we present a vehicular edge\u2013cloud computing (VECC) network that leverages powerful computation capabilities through the deployment of servers in proximity to task-generated devices, as well as the utilization of idle resources from smart vehicles to share the workload. Because these limited resources are vulnerable to sudden data arising, it is imperative to incorporate cloud servers to prevent system overload. The challenge now is to find a task offloading strategy that collaborates both edges and cloud resources to minimize the total time surpassing the quality baseline of each task (tolerance time) and make all tasks meet their soft deadlines of quality. To reach this goal, we first model the task offloading problem in VECC as a Markov decision process (MDP). Then, we propose advantage-oriented task offloading with a dueling actor-insulator network scheme to solve the problem. This value-based reinforcement learning (RL) method helps the agent find an effective policy when not knowing all the state attributes changes. The effectiveness of our method is demonstrated by performance evaluations based on real-world bus traces in Rio de Janeiro (Brazil). The experimental results show that our proposal reduces the tolerance time by at least 8.81% compared to other RL algorithms and 75% compared to greedy approaches.", "venue": "IEEE Internet of Things Journal", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-01-15", "journal": {"name": "IEEE Internet of Things Journal", "pages": "2058-2069", "volume": "11"}, "authors": [{"authorId": "2164506451", "name": "Ta Huu Binh"}, {"authorId": "34048851", "name": "D. Son"}, {"authorId": "87121831", "name": "H. Vo"}, {"authorId": "1698513", "name": "B. Nguyen"}, {"authorId": "3359343", "name": "Huynh Thi Thanh Binh"}], "citations": [{"paperId": "fbf03b9f30c8054d621d7f1c0f3496c73f83d2dc", "title": "Feasibility and reliability of peercloud in vehicular networks: A comprehensive study"}, {"paperId": "b7b225d85ec06e617b23aeb59f20c85baabcd967", "title": "Graph-Powered Reinforcement Learning for Intelligent Task Offloading in Vehicular Networks"}, {"paperId": "8dddbc8f3ec1d8fd7c769ecb4d2e5627e9f2e69a", "title": "Intelligent Vehicle Computation Offloading in Vehicular Ad Hoc Networks: A Multi-Agent LSTM Approach with Deep Reinforcement Learning"}, {"paperId": "00f10f86f8379084e777ab6a7291cb72d61d7ad7", "title": "DRL-Based Distributed Task Offloading Framework in Edge-Cloud Environment"}]}

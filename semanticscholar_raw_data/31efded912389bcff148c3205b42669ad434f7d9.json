{"paperId": "31efded912389bcff148c3205b42669ad434f7d9", "publicationVenue": {"id": "b9c462e2-3c38-4569-be08-59ccd0e270f5", "name": "Natural Language Processing Journal", "type": "journal", "alternate_names": ["Nat Lang Process J"], "issn": "2949-7191"}, "title": "An Evaluation on Large Language Model Outputs: Discourse and Memorization", "abstract": null, "venue": "Natural Language Processing Journal", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-04-17", "journal": {"name": "ArXiv", "volume": "abs/2304.08637"}, "authors": [{"authorId": "1388060354", "name": "Adrian de Wynter"}, {"authorId": "2115535412", "name": "Xun Wang"}, {"authorId": "33705021", "name": "Alex Sokolov"}, {"authorId": "2054919208", "name": "Qilong Gu"}, {"authorId": "2111638099", "name": "Si-Qing Chen"}], "citations": [{"paperId": "9a741f33aa4d782639e1f81a7e9c341b58b6ed2a", "title": "Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices"}, {"paperId": "6a1d85d1a73d2b80f8a61db62e9b64299eb2dd7e", "title": "Will GPT-4 Run DOOM?"}, {"paperId": "3097cc81b49ff79d8999b9127ff2c7071701ae78", "title": "ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models"}, {"paperId": "bac8a5858ac1dc449ab642fb3deb03f4860802ce", "title": "Evaluations of Large Language Models a Bibliometric analysis"}, {"paperId": "b6ee2c33640bad7698073f7d7537b1f371048bcf", "title": "Exploring Musical Roots: Applying Audio Embeddings to Empower Influence Attribution for a Generative Music Model"}, {"paperId": "394236c1017a8460c0486e97ecb6379a0441f06c", "title": "I Wish to Have an Argument: Argumentative Reasoning in Large Language Models"}, {"paperId": "916c798b34d55a78c47ae44906fe018a60a30613", "title": "GPTEval: A Survey on Assessments of ChatGPT and GPT-4"}, {"paperId": "2525f8185ff4eee23dea96f2a820714a1619fb89", "title": "Evaluating Large Language Models for Radiology Natural Language Processing"}, {"paperId": "be658d4482299d7a77be324bdb9946bfcbcbad25", "title": "Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization"}, {"paperId": "131f499e4d3503da93022d07fcf804a18483bea9", "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions"}, {"paperId": "8e0f0f46fb95baa2efa404cb2d020e57ed18b726", "title": "Sentiment and Emotion Classification in Low-resource Settings"}, {"paperId": "643f3e79ca5a7effee96973a21af50a9dddeaf10", "title": "What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks"}]}

{"paperId": "289a3351da7b5e8ea4360f504d8f0ff5ed94d8d0", "publicationVenue": {"id": "e35a87a3-a6c4-47bf-acca-3e615ddb9c58", "name": "ACM Transactions on Database Systems", "type": "journal", "alternate_names": ["ACM Trans Database Syst"], "issn": "0362-5915", "url": "http://www.acm.org/pubs/contents/journals/tods/", "alternate_urls": ["http://tods.acm.org/", "http://www.acm.org/tods/", "http://portal.acm.org/tods", "https://tods.acm.org/"]}, "title": "Incremental and Approximate Computations for Accelerating Deep CNN Inference", "abstract": "Deep learning now offers state-of-the-art accuracy for many prediction tasks. A form of deep learning called deep convolutional neural networks (CNNs) are especially popular on image, video, and time series data. Due to its high computational cost, CNN inference is often a bottleneck in analytics tasks on such data. Thus, a lot of work in the computer architecture, systems, and compilers communities study how to make CNN inference faster. In this work, we show that by elevating the abstraction level and re-imagining CNN inference as queries, we can bring to bear database-style query optimization techniques to improve CNN inference efficiency. We focus on tasks that perform CNN inference repeatedly on inputs that are only slightly different. We identify two popular CNN tasks with this behavior: occlusion-based explanations (OBE) and object recognition in videos (ORV). OBE is a popular method for \u201cexplaining\u201d CNN predictions. It outputs a heatmap over the input to show which regions (e.g., image pixels) mattered most for a given prediction. It leads to many re-inference requests on locally modified inputs. ORV uses CNNs to identify and track objects across video frames. It also leads to many re-inference requests. We cast such tasks in a unified manner as a novel instance of the incremental view maintenance problem and create a comprehensive algebraic framework for incremental CNN inference that reduces computational costs. We produce materialized views of features produced inside a CNN and connect them with a novel multi-query optimization scheme for CNN re-inference. Finally, we also devise novel OBE-specific and ORV-specific approximate inference optimizations exploiting their semantics. We prototype our ideas in Python to create a tool called Krypton that supports both CPUs and GPUs. Experiments with real data and CNNs show that Krypton reduces runtimes by up to 5\u00d7 (respectively, 35\u00d7) to produce exact (respectively, high-quality approximate) results without raising resource requirements.", "venue": "ACM Transactions on Database Systems", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-12-06", "journal": {"name": "ACM Transactions on Database Systems (TODS)", "pages": "1 - 42", "volume": "45"}, "authors": [{"authorId": "1414310714", "name": "Supun Nakandala"}, {"authorId": "2003802919", "name": "Kabir Nagrecha"}, {"authorId": "2119303314", "name": "Arun Kumar"}, {"authorId": "1786049", "name": "Y. Papakonstantinou"}], "citations": [{"paperId": "3ac173e1ca99f4574ede923a64e1171645be188f", "title": "Saturn: Efficient Multi-Large-Model Deep Learning"}, {"paperId": "3a29a9e6168cf1620fe76b3702e473de6f6fec67", "title": "Saturn: An Optimized Data System for Multi-Large-Model Deep Learning Workloads"}, {"paperId": "d2a8294f1aede0ca6a89920475dc780e918a79aa", "title": "InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models"}, {"paperId": "7c0b26d4035ead54985c94ed041032fa4931e7ed", "title": "A Lightweight Automatic Wildlife Recognition Model Design Method Mitigating Shortcut Learning"}, {"paperId": "8bfab0a25cf03f307703bfb1cc4a22e10b3cbcb6", "title": "Does Federated Learning Really Need Backpropagation?"}, {"paperId": "28fa9d31301e3338c7d39430c29d7feda6f67e12", "title": "Systems for Parallel and Distributed Large-Model Deep Learning Training"}, {"paperId": "6dedfaf156a4a7295bb16047680eb49d67836f64", "title": "INS-Conv: Incremental Sparse Convolution for Online 3D Segmentation"}, {"paperId": "4b3ebac2e9415d7d1124d6677386f199ab9b3a5f", "title": "Explainable AI: Foundations, Applications, Opportunities for Data Management Research"}, {"paperId": "36e696827d2d8d2a07bea711b3e1fda9ee1c426f", "title": "Hydra: A System for Large Multi-Model Deep Learning"}, {"paperId": "2944bb6b684428d5c1413ca5c708eb8dcf9da23f", "title": "Query Optimization for Faster Deep CNN Explanations"}, {"paperId": "78ac34f3b6398cf1e654801b768b139c191e6514", "title": "Model-Parallel Task Parallelism for Ef\ufb01cient Multi-Large-Model Deep Learning"}, {"paperId": "8eede56dc8139a266cc87b9bb132bc5c75e338db", "title": "Hydra: An Optimized Data System for Large Multi-Model Deep Learning [Information System Architectures]"}, {"paperId": "4c55a58372f12aed456f90991fa93df9c53e413e", "title": "Cerebro: A Layered Data Platform for Scalable Deep Learning"}, {"paperId": "4a52a1b8e8b0cf25b4fed2fe15374148364645c1", "title": "Some Damaging Delusions of Deep Learning Practice (and How to Avoid Them)"}, {"paperId": "df9ee928e73efb498ebd1502bfc8c48a87241118", "title": "Hydra: A Scalable and Optimized Data System for Large Multi-Model Deep Learning"}]}

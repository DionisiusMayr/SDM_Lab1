{"paperId": "08f7aeca8f94bedbeb425bef1f0b3fcd9361f785", "publicationVenue": {"id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44", "name": "Annual Meeting of the Association for Computational Linguistics", "type": "conference", "alternate_names": ["Annu Meet Assoc Comput Linguistics", "Meeting of the Association for Computational Linguistics", "ACL", "Meet Assoc Comput Linguistics"], "url": "https://www.aclweb.org/anthology/venues/acl/"}, "title": "SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems", "abstract": "The social impact of natural language processing and its applications has received increasing attention. In this position paper, we focus on the problem of safety for end-to-end conversational AI. We survey the problem landscape therein, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects. We then empirically assess the extent to which current tools can measure these effects and current systems display them. We release these tools as part of a \u201cfirst aid kit\u201d (SafetyKit) to quickly assess apparent safety concerns. Our results show that, while current tools are able to provide an estimate of the relative safety of systems in various settings, they still have several shortcomings. We suggest several future directions and discuss ethical considerations.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference", "Review"], "publicationDate": null, "journal": {"pages": "4113-4133"}, "authors": [{"authorId": "31461304", "name": "Emily Dinan"}, {"authorId": "17038002", "name": "Gavin Abercrombie"}, {"authorId": "50203765", "name": "A. Bergman"}, {"authorId": "3416737", "name": "Shannon L. Spruit"}, {"authorId": "2022288", "name": "Dirk Hovy"}, {"authorId": "90841478", "name": "Y-Lan Boureau"}, {"authorId": "1681799", "name": "Verena Rieser"}], "citations": [{"paperId": "d862aae89c364eb97442372979a0d185e95ae3bb", "title": "SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety"}, {"paperId": "9aeae8e712343f2717ea6e55ee4414b220a712e1", "title": "Behind the Counter: Exploring the Motivations and Barriers of Online Counterspeech Writing"}, {"paperId": "6ecb6f2c4544e3c7f8dfd33a8e2f14735653b6ef", "title": "Improving Dialog Safety using Socially Aware Contrastive Learning"}, {"paperId": "ef7097244ee0cc2d54649e7bec121abf7c628947", "title": "A Survey of the Evolution of Language Model-Based Dialogue Systems"}, {"paperId": "ec23c1a8e326bd55cc3d6bfcb9388d40a442ac5c", "title": "Walking a Tightrope \u2013 Evaluating Large Language Models in High-Risk Domains"}, {"paperId": "c11ac248290acf6bba414cd6d6be25df6c7eacf4", "title": "SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models"}, {"paperId": "9ec29a26336f043a705ac99baa04c8d7f69fe4b4", "title": "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"}, {"paperId": "aa9aa1c315cb2a0c1759d82fb3d4b4506c2dbb7c", "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models"}, {"paperId": "6f542f60a5d4f540d056bb49d47f89f1035ad0cf", "title": "A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement"}, {"paperId": "451a657dabf80ebc43f6a3be518250b2cd5dfe1a", "title": "Through the Lens of Core Competency: Survey on Evaluation of Large Language Models"}, {"paperId": "b67eb8213a63be8a4b0274728ffdc50bfa109e10", "title": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models"}, {"paperId": "8e1d9e6e81d41ab3b598298835a233474892504e", "title": "A Benchmark for Understanding Dialogue Safety in Mental Health Support"}, {"paperId": "736dfc6b6bb14c011335871f360013c1c2f5e880", "title": "Interpretable Stereotype Identification through Reasoning"}, {"paperId": "49f97e7b63b0c6e592e256c0d47eb1f4150ad7e1", "title": "Proactive Conversational Agents in the Post-ChatGPT World"}, {"paperId": "2fca068a24b1b766c9c02c6aa004ca60d81023cc", "title": "Understanding Counterspeech for Online Harm Mitigation"}, {"paperId": "6e30a511242cd48a1394d87ce8d2b682978014a0", "title": "DICES Dataset: Diversity in Conversational AI Evaluation for Safety"}, {"paperId": "0b6edce3dde7e502c6b7c6d83bac0230ec912482", "title": "Improving Open Language Models by Learning from Organic Interactions"}, {"paperId": "0b641cc51d8e25c6c0b2362317fec7e0bf26fbf1", "title": "KoSBI: A Dataset for Mitigating Social Bias Risks Towards Safer Large Language Model Applications"}, {"paperId": "f0e9998ddec97b5275eada7308104d867a1dda19", "title": "This Prompt is Measuring : Evaluating Bias Evaluation in Language Models"}, {"paperId": "9379d519b8ddfa194ef6f575127451e5016e1803", "title": "Mirages: On Anthropomorphism in Dialogue Systems"}, {"paperId": "bf1f3bcd50220315b8c069988aa9998f25f571cb", "title": "SWAN: A Generic Framework for Auditing Textual Conversational Systems"}, {"paperId": "861761d8c14c824a4dcb9a39a8f2d5871575916b", "title": "Proactive Conversational Agents"}, {"paperId": "1d75f8de31bf47ec46fa5586056420ec8bc97e86", "title": "Using In-Context Learning to Improve Dialogue Safety"}, {"paperId": "4f4f25fbe7479cd7dfd1bca7c817600ee517c8b9", "title": "Viewpoint: Artificial Intelligence Accidents Waiting to Happen?"}, {"paperId": "6d1fd99a686f9be91355985e3149b3b5b8337a7a", "title": "Computer says \"No\": The Case Against Empathetic Conversational AI"}, {"paperId": "8616da9215843353f2169916766054dfbd50a671", "title": "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines"}, {"paperId": "7c2a7a9db293eeaff35c45ce3935accc4efe6a99", "title": "Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI"}, {"paperId": "f6a6b32b61512b62eddac6097769a3d84e9a69cc", "title": "Don\u2019t Forget Your ABC\u2019s: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems"}, {"paperId": "8c5dfc418b937ba78e481ca46a5f43ac61863059", "title": "Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems"}, {"paperId": "2b6291eb76e2ff885238e94704bb795046d7d530", "title": "SafeText: A Benchmark for Exploring Physical Safety in Language Models"}, {"paperId": "0b4681139e8a77a92207ed81233c16bb3772e238", "title": "Mitigating Covertly Unsafe Text within Natural Language Systems"}, {"paperId": "e085bd71d3cc53a6eba3aa7e6940171a3a5d1086", "title": "Risk-graded Safety for Handling Medical Queries in Conversational AI"}, {"paperId": "737486a30a7499573b5c7ec0b60cc587c81273cb", "title": "Conversational AI for multi-agent communication in Natural Language"}, {"paperId": "a3076ecfed0571fbbb5217a5cc6b4b6f24f6f7dd", "title": "BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage"}, {"paperId": "36c50e6638dddc8324eef9bfa064bfcab80cbef4", "title": "ProsocialDialog: A Prosocial Backbone for Conversational Agents"}, {"paperId": "45c55fe92abc0ed4c2190fe039c9a23d70a0e33a", "title": "Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges"}, {"paperId": "03c6e5e31728c7c04c05c0a5d45520c10a9d4699", "title": "Social Commonsense Reasoning-How well can Deep Learning models"}, {"paperId": "00563f1039d6d293cc3f34d453b85f9c7a256106", "title": "Concept-based Persona Expansion for Improving Diversity of Persona-Grounded Dialogue"}, {"paperId": "aecbf7b6d52290d4daa7830325add4fa427ea334", "title": "I already said that! Degenerating redundant questions in open-domain dialogue systems."}, {"paperId": "d14f679f6fa39dfac2f2161cfd4f178286620c3d", "title": "Bootstrapping a Conversational Guide for Colonoscopy Prep"}, {"paperId": "b064e4f72f4fa7d8bae5f6c7f49b946699cdd92d", "title": "Safety and Robustness in Conversational AI"}, {"paperId": "39061cead45e4aea31e5710519879717fe4db7bb", "title": "Guiding the Release of Safer E2E Conversational AI through Value Sensitive Design"}, {"paperId": "dd261b7a33cfaa3688f3593081be249164123b09", "title": "Foveate, Attribute, and Rationalize: Towards Safe and Trustworthy AI"}]}

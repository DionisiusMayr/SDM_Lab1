{"paperId": "38ec4e01e32edd3ee504cd267dbad41fa6e67d11", "publicationVenue": {"id": "2b05540e-d9fa-4b45-9aac-08c1090f1c16", "name": "IEEE International Conference on Application-Specific Systems, Architectures, and Processors", "type": "conference", "alternate_names": ["Application-Specific Systems, Architectures, and Processors", "ASAP", "International Conference on Application Specific Array Processors", "Int Conf Appl Specif Array Process", "IEEE Int Conf Appl Syst Archit Process", "Appl Syst Archit Process"], "url": "http://www.asapconference.org/"}, "title": "SieveMem: A Computation-in-Memory Architecture for Fast and Accurate Pre-Alignment", "abstract": "The high execution time of DNA sequence alignment negatively affects many genomic studies that rely on sequence alignment results. Pre-alignment filtering was introduced as a step before alignment to reduce the execution time of short-read sequence alignment greatly. With its success, i.e., achieving high accuracy and thus removing unnecessary alignments, the filtering itself now constitutes the larger portion of the execution time. A significant contributing factor entails the movement of sequences from the memory to the processing units, while a majority will filter out as they do not result in an acceptable alignment. State-of-the-art (SotA) pre-alignment filtering accelerators suffer from the same overhead for data movements. Furthermore, these accelerators lack support for future pre-alignment filtering algorithms using the same operations and underlying hardware. This paper addresses these shortcomings by introducing SieveMem. SieveMem is an architecture that exploits the Computation-in-Memory paradigm with memristive-based devices to support shared kernels of pre-alignment filters and algorithms inside the memory (i.e., preventing data movements). SieveMem architecture also provides support for future algorithms. SieveMem supports more than 47.6% of shared operations among all top 5 SotA filters. Moreover, SieveMem includes a hardware-friendly pre-alignment filtering algorithm called BandedKrait, inspired by a combination of mentioned kernels. Our evaluations show that SieveMem provides up to 331.1 x and $\\mathbf{446.8}\\times$ improvement in the execution time of the two most-common kernels. Our evaluations also show that BandedKrait provides accuracy at the SotA level. Using BandedKrait on SieveMem, a design we call Mem-BandedKrait, one can improve the execution time of end-to-end sequence alignment irrespective of the dataset, which can go up to $\\mathbf{91.4}\\times$ compared to the SotA accelerator on GPU.", "venue": "IEEE International Conference on Application-Specific Systems, Architectures, and Processors", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-07-01", "journal": {"name": "2023 IEEE 34th International Conference on Application-specific Systems, Architectures and Processors (ASAP)", "pages": "156-164"}, "authors": [{"authorId": "51017214", "name": "Taha Shahroodi"}, {"authorId": "2253772957", "name": "Michael Miao"}, {"authorId": "1864957026", "name": "Mahdi Zahedi"}, {"authorId": "2171100110", "name": "Stephan Wong"}, {"authorId": "2253779185", "name": "Said Hamdioui"}], "citations": [{"paperId": "0f2e49efe9885addc341a1cdb9c7910e68faeb26", "title": "High-Performance Data Mapping for BNNs on PCM-based Integrated Photonics"}]}

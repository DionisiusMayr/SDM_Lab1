{"paperId": "cb253190cf6824cafbefa4b5de6efee9b4f637e9", "publicationVenue": {"id": "de454aec-8c73-4737-bb1f-5231453ca8fa", "name": "Frontiers in Neurorobotics", "type": "journal", "alternate_names": ["Front Neurorobotics"], "issn": "1662-5218", "url": "https://www.frontiersin.org/journals/neurorobotics#articles", "alternate_urls": ["http://www.frontiersin.org/neurorobotics/"]}, "title": "Deep Cross-Corpus Speech Emotion Recognition: Recent Advances and Perspectives", "abstract": "Automatic speech emotion recognition (SER) is a challenging component of human-computer interaction (HCI). Existing literatures mainly focus on evaluating the SER performance by means of training and testing on a single corpus with a single language setting. However, in many practical applications, there are great differences between the training corpus and testing corpus. Due to the diversity of different speech emotional corpus or languages, most previous SER methods do not perform well when applied in real-world cross-corpus or cross-language scenarios. Inspired by the powerful feature learning ability of recently-emerged deep learning techniques, various advanced deep learning models have increasingly been adopted for cross-corpus SER. This paper aims to provide an up-to-date and comprehensive survey of cross-corpus SER, especially for various deep learning techniques associated with supervised, unsupervised and semi-supervised learning in this area. In addition, this paper also highlights different challenges and opportunities on cross-corpus SER tasks, and points out its future trends.", "venue": "Frontiers in Neurorobotics", "year": 2021, "fieldsOfStudy": ["Computer Science", "Medicine"], "publicationTypes": ["Review", "JournalArticle"], "publicationDate": "2021-11-29", "journal": {"name": "Frontiers in Neurorobotics", "volume": "15"}, "authors": [{"authorId": "1695589", "name": "Shiqing Zhang"}, {"authorId": "47246298", "name": "Ruixin Liu"}, {"authorId": "2070899068", "name": "Xin Tao"}, {"authorId": "48551029", "name": "Xiaoming Zhao"}], "citations": [{"paperId": "ed4f3cd9fdf6c44bfebe8b3bca83515932ee063e", "title": "Optimizing Speech Emotion Recognition with Hilbert Curve and convolutional neural network"}, {"paperId": "ea8ccb8df904f8787e1bbb085e6925bf739139fb", "title": "Deep learning-based multimodal emotion recognition from audio, visual, and text modalities: A systematic review of recent advancements and future prospects"}, {"paperId": "c69cd5ba401a20261bbb9dd301c12e58aef7b3d7", "title": "Detection of Emotional Hotspots in Meetings Using a Cross-Corpus Approach"}, {"paperId": "24e7803d58a7ed3f6279bb90ccd21e9ba58f11a8", "title": "Speaker Embeddings as Individuality Proxy for Voice Stress Detection"}, {"paperId": "b9862f234a9fc8c7e59ee187b912525b34c9df42", "title": "An ongoing review of speech emotion recognition"}, {"paperId": "d3fa8f4d989f02b88c2a4c1863398cd40c7b13d4", "title": "Human\u2013Computer Interaction with a Real-Time Speech Emotion Recognition with Ensembling Techniques 1D Convolution Neural Network and Attention"}, {"paperId": "b127c71f0f5703e5c4a6eddaadf0d2abe30ae9f1", "title": "Improved multi-lingual sentiment analysis and recognition using deep learning"}, {"paperId": "ce189f25a7036666279d11bd01660df167a4fee5", "title": "AI Based Web App and Framework for Detecting Emotions from Human Speech"}, {"paperId": "afacb54e1ab50a4f5dd2be83f08b7d212aaad961", "title": "Unsupervised Domain Adaptation Integrating Transformer and Mutual Information for Cross-Corpus Speech Emotion Recognition"}, {"paperId": "73bf16733d3dcc5b0e96484efec166100b582a65", "title": "CTL-MTNet: A Novel CapsNet and Transfer Learning-Based Mixed Task Net for the Single-Corpus and Cross-Corpus Speech Emotion Recognition"}, {"paperId": "18278f84d95a3560cf0700a8e35a7607d4d6bb59", "title": "Multi-Source Discriminant Subspace Alignment for Cross-Domain Speech Emotion Recognition"}, {"paperId": "c17c3e8d4ba0225f1705d03d9531cbce64239ffe", "title": "Transfer Learning and Data Augmentation Techniques applied to Speech Emotion Recognition in SE&R 2022"}, {"paperId": "625abc6cedfbf7742206449a132b0bfd4e3a1ab1", "title": "Chung-Ang Auditory Database of Korean Emotional Speech: A Validated Set of Vocal Expressions With Different Intensities"}]}

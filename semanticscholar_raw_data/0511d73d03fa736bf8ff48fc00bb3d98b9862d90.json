{"paperId": "0511d73d03fa736bf8ff48fc00bb3d98b9862d90", "publicationVenue": {"id": "7cd7bf33-3c9a-4b3f-8b1a-177673c6ca73", "name": "Consumer Communications and Networking Conference", "type": "conference", "alternate_names": ["CCNC", "Consum Commun Netw Conf"], "url": "http://ieee-ccnc.org/"}, "title": "Addressing the Heterogeneity of A Wide Area Network for DNNs", "abstract": "In general, deep neural networks (DNNs) achieve higher accuracy as the amount of training data increases. However, training data are often privacy sensitive, and they may not be collected. There are several methods that leave the training data decentralized in a wide area network and share models. These methods update the models locally based on stochastic gradient descent (SGD) and communicate to aggregate the models. The network bandwidth, training data, and machines are heterogeneous in a wide area network unlike distributed DNNs which use a computer cluster. Due to heterogeneity, the methods using synchronous communication, such as all-reduce SGD, are not suitable, and gossip SGD using asynchronous communication is a dominant method. In this paper, we show that when the network bandwidth is heterogeneous, conventional gossip SGD causes network congestion, and the learning efficiency is not greatly different from the case in which the network bandwidth is homogeneous. We show that the congestion problem can be solved by adjusting the communication frequency, that is, by training multiple times and communicating once. In many works, learning in local nodes and communicating with other nodes are alternated. Furthermore, we propose a warm-up technique to improve the learning efficiency. This proposed technique decreases the amount of communication with nodes that require a long communication time. We verify the effect of the proposed technique in experiments using CIFAR-10 and CIFAR-100.", "venue": "Consumer Communications and Networking Conference", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-01-09", "journal": {"name": "2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)", "pages": "1-6"}, "authors": [{"authorId": "2054844620", "name": "Hideaki Oguni"}, {"authorId": "1856020", "name": "Kazuyuki Shudo"}], "citations": [{"paperId": "1f3368152930166e6461fb55d6d6a049ad71cbca", "title": "Gossip Distillation: Decentralized Deep Learning Transmitting Neither Training Data Nor Models"}, {"paperId": "33bcca5e7e0d4ead2b9f82ca0c52ec16fefb7e22", "title": "The Shift in the Authority of Islamic Religious Education: A Qualitative Content Analysis on Online Religious Teaching"}, {"paperId": "96c23fbe3dcf55151ef44686f8135df41712b65d", "title": "Communication Scheduling for Gossip SGD in a Wide Area Network"}, {"paperId": "f2c694c34612eff1bd260640bca9ca12fa2da94f", "title": "2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)"}]}

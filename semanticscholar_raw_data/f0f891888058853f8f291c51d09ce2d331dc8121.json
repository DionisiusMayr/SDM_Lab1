{"paperId": "f0f891888058853f8f291c51d09ce2d331dc8121", "publicationVenue": {"id": "0c1420a4-aa9b-44f9-b264-ba3ac5c37050", "name": "International Conference for High Performance Computing, Networking, Storage and Analysis", "alternate_names": ["Int Conf High Perform Comput Netw Storage Anal"], "issn": "2167-4337", "alternate_issns": ["2167-4329"], "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000729"}, "title": "Canary: Fault-Tolerant FaaS for Stateful Time-Sensitive Applications", "abstract": "Function-as-a-Service (FaaS) platforms have recently gained rapid popularity. Many stateful applications have been migrated to FaaS platforms due to their ease of deployment, scalability, and minimal management overhead. However, failures in FaaS have not been thoroughly investigated, thus making these desirable platforms unreliable for guaranteeing function execution and ensuring performance requirements. In this paper, we propose Canary, a highly resilient and fault-tolerant framework for FaaS that mitigates the impact of failures and reduces the overhead of function restart. Canary utilizes replicated container runtimes and application-level checkpoints to reduce application recovery time over FaaS platforms. Our evaluations using representative stateful FaaS applications show that Canary reduces the application recovery time and dollar cost by up to 83% and 12%, respectively over the default retry-based strategy. Moreover, it improves application availability with an additional average execution time and cost overhead of 14% and 8%, respectively, as compared to the ideal failure-free execution.", "venue": "International Conference for High Performance Computing, Networking, Storage and Analysis", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2022-11-01", "journal": {"name": "SC22: International Conference for High Performance Computing, Networking, Storage and Analysis", "pages": "1-16"}, "authors": [{"authorId": "1392416738", "name": "Moiz Arif"}, {"authorId": "41035691", "name": "Kevin Assogba"}, {"authorId": "144343120", "name": "M. M. Rafique"}], "citations": [{"paperId": "99bcc0edbdeda56e79d23c83422256b522ed8fd2", "title": "Optimizing the Training of Co-Located Deep Learning Models Using Cache-Aware Staggering"}, {"paperId": "15a3aaf82edb35516527076f3b52b1480ae66503", "title": "HashCache: Accelerating Serverless Computing by Skipping Duplicated Function Execution"}, {"paperId": "c4418610df7224fbd92286a023eea9e490e0fa72", "title": "PredictDDL: Reusable Workload Performance Prediction for Distributed Deep Learning"}, {"paperId": "38f19990c469d39cfac56fbc19dc0528d131dbd6", "title": "GPU-Enabled Asynchronous Multi-level Checkpoint Caching and Prefetching"}]}

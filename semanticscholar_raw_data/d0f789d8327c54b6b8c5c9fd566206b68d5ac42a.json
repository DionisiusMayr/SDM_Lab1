{"paperId": "d0f789d8327c54b6b8c5c9fd566206b68d5ac42a", "publicationVenue": {"id": "406d9f60-417a-4dc5-a6b7-1fe4689a4ff7", "name": "IEEE International Conference on Cloud Computing", "type": "conference", "alternate_names": ["Int Conf Cloud Comput [services Soc", "CLOUD", "International Conference on Cloud Computing [Services Society]", "IEEE Int Conf Cloud Comput"]}, "title": "Storm-RTS: Stream Processing with Stable Performance for Multi-Cloud and Cloud-edge", "abstract": "Stream Processing Engines (SPEs) traditionally de-ploy applications on a set of shared workers (e.g., threads, processes, or containers) requiring complex performance man-agement by SPEs and application developers. We explore a new approach that replaces workers with Rate-based Abstract Ma-chines (RBAMs). This allows SPEs to translate stream operations into FaaS invocations, and exploit guaranteed invocation rates to manage performance. This approach enables SPE applications to achieve transparent and predictable performance. We realize the approach in the Storm-RTS system. Exploring 36 stream processing scenarios over 5 different hardware config-urations, we demonstrate several key advantages. First, Storm-RTS provides stable application performance and can enable flexible reconfiguration across cloud resource configurations. Sec-ond, SPEs built on RBAM can be resource-efficient and scalable. Finally, Storm-RTS allows the stream-processing paradigm to be extended from the cloud to the edge, using its performance stability to hide edge heterogeneity and resource competition. An experiment with 4 cloud and edge sites over 300 cores shows how Storm-RTS can support flexible reconfiguration and simple high-level declarative policies that optimize resource cost or other criteria.", "venue": "IEEE International Conference on Cloud Computing", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-07-01", "journal": {"name": "2023 IEEE 16th International Conference on Cloud Computing (CLOUD)", "pages": "45-57"}, "authors": [{"authorId": "2227237657", "name": "Hai Nguyen"}, {"authorId": "2247457474", "name": "Andrew A. Chien"}], "citations": [{"paperId": "ed2db05074b86da6fbcb01b45bd0f1693baa93c4", "title": "Reducing the Carbon Impact of Generative AI Inference (today and in 2035)"}]}

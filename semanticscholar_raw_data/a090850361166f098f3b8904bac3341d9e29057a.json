{"paperId": "a090850361166f098f3b8904bac3341d9e29057a", "publicationVenue": null, "title": "Trends in Explanations", "abstract": "Humans reason about the world around them by seeking to understand why and how something occurs. The same principle extends to the technology that so many of human activities increasingly rely on. Issues of trust, transparency, and understandability are critical in promoting adoption and proper use of systems. However, with increasing complexity of the systems and technologies we use, it is hard or even impossible to comprehend their function and behavior, and justify surprising observations through manual investigation alone. Explanation support can ease humans\u2019 interactions with technology: explanations can help users understand a system\u2019s function, justify system results, and increase their trust in automated decisions. Our goal in this article is to provide an overview of existing work in explanation support for data-driven processes, through a lens that identifies commonalities across varied problem settings and solutions. We suggest a classification of explainability requirements across three dimensions: the target of the explanation (\u201cWhat\u201d), the audience of the explanation (\u201cWho\u201d), and the purpose of the explanation (\u201cWhy\u201d). We identify dominant themes across these dimensions and the high-level desiderata each implies, accompaBoris Glavic, Alexandra Meliou and Sudeepa Roy (2021), \u201cTrends in Explanations\u201d, Foundations and Trends\u00ae in Databases: Vol. xx, No. xx, pp 1\u201318. DOI: 10.1561/XXXXXXXXX.", "venue": "", "year": 2021, "fieldsOfStudy": null, "publicationTypes": ["Review"], "publicationDate": null, "journal": null, "authors": [{"authorId": "1798930", "name": "Boris Glavic"}, {"authorId": "2283085", "name": "A. Meliou"}], "citations": []}

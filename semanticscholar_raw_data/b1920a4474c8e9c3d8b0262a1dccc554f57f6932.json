{"paperId": "b1920a4474c8e9c3d8b0262a1dccc554f57f6932", "publicationVenue": null, "title": "This Thing Called Fairness", "abstract": "The explosion in the use of software in important sociotechnical systems has renewed focus on the study of the way technical constructs reflect policies, norms, and human values. This effort requires the engagement of scholars and practitioners from many disciplines. And yet, these disciplines often conceptualize the operative values very differently while referring to them using the same vocabulary. The resulting conflation of ideas confuses discussions about values in technology at disciplinary boundaries. In the service of improving this situation, this paper examines the value of shared vocabularies, analytics, and other tools that facilitate conversations about values in light of these disciplinary specific conceptualizations, the role such tools play in furthering research and practice, outlines different conceptions of \"fairness\" deployed in discussions about computer systems, and provides an analytic tool for interdisciplinary discussions and collaborations around the concept of fairness. We use a case study of risk assessments in criminal justice applications to both motivate our effort--describing how conflation of different concepts under the banner of \"fairness\" led to unproductive confusion--and illustrate the value of the fairness analytic by demonstrating how the rigorous analysis it enables can assist in identifying key areas of theoretical, political, and practical misunderstanding or disagreement, and where desired support alignment or collaboration in the absence of consensus.", "venue": "Proc. ACM Hum. Comput. Interact.", "year": 2019, "fieldsOfStudy": ["Computer Science", "Sociology"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-09-26", "journal": {"name": "Proceedings of the ACM on Human-Computer Interaction", "pages": "1 - 36", "volume": "3"}, "authors": [{"authorId": "34421129", "name": "D. Mulligan"}, {"authorId": "145973578", "name": "Joshua A. Kroll"}, {"authorId": "51114342", "name": "Nitin Kohli"}, {"authorId": "9063054", "name": "Richmond Y. Wong"}], "citations": [{"paperId": "4bcee00956e03c066291a50415f19194b77b6c01", "title": "Preserving data privacy in machine learning systems"}, {"paperId": "b37f9d86a78d1998240897c4fe9c75ed62d1074b", "title": "A Critical Survey on Fairness Benefits of XAI"}, {"paperId": "02dcada452b0b2c159f922d5dc7bf5d49a4a6ec8", "title": "Purposeful AI"}, {"paperId": "0f45313929a6e0a313ee02b540cada6f7fa1c7ab", "title": "On Prediction-Modelers and Decision-Makers: Why Fairness Requires More Than a Fair Prediction Model"}, {"paperId": "d9b650fea9371686113f678799296401a1dcf1dc", "title": "\u201c\u2611 Fairness Toolkits, A Checkbox Culture?\u201d On the Factors that Fragment Developer Practices in Handling Algorithmic Harms"}, {"paperId": "12b1f49ba04077cd6cc1d5489a69298a1272b932", "title": "More or less discrimination? Practical feasibility of fairness auditing of technologies for personnel selection"}, {"paperId": "64fdc9af57060d2113548f3c1283626ac71e4c5f", "title": "Broadening Privacy and Surveillance: Eliciting Interconnected Values with a Scenarios Workbook on Smart Home Cameras"}, {"paperId": "8bc1daf446c49556d073ecd4c614bd81a5d30fff", "title": "Dirty data labeled dirt cheap: epistemic injustice in machine learning systems"}, {"paperId": "f6194a242b2184b8896481d4cd6f1e81db4f7286", "title": "Help or Hinder? Evaluating the Impact of Fairness Metrics and Algorithms in Visualizations for Consensus Ranking"}, {"paperId": "dcac6cbdc93c52dc9f864ce1e9dc930de860fe66", "title": "Research Challenges in Trustworthy Artificial Intelligence and Computing for Health: The Case of the PRE-ACT project"}, {"paperId": "5d6fa977dc44590c778f942013845ef52dac04b1", "title": "The Indian approach to Artificial Intelligence: an analysis of policy discussions, constitutional values, and regulation"}, {"paperId": "3ce9224deaf5d3a2b1a6cbb5f6730a8b46441baf", "title": "A Psychometric Framework for Evaluating Fairness in Algorithmic Decision Making: Differential Algorithmic Functioning"}, {"paperId": "9e406bacce870f13de4a2d0a7412bdd8c2d12ec6", "title": "Integrative Objects in Sociotechnical Contexts: Constructing Digital Well-Being with Generic Epistemology"}, {"paperId": "278606840f22deada8cdbdd842493e98b6a5ced8", "title": "Faulty or Ready? Handling Failures in Deep-Learning Computer Vision Models until Deployment: A Study of Practices, Challenges, and Needs"}, {"paperId": "ac1e0e124fbc42db4ec0f5f388d372900928c42a", "title": "Regulatory Markets: The Future of AI Governance"}, {"paperId": "13aeb868a6cad9a2478c27ef5b5183bff8ff839b", "title": "Uncovering Bias in Personal Informatics"}, {"paperId": "0d57c580c2e7b410348e4f8712abfc7d38ad274f", "title": "Examining Cashless Payment Services in a Post-Pandemic Environment"}, {"paperId": "3eb82662684b6d9bed32bdf77e89dfef9e53f692", "title": "The Equitable AI Research Roundtable (EARR): Towards Community-Based Decision Making in Responsible AI Development"}, {"paperId": "65702ea3a1da72caeaae8ff6535cbeefd944bb0a", "title": "Pitfalls and Tensions in Digitalizing Talent Acquisition: An Analysis of HRM Professionals' Considerations Related to Digital Ethics"}, {"paperId": "9ae71b326bf1961d558ab0042da0156e6821ab56", "title": "A seven-layer model with checklists for standardising fairness assessment throughout the AI lifecycle"}, {"paperId": "c2ad7f32927392f22addc227d97a777e3ad57f6f", "title": "A Systematic Literature Review of Explainable AI for Software Engineering"}, {"paperId": "2c5e7471c33b5092a3c23ef4fa159a3a53474f95", "title": "Concrete Safety for ML Problems: System Safety for ML Development and Assessment"}, {"paperId": "3200e16772cd05c63f08027adf842b24a4f1f64d", "title": "Out of Context: Investigating the Bias and Fairness Concerns of \u201cArtificial Intelligence as a Service\u201d"}, {"paperId": "f04d1206123386f0e62d4355cc39d0d2b341daff", "title": "A Call to Action on Assessing and Mitigating Bias in Artificial Intelligence Applications for Mental Health"}, {"paperId": "755f1b677cf76e3332028ed73af91e797b945740", "title": "Normative Challenges of Risk Regulation of Artificial Intelligence and Automated Decision-Making"}, {"paperId": "f2497f80808fceead01a7a04077fca3b65c900e5", "title": "System Safety Engineering for Social and Ethical ML Risks: A Case Study"}, {"paperId": "e59c7cba844ee412661fa1334db2c9ab980b0d59", "title": "AI for hiring in context: a perspective on overcoming the unique challenges of employment research to mitigate disparate impact"}, {"paperId": "c5678a779e03f125faf8bec9d3a99a18bb18d953", "title": "FairSNA: Algorithmic Fairness in Social Network Analysis"}, {"paperId": "9757f1182971a91038f316c47043b738d051f0e8", "title": "Detecting shortcut learning for fair medical AI using shortcut testing"}, {"paperId": "f374d46a50f01c8e589d8d29dd8bd6f72a85688e", "title": "The Multisided Complexity of Fairness in Recommender Systems"}, {"paperId": "bb5c2e2cb4abd175dc43e5606ded5c5dbdb840eb", "title": "Fairness in recommender systems: research landscape and future directions"}, {"paperId": "594e9d5c39ed84371bd240ccc9e7775803a6bded", "title": "Exploring How Machine Learning Practitioners (Try To) Use Fairness Toolkits"}, {"paperId": "36d734ecaa3e4dea5e482dda796fbe42d4f38d71", "title": "\u201cThere Is Not Enough Information\u201d: On the Effects of Explanations on Perceptions of Informational Fairness and Trustworthiness in Automated Decision-Making"}, {"paperId": "1c9eb8496756df1c397022300420c7f4fb90b3b8", "title": "A Human-Centric Perspective on Fairness and Transparency in Algorithmic Decision-Making"}, {"paperId": "4aad069a072c5a11ae2c5ba69ab5086f5f206ba6", "title": "Disability, fairness, and algorithmic bias in AI recruitment"}, {"paperId": "830ed45abde65ee1994c94c3f85d614eb826d596", "title": "A study of bias mitigation strategies for speaker recognition"}, {"paperId": "70286a248345b1005814daec33b78bad7ec4044d", "title": "Towards a Standard for Identifying and Managing Bias in Artificial Intelligence"}, {"paperId": "64c2fa6b3c161fe2a5ae20f03ff77c3250027e10", "title": "Fairness Score and process standardization: framework for fairness certification in artificial intelligence systems"}, {"paperId": "457881cb81c0408fc546ca5bc61556bdd21a6810", "title": "The Fairness Impact Assessment: Conceptualizing Problems of Fairness in Technological Design"}, {"paperId": "9fbb6b9e6e80cdd85071ec90469569f670596826", "title": "A sociotechnical view of algorithmic fairness"}, {"paperId": "48709b65320bf979d19c1874aebf6bf8bd85de88", "title": "Just What do You Think You're Doing, Dave?' A Checklist for Responsible Data Use in NLP"}, {"paperId": "8afe359953194a5daea47ce9dc44ba51031592db", "title": "Measurement as governance in and for responsible AI"}, {"paperId": "4069a5930a5bdcedda85b9e2832980d58497e4b8", "title": "Good Proctor or \u201cBig Brother\u201d? Ethics of Online Exam Supervision Technologies"}, {"paperId": "287cbaf61780b133ab7a2245c9c99e7e57a31c7c", "title": "Appropriate Fairness Perceptions? On the Effectiveness of Explanations in Enabling People to Assess the Fairness of Automated Decision Systems"}, {"paperId": "081257cb37997cae6cc4b2858ec7aed67d682a11", "title": "Algorithmic bias: review, synthesis, and future research directions"}, {"paperId": "376f8a51cd961c845e50f1cf54e00e843dd2387c", "title": "A clarification of the nuances in the fairness metrics landscape"}, {"paperId": "5cd03c68c46e1f5f518a5a5455de7ef8f6fa068b", "title": "Using the Crowd to Prevent Harmful AI Behavior"}, {"paperId": "b0434df9b6ed85aa79859335905f549eeac3e817", "title": "Constitutional Rights in the Machine Learning State"}, {"paperId": "3cc2f69951cd24fe61be4cf32d62afbac297bc2b", "title": "Social Biases in NLP Models as Barriers for Persons with Disabilities"}, {"paperId": "681f4fbce872f138cbac9cdd92e8f6ed89ba6f8d", "title": "Measurement and Fairness"}, {"paperId": "aac29b1b8627f56a258c52e95092a3fdd863b137", "title": "ORES"}, {"paperId": "c28b38a584c82f5ee41cf90b3a6e0af1ca55a079", "title": "Egaleco: Advancing Fairness in Machine Learning Final Submission"}, {"paperId": null, "title": "Abigail Z. Jacobs Assistant Professor of InformationAssistant Professor of Complex SystemsUniversity of Michiganazjacobs@umich.edu \u2013"}, {"paperId": "7b68a315348e811b8e600ed3bab86f0b930e9bc3", "title": "What AI Practitioners Say about Human-AI Trust: Its Role, Importance, and Factors That Affect It"}, {"paperId": "00204248038e6fc7d0b9e9d51ebeb29626d4a9fa", "title": "Modes of Uncertainty in HCI"}, {"paperId": "13ab3f2ecb687d73acf7f7cd2addcdabe7245227", "title": "Risikoregulierung der KI: normative Herausforderungen und politische Entscheidungen. Stellungnahme zum Wei\u00dfbuch der Europ\u00e4ischen Kommission \u201eZur K\u00fcnstlichen Intelligenz \u2012 ein europ\u00e4isches Konzept f\u00fcr Exzellenz und Vertrauen\u201c"}, {"paperId": "55c9b62b69b7f644e326969f8f712e6487cd4b9d", "title": "Constitutional Rights in the Machine Learning State"}, {"paperId": "3f191b2e4916a0255331bfe123ce64de2d178710", "title": "Making Algorithms Public: Reimagining Auditing from Matters of Fact to Matters of Concern"}]}

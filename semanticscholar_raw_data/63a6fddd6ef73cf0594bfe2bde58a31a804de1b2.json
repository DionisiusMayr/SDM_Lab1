{"paperId": "63a6fddd6ef73cf0594bfe2bde58a31a804de1b2", "publicationVenue": {"id": "29df4b17-9a16-4a4c-94a6-002f52e628b4", "name": "International Conference on Parallel Processing", "type": "conference", "alternate_names": ["ICPP", "Int Conf Parallel Process", "IEEE Int Conf Pulsed Power", "IEEE International Conference on Pulsed Power"], "url": "http://www.wikicfp.com/cfp/program?id=1447"}, "title": "Ascetic: Enhancing Cross-Iterations Data Efficiency in Out-of-Memory Graph Processing on GPUs", "abstract": "Graph analytics are widely used in real-world applications, and GPUs are major accelerators for such applications. However, as graph sizes become significantly larger than the capacity of GPU memory, the performance can degrade significantly due to the heavy overhead required in moving a large amount of graph data between CPU main memory and GPU memory. Some existing approaches have tried to exploit data locality and addressed the issues of memory oversubscription on GPUs. However, these approaches have yet to take advantage of the data reuse cross iterations because of the data sizes in most large-graph analytics. In our studies, we have found that in most graph applications the graph traversals exhibit a roughly sequential scan over the graph data with an extremely large memory footprint. Based on the observation, we propose a novel framework, called Ascetic, to exploit temporal locality with very long reuse distances. In Ascetic, the GPU memory is divided into a Static Region and an On-demand Region. The static region can exploit data reuse across iterations. The on-demand region is designed to load the data requested in the iteration of the graph traversal while not found in the static region. We have implemented a prototype of the Ascetic framework and conducted a series of experiments on performance evaluation. The experimental results show that Ascetic can significantly reduce the data transfer overhead, and allow more overlapped execution between GPU and CPU, which leads to an average of 2.0x speedup over a state-of-the-art approach.", "venue": "International Conference on Parallel Processing", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2021-08-09", "journal": {"name": "Proceedings of the 50th International Conference on Parallel Processing"}, "authors": [{"authorId": "47043873", "name": "Ruiqi Tang"}, {"authorId": "1596793975", "name": "Ziyi Zhao"}, {"authorId": "47373047", "name": "Kailun Wang"}, {"authorId": "39827582", "name": "Xiaoli Gong"}, {"authorId": "2117169560", "name": "Jin Zhang"}, {"authorId": "1597346687", "name": "Wenwen Wang"}, {"authorId": "1699961", "name": "P. Yew"}], "citations": [{"paperId": "daac6116da574ae21551a9f0037972067257b5b2", "title": "GRIT: Enhancing Multi-GPU Performance with Fine-Grained Dynamic Page Placement"}, {"paperId": "ae1d0f32e24bafed0539b9b7152949db50ea1460", "title": "OneGraph: a cross-architecture framework for large-scale graph computing on GPUs based on oneAPI"}, {"paperId": "be2f8368f414c4806b37bcf2d2283391d3680ca3", "title": "Liberator: A Data Reuse Framework for Out-of-Memory Graph Computing on GPUs"}, {"paperId": "d9f1ae12e9a9d5b8eec465b4127285bae265112b", "title": "GraphTune: An Efficient Dependency-Aware Substrate to Alleviate Irregularity in Concurrent Graph Processing"}, {"paperId": "35cb6c17693ddec0d3ceaa598f3cd451637f08ea", "title": "iQAN: Fast and Accurate Vector Search with Efficient Intra-Query Parallelism on Multi-Core Architectures"}, {"paperId": "9ca0f04c432d19de7db252e47a3b63d48944d9c3", "title": "UVM Discard: Eliminating Redundant Memory Transfers for Accelerators"}, {"paperId": "3b9e59e91d99a49122124b25d58e8a1a887e448b", "title": "HyTGraph: GPU-Accelerated Graph Processing with Hybrid Transfer Management"}]}

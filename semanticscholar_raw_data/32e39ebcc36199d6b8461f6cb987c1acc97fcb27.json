{"paperId": "32e39ebcc36199d6b8461f6cb987c1acc97fcb27", "publicationVenue": {"id": "b0dc264e-1ef6-4c58-be54-d2e6137ac35f", "name": "Natural Language Engineering", "type": "journal", "alternate_names": ["Nat Lang Eng"], "issn": "1351-3249", "url": "https://www.cambridge.org/core/journals/natural-language-engineering", "alternate_urls": ["http://journals.cambridge.org/action/displayJournal?jid=NLE"]}, "title": "A study towards contextual understanding of toxicity in online conversations", "abstract": "Abstract Identifying and annotating toxic online content on social media platforms is an extremely challenging problem. Work that studies toxicity in online content has predominantly focused on comments as independent entities. However, comments on social media are inherently conversational, and therefore, understanding and judging the comments fundamentally requires access to the context in which they are made. We introduce a study and resulting annotated dataset where we devise a number of controlled experiments on the importance of context and other observable confounders \u2013 namely gender, age and political orientation \u2013 towards the perception of toxicity in online content. Our analysis clearly shows the significance of context and the effect of observable confounders on annotations. Namely, we observe that the ratio of toxic to non-toxic judgements can be very different for each control group, and a higher proportion of samples are judged toxic in the presence of contextual information.", "venue": "Natural Language Engineering", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-08-30", "journal": {"name": "Natural Language Engineering", "pages": "1538 - 1560", "volume": "29"}, "authors": [{"authorId": "3238408", "name": "P. Madhyastha"}, {"authorId": "35739523", "name": "Antigoni-Maria Founta"}, {"authorId": "1702974", "name": "Lucia Specia"}], "citations": []}

{"paperId": "84094e166ccfddff8cb522faa0eb736d1d12369a", "publicationVenue": {"id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd", "name": "Neural Information Processing Systems", "type": "conference", "alternate_names": ["Neural Inf Process Syst", "NeurIPS", "NIPS"], "url": "http://neurips.cc/"}, "title": "Park: An Open Platform for Learning-Augmented Computer Systems", "abstract": "We present Park, a platform for researchers to experiment with Reinforcement Learning (RL) for computer systems. Using RL for improving the performance of systems has a lot of potential, but is also in many ways very different from, for example, using RL for games. Thus, in this work we first discuss the unique challenges RL for systems has, and then propose Park an open extensible platform, which makes it easier for ML researchers to work on systems problems. Currently, Park consists of 12 real world system-centric optimization problems with one common easy to use interface. Finally, we present the performance of existing RL approaches over those 12 problems and outline potential areas of future work.", "venue": "Neural Information Processing Systems", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2019-05-01", "journal": {"pages": "2490-2502"}, "authors": [{"authorId": "2512621", "name": "Hongzi Mao"}, {"authorId": "50816104", "name": "Parimarjan Negi"}, {"authorId": "2124328793", "name": "Akshay Narayan"}, {"authorId": "1477757714", "name": "Hanrui Wang"}, {"authorId": "2141054362", "name": "Jiacheng Yang"}, {"authorId": "2282443186", "name": "Haonan Wang"}, {"authorId": "40412858", "name": "Ryan Marcus"}, {"authorId": "104000494", "name": "Ravichandra Addanki"}, {"authorId": "1910363", "name": "Mehrdad Khani Shirkoohi"}, {"authorId": "3143190", "name": "Songtao He"}, {"authorId": "2335477", "name": "Vikram Nathan"}, {"authorId": "3155173", "name": "Frank Cangialosi"}, {"authorId": "2043402", "name": "S. Venkatakrishnan"}, {"authorId": "2088565", "name": "W. Weng"}, {"authorId": "2115659086", "name": "Song Han"}, {"authorId": "1746961", "name": "Tim Kraska"}, {"authorId": "79404966", "name": "Mohammad Alizadeh"}], "citations": [{"paperId": "ca0cc10b9a017576505c802470b86a5147fcc33d", "title": "Quality of Experience in Video Streaming: Status Quo, Pitfalls, and Guidelines"}, {"paperId": "e96c489ef238804d6d24e3afd5810e344f88cd78", "title": "Empowerment of Atypical Viewers via Low-Effort Personalized Modeling of Video Streaming Quality"}, {"paperId": "846aa907d254abadb32ef4b01347f1b62584a257", "title": "Research on technical architecture and service models of the internet open platform"}, {"paperId": "adfbc0db2cbc042261193fab9cb8ba89d15a86e4", "title": "Improving Mobile Interactive Video QoE via Two-Level Online Cooperative Learning"}, {"paperId": "46f9827e81e0d46d68f4a7d16cc62091ed1b2406", "title": "Lifting the Fog of Uncertainties: Dynamic Resource Orchestration for the Containerized Cloud"}, {"paperId": "8c84b6719b2d3467fcb7852bd13fae06b51585f3", "title": "Smart-Kube: Energy-Aware and Fair Kubernetes Job Scheduler Using Deep Reinforcement Learning"}, {"paperId": "b2395962fd9eb2f175e7e03675220f23c865dbff", "title": "Optimizing Adaptive Video Streaming with Human Feedback"}, {"paperId": "bed5ac98a8e189f38823b21651c759d7d569e86e", "title": "JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning"}, {"paperId": "86633a906653c2d0f6a4a8104aa9e0bd2869b9a5", "title": "Making Data Clouds Smarter at Keebo: Automated Warehouse Optimization using Data Learning"}, {"paperId": "65eca63de01a9e43fec47ea70f67f312acf61eb0", "title": "Auto-WLM: Machine Learning Enhanced Workload Management in Amazon Redshift"}, {"paperId": "feee9012f3a78cf6a563ad7787347ae0667d4d26", "title": "Meta Reinforcement Learning for Rate Adaptation"}, {"paperId": "718bab32df981b6e89f8ad5ea3f2ec4689745e82", "title": "Buffer Awareness Neural Adaptive Video Streaming for Avoiding Extra Buffer Consumption"}, {"paperId": "da9c3f069f06ca6aa31667ab0c3857d6c9556faf", "title": "CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems"}, {"paperId": "bdc49f4e619f9bc43b614ce6aedd73a105fec3dd", "title": "MARLIN: Soft Actor-Critic based Reinforcement Learning for Congestion Control in Real Networks"}, {"paperId": "1e9a22488bd872b9f1ee71216e2d6848c266e15d", "title": "DRAS: Deep Reinforcement Learning for Cluster Scheduling in High Performance Computing"}, {"paperId": "d6e51a368b93225ff33d35859fb172fe670846dc", "title": "Understanding Microquanta Process Scheduling for Cloud Applications"}, {"paperId": "83d5a9faeb733b876506cb741781faea77380357", "title": "Mobile-Kube: Mobility-aware and Energy-efficient Service Orchestration on Kubernetes Edge Servers"}, {"paperId": "249e261452dd5418c5212ffc0a50d1e153c77791", "title": "SIMPPO: a scalable and incremental online learning framework for serverless resource management"}, {"paperId": "5ee82305af1eb1b61aa66e2b7f32baf4db224a75", "title": "ADSTS: Automatic Distributed Storage Tuning System Using Deep Reinforcement Learning"}, {"paperId": "8cafcdc8ecdd66701901027934f7a2ce6749fee1", "title": "Learning Tailored Adaptive Bitrate Algorithms to Heterogeneous Network Conditions: A Domain-Specific Priors and Meta-Reinforcement Learning Approach"}, {"paperId": "7711774cf9f1d8683daf853b9e5773158b064980", "title": "Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications"}, {"paperId": "6d0adac188152fbaa45a88ba4da788926ed8144a", "title": "Reinforcement Learning in Practice: Opportunities and Challenges"}, {"paperId": "c0cf8f1e5f7ed44c80d7ab3cf50ae385a5460fad", "title": "Genet: automatic curriculum generation for learning adaptation in networking"}, {"paperId": "63a80f8e140ca6cd1073c213436a790c6af9e78e", "title": "ORSuite"}, {"paperId": "269e9f62b956bbd384af4919ce275e2944a1d935", "title": "Demystifying Reinforcement Learning in Time-Varying Systems"}, {"paperId": "ad3b663251d674292b43de84b6c7db5f8f0e0bea", "title": "Interpretable Feedback for AutoML and a Proposal for Domain-customized AutoML for Networking"}, {"paperId": "5d697bca4990a6c0fc082fc1816b87912433002b", "title": "Syrup: User-Defined Scheduling Across the Stack"}, {"paperId": "fe151922c4a3e6dd5489bbcb0d021fe06f16c25a", "title": "VCMaker: Content-aware configuration adaptation for video streaming and analysis in live augmented reality"}, {"paperId": "b9804fed72a26751e2103007004944c01e6bc0e8", "title": "A Survey on Deep Reinforcement Learning for Data Processing and Analytics"}, {"paperId": "146677fe1d79b320ab7e43b2d29c040699762406", "title": "Verifying learning-augmented systems"}, {"paperId": "6a08407ad81a730453b0fd6a5c5e8bfeb6e9c53a", "title": "QuantumNAS: Noise-Adaptive Search for Robust Quantum Circuits"}, {"paperId": "276fe87021c3deebd0ff916c7a063a6e873c0724", "title": "FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning"}, {"paperId": "a68555a8d702ad5add8ffacb8b5d654df5c2f30c", "title": "Towards instance-optimized data systems"}, {"paperId": "8f5562ead9861744a1192c1bef69283e25200aa8", "title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement"}, {"paperId": "f98a5fe66fc1ca404b982f149715d47c88dc6674", "title": "A Scalable and Reproducible System-on-Chip Simulation for Reinforcement Learning"}, {"paperId": "7c0ddae1d9f1a9a249480d5cddd67fe50fda80c6", "title": "Fast Design Space Exploration of Nonlinear Systems: Part II"}, {"paperId": "52f4f5146a8c0e27250f88a4def1b0bec9c9d28d", "title": "Cuttlefish: Neural Configuration Adaptation for Video Analysis in Live Augmented Reality"}, {"paperId": "335f33b9fbbfd0a7da6eb36af4942829d1104ffb", "title": "Toward Robust Long Range Policy Transfer"}, {"paperId": "fd15384646a386521ee4824c35011bc17e6fa987", "title": "Queue-Learning: A Reinforcement Learning Approach for Providing Quality of Service"}, {"paperId": "73e0f38ab49b19b86321016b773e15f1d02e3a72", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"}, {"paperId": "5d80be9f6e2fe677c129e3ed52ea019057cb2ff6", "title": "Towards a common environment for learning scheduling algorithms"}, {"paperId": "82336295513221f4ceeca5246d664f28cfda4321", "title": "Metis: Learning to Schedule Long-Running Applications in Shared Container Clusters at Scale"}, {"paperId": "a00ca839999a6a461b0f63a88c2d702afb8ed101", "title": "REINDEAR : REINforcement learning agent for Dynamic system control in Edge-Assisted Augmented Reality service"}, {"paperId": "16e83f3f0f78ceb203746eeb88f1f5aae9ba3092", "title": "Deep reinforcement learning: a survey"}, {"paperId": "67bff7420011b2b08b450e806cfe2f768d9974af", "title": "Consolidation of Services in Mobile Edge Clouds using a Learning-based Framework"}, {"paperId": "a9a1b2818dbb46a05d570b6f43a9ae99176a81ea", "title": "World-Models for Bitrate Streaming"}, {"paperId": "22676b1e6d9662215ef9833321a3a37decfe0aca", "title": "DISPATCH: Design Space Exploration of Cyber-Physical Systems"}, {"paperId": "7f6179569a9f143be0c6c2917da04085c8b94e53", "title": "OnRL: improving mobile video telephony via online reinforcement learning"}, {"paperId": "061e4339df833cba739abf8c743199af24256451", "title": "Reinforcement Learning-based Admission Control in Delay-sensitive Service Systems"}, {"paperId": "662e891fba7e8f4349c0c7f2c3cf2ba7417c4b3a", "title": "Reinforcement Learning Based Congestion Control in a Real Environment"}, {"paperId": "8af583b22b2a27c3aac36ac0a6ae26eda21e5281", "title": "Stick: A Harmonious Fusion of Buffer-based and Learning-based Approach for Adaptive Streaming"}, {"paperId": "1c55f470a8273788d82f05500d507b408a5722b8", "title": "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization"}, {"paperId": "9bb5665fe48e7122beda73a53316de9f7f243b19", "title": "APQ: Joint Search for Network Architecture, Pruning and Quantization Policy"}, {"paperId": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"}, {"paperId": "780270a7940c96b0c907103ff8e77dfe082f564f", "title": "GCN-RL Circuit Designer: Transferable Transistor Sizing with Graph Neural Networks and Reinforcement Learning"}, {"paperId": "15f5ec8565de63353d13bdde3aad9541927fc38e", "title": "Towards A Domain-Customized Automated Machine Learning Framework For Networks and Systems"}, {"paperId": "951f876a742dfc28eed01badf8d98318376b72b7", "title": "Bao: Making Learned Query Optimization Practical"}, {"paperId": "70acb0ee229593fffe73885f3004f24df38f74ec", "title": "A Survey of Deep Learning for Scientific Discovery"}, {"paperId": "7af3992959ff24e369da7c514c041062f5249b1e", "title": "SpArch: Efficient Architecture for Sparse Matrix Multiplication"}, {"paperId": "4dc5637dfedc4fa286b4d9f88c4b9f8d38924479", "title": "Interpreting Deep Learning-Based Networking Systems"}, {"paperId": "1a0d93034215411c8227dedaf5fa18d5929b448c", "title": "MVFST-RL: An Asynchronous RL Framework for Congestion Control with Delayed Actions"}, {"paperId": "fb387c0576f355b37bc2739dc183cf7b37b2a52c", "title": "Explaining Deep Learning-Based Networked Systems"}, {"paperId": "a9ae2bf20151247910fe8fc77cd4db8f35bfead0", "title": "Wield: Systematic Reinforcement Learning With Progressive Randomization"}, {"paperId": "5edf64460a51e05044552369059190e898c93bd4", "title": "Deep Reinforcement Learning in System Optimization"}, {"paperId": "bb70d027935033808f1a5504ec120fb4da833338", "title": "A View on Deep Reinforcement Learning in System Optimization"}, {"paperId": "9f92903af4c2340e4c13ecf88f22d89259af2fac", "title": "CrystalBox: Future-Based Explanations for DRL Network Controllers"}, {"paperId": "fbd2ec1505de35ccceca9bf29c2746733cb09278", "title": "Database Gyms"}, {"paperId": "1f99aea6082b0fdaca67e906d0a85a49220013f5", "title": "Reinforcement Learning in Time-Varying Systems: an Empirical Study"}, {"paperId": "8c8868d75f5fc7a055fdbc8610ab20b0a4304829", "title": "Deep Reinforcement Learning: Opportunities and Challenges"}, {"paperId": "82a211b414d73a36fb399dbc8bae43ec6316af8d", "title": "A Progress Report on DBOS: A Database-oriented Operating System"}, {"paperId": "11e1f23af5e50a2d2b80ec4aaf8470be0d6415e9", "title": "Performance Profiles of Basic, Memory-Based and Hybrid Deep Reinforcement Learning agents with B-Suite"}, {"paperId": "d127beebf9ba7181c0133cfd417c3dbbd8876365", "title": "This paper is included in the Proceedings of the 2022 USENIX Annual Technical Conference."}, {"paperId": "054146c30ca12c7d4e322d154e1b24f22e4c0c25", "title": "HAT: Hierarchical Alternative Training for Long Range Policy Transfer"}, {"paperId": "b655629cf5d61d129c1c5619001d47469f5e264f", "title": "High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization"}, {"paperId": "9819213d5667c9f30cc74bc4e10950ea37f62e50", "title": "F ACTORED RL: L EVERAGING F ACTORED G RAPHS FOR D EEP R EINFORCEMENT L EARNING"}, {"paperId": "84955f5f3dee8ef07517b223000706a428553569", "title": "Production-Ready Learning-Augmented Data Management with Deep Reinforcement Learning ?"}, {"paperId": "38b9021b1d2d559b3d109c2b388086604951b742", "title": "Learning Caching Policies with Subsampling"}, {"paperId": "66f775e8f45ffe39219017a301e1910941851fe6", "title": "Learning automatic schedulers with projective reparameterization"}, {"paperId": "15be954fe1d8b591be64ff7c0fc7eaa2ace0e32a", "title": "A Comparative Evaluation of Deep Reinforcement Learning Frameworks"}, {"paperId": "6fd61a8dd308fab62f7e5efb0dcde074d7ddfb93", "title": "Characterizing Neural Network Veri\ufb01cation for Systems with NN4S YS B ENCH"}]}

{"paperId": "b6a99a08fecfd9eed08d000a467c21d07a21367c", "publicationVenue": {"id": "2633f5b2-c15c-49fe-80f5-07523e770c26", "name": "IEEE Access", "type": "journal", "issn": "2169-3536", "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=6287639"]}, "title": "Delay Constrained Hybrid Task Offloading of Internet of Vehicle: A Deep Reinforcement Learning Method", "abstract": "The rapid development of the Internet of Things (IoTs) has driven the progress of intelligent transportation systems (ITS), which provides basic elements, such as vehicles, traffic lights, cameras, roadside units (RSUs) and their interconnected 5G communications, to constitute the Internet of vehicles (IoVs). In the IoVs, an intelligent vehicle can not only share information with the infrastructures like RSUs by vehicle to infrastructure (V2I) communication but also with vehicles on the road through vehicle-to-vehicle (V2V) communications. We thus expect that vehicles can collaborate with other well-resourced and idling vehicles, making full use of the wasted resources. However, existing approaches cannot achieve this goal due to the increasing strict delay constraints and the dynamic characteristics of the IoVs tasks. To improve the utilization of resources and perform better resource management, in this paper, we propose a hybrid task offloading scheme (HyTOS) based on deep reinforcement learning (DRL), which achieves the vehicle-to-edge (V2E) and V2V offloading by jointly considers the delay constraints and resource demand. To perform optimal offloading decision-making, we introduce a dynamic decision-making method, namely deep Q networks (DQN). To verify the effectiveness of this approach, we choose three baseline offloading approaches (one game theory-based and two single-scenario approaches) and perform a series of simulation experiments. The simulation results demonstrate that, compared to the baseline offloading approaches, our approach can effectively reduce task delay and energy consumption, achieving high-efficiency resource management.", "venue": "IEEE Access", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal": {"name": "IEEE Access", "pages": "102778-102788", "volume": "10"}, "authors": [{"authorId": "13436403", "name": "Chenhao Wu"}, {"authorId": "2109670798", "name": "Zhongwei Huang"}, {"authorId": "2113959135", "name": "Yuntao Zou"}], "citations": [{"paperId": "8ae768589f5bc24b68ed20ae1d663d5c4e951c11", "title": "Efficient vehicular networks offloading using Hybrid Localization Algorithm and Deep Reinforcement Learning"}, {"paperId": "b7b225d85ec06e617b23aeb59f20c85baabcd967", "title": "Graph-Powered Reinforcement Learning for Intelligent Task Offloading in Vehicular Networks"}, {"paperId": "1f2a6836b50cd8f2f44a3903ddf17432f5277db3", "title": "DRL-Based Hybrid Task Offloading and Resource Allocation in Vehicular Networks"}, {"paperId": "be85c292762cb85336b85ffb8f70fb4a015cc409", "title": "Wireless Network Resource Optimization in the Internet of Vehicles"}, {"paperId": "7d9d495aef61039d3d908195bb1d3f6eda2cdb16", "title": "Computation Offloading Method Using Stochastic Games for Software-Defined-Network-Based Multiagent Mobile Edge Computing"}, {"paperId": "bb6ecda4927f79191c5e234b83f3856ce61a07bf", "title": "Weighted Feature detection Mechanism for Internet of Vehicles over Heterogeneous Vehicular Network"}, {"paperId": "4444e34de7fde11c048c9165ed6f5b0b20358d2d", "title": "DRL-Based Hybrid Task Of\ufb02oading and Resource Allocation in Vehicular Networks"}]}

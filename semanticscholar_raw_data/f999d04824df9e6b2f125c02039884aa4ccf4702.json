{"paperId": "f999d04824df9e6b2f125c02039884aa4ccf4702", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs", "abstract": "This paper introduces FedMLSecurity , a benchmark that simulates adversarial attacks and corresponding defense mechanisms in Federated Learning (FL). As an integral module of the open-sourced library FedML [22] that facilitates FL algo-rithm development and performance comparison, FedMLSecurity enhances the security assessment capacity of FedML. FedMLSecurity comprises two principal components: FedMLAttacker , which simulates attacks injected into FL training, and FedMLDefender , which emulates defensive strategies designed to mitigate the impacts of the attacks. FedMLSecurity is open-sourced 1 and is customizable to a wide range of machine learning models ( e . g ., Logistic Regression, ResNet [23], GAN [19], etc.) and federated optimizers ( e . g ., FedAVG [32], FedOPT [37], FedNOVA [46], etc.). Experimental evaluations in this paper also demonstrate the ease of application of FedMLSecurity to Large Language Models (LLMs), further reinforcing its versatility and practical utility in various scenarios.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal": {"name": "ArXiv", "volume": "abs/2306.04959"}, "authors": [{"authorId": "2159214992", "name": "Shanshan Han"}, {"authorId": "51884695", "name": "Baturalp Buyukates"}, {"authorId": "2111189645", "name": "Zijian Hu"}, {"authorId": "2219774222", "name": "Han Jin"}, {"authorId": "97242910", "name": "Weizhao Jin"}, {"authorId": "49755259", "name": "Lichao Sun"}, {"authorId": "2216249996", "name": "Xiaoya Wang"}, {"authorId": "150961077", "name": "Chulin Xie"}, {"authorId": null, "name": "Kai Zhang"}, {"authorId": "2219708195", "name": "Qifan Zhang"}, {"authorId": "2189361403", "name": "Yuhui Zhang"}, {"authorId": "31927890", "name": "Chaoyang He"}, {"authorId": "121011351", "name": "S. Avestimehr"}], "citations": [{"paperId": "9a741f33aa4d782639e1f81a7e9c341b58b6ed2a", "title": "Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices"}, {"paperId": "e0cad7a42d7039ead9b7f88439208444c3fa1454", "title": "FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System"}, {"paperId": "be96d307631aae2f9b2ab69b6c025f9381c4ef19", "title": "Blades: A Unified Benchmark Suite for Byzantine Attacks and Defenses in Federated Learning"}]}

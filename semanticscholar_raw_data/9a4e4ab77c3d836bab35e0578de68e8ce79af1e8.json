{"paperId": "9a4e4ab77c3d836bab35e0578de68e8ce79af1e8", "publicationVenue": {"id": "bdc2e585-4e48-4e36-8af1-6d859763d405", "name": "AAAI Conference on Artificial Intelligence", "type": "conference", "alternate_names": ["National Conference on Artificial Intelligence", "National Conf Artif Intell", "AAAI Conf Artif Intell", "AAAI"], "url": "http://www.aaai.org/"}, "title": "Graph Neural Prompting with Large Language Models", "abstract": "Large language models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs (KGs) to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. Therefore, how to enhance pre-trained LLMs using grounded knowledge, e.g., retrieval-augmented generation, remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple datasets demonstrate the superiority of GNP on both commonsense and biomedical reasoning tasks across different LLM sizes and settings. Code is available at https://github.com/meettyj/GNP.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-09-27", "journal": {"pages": "19080-19088"}, "authors": [{"authorId": "2143725803", "name": "Yijun Tian"}, {"authorId": "2248096816", "name": "Huan Song"}, {"authorId": "2249432235", "name": "Zichen Wang"}, {"authorId": "2256768980", "name": "Haozhu Wang"}, {"authorId": "2248753090", "name": "Ziqing Hu"}, {"authorId": "2262512203", "name": "Fang Wang"}, {"authorId": "144539424", "name": "N. Chawla"}, {"authorId": "2248954229", "name": "Panpan Xu"}], "citations": [{"paperId": "a41d4a3b005c8ec4f821e6ee96672d930ca9596c", "title": "G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering"}, {"paperId": "7095d1647168c4cb6a75feafe2b1da50792b6282", "title": "UGMAE: A Unified Framework for Graph Masked Autoencoders"}, {"paperId": "de02ba19fb957ae30de7f09904ae3d983c3b50e7", "title": "GLaM: Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding"}, {"paperId": "d25c6e3fd588edb4eea39b09c90da0401bd16a85", "title": "TinyLLM: Learning a Small Student from Multiple Large Language Models"}, {"paperId": "d094c9e8b0231aaf61c7f89caed91cb99afb7c00", "title": "SemPool: Simple, robust, and interpretable KG pooling for enhancing language models"}, {"paperId": "eff9d7ed06f30f121d30ee13802a11f172ef66f4", "title": "Demystifying Chains, Trees, and Graphs of Thoughts"}, {"paperId": "67239d6e9c2c5f8a6d19cb35154e5aa7eaa00f51", "title": "Large Language Models on Graphs: A Comprehensive Survey"}, {"paperId": "9ad4911a7923e19df9fb36cd03de5a63cb86ba63", "title": "Graph Prompt Learning: A Comprehensive Survey and Beyond"}, {"paperId": "33e82c122f325f61e07dc7b7573e83dd3754a35b", "title": "AutoKG: Efficient Automated Knowledge Graph Generation for Language Models"}, {"paperId": "629f44f5fb78ec390ef66633dc627f1d04f3eb85", "title": "Knowledge Graph Prompting for Multi-Document Question Answering"}]}

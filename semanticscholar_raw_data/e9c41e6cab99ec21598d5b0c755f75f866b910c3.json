{"paperId": "e9c41e6cab99ec21598d5b0c755f75f866b910c3", "publicationVenue": null, "title": "Approximate query processing in a data warehouse using random sampling", "abstract": "Data analysis consumes a large volume of data on a routine basis. With the fast increase in both the volume of the data and the complexity of the analytic tasks, data processing becomes more complicated and expensive. The cost efficiency is a key factor in the design and deployment of data warehouse systems. Approximate query processing is a well-known approach to handle massive data among different methods to make big data processing more efficient, in which a small sample is used to answer the query. For many applications, a small error is justifiable for the saving of resources consumed to answer the query, as well as reducing the latency. We focus on the approximate query processing using random sampling in a data warehouse system, including algorithms to draw samples, methods to maintain sample quality, and effective usages of the sample for approximately answering different classes of queries. First, we study different methods of sampling, focusing on stratified sampling that is optimized for population aggregate query. Next as the query involves, we propose sampling algorithms for group-by aggregate queries. Finally, we introduce the sampling over the pipeline model of queries processing, where multiple queries and tables are involved in order to accomplish complicated tasks. Modern big data analyses routinely involve complex pipelines in which multiple tasks are choreographed to execute queries over their inputs and write the results into their outputs (which, in turn, may be used as inputs for other tasks) in a synchronized dance of gradual data refinement until the final insight is calculated. In a pipeline, approximate results are fed into downstream queries, unlike in a single query. Thus, we see both aggregate computations from sampled input and approximate input. We propose a sampling-based approximate pipeline processing algorithm that uses unbiased estimation and calculates the confidence interval for produced approximate results. The key insight of the algorithm calls for enriching the output of queries with additional information. This enables the algorithm to piggyback on the modular structure of the pipeline without having to perform any", "venue": "", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "3400339", "name": "Trong Duc Nguyen"}], "citations": [{"paperId": "53e7420661a6fb632a5447b933ac44c25f93c1be", "title": "Models of Distributed Systems Testing Based on Energy Consumption in Behavior"}]}

{"paperId": "b6b49a667dd268782150d2af60c73324a7d78aac", "publicationVenue": {"id": "5353d583-6f50-4967-ab34-74338b908b90", "name": "ACM/IEEE International Conference on Model Driven Engineering Languages and Systems", "type": "conference", "alternate_names": ["Model Driven Eng Lang Syst", "ACM/IEEE Int Conf Model Driven Eng Lang Syst", "Model Driven Engineering Languages and Systems", "MoDELS"], "url": "https://dl.acm.org/conference/models"}, "title": "Automated Domain Modeling with Large Language Models: A Comparative Study", "abstract": "Domain modeling is an essential part of software engineering and serves as a way to represent and understand the concepts and relationships in a problem domain. Typically, software engineers interpret the problem description written in natural language and manually translate it into a domain model. Domain modeling can be time-consuming and highly depends on the expertise of software engineers. Recently, Large Language Models (LLMs) have exhibited remarkable ability in language understanding, generation, and reasoning. In this paper, we conduct a comprehensive, comparative study of using LLMs for fully automated domain modeling. We assess two powerful LLMs, GPT3.5 and GPT4, employing various prompt engineering techniques on a data set containing ten diverse domain modeling examples with reference solutions created by modeling experts. Our findings reveal that while LLMs demonstrate impressive domain understanding capabilities, they are still impractical for full automation, with the top-performing LLM achieving F1 scores of 0.76 for class generation, 0.61 for attribute generation, and 0.34 for relationship generation. Moreover, the F1 score is characterized by higher precision and lower recall; thus, domain elements retrieved by LLMs are often reliable, but there are many missing elements. Furthermore, modeling best practices are rarely followed in auto-generated domain models. Our data set and evaluation provide a valuable baseline for future research in automated LLM-based domain modeling.", "venue": "ACM/IEEE International Conference on Model Driven Engineering Languages and Systems", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-10-01", "journal": {"name": "2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS)", "pages": "162-172"}, "authors": [{"authorId": "2274062680", "name": "Kua Chen"}, {"authorId": "2274094258", "name": "Yujing Yang"}, {"authorId": "2237865625", "name": "Boqi Chen"}, {"authorId": "2278216476", "name": "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez"}, {"authorId": "2273986771", "name": "Gunter Mussbacher"}, {"authorId": "2273976114", "name": "D\u00e1niel Varr\u00f3"}], "citations": []}

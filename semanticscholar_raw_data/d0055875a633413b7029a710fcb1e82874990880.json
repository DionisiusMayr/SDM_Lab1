{"paperId": "d0055875a633413b7029a710fcb1e82874990880", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Poisoning Attacks Against Contrastive Recommender Systems", "abstract": "Contrastive learning (CL) has recently gained significant popularity in the field of recommendation. Its ability to learn without heavy reliance on labeled data is a natural antidote to the data sparsity issue. Previous research has found that CL can not only enhance recommendation accuracy but also inadvertently exhibit remarkable robustness against noise. However, this paper identifies a vulnerability of CL-based recommender systems: Compared with their non-CL counterparts, they are even more susceptible to poisoning attacks that aim to promote target items. Our analysis points to the uniform dispersion of representations led by the CL loss as the very factor that accounts for this vulnerability. We further theoretically and empirically demonstrate that the optimization of CL loss can lead to smooth spectral values of representations. Based on these insights, we attempt to reveal the potential poisoning attacks against CL-based recommender systems. The proposed attack encompasses a dual-objective framework: One that induces a smoother spectral value distribution to amplify the CL loss's inherent dispersion effect, named dispersion promotion; and the other that directly elevates the visibility of target items, named rank promotion. We validate the destructiveness of our attack model through extensive experimentation on four datasets. By shedding light on these vulnerabilities, we aim to facilitate the development of more robust CL-based recommender systems.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-30", "journal": {"name": "ArXiv", "volume": "abs/2311.18244"}, "authors": [{"authorId": "2040449292", "name": "Zongwei Wang"}, {"authorId": "28584977", "name": "Junliang Yu"}, {"authorId": "2155431892", "name": "Min Gao"}, {"authorId": "2260297841", "name": "Hongzhi Yin"}, {"authorId": "2257282067", "name": "Bin Cui"}, {"authorId": "2268756599", "name": "Shazia Sadiq"}], "citations": [{"paperId": "e5a1d2a4622bef28ea2936efce2de78230e1d53a", "title": "Poisoning Attacks against Recommender Systems: A Survey"}]}

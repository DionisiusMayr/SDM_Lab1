{"paperId": "a8b01c9b98bcd1df5145f9595a4a7572decb22ab", "publicationVenue": {"id": "fbbafe0e-5e14-431f-9456-f569300a37cb", "name": "IEEE Open Journal of the Communications Society", "type": "journal", "alternate_names": ["IEEE Open J Commun Soc"], "issn": "2644-125X", "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8782661"}, "title": "Adaptive and Resilient Model-Distributed Inference in Edge Computing Systems", "abstract": "The traditional approach to distributed deep neural network (DNN) inference in edge computing systems is data-distributed inference. In this paradigm, each worker has a pre-trained DNN model. Using the DNN model, the worker processes the data that is offloaded to itself. The data-distributed inference approach (i) has high communication cost especially when the size of data is large, and (ii) is not efficient in terms of memory as the whole model should be stored and computed in each worker. Model-distributed inference is emerging as a promising solution, where a DNN model is distributed across workers. Although there is a huge amount of work on model-distributed training, the benefit of model distribution for inference is not understood well. In this paper, we analyze the potential of model-distributed inference in edge computing systems. Then, we develop an Adaptive and Resilient Model-Distributed Inference (AR-MDI) algorithm based on our optimal model allocation formulation. AR-MDI performs model allocation in a lightweight and decentralized way and it is resilient against delayed workers and failures. We implement AR-MDI in a real testbed consisting of NVIDIA Jetson TX2s and show that AR-MDI improves the inference time significantly as compared to baselines when the size of data is large, such as ImageNet.", "venue": "IEEE Open Journal of the Communications Society", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal": {"name": "IEEE Open Journal of the Communications Society", "pages": "1263-1273", "volume": "4"}, "authors": [{"authorId": "2144889163", "name": "Pengzhen Li"}, {"authorId": "1758251", "name": "Erdem Koyuncu"}, {"authorId": "145991708", "name": "H. Seferoglu"}], "citations": [{"paperId": "492fb417b9c29cffce225c14330cf3f5f7522db4", "title": "Measuring Data Transmissions from the Edge for Distributed Inferencing with gRPC"}, {"paperId": "a00de0e4c56918abf96dfa03e8d0929e7090a077", "title": "Characterizing Distributed Inferencing at the Edge in Resource-Constrained Environments"}, {"paperId": "178cfb0234e3d39fd6ea737c5e17838b02436a5a", "title": "Model-Distributed Inference in Multi-Source Edge Networks"}]}

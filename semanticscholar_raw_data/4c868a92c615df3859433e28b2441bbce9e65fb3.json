{"paperId": "4c868a92c615df3859433e28b2441bbce9e65fb3", "publicationVenue": {"id": "ace94611-0469-4818-ae70-43bdb8082d73", "name": "AAAI/ACM Conference on AI, Ethics, and Society", "type": "conference", "alternate_names": ["AAAI/ACM conference Artificial Intelligence, Ethics, and Society", "AIES", "AAAI/ACM Conf AI Ethics Soc", "AAAI/ACM conf Artif Intell Ethics Soc", "AIES "]}, "title": "Reward Reports for Reinforcement Learning", "abstract": "Building systems that are good for society in the face of complex societal effects requires a dynamic approach. Recent approaches to machine learning (ML) documentation have demonstrated the promise of discursive frameworks for deliberation about these complexities. However, these developments have been grounded in a static ML paradigm, leaving the role of feedback and post-deployment performance unexamined. Meanwhile, recent work in reinforcement learning has shown that the effects of feedback and optimization objectives on system behavior can be wide-ranging and unpredictable. In this paper we sketch a framework for documenting deployed and iteratively updated learning systems, which we call Reward Reports. Taking inspiration from technical concepts in reinforcement learning, we outline Reward Reports as living documents that track updates to design choices and assumptions behind what a particular automated system is optimizing for. They are intended to track dynamic phenomena arising from system deployment, rather than merely static properties of models or data. After presenting the elements of a Reward Report, we discuss a concrete example: Meta\u2019s BlenderBot 3 chatbot. Several others for game-playing (DeepMind\u2019s MuZero), content recommendation (MovieLens), and traffic control (Project Flow) are included in the appendix.", "venue": "AAAI/ACM Conference on AI, Ethics, and Society", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2022-04-22", "journal": {"name": "Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society"}, "authors": [{"authorId": "50708404", "name": "T. Gilbert"}, {"authorId": "1491339790", "name": "Sarah Dean"}, {"authorId": "2052363815", "name": "Nathan Lambert"}, {"authorId": "93800231", "name": "T. Zick"}, {"authorId": "10345590", "name": "Aaron J. Snoswell"}], "citations": [{"paperId": "e6170d1936bd0e8bcfa4382b001ef2cf137e7e66", "title": "Visibility into AI Agents"}, {"paperId": "7bf0c06ae095f9fc118b030c0eb1dc812878b979", "title": "Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability"}, {"paperId": "c085e88a0351e393609a95305afc1db792d1db0f", "title": "The History and Risks of Reinforcement Learning and Human Feedback"}, {"paperId": "c2f0f0af993c4bf6af7191b65b0d187cf95d72e9", "title": "FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines"}, {"paperId": "6eb46737bf0ef916a7f906ec6a8da82a45ffb623", "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback"}, {"paperId": "15162e1285a7681d1ea109c2a4a2cfd69e1cfb0f", "title": "Ranking with Long-Term Constraints"}, {"paperId": "494b043fce4da2ecc7f87bc96f7c29a5278cca61", "title": "Frontier AI Regulation: Managing Emerging Risks to Public Safety"}, {"paperId": "ae75b8ba5f62820a236b401f89da8030a58a4261", "title": "Accountability Infrastructure: How to implement limits on platform optimization to protect population health"}, {"paperId": "ed419cfb279c0116dd2ce8e7e7ef2dd39fd7267b", "title": "A Matrix for Selecting Responsible AI Frameworks"}, {"paperId": "c38b8b822376c09a7e38d6bb527522109edfdc77", "title": "Optimization\u2019s Neglected Normative Commitments"}, {"paperId": "d5730625a638d9a3d6ca9b52b9d169c589c669a3", "title": "Dynamic Documentation for AI Systems"}, {"paperId": "7f4dd74186b5792924f441474ce57140198df4b2", "title": "Bridging adaptive management and reinforcement learning for more robust decisions"}, {"paperId": "25d4ffc9fb1b320137ea51612ad4fdb1fdfcee19", "title": "Harms from Increasingly Agentic Algorithmic Systems"}, {"paperId": "9742b1cc377da84c3e08046a192974d7ca3877c7", "title": "Bridging Systems: Open Problems for Countering Destructive Divisiveness across Ranking, Recommenders, and Governance"}, {"paperId": "5cf0dbc77300c831def249e6995bb60ccc3e9555", "title": "A Penalty Default Approach to Preemptive Harm Disclosure and Mitigation for AI Systems"}, {"paperId": "295990165af1dfa4ed0dc338d9e4f0189fc75b75", "title": "Lessons Learned from Assessing Trustworthy AI in Practice"}, {"paperId": "871037ca207f36ffc5322d7815a2dd58951a6227", "title": "Aligning to Social Norms and Values in Interactive Narratives"}, {"paperId": "611609d35716f831f3cac0179fc17b2c5a50ee61", "title": "Large Language Models as SocioTechnical Systems"}, {"paperId": "3d5e369c65725e8fb2d783cd4987233651f38522", "title": "From Principles to Practice: An Accountability Metrics Catalogue for Managing AI Risks"}]}

{"paperId": "2fffd4da76973247b6751d246b3f23491611fb07", "publicationVenue": {"id": "312ca99c-9149-490d-813e-c60d5e949f65", "name": "Concurrency and Computation", "type": "journal", "alternate_names": ["Concurr Comput Pract Exp", "Concurrency and Computation: Practice and Experience", "Concurr Comput"], "issn": "1532-0626", "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/77004395?CRETRY=1&SRETRY=0", "alternate_urls": ["http://www3.interscience.wiley.com/cgi-bin/jtoc?ID=77004395", "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1532-0634"]}, "title": "On the effects of allocation strategies for exascale computing systems with distributed storage and unified interconnects", "abstract": "The convergence between computing\u2010 and data\u2010centric workloads and platforms is imposing new challenges on how to best use the resources of modern computing systems. In this paper, we investigate alternatives for the storage subsystem of a novel exascale\u2010capable system with special emphasis on how allocation strategies would affect the overall performance. We consider several aspects of data\u2010aware allocation such as the effect of spatial and temporal locality, the affinity of data to storage sources, and the network\u2010level traffic prioritization for different types of flows. In our experimental set\u2010up, temporal locality can have a substantial effect on application runtime (up to a 10% reduction), whereas spatial locality can be even more significant (up to one order of magnitude faster with perfect locality). The use of structured access patterns to the data and the allocation of bandwidth at the network level can also have a significant impact (up to 20% and 17% reduction of runtime, respectively). These results suggest that scheduling policies exposing data\u2010locality information can be essential for the appropriate utilization of future large\u2010scale systems. Finally, we found that the distributed storage system we are implementing can outperform traditional SAN architectures, even with a much smaller (in terms of I/O servers) back\u2010end.", "venue": "Concurrency and Computation", "year": 2018, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2018-07-17", "journal": {"name": "Concurrency and Computation: Practice and Experience", "volume": "31"}, "authors": [{"authorId": "152854906", "name": "J. A. Pascual"}, {"authorId": "50191209", "name": "Joshua Lant"}, {"authorId": "1775023", "name": "Caroline Concatto"}, {"authorId": "32152518", "name": "Andrew Attwood"}, {"authorId": "2664393", "name": "J. Navaridas"}, {"authorId": "145141724", "name": "M. Luj\u00e1n"}, {"authorId": "87524989", "name": "J. Goodacre"}], "citations": [{"paperId": "aaee1500a882fc2480b3f2d876a81b606a93dbf8", "title": "INRFlow: An interconnection networks research flow-level simulation framework"}, {"paperId": "df057f97e9075d40b7bf6cb6e8c950f7415c32a8", "title": "Foreword to the Special Issue on Processors, Interconnects, Storage, and Caches for Exascale Systems"}]}

{"paperId": "ed1eba735e9307492ee24efdabadfd399cdbf864", "publicationVenue": {"id": "036e4843-9039-4bf3-a12d-2ee5b12cdee8", "name": "International Conference on Trust, Privacy and Security in Intelligent Systems and Applications", "type": "conference", "alternate_names": ["TPS-ISA", "Int Conf Trust Priv Secur Intell Syst Appl"]}, "title": "Metamorphic Malware Evolution: The Potential and Peril of Large Language Models", "abstract": "Code metamorphism refers to a computer programming exercise wherein the program modifies its own code (partial or entire) consistently and automatically while retaining its core functionality. This technique is often used for online performance optimization and automated crash recovery in certain mission-critical applications. However, the technique has been misappropriated by malware creators to bypass signature-based detection measures instituted by anti-malware engines. However, current code mutation engines used by threat actors offer only a limited degree of mutation, which is frequently detectable via static code analysis. The advent of large language models (LLMs), such as ChatGPT 4.0 and Google Bart may lead to a significant evolution in this landscape. These models have demonstrated a level of algorithm comprehension and code synthesis capability that closely resembles human abilities. This advancement has sparked concerns among experts that such models could be exploited by threat actors to generate sophisticated metamorphic malware. This paper explores the potential of several prominent LLMs for software code mutation that may be used to reconstruct (with mutation) existing malware code bases or create new forms of embedded mutation engines for next-gen metamorphic malwares. In this work, we introduce a framework for creating self-testing program mutation engines based on LLM/Transformer-based models. The proposed framework serves as an essential tool in testing next-gen metamorphic malware detection engines.", "venue": "International Conference on Trust, Privacy and Security in Intelligent Systems and Applications", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-11-01", "journal": {"name": "2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)", "pages": "74-81"}, "authors": [{"authorId": "2961612", "name": "Pooria Madani"}], "citations": [{"paperId": "9cca0ff4ddd8ea65650da5968c800eafec2da5bb", "title": "Review of Generative AI Methods in Cybersecurity"}]}

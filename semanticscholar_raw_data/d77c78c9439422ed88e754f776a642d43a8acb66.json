{"paperId": "d77c78c9439422ed88e754f776a642d43a8acb66", "publicationVenue": {"id": "e0dbf116-86aa-418d-859f-a49952d7e44a", "name": "Transactions of the Association for Computational Linguistics", "type": "journal", "alternate_names": ["Trans Assoc Comput Linguistics", "TACL"], "issn": "2307-387X", "url": "https://www.mitpressjournals.org/loi/tacl", "alternate_urls": ["http://www.transacl.org/"]}, "title": "Reducing Conversational Agents\u2019 Overconfidence Through Linguistic Calibration", "abstract": "Abstract While improving neural dialogue agents\u2019 factual accuracy is the object of much research, another important aspect of communication, less studied in the setting of neural dialogue, is transparency about ignorance. In this work, we analyze to what extent state-of-the-art chit-chat models are linguistically calibrated in the sense that their verbalized expression of doubt (or confidence) matches the likelihood that the model\u2019s responses are factually incorrect (or correct). We find that these models are poorly calibrated, yet we show that likelihood of correctness can accurately be predicted. By incorporating such metacognitive features into the training of a controllable generation model, we obtain a dialogue agent with greatly improved linguistic calibration.", "venue": "Transactions of the Association for Computational Linguistics", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-12-30", "journal": {"name": "Transactions of the Association for Computational Linguistics", "pages": "857-872", "volume": "10"}, "authors": [{"authorId": "27689253", "name": "Sabrina J. Mielke"}, {"authorId": "3149531", "name": "Arthur Szlam"}, {"authorId": "31461304", "name": "Emily Dinan"}, {"authorId": "90841478", "name": "Y-Lan Boureau"}], "citations": [{"paperId": "d6bfbce1c8995a6d5a3a7c3d5bb1c3006d23ba65", "title": "Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing"}, {"paperId": "b58b319d2b3f933ae201f747dabb4b9ea070e50e", "title": "Linguistic Calibration of Language Models"}, {"paperId": "e9ab14dbbad99c2b31dce690816d53c21320239e", "title": "Few-Shot Recalibration of Language Models"}, {"paperId": "19d3099bf0fbe63372df304c35f2ebe2ff1af357", "title": "Explore until Confident: Efficient Exploration for Embodied Question Answering"}, {"paperId": "46dae0599a6397b603282809a724a188a0b60412", "title": "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods"}, {"paperId": "f7d8fa345e4ff788707eb132a4a30c830e3f648d", "title": "Gotcha! Don't trick me with unanswerable questions! Self-aligning Large Language Models for Responding to Unknown Questions"}, {"paperId": "992c554b1bf343eef3509579930b2552f1b6f1db", "title": "Calibrating Large Language Models with Sample Consistency"}, {"paperId": "1539bb565a86c764aae690b77a6a2e78f476ae4f", "title": "Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer for Compositional Unknown Questions"}, {"paperId": "c76541024ed59403f99a5a73ba69849112959a6e", "title": "A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models"}, {"paperId": "00134f96e2188eff33516ec1d2ddd998d48d2b23", "title": "Softmax Probabilities (Mostly) Predict Large Language Model Correctness on Multiple-Choice Q&A"}, {"paperId": "0614dd89988419d379f618f46bbad72b6f5b686f", "title": "Thermometer: Towards Universal Calibration for Large Language Models"}, {"paperId": "7d2991d25d50d0b82c3b4eaf4a03909ea6ee499c", "title": "Explain then Rank: Scale Calibration of Neural Rankers Using Natural Language Explanations from Large Language Models"}, {"paperId": "2ac35475ccf0a6a89bbd04377a4fe61c175030a4", "title": "Meta Ranking: Less Capable Language Models are Capable for Single Response Judgement"}, {"paperId": "2be4cc6d28ced11a13c767dd5edaabea06825272", "title": "Uncertainty quantification in fine-tuned LLMs using LoRA ensembles"}, {"paperId": "4bb30cdd7216d0bde3f937489ec04b161b44977c", "title": "Comparing Hallucination Detection Metrics for Multilingual Generation"}, {"paperId": "14d0489047a1390434e7ea454e7e5165d9721ae3", "title": "Calibrating Long-form Generations from Large Language Models"}, {"paperId": "754f9c903754d909cb754364f4d6416ada0ab2b5", "title": "Reconfidencing LLMs from the Grouping Loss Perspective"}, {"paperId": "b1ec3002f4c80d721fc7d975cf469dce0833fed0", "title": "DeLLMa: A Framework for Decision Making Under Uncertainty with Large Language Models"}, {"paperId": "4feb412574eb5d0b187276069fe6024c22629c0e", "title": "The Calibration Gap between Model and Human Confidence in Large Language Models"}, {"paperId": "6789e0a19f70e283b120fd6a3792162d01a021d5", "title": "Do Androids Know They're Only Dreaming of Electric Sheep?"}, {"paperId": "9b996cdf31e1078cc38dedb4980f42a5ca8fd10a", "title": "Robust Knowledge Extraction from Large Language Models using Social Choice Theory"}, {"paperId": "1834f8126e97057e321149b50e342754a096d14d", "title": "Examining LLMs' Uncertainty Expression Towards Questions Outside Parametric Knowledge"}, {"paperId": "67fa2f2072cca1071ed2c820d6a7f50de6ea2ff3", "title": "Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling"}, {"paperId": "6aa6003c7d7b3d275ae981aa6200014968c32430", "title": "A Survey of Confidence Estimation and Calibration in Large Language Models"}, {"paperId": "337516aed1c85a46755a1b362f79d1cfa0e03336", "title": "To protect science, we must use LLMs as zero-shot translators"}, {"paperId": "c1284ee1ddf29955a1a02bdc45abdaac63745017", "title": "Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method"}, {"paperId": "28fbbf98bac1bb941162df553ca034d600cb59a6", "title": "Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models"}, {"paperId": "6101085b4a0c53eae87f7e9660713917068c9b13", "title": "An Improved Chinese Pause Fillers Prediction Module Based on RoBERTa"}, {"paperId": "63549bf78e4b1e7e1cec505ce65e6e8f90474f41", "title": "ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs"}, {"paperId": "4b0b56be0ae9479d2bd5c2f0943db1906343c10f", "title": "Chain-of-Verification Reduces Hallucination in Large Language Models"}, {"paperId": "33935c64228d249e20fb41ac9da7de85463c1ec4", "title": "PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis"}, {"paperId": "9582717ca2c7cf7f6d39fff408013d636accf4e6", "title": "Conformal Autoregressive Generation: Beam Search with Coverage Guarantees"}, {"paperId": "fb00016c1e048b9373803add001c1ec7e877cb23", "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A. Will LLMs Replace Knowledge Graphs?"}, {"paperId": "451a657dabf80ebc43f6a3be518250b2cd5dfe1a", "title": "Through the Lens of Core Competency: Survey on Evaluation of Large Language Models"}, {"paperId": "76513f54fcecf7a380f77ad785f05c3bc869db4a", "title": "Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering"}, {"paperId": "f27a23716798526746d87cc34aa56484734eb140", "title": "Uncertainty in Natural Language Generation: From Theory to Applications"}, {"paperId": "205c65fec719f923a6bfaddfffff365d3cbfd845", "title": "PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models"}, {"paperId": "6697e7e490fb69385c9404a96e5f6ea523fca9b0", "title": "Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts"}, {"paperId": "d1500f1dbd62e26ef0753f31e845078f58479968", "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners"}, {"paperId": "fb64b994bb510fed9fbcb5ff8f10fcf2b9049073", "title": "The Inner Sentiments of a Thought"}, {"paperId": "8f7297454d7f44365b9bcda5ebb9439a43daf5e6", "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"}, {"paperId": "1c1d1b4e1edae9dca84ea655624a4c8dc7fef2a7", "title": "Conformal Language Modeling"}, {"paperId": "ec9af8d8973fa4d302ccd53e5e0236651201351c", "title": "Your Prompt is My Command: On Assessing the Human-Centred Generality of Multimodal Models"}, {"paperId": "ce086a9cae74573426cd5a1b1a44caadff38b65c", "title": "When to Read Documents or QA History: On Unified and Selective Open-domain QA"}, {"paperId": "ad934a9344f68fcc0b9aa704102aa48c39c5b591", "title": "Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models"}, {"paperId": "1c296df26baf7daa72eba1619a1bd15b3168fa48", "title": "Improved Instruction Ordering in Recipe-Grounded Conversation"}, {"paperId": "d72ff44e3094dd9466b66d0522aff5dd1cf6b614", "title": "Mastering the ABCDs of Complex Questions: Answer-Based Claim Decomposition for Fine-grained Self-Evaluation"}, {"paperId": "ab4ce5dda7ad4d9032995c9c049a89d65723c6aa", "title": "Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback"}, {"paperId": "0e0d72be9950fde9b5e8996e2147d1318f216ebb", "title": "Prompting is not a substitute for probability measurements in large language models"}, {"paperId": "9379d519b8ddfa194ef6f575127451e5016e1803", "title": "Mirages: On Anthropomorphism in Dialogue Systems"}, {"paperId": "38be7643bcad936739550a1802220eb53ca9b1df", "title": "Simple Token-Level Confidence Improves Caption Correctness"}, {"paperId": "a206a0c96d6076c6ab081288b0c2c95d3c7efd64", "title": "Inspecting and Editing Knowledge Representations in Language Models"}, {"paperId": "e0a460d77dc29cea3cd5753e8e0bf57cfb812d6e", "title": "Fillers in Spoken Language Understanding: Computational and Psycholinguistic Perspectives"}, {"paperId": "4e53b481beabba42aac027e5a8c69fed26ab4062", "title": "RHO ($\u03c1$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding"}, {"paperId": "c428f1621f79925311082d8d7425dd4d50cd64ed", "title": "Calibrated Interpretation: Confidence Estimation in Semantic Parsing"}, {"paperId": "711d5e8ddbb840ad31a9ffa3d38590603ba69a92", "title": "Prompting GPT-3 To Be Reliable"}, {"paperId": "374dd173491a59a10bbb2b3519ebcfe3649f529d", "title": "Teaching Models to Express Their Uncertainty in Words"}, {"paperId": "9ffefdf1fcd780cb71450b0a7a29247c66aa87be", "title": "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning"}, {"paperId": "1ea7ad7ae45d3d4634b6ffad2a8b0d41ad2fcb25", "title": "FaithDial: A Faithful Benchmark for Information-Seeking Dialogue"}, {"paperId": "a6ee3088c5c1f4dffb43c55394793fca2b585b1d", "title": "A Proposal for Scaling the Scaling Laws"}, {"paperId": "1fa4469e5bc5d096572902fe14b0d66078a24c47", "title": "Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models"}, {"paperId": "dd7c4bf0ab04dff4ca36937933dc3c4e7665fd0d", "title": "Emergent deception and skepticism via theory of mind"}, {"paperId": "b6e880ef05be2fb91535173ac0340fd9891b814b", "title": "PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis"}, {"paperId": "47eb0468ba7b6457d32b6aa0ee15ad269c04864d", "title": "Confidently Wrong: Exploring the Calibration and Expression of (Un)Certainty of Large Language Models in a Multilingual Setting"}, {"paperId": "b15cddd33b36d1f38a8e59412026f6dfde0ca38d", "title": "Calibrated Interpretation: Con\ufb01dence Estimation in Semantic Parsing"}, {"paperId": "fd22a98fbb5675e86d88a825448a611302dd41a9", "title": "Towards In-Context Non-Expert Evaluation of Reflection Generation for Counselling Conversations"}]}

{"paperId": "3b902f818ee763a3fbaf27ab625a3c71f35529d0", "publicationVenue": {"id": "136edf8d-0f88-4c2c-830f-461c6a9b842e", "name": "Applied Sciences", "type": "journal", "alternate_names": ["Appl Sci"], "issn": "2076-3417", "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-217814", "alternate_urls": ["http://www.mathem.pub.ro/apps/", "https://www.mdpi.com/journal/applsci", "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-217814"]}, "title": "A Robust and Automated Vision-Based Human Fall Detection System Using 3D Multi-Stream CNNs with an Image Fusion Technique", "abstract": "Unintentional human falls, particularly in older adults, can result in severe injuries and death, and negatively impact quality of life. The World Health Organization (WHO) states that falls are a significant public health issue and the primary cause of injury-related fatalities worldwide. Injuries resulting from falls, such as broken bones, trauma, and internal injuries, can have severe consequences and can lead to a loss of mobility and independence. To address this problem, there have been suggestions to develop strategies to reduce the frequency of falls, in order to decrease healthcare costs and productivity loss. Vision-based fall detection approaches have proven their effectiveness in addressing falls on time, which can help to reduce fall injuries. This paper introduces an automated vision-based system for detecting falls and issuing instant alerts upon detection. The proposed system processes live footage from a monitoring surveillance camera by utilizing a fine-tuned human segmentation model and image fusion technique as pre-processing and classifying a set of live footage with a 3D multi-stream CNN model (4S-3DCNN). The system alerts when the sequence of the Falling of the monitored human, followed by having Fallen, takes place. The effectiveness of the system was assessed using the publicly available Le2i dataset. System validation revealed an impressive result, achieving an accuracy of 99.44%, sensitivity of 99.12%, specificity of 99.12%, and precision of 99.59%. Based on the reported results, the presented system can be a valuable tool for detecting human falls, preventing fall injury complications, and reducing healthcare and productivity loss costs.", "venue": "Applied Sciences", "year": 2023, "fieldsOfStudy": null, "publicationTypes": ["JournalArticle"], "publicationDate": "2023-06-07", "journal": {"name": "Applied Sciences"}, "authors": [{"authorId": "2219825254", "name": "Thamer Alanazi"}, {"authorId": "2742512", "name": "Khalid Babutain"}, {"authorId": "46669879", "name": "G. Muhammad"}], "citations": [{"paperId": "d2907d310a4b756ad5379ae9b1960c0cb74ac4d9", "title": "A Hybrid Visionary for Unveiling Human Motion in the Face of Occlusion with Mask R-CNN, RNN, and MHT"}, {"paperId": "bc1cacec28da4271996f505eb8f247a7355d0e12", "title": "Fall Recognition Based on Time-Level Decision Fusion Classification"}, {"paperId": "873768c4d3d8a061ee0a1ac76f1d8a67295f17b4", "title": "A systematic review on fall detection systems for elderly healthcare"}]}

{"paperId": "5c525592670cf7d62275d7871ae1b2aafca544b2", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO", "abstract": "Smart glasses are rapidly gaining advanced functionality thanks to cutting-edge computing technologies, accelerated hardware architectures, and tiny AI algorithms. Integrating AI into smart glasses featuring a small form factor and limited battery capacity is still challenging when targeting full-day usage for a satisfactory user experience. This paper illustrates the design and implementation of tiny machine-learning algorithms exploiting novel low-power processors to enable prolonged continuous operation in smart glasses. We explore the energy- and latency-efficient of smart glasses in the case of real-time object detection. To this goal, we designed a smart glasses prototype as a research platform featuring two microcontrollers, including a novel milliwatt-power RISC-V parallel processor with a hardware accelerator for visual AI, and a Bluetooth low-power module for communication. The smart glasses integrate power cycling mechanisms, including image and audio sensing interfaces. Furthermore, we developed a family of novel tiny deep-learning models based on YOLO with sub-million parameters customized for microcontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming at benchmarking object detection with smart glasses for energy and latency. Evaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's 17ms inference latency and 1.59mJ energy consumption per inference while ensuring acceptable detection accuracy. Further evaluation reveals an end-to-end latency from image capturing to the algorithm's prediction of 56ms or equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to a 9.3 hours of continuous run time on a 154mAh battery. These results outperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image classification) at just 7.3 fps per second.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-02", "journal": {"name": "ArXiv", "volume": "abs/2311.01057"}, "authors": [{"authorId": "2264976270", "name": "Julian Moosmann"}, {"authorId": "2223593877", "name": "Pietro Bonazzi"}, {"authorId": "2223676395", "name": "Yawei Li"}, {"authorId": "81428243", "name": "Sizhen Bian"}, {"authorId": "2008430476", "name": "Philipp Mayer"}, {"authorId": "2238205999", "name": "Luca Benini"}, {"authorId": "145274281", "name": "M. Magno"}], "citations": [{"paperId": "a4acb31dd03eb904ce646db5fa1646eeaa482318", "title": "ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data"}, {"paperId": "e5f42d6c265c93d45a10d657c9fa4bd0a159f896", "title": "Research on the Algorithm of Position Correction for High-Speed Moving Express Packages Based on Traditional Vision and AI Vision"}, {"paperId": "1328e00ddf5924e74a312e283193e75817523318", "title": "Q-Segment: Segmenting Images In-Sensor for Vessel-Based Medical Diagnosis"}, {"paperId": "7be60ac7795c5dadf83ef92f8ad7469b71dcbc3a", "title": "A Low-Power Neuromorphic Approach for Efficient Eye-Tracking"}]}

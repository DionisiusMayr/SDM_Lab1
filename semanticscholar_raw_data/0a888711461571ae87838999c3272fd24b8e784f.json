{"paperId": "0a888711461571ae87838999c3272fd24b8e784f", "publicationVenue": {"id": "41bf9ed3-85b3-4c90-b015-150e31690253", "name": "Conference on Empirical Methods in Natural Language Processing", "type": "conference", "alternate_names": ["Empir Method Nat Lang Process", "Empirical Methods in Natural Language Processing", "Conf Empir Method Nat Lang Process", "EMNLP"], "url": "https://www.aclweb.org/portal/emnlp"}, "title": "Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization", "abstract": "Dialogue summarization involves a wide range of scenarios and domains. However, existing methods generally only apply to specific scenarios or domains. In this study, we propose a new pre-trained model specifically designed for multi-scenario multi-domain dialogue summarization. It adopts a multi-stage pre-training strategy to reduce the gap between the pre-training objective and fine-tuning objective. Specifically, we first conduct domain-aware pre-training using large-scale multi-scenario multi-domain dialogue data to enhance the adaptability of our pre-trained model. Then, we conduct task-oriented pre-training using large-scale multi-scenario multi-domain\"dialogue-summary\"parallel data annotated by ChatGPT to enhance the dialogue summarization ability of our pre-trained model. Experimental results on three dialogue summarization datasets from different scenarios and domains indicate that our pre-trained model significantly outperforms previous state-of-the-art models in full fine-tuning, zero-shot, and few-shot settings.", "venue": "Conference on Empirical Methods in Natural Language Processing", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-10-16", "journal": {"pages": "6893-6908"}, "authors": [{"authorId": "2258930051", "name": "Weixiao Zhou"}, {"authorId": "2258804465", "name": "Gengyao Li"}, {"authorId": "2174103319", "name": "Xianfu Cheng"}, {"authorId": "120436437", "name": "Xinnian Liang"}, {"authorId": "24925751", "name": "Junnan Zhu"}, {"authorId": "9091828", "name": "Feifei Zhai"}, {"authorId": "2258837278", "name": "Zhoujun Li"}], "citations": [{"paperId": "9150e501bb9d43607c40d152e619a2ef1bd874a6", "title": "VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text Recognition"}, {"paperId": "7d5ea474aa1cf732bb1d00faa07a5bb2c9119cfd", "title": "The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text"}]}

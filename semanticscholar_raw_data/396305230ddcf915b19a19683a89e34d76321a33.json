{"paperId": "396305230ddcf915b19a19683a89e34d76321a33", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Cognitive Mirage: A Review of Hallucinations in Large Language Models", "abstract": "As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-09-13", "journal": {"name": "ArXiv", "volume": "abs/2309.06794"}, "authors": [{"authorId": "2239197934", "name": "Hongbin Ye"}, {"authorId": "2239249506", "name": "Tong Liu"}, {"authorId": "2239587085", "name": "Aijia Zhang"}, {"authorId": "2239199462", "name": "Wei Hua"}, {"authorId": "2239200814", "name": "Weiqiang Jia"}], "citations": [{"paperId": "71d517ea75fac9f9fc62aefca4ad02eaa7cc0c76", "title": "Multicalibration for Confidence Scoring in LLMs"}, {"paperId": "8719833751cf1bfc779c944fc7954a337b2c0833", "title": "Source-Aware Training Enables Knowledge Attribution in Language Models"}, {"paperId": "d33ebdc84509feeb8f66c0fd22b6463cd47ba694", "title": "Recommendation of data-free class-incremental learning algorithms by simulating future data"}, {"paperId": "e35e304fd28db3c74295fbc905e7f28f845da91a", "title": "ChatGPT y GPT-4: utilidades en el sector jur\u00eddico, funcionamiento, limitaciones y riesgos de los modelos fundacionales"}, {"paperId": "b877f5076c617a948081e12e08809e6c6b84b468", "title": "ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models"}, {"paperId": "a7a13907a1c4de7ae740d778a92ef587322f38d3", "title": "Eternal Sunshine of the Mechanical Mind: The Irreconcilability of Machine Learning and the Right to be Forgotten"}, {"paperId": "9120d793a1681128d064bc19aab4dc29ce7a38b8", "title": "AutoSAT: Automatically Optimize SAT Solvers via Large Language Models"}, {"paperId": "525ff089b6c5df9b311124adc3e549060093c982", "title": "Do Large Language Models Show Human-like Biases? Exploring Confidence - Competence Gap in AI"}, {"paperId": "c072d217732edb066de2192ab9ad6b02aec9c7a0", "title": "Financial Report Chunking for Effective Retrieval Augmented Generation"}, {"paperId": "e9bd3ca79f41e18c0dcd04ebc7afa7bc4e6f8721", "title": "IllusionX: An LLM-powered mixed reality personal companion"}, {"paperId": "92e9469197a53e82f42b66876b221aaa25d07292", "title": "A Survey on Large Language Model Hallucination via a Creativity Perspective"}, {"paperId": "fbb9baa37b1661c052fcbb07c7f52d6b9fee663b", "title": "AI Hallucinations: A Misnomer Worth Clarifying"}, {"paperId": "f1847c5693f7dac9ba89b3e0571ee27cfca720dc", "title": "Measurement in the Age of LLMs: An Application to Ideological Scaling"}, {"paperId": "5682fc5ee0218858d8de9908c1be4c754f316625", "title": "HALO: An Ontology for Representing and Categorizing Hallucinations in Large Language Models"}, {"paperId": "205ada2927972cb3156e94247e29d454bf620399", "title": "Towards Knowledge-driven Autonomous Driving"}, {"paperId": "581da1b691dfb1b5e417a6694a34d45ca434c54c", "title": "On The Truthfulness of 'Surprisingly Likely' Responses of Large Language Models"}, {"paperId": "8dd5ef8f047a2c74a30cc21d12b82c80232aa41d", "title": "Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision"}, {"paperId": "b3474a0bfddd48d46abe2214f42e660b569cc4aa", "title": "FactCHD: Benchmarking Fact-Conflicting Hallucination Detection"}, {"paperId": "3856fce2fca56e2d7be0134889bf6f9d2f01b931", "title": "Advancing Perception in Artificial Intelligence through Principles of Cognitive Science"}, {"paperId": "03fab98a9be74a253688840dba9144737a8ca92d", "title": "Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity"}, {"paperId": "7817d4dbe7f85f77b6ce6719ab5f6e2423e5724e", "title": "The Confidence-Competence Gap in Large Language Models: A Cognitive Study"}, {"paperId": "6f75e8b61f13562237851d8119cb2f9d49e073fb", "title": "Can LLM-Generated Misinformation Be Detected?"}, {"paperId": "33935c64228d249e20fb41ac9da7de85463c1ec4", "title": "PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis"}, {"paperId": "b5f86b74a60b69fac4b34d02065ac28fa3f2e872", "title": "Cross-Modal Entity Matching for Visually Rich Documents"}, {"paperId": "2e674e2918e387fe4b545987ef26ed6599818bd6", "title": "Domain-Agnostic Molecular Generation with Chemical Feedback"}, {"paperId": "8b3d0ca15acca6911d7a45bce3f18ba8b03622cc", "title": "Exploring the opportunities and challenges of using large language models to represent institutional agency in land system modelling"}]}

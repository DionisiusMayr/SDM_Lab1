{"paperId": "a88002788d492a6155a30bb77eb51f1290ebf860", "publicationVenue": null, "title": "Spur: Mitigating Slow Instances in Large-Scale Streaming Pipelines", "abstract": "Bing's monetization pipeline is one of the largest and most critical streaming workloads deployed in Microsoft's internal data lake. The pipeline runs 24/7 at a scale of 3500 YARN containers and is required to meet a Service Level Objective (SLO) of low tail latency. In this paper, we highlight some of the unique challenges imposed by this large scale of operation: other concurrent workloads sharing the cluster may cause random performance deterioration; unavailability of external dependencies may cause temporary stalls in the pipeline; scarcity in the underlying resource manager may cause arbitrarily long delays or rejection of container allocation requests. Weathering these challenges requires specially tailored dynamic control policies that react to these issues as and when they arise. We focus on the problem of reducing the latency in the tail, i.e., 99th percentile (p99), by detecting and mitigating slow instances through speculative replication. We show that widely used approaches do not satisfactorily solve this issue at our scale. A conservative approach is hesitant to acquire additional resources, reacts too slowly to the changes in the environment and therefore achieves little improvement in p99 latency. On the other hand, an aggressive approach overwhelms the underlying resource manager with unnecessary resource requests and paradoxically worsens the p99 latency. Our proposed approach, Spur, is designed for this challenging environment. It combines aggressive detection of slow instances with smart pruning of false positives to achieve a far better trade-off between these conflicting objectives. Using only 0.5% additional resources (similar to the conservative approach), we demonstrate a 10% -38% improvement in the tail latency compared to both conservative and aggressive approaches.", "venue": "SIGMOD Conference", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2020-05-29", "journal": {"name": "Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data"}, "authors": [{"authorId": "14161046", "name": "Ke Wang"}, {"authorId": "2327080", "name": "Avrilia Floratou"}, {"authorId": "9490513", "name": "Ashvin Agrawal"}, {"authorId": "2082081930", "name": "Daniel Musgrave"}], "citations": [{"paperId": "6e6044684ba7a26eb913177953e71de312374eb7", "title": "Hierarchical Auto-scaling Policies for Data Stream Processing on Heterogeneous Resources"}, {"paperId": "2a6baff0ce9f752f43691687cfdcff5cf6eb048f", "title": "Runtime Adaptation of Data Stream Processing Systems: The State of the Art"}, {"paperId": "b362eae4b08e36a01e03ab2b7a51870ebf6d3a97", "title": "Machine Learning for Cloud Data Systems: the Promise, the Progress, and the Path Forward"}, {"paperId": "6eed456b892fb3ad529e1f0cdf3285230d209d85", "title": "Hazelcast Jet: Low-latency Stream Processing at the 99.99th Percentile"}]}

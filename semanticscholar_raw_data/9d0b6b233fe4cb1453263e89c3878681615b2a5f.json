{"paperId": "9d0b6b233fe4cb1453263e89c3878681615b2a5f", "publicationVenue": {"id": "0942fb86-c16f-4084-9902-10ddcfe18180", "name": "Micro", "type": "conference", "alternate_names": ["Int Symp Microarchitecture", "MICRO", "International Symposium on Microarchitecture", "Annual IEEE/ACM International Symposium on Microarchitecture", "Annu IEEE/ACM Int Symp Microarchitecture"], "issn": "0271-9002", "alternate_issns": ["2151-4143", "2673-8023"], "url": "http://www.microarch.org/"}, "title": "A Data-Centric Accelerator for High-Performance Hypergraph Processing", "abstract": "Hypergraph processing has emerged as a powerful approach for analyzing complex multilateral relationships among multiple entities. Past research on building hypergraph systems suggests that changing the scheduling order of bipartite edge tasks can improve the overlap-induced data locality in hypergraph processing. However, due to the complex intertwined connections between vertices and hyperedges, it is almost impossible to find a locality-optimal scheduling order. Thus, these task-centric hypergraph systems often suffer from substantial off-chip communications. In this paper, we first propose a novel data-centric Load-Trigger-Reduce (LTR) execution model to exploit fully the locality in hypergraph processing. Unlike a task-centric model that loads the required data along with a task, our LTR model invokes tasks as per the data used. Specifically, once the hypergraph data is loaded into the on-chip memory, all of its relevant computation tasks will be triggered simultaneously to output intermediate results, which are finally reduced to update the final results. Our LTR model enables all hypergraph data to be accessed once in each iteration. To fully exploit the LTR performance potential, we further architect an LTR-driven hypergraph accelerator, XuLin, which features with an adaptive data loading mechanism to minimize the loading cost via chunk merging at runtime. XuLin is also equipped with a priority-based differential data reduction scheme to reduce the impact of conflicting updates on performance. We have implemented XuLin both on a Xilinx Alveo U250 FPGA card and using a cycle-accurate simulator. The results show that XuLin outperforms the state-of-the-art hypergraph processing solutions Hygra and ChGraph by $20.47 \\times$ and $8.77 \\times$ on average, respectively.", "venue": "Micro", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-10-01", "journal": {"name": "2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO)", "pages": "1326-1341"}, "authors": [{"authorId": "2109183880", "name": "Qinggang Wang"}, {"authorId": "9135861", "name": "Long Zheng"}, {"authorId": "1842300439", "name": "Ao Hu"}, {"authorId": "2108860901", "name": "Yu Huang"}, {"authorId": "2099667639", "name": "Pengcheng Yao"}, {"authorId": "73767790", "name": "Chuangyi Gui"}, {"authorId": "144925807", "name": "Xiaofei Liao"}, {"authorId": "145914251", "name": "Hai Jin"}, {"authorId": "144198209", "name": "Jingling Xue"}], "citations": []}

{"paperId": "412fe1f135cb20c952962133ca1e534a71bfd27f", "publicationVenue": {"id": "bdc2e585-4e48-4e36-8af1-6d859763d405", "name": "AAAI Conference on Artificial Intelligence", "type": "conference", "alternate_names": ["National Conference on Artificial Intelligence", "National Conf Artif Intell", "AAAI Conf Artif Intell", "AAAI"], "url": "http://www.aaai.org/"}, "title": "When Do Program-of-Thoughts Work for Reasoning?", "abstract": "In the realm of embodied artificial intelligence, the reasoning capabilities of Large Language Models (LLMs) play a pivotal role. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score CIRS, which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing and stratifying algorithm, and apply it to instruction generation for mathematical reasoning and code data filtering for code generation tasks. Extensive results demonstrates the effectiveness of our proposed approach.", "venue": "AAAI Conference on Artificial Intelligence", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-08-29", "journal": {"name": "ArXiv", "volume": "abs/2308.15452"}, "authors": [{"authorId": "2059276046", "name": "Zhen Bi"}, {"authorId": "2153010067", "name": "Ningyu Zhang"}, {"authorId": "2157838086", "name": "Yinuo Jiang"}, {"authorId": "152931849", "name": "Shumin Deng"}, {"authorId": "1706307", "name": "Guozhou Zheng"}, {"authorId": "2144200945", "name": "Huajun Chen"}], "citations": [{"paperId": "a0f15d57cc627e5224aa439fde4e9b78cf7336e7", "title": "A Theory for Length Generalization in Learning to Reason"}, {"paperId": "c4e7bb35c826548c11527f33b855ffdb67ae5c57", "title": "Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation"}, {"paperId": "4a5b69b3f79d9fed2eeb82585df35c6bb9a72194", "title": "EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models"}, {"paperId": "4ba57555bef02f988f2ed3bab2f102733dc55221", "title": "Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations"}, {"paperId": "d4346af837aa6c2bb4a341cfe9bd91862ea5910a", "title": "Large Knowledge Model: Perspectives and Challenges"}, {"paperId": "83f9027ff30430ff7d1ca15d565601d290c0da7d", "title": "Applying Large Language Models and Chain-of-Thought for Automatic Scoring"}, {"paperId": "dd69049674f41d4ef5314b8f95bacfe59de31376", "title": "Conditions for Length Generalization in Learning Reasoning Skills"}, {"paperId": "6fa0677731184444df0e1fc8070938419cd6da47", "title": "Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents"}, {"paperId": "03f3801956fc4cc026860568670f9f65ed29b192", "title": "Towards A Unified View of Answer Calibration for Multi-Step Reasoning"}, {"paperId": "11a4284e335ba39330b59d9f42ca3272a6166991", "title": "A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"}, {"paperId": "396305230ddcf915b19a19683a89e34d76321a33", "title": "Cognitive Mirage: A Review of Hallucinations in Large Language Models"}, {"paperId": "02033e83ff310f35e4623bd339982c52d926f2d5", "title": "Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling"}, {"paperId": "758985395372f5378fcf036094195b2848e13a21", "title": "PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning"}, {"paperId": "e277bef6465198c2ea2786dbb832834cd9a0dfc3", "title": "M ATH -S HEPHERD : A L ABEL -F REE S TEP - BY -S TEP V ERIFIER FOR LLM S IN M ATHEMATICAL R EASONING"}]}

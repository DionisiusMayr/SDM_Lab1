{"paperId": "a00dc9750bca4ddaed171866ce696b5da1fe4cbd", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "GPT-who: An Information Density-based Machine-Generated Text Detector", "abstract": "The Uniform Information Density (UID) principle posits that humans prefer to spread information evenly during language production. We examine if this UID principle can help capture differences between Large Language Models (LLMs)-generated and human-generated texts. We propose GPT-who, the first psycholinguistically-inspired domain-agnostic statistical detector. This detector employs UID-based features to model the unique statistical signature of each LLM and human author for accurate detection. We evaluate our method using 4 large-scale benchmark datasets and find that GPT-who outperforms state-of-the-art detectors (both statistical-&non-statistical) such as GLTR, GPTZero, DetectGPT, OpenAI detector, and ZeroGPT by over $20$% across domains. In addition to better performance, it is computationally inexpensive and utilizes an interpretable representation of text articles. We find that GPT-who can distinguish texts generated by very sophisticated LLMs, even when the overlying text is indiscernible. UID-based measures for all datasets and code are available at https://github.com/saranya-venkatraman/gpt-who.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-09", "journal": {"name": "ArXiv", "volume": "abs/2310.06202"}, "authors": [{"authorId": "2189394679", "name": "Saranya Venkatraman"}, {"authorId": "150035131", "name": "Adaku Uchendu"}, {"authorId": "2158951945", "name": "Dongwon Lee"}], "citations": [{"paperId": "c522009902ae5dbfb23db9ffac69da11d2cb778b", "title": "AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for Detecting Multi-generator Machine-generated Text"}, {"paperId": "730347f776dfd764579c1654525e1499961404a4", "title": "TM-TREK at SemEval-2024 Task 8: Towards LLM-Based Automatic Boundary Detection for Human-Machine Mixed Text"}, {"paperId": "6badf08bcf2f6ef3f9a6c83d7bd46e03520dddf7", "title": "GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick"}, {"paperId": "c59628de894a4aa7f91548bad5b4103b747256e8", "title": "M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection"}, {"paperId": "12ed45473dee6d0917f8577157cb86952cb162ce", "title": "Detecting Multimedia Generated by Large AI Models: A Survey"}, {"paperId": "3faa802714bfc051ada8317fdbf483742df65bd0", "title": "A Robust Semantics-based Watermark for Large Language Model against Paraphrasing"}, {"paperId": "311841075acf5a5b38d807c68fa9f55e4aa274bf", "title": "A Ship of Theseus: Curious Cases of Paraphrasing in LLM-Generated Texts"}, {"paperId": "6c5d2469c71fdfec4367fad5b8bd113ba7ba2910", "title": "AI-generated text boundary detection with RoFT"}, {"paperId": "60bd26bdb23ba353e5d79f161542dd074bc8391c", "title": "A Survey on Detection of LLMs-Generated Content"}]}

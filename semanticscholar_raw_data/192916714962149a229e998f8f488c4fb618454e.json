{"paperId": "192916714962149a229e998f8f488c4fb618454e", "publicationVenue": {"id": "d263025a-9eaf-443f-9bbf-72377e8d22a6", "name": "Data mining and knowledge discovery", "type": "journal", "alternate_names": ["Data Mining and Knowledge Discovery", "Data Min Knowl Discov", "Data min knowl discov"], "issn": "1384-5810", "url": "https://www.springer.com/computer/database+management+&+information+retrieval/journal/10618", "alternate_urls": ["https://link.springer.com/journal/10618", "http://www.springer.com/computer/database+management+&+information+retrieval/journal/10618"]}, "title": "Enhancing cluster analysis via topological manifold learning", "abstract": "We discuss topological aspects of cluster analysis and show that inferring the topological structure of a dataset before clustering it can considerably enhance cluster detection: we show that clustering embedding vectors representing the inherent structure of a dataset instead of the observed feature vectors themselves is highly beneficial. To demonstrate, we combine manifold learning method UMAP for inferring the topological structure with density-based clustering method DBSCAN. Synthetic and real data results show that this both simplifies and improves clustering in a diverse set of low- and high-dimensional problems including clusters of varying density and/or entangled shapes. Our approach simplifies clustering because topological pre-processing consistently reduces parameter sensitivity of DBSCAN. Clustering the resulting embeddings with DBSCAN can then even outperform complex methods such as SPECTACL and ClusterGAN. Finally, our investigation suggests that the crucial issue in clustering does not appear to be the nominal dimension of the data or how many irrelevant features it contains, but rather how separable the clusters are in the ambient observation space they are embedded in, which is usually the (high-dimensional) Euclidean space defined by the features of the data. The approach is successful because it performs the cluster analysis after projecting the data into a more suitable space that is optimized for separability, in some sense.", "venue": "Data mining and knowledge discovery", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-07-01", "journal": {"name": "Data Mining and Knowledge Discovery", "pages": "1-48", "volume": ""}, "authors": [{"authorId": "34911110", "name": "M. Herrmann"}, {"authorId": "3212542", "name": "Daniyal Kazempour"}, {"authorId": "1949120", "name": "F. Scheipl"}, {"authorId": "1782292", "name": "Peer Kr\u00f6ger"}], "citations": [{"paperId": "d6c0cbcd72d380e60f9c3eb166fc4bb85b25135a", "title": "Data reduction for SVM training using density-based border identification"}]}

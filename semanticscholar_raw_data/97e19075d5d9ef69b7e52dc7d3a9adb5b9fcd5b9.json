{"paperId": "97e19075d5d9ef69b7e52dc7d3a9adb5b9fcd5b9", "publicationVenue": {"id": "c2eeb1be-38e9-4a0a-a89d-957f4fd71ea1", "name": "IEEE Transactions on Intelligent Vehicles", "alternate_names": ["IEEE Trans Intell Veh"], "issn": "2379-8858", "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274857"}, "title": "EPtask: Deep Reinforcement Learning Based Energy-Efficient and Priority-Aware Task Scheduling for Dynamic Vehicular Edge Computing", "abstract": "The increasing complexity of vehicles has led to a growing demand for in-vehicle services that rely on multiple sensors. In the Vehicular Edge Computing (VEC) paradigm, energy-efficient task scheduling is critical to achieving optimal completion time and energy consumption. Although extensive research has been conducted in this field, challenges remain in meeting the requirements of time-sensitive services and adapting to dynamic traffic environments. In this context, a novel algorithm called Multi-action and Environment-adaptive Proximal Policy Optimization algorithm (MEPPO) is designed based on the conventional PPO algorithm and then a joint task scheduling and resource allocation method is proposed based on the designed MEPPO algorithm. In specific, the method involves three core aspects. Firstly, task scheduling strategy is designed to generate task offloading decisions and priority assignment decisions for the tasks utilizing PPO algorithm, which can further reduce the completion time of service requests. Secondly, transmit power allocation scheme is designed considering the expected transmission distance among vehicles and edge servers, which can minimize transmission energy consumption by adjusting the allocated transmit power dynamically. Thirdly, the proposed MEPPO-based scheduling method can make scheduling decisions for vehicles with different numbers of tasks by manipulating the state space of the PPO algorithm, which makes the proposed method be adaptive to real-world dynamic VEC environment. At last, the effectiveness of the proposed method is demonstrated through extensive simulation and on-site experiments.", "venue": "IEEE Transactions on Intelligent Vehicles", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-01-01", "journal": {"name": "IEEE Transactions on Intelligent Vehicles", "pages": "1830-1846", "volume": "9"}, "authors": [{"authorId": "2253583865", "name": "Peisong Li"}, {"authorId": "2189029824", "name": "Ziren Xiao"}, {"authorId": "2108062979", "name": "Xinheng Wang"}, {"authorId": "2238398725", "name": "Kaizhu Huang"}, {"authorId": "2181845371", "name": "Yi Huang"}, {"authorId": "2112666114", "name": "Honghao Gao"}], "citations": [{"paperId": "4b6913b8007f7d29a98afdf531b327abbdfea0d2", "title": "Evaluation of Infrastructure-based Warning System on Driving Behaviors-A Roundabout Study"}, {"paperId": "72c9d70a1cf3d1ba81b3786db2ed8be33e4d85d3", "title": "Video data offloading techniques in Mobile Edge Computing: A survey"}, {"paperId": "dd35fed8ebddb094fddd12a3cd52a00e32e51f18", "title": "Deep Reinforcement Learning Based Medical Supplies Dispatching Model for Major Infectious Diseases: Case Study of COVID-19"}]}

{"paperId": "0f119b265c39f70db0b6965ed9a68a85959e1e3f", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Towards General and Efficient Online Tuning for Spark", "abstract": "The distributed data analytic system - Spark is a common choice for processing massive volumes of heterogeneous data, while it is challenging to tune its parameters to achieve high performance. Recent studies try to employ auto-tuning techniques to solve this problem but suffer from three issues: limited functionality, high overhead, and inefficient search.\n In this paper, we present a general and efficient Spark tuning framework that can deal with the three issues simultaneously. First, we introduce a generalized tuning formulation, which can support multiple tuning goals and constraints conveniently, and a Bayesian optimization (BO) based solution to solve this generalized optimization problem. Second, to avoid high overhead from additional offline evaluations in existing methods, we propose to tune parameters along with the actual periodic executions of each job (i.e., online evaluations). To ensure safety during online job executions, we design a safe configuration acquisition method that models the safe region. Finally, three innovative techniques are leveraged to further accelerate the search process: adaptive sub-space generation, approximate gradient descent, and meta-learning method.\n We have implemented this framework as an independent cloud service, and applied it to the data platform in Tencent. The empirical results on both public benchmarks and large-scale production tasks demonstrate its superiority in terms of practicality, generality, and efficiency. Notably, this service saves an average of 57.00% memory cost and 34.93% CPU cost on 25K in-production tasks within 20 iterations, respectively.", "venue": "Proceedings of the VLDB Endowment", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-08-01", "journal": {"name": "Proc. VLDB Endow.", "pages": "3570-3583", "volume": "16"}, "authors": [{"authorId": "2154902040", "name": "Yang Li"}, {"authorId": "2156396421", "name": "Huaijun Jiang"}, {"authorId": "2117688209", "name": "Yu Shen"}, {"authorId": "2237945466", "name": "Yide Fang"}, {"authorId": "2237958586", "name": "Xiaofeng Yang"}, {"authorId": "2237965289", "name": "Danqing Huang"}, {"authorId": "2120364630", "name": "Xinyi Zhang"}, {"authorId": "2136776579", "name": "Wentao Zhang"}, {"authorId": "1776014", "name": "Ce Zhang"}, {"authorId": "2238070159", "name": "Peng Chen"}, {"authorId": "2143385807", "name": "Bin Cui"}], "citations": [{"paperId": "4601707a5e77daa25c69314f13c89dda2a0713d2", "title": "An Efficient Transfer Learning Based Configuration Adviser for Database Tuning"}]}

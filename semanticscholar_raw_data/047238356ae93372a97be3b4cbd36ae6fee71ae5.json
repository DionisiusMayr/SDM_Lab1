{"paperId": "047238356ae93372a97be3b4cbd36ae6fee71ae5", "publicationVenue": {"id": "2194778f-4fb6-471e-b2ff-5ad194635f72", "name": "Measurement and Modeling of Computer Systems", "type": "conference", "alternate_names": ["Meas Model Comput Syst", "SIGMETRICS"], "url": "http://www.acm.org/sigmetrics/"}, "title": "Demystifying Complex Workload-DRAM Interactions: An Experimental Study", "abstract": "It has become increasingly difficult to understand the complex interaction between modern applications and main memory, composed of Dynamic Random Access Memory (DRAM) chips. Manufacturers and researchers are developing many different types of DRAM, with each DRAM type catering to different needs (e.g., high throughput, low power, high memory density). At the same time, the memory access patterns of prevalent and emerging applications are rapidly diverging, as these applications manipulate larger data sets in very different ways. As a result, the combined DRAM-workload behavior is often difficult to intuitively determine today, which can hinder memory optimizations in both hardware and software. In this work, we identify important families of workloads, as well as prevalent types of DRAM chips, and rigorously analyze the combined DRAM-workload behavior. To this end, we perform a comprehensive experimental study of the interaction between nine different DRAM types (DDR3/4, LPDDR3/4, GDDR5, Wide I/O, Wide I/O 2, HBM, HMC) and 115 modern applications and multiprogrammed workloads from six diverse application families (desktop/scientific, server/cloud, multimedia acceleration, network acceleration, GPGPU, OS routines). We draw 12 key observations from our characterization, enabled in part by our development of new metrics that quantify the effect of memory access patterns on hardware utilization. We highlight our five most significant observations here: (1) Despite having 50% higher memory bandwidth than DDR3, the newer DDR4 rarely outperforms DDR3 on the applications we evaluate, as DDR4's access latency is 11-14% higher. (2) The high-bandwidth HMC does not outperform DDR3 for most single-thread workloads and many multithreaded applications. This is because HMC's design trade-offs (e.g., a row width that is 97% smaller than DDR3) fundamentally limit opportunities for exploiting spatial locality. For example, single-thread desktop and scientific applications actually perform 5.8% worse with HMC than with DDR3, on average, even though HMC offers 87.4% more memory bandwidth. HMC provides significant performance improvements over other DRAM types in cases where application spatial locality is low(or is destroyed), such as highly-memory-intensive multiprogrammed workloads. (3) While low-power DRAM types typically perform worse than standard-power DRAM for most memory-intensive applications, some low-power DRAM types perform well when bandwidth demand is very high. For example, on average, LPDDR4 performs only 7.0% worse than DDR3 for our multiprogrammed desktop workloads, while consuming 68.2% less energy, and Wide I/O 2 performs 2.3% better than DDR3 for multimedia acceleration. (4) The best DRAM for a heterogeneous system depends heavily on the predominant function(s) performed by the system. We study three types of applications for heterogeneous systems. First, multimedia acceleration benefits most from high-throughput memories that exploit a high amount of spatial locality, running up to 21.6% faster with GDDR5 and 14.7% faster with HBM than DDR3, but only 5.0% faster with HMC. Second, a network accelerator's memory requests are highly bursty and do not exhibit significant spatial locality, and are thus a good fit for the high bank-level parallelism of HMC (88.4% faster on average over DDR3). Third, GPGPU applications exhibit a wide range of memory intensity, but memory-intensive GPGPU applications typically also take advantage of spatial locality due to memory coalescing, and perform more effectively with HBM (26.9% higher on average over DDR3) and GDDR5 (39.7%) than with DDR3 or HMC. (5) Several common OS routines (e.g., file I/O, process forking) exhibit extremely high spatial locality, and do not benefit from high amounts of bank-level parallelism. As a result, they perform better with memories such as DDR3 and GDDR5, which have lower access latencies than the other memory types that we study. Since OS routines are used across most computer systems in a widespread manner, we believe DRAM designers must provide low-latency access, instead of the current trend increasing the latency in order to deliver greater throughput. For more information on our extensive experimental characterization, we refer the reader to the full version of our paper. We hope that the trends we identify can drive optimizations in both hardware and software design. To aid further study, we open-source our extensively-modified simulators, as well as MemBen, a benchmark suite containing our applications.", "venue": "Measurement and Modeling of Computer Systems", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2019-06-20", "journal": {"name": "Abstracts of the 2019 SIGMETRICS/Performance Joint International Conference on Measurement and Modeling of Computer Systems"}, "authors": [{"authorId": "33801185", "name": "Saugata Ghose"}, {"authorId": "3257288", "name": "Tianshi Li"}, {"authorId": "19170520", "name": "Nastaran Hajinazar"}, {"authorId": "70029851", "name": "Damla Senol Cali"}, {"authorId": "145929920", "name": "O. Mutlu"}], "citations": [{"paperId": "f275782ae08158ca9945676fdf499c5c9de09fb3", "title": "Accelerating Sparse Tensor Decomposition Using Adaptive Linearized Representation"}, {"paperId": "c9edf92c1f762c52a90cc0cb45eb06d4eed82110", "title": "MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Computing"}, {"paperId": "d5f2e95be45d3e003655a9a84e0adda9468b0838", "title": "MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Processing"}, {"paperId": "8c5ef03e9118253ec019965bf142d1be7998a453", "title": "Functionally-Complete Boolean Logic in Real DRAM Chips: Experimental Characterization and Analysis"}, {"paperId": "6ba01138fcabdc9df56e8a69588a82fd91480a63", "title": "Spatial Variation-Aware Read Disturbance Defenses: Experimental Analysis of Real DRAM Chips and Implications on Future Solutions"}, {"paperId": "763488734b9b5f6f475838c43746cf16f3fe5b0a", "title": "Rethinking the Producer-Consumer Relationship in Modern DRAM-Based Systems"}, {"paperId": "e82e950aca92ed94f5ff5901c557cae2453396ad", "title": "MetaStore: High-Performance Metagenomic Analysis via In-Storage Computing"}, {"paperId": "cccf7e41660e45992cb2052ed64f06470086b908", "title": "Siloz: Leveraging DRAM Isolation Domains to Prevent Inter-VM Rowhammer"}, {"paperId": "3f42e18e10f251bd0e1ac25981f65451568ccc9b", "title": "CDAR-DRAM: Enabling Runtime DRAM Performance and Energy Optimization via In-Situ Charge Detection and Adaptive Data Restoration"}, {"paperId": "ceda5606b2189405adb20b12424e12388acb0a4e", "title": "RowPress: Amplifying Read Disturbance in Modern DRAM Chips"}, {"paperId": "2dfbef5f657e7e53916dc2ed1038abd1e32c43e9", "title": "An Experimental Analysis of RowHammer in HBM2 DRAM Chips"}, {"paperId": "05f3fd64e1d6479a95458613381ad4fe595d0516", "title": "DSAC: Low-Cost Rowhammer Mitigation Using In-DRAM Stochastic and Approximate Counting Algorithm"}, {"paperId": "8b9292e23a5880d0e8e16a07ea995c65f5f3e89f", "title": "Exploring Pareto-Optimal Hybrid Main Memory Configurations Using Different Emerging Memories"}, {"paperId": "ce0a2e51574ba380ea12ceeba8aa81821a8256af", "title": "Automatic DRAM Subsystem Configuration with irace"}, {"paperId": "8c935fc93868cc7766d2083e833f54ad2f6e7f3a", "title": "Toward Energy-Efficient Sparse Matrix-Vector Multiplication with Near STT-MRAM Computing Architecture"}, {"paperId": "452a416cbd7cde150f6ab33df7ada10a4c1ff162", "title": "A Low-Cost Reduced-Latency DRAM Architecture With Dynamic Reconfiguration of Row Decoder"}, {"paperId": "d32ccb6b56ae85efde63e5692a35d5c7e46f784a", "title": "RevaMp3D: Architecting the Processor Core and Cache Hierarchy for Systems with Monolithically-Integrated Logic and Memory"}, {"paperId": "2eefa611c1def246d61db3d6089bbdb380fdd8e9", "title": "Unveiling the Real Performance of LPDDR5 Memories"}, {"paperId": "3a2548a8286a15e0141dba6008f0eae2ac1ad724", "title": "Flash-Cosmos: In-Flash Bulk Bitwise Operations Using Inherent Computation Capability of NAND Flash Memory"}, {"paperId": "ac6b94543492cc4cac95d72240179dcf018ff38d", "title": "EnforceSNN: Enabling resilient and energy-efficient spiking neural network inference considering approximate DRAMs for embedded systems"}, {"paperId": "87b07a8268cc912825a68c9778e454b2d1fb99dd", "title": "Near-memory Computing on FPGAs with 3D-stacked Memories: Applications, Architectures, and Optimizations"}, {"paperId": "66905bb52c89d44594cf3e87ab23d5aba7ce45aa", "title": "MOESI-prime: preventing coherence-induced hammering in commodity workloads"}, {"paperId": "2106b4aa6b61168c317dccd94f8ded96bbae10b8", "title": "PiDRAM: An FPGA-based Framework for End-to-end Evaluation of Processing-in-DRAM Techniques"}, {"paperId": "5695f14582e4cef36d3fc41d4a52da4b2ffbcafa", "title": "SeGraM: a universal hardware accelerator for genomic sequence-to-graph and sequence-to-sequence mapping"}, {"paperId": "40b261c056da0e26f598b75000a6bccafffd09fd", "title": "A Case for Transparent Reliability in DRAM Systems"}, {"paperId": "9534c90b7c19020a686ddee51d8b6899277c87c9", "title": "DRAMSys4.0: An Open-Source Simulation Framework for In-depth DRAM Analyses"}, {"paperId": "729e8ed4e3356cded9b1a465f72a76813bac62a1", "title": "GenStore: a high-performance in-storage processing system for genome sequence analysis"}, {"paperId": "e26971448910591e39bc26d159c37e68cd950787", "title": "Data Convection"}, {"paperId": "4d3fb0382d679483570650e091c89a086a585c07", "title": "GenStore: A High-Performance and Energy-Efficient In-Storage Computing System for Genome Sequence Analysis"}, {"paperId": "361b14bbd0345f404c3be486464fb3cb6c78aad4", "title": "PiDRAM: A Holistic End-to-end FPGA-based Framework for Processing-in-DRAM"}, {"paperId": "7b78d629c823f6345343cce85a11f3d95aa4ac3e", "title": "Benchmarking Memory-Centric Computing Systems: Analysis of Real Processing-In-Memory Hardware"}, {"paperId": "3abce1cd005299308f86bfead113bdc2ffdcfc7c", "title": "DuoMC: Tight DRAM Latency Bounds with Shared Banks and Near-COTS Performance"}, {"paperId": "e2bcac2fc8791c8d3624ad52502c5d8e62380d59", "title": "An LPDDR4 Safety Model for Automotive Applications"}, {"paperId": "55498b39456290025c43e26cd269b11b353fe281", "title": "ReSpawn: Energy-Efficient Fault-Tolerance for Spiking Neural Networks considering Unreliable Memories"}, {"paperId": "2a47d481636a67bf1edbd2bcd73d823e69bc4c75", "title": "Accelerating Weather Prediction Using Near-Memory Reconfigurable Fabric"}, {"paperId": "8e87c31c9174c254b824910e28b5bf66f274650e", "title": "Benchmarking a New Paradigm: An Experimental Analysis of a Real Processing-in-Memory Architecture"}, {"paperId": "8e85281351edfd13081f1175fb102836ccc4baca", "title": "DAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks"}, {"paperId": "e0f51713d61f91850e8a20073951e5e03d28c2c4", "title": "Holistic defenses against microarchitectural attacks"}, {"paperId": "01178c1dc4555d388fb773f5966c98783b567095", "title": "ALTO: adaptive linearized storage of sparse tensors"}, {"paperId": "304b971520976e3a060abfd23399108434a3308e", "title": "BlockHammer: Preventing RowHammer at Low Cost by Blacklisting Rapidly-Accessed DRAM Rows"}, {"paperId": "9817bf0f78047452761e950c02a1a56f59a1e593", "title": "SynCron: Efficient Synchronization Support for Near-Data-Processing Architectures"}, {"paperId": "8dd6c84dce582389df1c0b72471d7ab1e0b9f27b", "title": "Understanding Power Consumption and Reliability of High-Bandwidth Memory with Voltage Underscaling"}, {"paperId": "7bb6015f45457fdbe3bb39e17dc9cb0786ecd688", "title": "A Modern Primer on Processing in Memory"}, {"paperId": "0f5bede8ed9412fecffbeafdc4581a7b51753e95", "title": "Exploring Memory Access Patterns for Graph Processing Accelerators"}, {"paperId": "f90f526b101cb8a0260f5165a3875928c58ae48a", "title": "NATSA: A Near-Data Processing Accelerator for Time Series Analysis"}, {"paperId": "46c462c389080d0eec5df105af5817e856bea89c", "title": "WoLFRaM: Enhancing Wear-Leveling and Fault Tolerance in Resistive Memories using Programmable Address Decoders"}, {"paperId": "9e5140f40c2dc97eff173fefe9d73337f4a523fc", "title": "FIGARO: Improving System Performance via Fine-Grained In-DRAM Data Relocation and Caching"}, {"paperId": "93dbd399b2c3d67754ee363250f8976850deef69", "title": "GenASM: A High-Performance, Low-Power Approximate String Matching Acceleration Framework for Genome Sequence Analysis"}, {"paperId": "817dd0fd0eaa9082f949204241c17560e80bd547", "title": "NERO: A Near High-Bandwidth Memory Stencil Accelerator for Weather Prediction Modeling"}, {"paperId": "42cc29152f725c0f94646558b0d8ea379d55be5a", "title": "3D-Stacked Memory For Shared-Memory Multithreaded Workloads"}, {"paperId": "3c8c28f979db20da445d9baf9fbf49522b19dff2", "title": "SysScale: Exploiting Multi-domain Dynamic Voltage and Frequency Scaling for Energy Efficient Mobile Processors"}, {"paperId": "acdfe34aab867d1a0101c88dba299a56274388d8", "title": "CLR-DRAM: A Low-Cost DRAM Architecture Enabling Dynamic Capacity-Latency Trade-Off"}, {"paperId": "ec6ca596b8a74e2a2c6a525fb9ccd3476c20eb3e", "title": "Revisiting RowHammer: An Experimental Analysis of Modern DRAM Devices and Mitigation Techniques"}, {"paperId": "21da3bfd4babc61c785859395cd146b29b75e59d", "title": "DRMap: A Generic DRAM Data Mapping Policy for Energy-Efficient Processing of Convolutional Neural Networks"}, {"paperId": "64de7c5a2434e8293c86dcc223283280a584604c", "title": "Demystifying Complex Workload-DRAM Interactions"}, {"paperId": "2ca11e69ae23eb51cdbc35f9b6a2981b3f5fdc0c", "title": "Refresh Triggered Computation"}, {"paperId": "ae216775f6d86773da7eeac27d361de019f386bb", "title": "EDEN: Enabling Energy-Efficient, High-Performance Deep Neural Network Inference Using Approximate DRAM"}, {"paperId": "3cf6a8031e5bd9e9680f819b6f272b236715d9ff", "title": "DSPatch: Dual Spatial Pattern Prefetcher"}, {"paperId": "f58b2906b3b8391e534f47ead2264f3dc4498589", "title": "Enabling and Exploiting Partition-Level Parallelism (PALP) in Phase Change Memories"}, {"paperId": "49532cb16924c06454301f989e2c37c9accc6cd3", "title": "A Workload and Programming Ease Driven Perspective of Processing-in-Memory"}, {"paperId": "b0197170bd915f3d4060096e5ffd8eed5f14f61f", "title": "CROW: A Low-Cost Substrate for Improving DRAM Performance, Energy Efficiency, and Reliability"}, {"paperId": "0ae04755143947de7618715c843744a82d75bc48", "title": "CoNDA: Efficient Cache Coherence Support for Near-Data Accelerators"}, {"paperId": "1c69b3bc6bbd9b1f0d6c58251d4be9f2193e9ddc", "title": "ROMANet: Fine-Grained Reuse-Driven Off-Chip Memory Access Management and Data Organization for Deep Neural Network Accelerators"}, {"paperId": "084809bcb66911c8cef94879311beb96d11bc6a6", "title": "Benchmarking a New Paradigm: Experimental Analysis and Characterization of a Real Processing-in-Memory System"}, {"paperId": "d1eb487fb036d05f5710f40d5217eb875a4b70e8", "title": "Sectored DRAM: An Energy-Efficient High-Throughput and Practical Fine-Grained DRAM Architecture"}, {"paperId": "60171634659cee07793a295489d8eeda9f785832", "title": "Parity Models: Erasure-Coded Resilience for Prediction Serving Systems"}, {"paperId": "a810a5adc1f90df6e90586b511c1fe709cbec20e", "title": "Lab 3: Memory Request Scheduling"}]}

{"paperId": "dd454b89302ff1650a31137a2da4b47ae089e41c", "publicationVenue": null, "title": "Distributed query processing over fluctuating streams", "abstract": "In a Big Data context, stream processing has become a very active research domain. In order to manage ephemeral data (Velocity) arriving at important rates (Volume), some specific solutions, denoted data stream management systems (DSMSs), have been developed. DSMSs take as inputs some queries, called continuous queries,defined on a set of data streams. A continuous query generates new results as long as new data arrive in input. In many application domains, data streams have input rates and distribution of values which change over time. These variations may impact significantly processing requirements for each continuous query. \nThis thesis takes place in the ANR project Socioplug (ANR-13-INFR-0003). In this context, we consider a collaborative platform for stream processing. Each user can submit multiple continuous queries and contributes to the execution support of the platform. However, as each processing unit supporting treatments has limited resources in terms of CPU and memory, a significant increase in input rate may cause the congestion of the system. The problem is then how to adjust dynamically resource usage to processing requirements for each continuous query ? It raises several challenges : i) how to detect a need of reconfiguration ? ii) when reconfiguring the system to avoid its congestion at runtime ? iii) how to avoid reconfigurations that do not improves the performance of the system ? \nIn this work, we are interested by the different processing steps involved in the treatment of a continuous query over a distributed infrastructure. From this global analysis, we extract mechanisms enabling dynamic adaptation of resource usage for each continuous query. We focus on automatic parallelization, or auto-parallelization, of operators composing the execution plan of a continuous query. We suggest an original approach based on the monitoring of operators and an estimation of processing requirements in near future. Thus, we can increase (scale-out), or decrease (scale-in) the parallelism degree of operators in a proactive way such as resource usage fits to processing requirements dynamically. Compared to a static configuration defined by an expert, we show that it is possible to avoid the congestion of the system in many cases or to delay it in most critical cases. Moreover, we show that resource usage can be reduced significantly while delivering equivalent throughput and result quality. \nWe suggest also to combine this approach with complementary mechanisms for dynamic adaptation of continuous queries at runtime. These differents approaches have been implemented within a widely used DSMS and have been tested over multiple and reproductible micro-benchmarks.", "venue": "", "year": 2018, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2018-06-29", "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "20750883", "name": "Roland Kotto Kombi"}], "citations": []}

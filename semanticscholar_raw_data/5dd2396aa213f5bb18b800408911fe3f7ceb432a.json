{"paperId": "5dd2396aa213f5bb18b800408911fe3f7ceb432a", "publicationVenue": {"id": "0aed7a40-85f3-4c66-9e1b-c1556c57001b", "name": "PLoS ONE", "type": "journal", "alternate_names": ["Plo ONE", "PLOS ONE", "PLO ONE"], "issn": "1932-6203", "url": "https://journals.plos.org/plosone/", "alternate_urls": ["http://www.plosone.org/"]}, "title": "Quantifying gender biases towards politicians on Reddit", "abstract": "Despite attempts to increase gender parity in politics, global efforts have struggled to ensure equal female representation. This is likely tied to implicit gender biases against women in authority. In this work, we present a comprehensive study of gender biases that appear in online political discussion. To this end, we collect 10 million comments on Reddit in conversations about male and female politicians, which enables an exhaustive study of automatic gender bias detection. We address not only misogynistic language, but also other manifestations of bias, like benevolent sexism in the form of seemingly positive sentiment and dominance attributed to female politicians, or differences in descriptor attribution. Finally, we conduct a multi-faceted study of gender bias towards politicians investigating both linguistic and extra-linguistic cues. We assess 5 different types of gender bias, evaluating coverage, combinatorial, nominal, sentimental and lexical biases extant in social media language and discourse. Overall, we find that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians. Rather than overt hostile or benevolent sexism, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians. Female politicians are often named by their first names and are described in relation to their body, clothing, or family; this is a treatment that is not similarly extended to men. On the now banned far-right subreddits, this disparity is greatest, though differences in gender biases still appear in the right and left-leaning subreddits. We release the curated dataset to the public for future studies.", "venue": "PLoS ONE", "year": 2021, "fieldsOfStudy": ["Computer Science", "Medicine"], "publicationTypes": ["JournalArticle"], "publicationDate": "2021-12-22", "journal": {"name": "PLOS ONE", "volume": "17"}, "authors": [{"authorId": "2146694845", "name": "S. Marjanovic"}, {"authorId": "82563120", "name": "Karolina Sta\u0144czak"}, {"authorId": "1736067", "name": "Isabelle Augenstein"}], "citations": [{"paperId": "d456a1b018616e9ffb1abc3a4ff250b99e1871ed", "title": "How do medical professionals make sense (or not) of AI? A social-media-based computational grounded theory study and an online survey"}, {"paperId": "14f16ff865945885c638f107d4b0619dddf4a82e", "title": "Soft-prompt Tuning for Large Language Models to Evaluate Bias"}, {"paperId": "99f540099d22c1c783c96717a552eed444b95627", "title": "Measuring Intersectional Biases in Historical Documents"}, {"paperId": "641f1e845c5baa1b6282a803a928c83290ddf669", "title": "Measuring Gender Bias in West Slavic Language Models"}, {"paperId": "04ec406caebff60e226695c921f0af1b29162c5f", "title": "A Survey on Gender Bias in Natural Language Processing"}, {"paperId": "5c454bc9e97310ea558097e01a77a6a7bca028ab", "title": "A Leader and a Lady? A Computational Approach to Detection of Political Gender Stereotypes in Facebook User Comments"}]}

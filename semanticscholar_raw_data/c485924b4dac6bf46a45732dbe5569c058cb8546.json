{"paperId": "c485924b4dac6bf46a45732dbe5569c058cb8546", "publicationVenue": {"id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd", "name": "Neural Information Processing Systems", "type": "conference", "alternate_names": ["Neural Inf Process Syst", "NeurIPS", "NIPS"], "url": "http://neurips.cc/"}, "title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs", "abstract": "Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source machine learning programs, featuring popular model architectures, e.g., ResNet, EfficientNet, Mask R-CNN, and Transformer. TpuGraphs provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs. This graph-level prediction task on large graphs introduces new challenges in learning, ranging from scalability, training efficiency, to model quality.", "venue": "Neural Information Processing Systems", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-08-25", "journal": {"name": "ArXiv", "volume": "abs/2308.13490"}, "authors": [{"authorId": "2623548", "name": "P. Phothilimthana"}, {"authorId": "1389570466", "name": "Sami Abu-El-Haija"}, {"authorId": "48865984", "name": "Kaidi Cao"}, {"authorId": "3422551", "name": "Bahare Fatemi"}, {"authorId": "32532671", "name": "Charith Mendis"}, {"authorId": "2271808", "name": "Bryan Perozzi"}], "citations": [{"paperId": "9c1628f73689e5a2e0ddcd4da3d93492085b9e36", "title": "Polynormer: Polynomial-Expressive Graph Transformer in Linear Time"}, {"paperId": "05c133c0b5863db8b8c36b4d37fcdb0d0f000715", "title": "Based on TPUGRAPHS Predicting Model Runtimes Using Graph Neural Networks"}, {"paperId": "3b7750ebd7be28146ed09fc17df8cd6ea6c360d2", "title": "Learning Large Graph Property Prediction via Graph Segment Training"}, {"paperId": "4ebcadfea9dfe5949a9220eea3f88c02c347d724", "title": "GNNs for TPU Graphs"}]}

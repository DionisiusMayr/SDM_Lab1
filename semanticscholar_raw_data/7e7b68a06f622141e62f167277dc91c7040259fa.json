{"paperId": "7e7b68a06f622141e62f167277dc91c7040259fa", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Portability of Scientific Workflows in NGS Data Analysis: A Case Study", "abstract": "The analysis of next-generation sequencing (NGS) data requires complex computational workflows consisting of dozens of autonomously developed yet interdependent processing steps. Whenever large amounts of data need to be processed, these workflows must be executed on a parallel and/or distributed systems to ensure reasonable runtime. Porting a workflow developed for a particular system on a particular hardware infrastructure to another system or to another infrastructure is non-trivial, which poses a major impediment to the scientific necessities of workflow reproducibility and workflow reusability. In this work, we describe our efforts to port a state-of-the-art workflow for the detection of specific variants in whole-exome sequencing of mice. The workflow originally was developed in the scientific workflow system snakemake for execution on a high-performance cluster controlled by Sun Grid Engine. In the project, we ported it to the scientific workflow system SaasFee that can execute workflows on (multi-core) stand-alone servers or on clusters of arbitrary sizes using the Hadoop. The purpose of this port was that also owners of low-cost hardware infrastructures, for which Hadoop was made for, become able to use the workflow. Although both the source and the target system are called scientific workflow systems, they differ in numerous aspects, ranging from the workflow languages to the scheduling mechanisms and the file access interfaces. These differences resulted in various problems, some expected and more unexpected, that had to be resolved before the workflow could be run with equal semantics. As a side-effect, we also report cost/runtime ratios for a state-of-the-art NGS workflow on very different hardware platforms: A comparably cheap stand-alone server (80 threads), a mid-cost, mid-sized cluster (552 threads), and a high-end HPC system (3784 threads).", "venue": "arXiv.org", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-06-04", "journal": {"name": "ArXiv", "volume": "abs/2006.03104"}, "authors": [{"authorId": "90982081", "name": "C. Schiefer"}, {"authorId": "145484939", "name": "M. Bux"}, {"authorId": "3056426", "name": "J. Brandt"}, {"authorId": "29929702", "name": "Clemens Messerschmidt"}, {"authorId": "2031588", "name": "K. Reinert"}, {"authorId": "49683177", "name": "D. Beule"}, {"authorId": "1693022", "name": "U. Leser"}], "citations": [{"paperId": "1b090b9ee520aa20f0c9cc1ad95f6d93f9f92d7e", "title": "Validity Constraints for Data Analysis Workflows"}, {"paperId": "0c7fac156fdcf0b82e1a827a390c9db58ffa9845", "title": "A Community Roadmap for Scientific Workflows Research and Development"}, {"paperId": "daa1b2301e42c75fb98ef23f2a69f2bfec8fd780", "title": "Workflows Community Summit: Advancing the State-of-the-art of Scientific Workflows Management Systems Research and Development"}, {"paperId": "329ab6c819f83f3060a008ef5950916dcde13bf8", "title": "Workflows Community Summit"}, {"paperId": "609968be423843d3af8fb13e5feec0753a6ab068", "title": "FORCE on Nextflow: Scalable Analysis of Earth Observation Data on Commodity Clusters"}]}

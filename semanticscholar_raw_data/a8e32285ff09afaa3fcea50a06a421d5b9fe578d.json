{"paperId": "a8e32285ff09afaa3fcea50a06a421d5b9fe578d", "publicationVenue": {"id": "e4f51561-5050-4b9c-87c2-c49957677fbf", "name": "European Conference on Computer Systems", "type": "conference", "alternate_names": ["Eur Conf Comput Syst", "EuroSys"], "url": "http://www.eurosys.org/"}, "title": "SiloD: A Co-design of Caching and Scheduling for Deep Learning Clusters", "abstract": "Deep learning training on cloud platforms usually follows the tradition of the separation of storage and computing. The training executes on a compute cluster equipped with GPUs/TPUs while reading data from a separate cluster hosting the storage service. To alleviate the potential bottleneck, a training cluster usually leverages its local storage as a cache to reduce the remote IO from the storage cluster. However, existing deep learning schedulers do not manage storage resources thus fail to consider the diverse caching effects across different training jobs. This could degrade scheduling quality significantly. To address this issue, we present SiloD, a scheduling framework that co-designs the cluster scheduler and the cache subsystems for deep learning training. SiloD treats cache and remote IO as first-class resources and can integrate different state-of-the-art deep learning scheduling policies in a unified scheduling framework. To achieve this, SiloD develops an enhanced job performance estimator to help different schedulers to jointly consider the impact of storage and compute resource allocation while preserving their respective scheduling objectives. The SiloD-enhanced performance estimator leverages the unique data access pattern of deep learning training to develop a closed-form analytic model that captures the diverse cache / remote IO requirements from different training jobs. Evaluations show that SiloD improves the average job completion time, cluster utilization, and fairness by up to 7.4x, 2.57x, and 1.89x, respectively, compared to different combinations of cache systems and cluster schedulers where they operate independently.", "venue": "European Conference on Computer Systems", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2023-05-08", "journal": {"name": "Proceedings of the Eighteenth European Conference on Computer Systems"}, "authors": [{"authorId": "47941070", "name": "Hanyu Zhao"}, {"authorId": "144518950", "name": "Zhenhua Han"}, {"authorId": "98256743", "name": "Zhi Yang"}, {"authorId": "3123382", "name": "Quanlu Zhang"}, {"authorId": "50651333", "name": "Mingxia Li"}, {"authorId": "145338263", "name": "Fan Yang"}, {"authorId": "2108076499", "name": "Qianxi Zhang"}, {"authorId": "2112206288", "name": "Binyang Li"}, {"authorId": "2108623481", "name": "Yuqing Yang"}, {"authorId": "2160727304", "name": "Lili Qiu"}, {"authorId": "1978393184", "name": "Lintao Zhang"}, {"authorId": "2143359114", "name": "Lidong Zhou"}], "citations": [{"paperId": "398bb60aed5d51d2053349f4149c5f44257ff850", "title": "cedar: Composable and Optimized Machine Learning Input Data Pipelines"}, {"paperId": "f4a8bba4817713c9e7ae3b6f5c9ed0f5bb3737ff", "title": "Joint Task Scheduling and Container Image Caching in Edge Computing"}, {"paperId": "50afc14226af83b4fc4276601bb310cc8627665b", "title": "Objcache: An Elastic Filesystem over External Persistent Storage for Container Clusters"}, {"paperId": "9ebb7441eb3c39b7fdba2342cd3f47976ec1daab", "title": "Dynamic Resource Allocation for Deep Learning Clusters with Separated Compute and Storage"}, {"paperId": "883b5a6cbbf3c499c8402204a657abf1e836d310", "title": "Deep Learning Workload Scheduling in GPU Datacenters: A Survey"}, {"paperId": "31d3c657987119aaa1e0b8306c0abbe84bf35222", "title": "A Survey on Scheduling Techniques in Computing and Network Convergence"}]}

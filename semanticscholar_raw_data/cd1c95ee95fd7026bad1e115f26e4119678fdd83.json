{"paperId": "cd1c95ee95fd7026bad1e115f26e4119678fdd83", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations", "abstract": "Learning unsupervised world models for autonomous driving has the potential to improve the reasoning capabilities of today's systems dramatically. However, most work neglects the physical attributes of the world and focuses on sensor data alone. We propose MUVO, a MUltimodal World Model with Geometric VOxel Representations to address this challenge. We utilize raw camera and lidar data to learn a sensor-agnostic geometric representation of the world, which can directly be used by downstream tasks, such as planning. We demonstrate multimodal future predictions and show that our geometric representation improves the prediction quality of both camera images and lidar point clouds.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-20", "journal": {"name": "ArXiv", "volume": "abs/2311.11762"}, "authors": [{"authorId": "73381787", "name": "Daniel Bogdoll"}, {"authorId": "2267360955", "name": "Yitian Yang"}, {"authorId": "144727983", "name": "J. Zollner"}], "citations": [{"paperId": "5769879f6f17819fd3f03fd632b7015d7c2e312e", "title": "World Models for Autonomous Driving: An Initial Survey"}, {"paperId": "83ee82e62f2eae18cc3472120eb9004109895a31", "title": "Delving into Multi-modal Multi-task Foundation Models for Road Scene Understanding: From Learning Paradigm Perspectives"}, {"paperId": "550c32e252722c2ad6b3ac17703654d96cb2c600", "title": "Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities"}, {"paperId": "91e3906550821c4624146e6e87db36c3296e773a", "title": "Applications of Large Scale Foundation Models for Autonomous Driving"}]}

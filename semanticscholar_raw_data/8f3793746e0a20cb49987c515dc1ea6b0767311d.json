{"paperId": "8f3793746e0a20cb49987c515dc1ea6b0767311d", "publicationVenue": null, "title": "RHEEMix in the Data Jungle \u2013 A Cross-Platform Query Optimizer \u2013", "abstract": "In pursuit of e\u0081cient and scalable data analytics, the insight that \u201cone size does not \u0080t all\u201d has given rise to a plethora of specialized data processing platforms and today\u2019s complex data analytics are moving beyond the limits of a single platform. In this paper, we present the cost-based optimizer of Rheem, an open-source crossplatform system that copes with these new requirements. \u008ce optimizer allocates the subtasks of data analytic tasks to the most suitable platforms. Our main contributions are: (i) a mechanism based on graph transformations to explore alternative execution strategies; (ii) a novel graph-based approach to e\u0081ciently plan data movement among subtasks and platforms; and (iii) an e\u0081cient plan enumeration algorithm, based on a novel enumeration algebra. We extensively evaluate our optimizer under diverse real tasks. \u008ce results show that our optimizer is capable of selecting the most e\u0081cient platform combination for a given task, freeing data analysts from the need to choose and orchestrate platforms. In addition, our optimizer allows tasks to run more than one order of magnitude faster by using multiple platforms instead of a single platform. 1 CROSS-PLATFORM DATA PROCESSING Modern data analytics are characterized by (i) increasing query/task1 complexity, (ii) heterogeneity of data sources, and (iii) a proliferation of data processing platforms (platforms, for short). As a result, today\u2019s data analytics o\u0089en need to perform cross-platform data processing, i. e., running their tasks on more than one platform. \u008ce research and industry communities have recently identi\u0080ed this need [11, 47] and have proposed systems to support di\u0082erent aspects of cross-platform data processing [1, 10, 15, 23, 25, 28]. \u008ce current practice to cope with cross-platform requirements is to write ad-hoc programs to glue di\u0082erent specialized platforms together [1, 2, 5, 15, 24]. \u008cis approach is not only expensive and error-prone, but it also requires to know the intricacies of the di\u0082erent platforms to achieve high e\u0081ciency. \u008cus, there is an urgent need for a systematic solution that enables e\u0081cient crossplatform data processing without requiring users to specify which platform to use. \u008ce holy grail would be to replicate the success of DBMSs to cross-platform applications: users formulate platformagnostic data analytic tasks and an intermediate system decides \u2217Work partially done while interning at QCRI. 1Henceforth, we use the term task without loss of generality. on which platforms to execute each (sub)task with the goal of minimizing cost (e. g., runtime or monetary cost). Recent research works have taken \u0080rst steps towards that direction [23, 28, 46, 48]. Nonetheless, they all lack important aspects. For instance, none of these works consider di\u0082erent alternatives for data movement, even though having a single way to move data from one platform to another (e. g., via \u0080les) may hinder cross-platform opportunities. Additionally, most focus on speci\u0080c applications, such as ETL [46] or speci\u0080c platforms [22, 34]. Recently, commercial engines, such as DB2 and Teradata, have extended their systems to support di\u0082erent platforms but none provides a systematic solution, i. e., users have to specify the platform to use. \u008ce key component for such a systematic solution is a crossplatform optimizer and it is thus the focus of this paper. Concretely, we consider the problem of \u0080nding the set of platforms that minimizes the execution cost of a given task. One might think of a rulebased optimizer: e. g., execute a task on a centralized/distributed platform when the input data is small/large. However, this approach is neither practical nor e\u0082ective. First, se\u008aing rules at the task level implicitly assumes that all the operations in a task have the same computational complexity and input cardinality. Such assumptions do not hold in practice, though. Second, the cost of a task on any given platform depends on many input parameters, which hampers a rule-based optimizer\u2019s e\u0082ectiveness as it oversimpli\u0080es the problem. \u008cird, as new platforms and applications emerge, maintaining a rule-based optimizer becomes very cumbersome. We thus pursue a cost-based approach. Devising a cost-based optimizer for cross-platform se\u008aings is quite challenging for many reasons: (i) the optimization search space grows exponentially with the number of atomic operations of the given data analytic task; (ii) platforms vastly di\u0082er w. r. t. their supported operations and processing abstractions; (iii) the optimizer must consider the cost of moving data across platforms; (iv) crossplatform se\u008aings are characterized by high uncertainty, i. e., data distributions are typically unknown and cost functions are hard to calibrate; and (iv) the optimizer must be extensible to accommodate new platforms and emerging application requirements. In this paper, we delve into the cross-platform optimizer of Rheem [9, 10], our open source cross-platform system [7]. To the best of our knowledge, our optimizer is the \u0080rst to tackle all of the above challenges. \u008ce idea is to split a single task into multiple atomic operators and to \u0080nd the most suitable platform for each ar X iv :1 80 5. 03 53 3v 2 [ cs .D B ] 1 5 O ct 2 01 8 operator (or set of operators) so that its cost is minimized. A\u0089er giving an overview on our optimizer (Section 2), we present our major contributions: (1) We propose a plan in\u0083ation mechanism that is a very compact representation of the entire plan search space and provide a cost model purely based on UDFs (Section 3). (2) We model data movement for cross-platform optimization as a new graph problem, which we prove to be NP-hard, and propose an e\u0081cient algorithm to solve it (Section 4). (3) We devise a new algebra and a new lossless pruning technique to enumerate executable cross-platform plans for a given task in a highly e\u0081cient manner (Section 5). (4) We discuss how we exploit our optimization pipeline for performing progressive optimization in order to deal with poor cardinality estimates (Section 6). (5) We extensively evaluate our optimizer under diverse tasks using real-world datasets and show that it allows tasks to run more than one order of magnitude faster by using multiple platforms instead of a single platform (Section 7). Eventually, we discuss related work (Section 8) and conclude this paper with a summary (Section 9). 2 BACKGROUND AND OVERVIEW Rheem background. Rheem decouples applications from platforms in order to enable cross-platform data processing. Although decoupling data processing was the driving motive when designing Rheem, we also adopted a three-layer decoupled optimization approach, as envisioned in [11]. One can see this three-layer optimization as a separation of concerns for query optimization. Overall, as Rheem applications have good knowledge of the tasks\u2019 logic and the data they operate on, they are in charge of any logical, such as operator re-ordering (the application optimization layer). Rheem receives from applications an optimized procedural plan, for which it determines the best platforms for execution (the core optimization layer). \u008cen, the selected platforms run the plan by performing further physical platform-speci\u0080c optimizations, such as se\u008aing the data bu\u0082er sizes (the platform optimization layer). Rheem is at the core optimization layer. Rheem is composed of two main components (among others): the cross-platform optimizer and the executor. \u008ce cross-platform optimizer gets as input a Rheem plan and produces an execution plan by specifying the platform to use for each operator in the Rheem plan. In turn, the executor orchestrates and monitors the execution of the generated execution plan on the selected platforms. In this paper, we focus on the cross-platform optimizer. Below, we \u0080rst detail what Rheem and execution plans are and then give an overview of our cross-platform optimizer. Rheem plan. As stated above, the input to Rheem optimizer is a procedural Rheem plan, which is essentially a directed data \u0083ow graph. \u008ce vertices are Rheem operators and the edges represent the data \u0083ow among the operators. Only Loop operators accept feedback edges, thus enabling iterative data \u0083ows. A Rheem plan without any loop operator is essentially an acyclic graph. Conceptually, the data is \u0083owing from source operators through the graph and is manipulated in the operators until it reaches a sink operator. Rheem operators are platform-agnostic and de\u0080ne a particular kind of data transformation over their input, e. g., a Reduce operator aggregates all input data into a single output. RepeatLoop Map parse", "venue": "", "year": 2018, "fieldsOfStudy": null, "publicationTypes": ["Review"], "publicationDate": null, "journal": null, "authors": [{"authorId": "2265955636", "name": "Sebastian Kruse"}], "citations": []}

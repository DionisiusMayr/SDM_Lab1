{"paperId": "7e40d0d3e94bfd03e5d749e0cfd70b70157950c4", "publicationVenue": {"id": "29df4b17-9a16-4a4c-94a6-002f52e628b4", "name": "International Conference on Parallel Processing", "type": "conference", "alternate_names": ["ICPP", "Int Conf Parallel Process", "IEEE Int Conf Pulsed Power", "IEEE International Conference on Pulsed Power"], "url": "http://www.wikicfp.com/cfp/program?id=1447"}, "title": "Improving Short Job Latency Performance in Hybrid Job Schedulers with Dice", "abstract": "It is common to find a mixture of both long batch jobs and latency-sensitive short jobs in enterprise data centers. Recently hybrid job schedulers emerge as attractive alternatives of conventional centralized job schedulers. In this paper, we conduct trace-driven experiments to study the job-completion-delay performance of two representative hybrid job schedulers (Hawk and Eagle), and find that short jobs still encounter long latency issues due to fluctuating bursty nature of workloads. To this end, we propose Dice, a general performance optimization framework for hybrid job schedulers, to alleviate the high job-completion-delay problem of short jobs. Dice is composed of two simple yet effective techniques: Elastic Sizing and Opportunistic Preemption. Both Elastic Sizing and Opportunistic Preemption keep track of the task waiting times of short jobs. When the mean task waiting time of short jobs is high, Elastic Sizing dynamically and adaptively increases the short partition size to prioritize short jobs over long jobs. On the other hand, Opportunistic Preemption preempts resources from long tasks running in the general partition on demand, so as to mitigate the \"head-of-line\" blocking problem of short jobs. We enhance the two schedulers with Dice and evaluate Dice performance improvement in our prototype implementation. Experiment results show that Dice achieves 50.9%, 54.5%, and 43.5% improvement on 50th-percentile, 75th-percentile, and 90th-percentile job completion delays of short jobs in Hawk respectively, as well as 33.2%, 74.1%, and 85.3% improvement on those in Eagle respectively under the Google trace, at low performance costs to long jobs.", "venue": "International Conference on Parallel Processing", "year": 2019, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2019-08-05", "journal": {"name": "Proceedings of the 48th International Conference on Parallel Processing"}, "authors": [{"authorId": null, "name": "Wei Zhou"}, {"authorId": "145335913", "name": "K. White"}, {"authorId": "150129397", "name": "Hongfeng Yu"}], "citations": [{"paperId": "4f005efd52334f68cace00980c69fba6326e79f8", "title": "G\u00f6del: Unified Large-Scale Resource Management and Scheduling at ByteDance"}, {"paperId": "2cf7973d70364263e1414d7fc78fe8178866538e", "title": "Holistic Resource Scheduling for Data Center In-Network Computing"}, {"paperId": "d037f3df7bcad91c18f394855054abf990f7bb40", "title": "Switches for HIRE: resource scheduling for data center in-network computing"}, {"paperId": "0fdec60e25a90214888201808d48525423f3d63c", "title": "Megha: Decentralized Global Fair Scheduling for Federated Clusters"}, {"paperId": "626e218fed651a454f35cd3e7da5f26ba165454c", "title": "Eirene: Improving Short Job Latency Performance with Coordinated Cold Data Migration and Scheduler-Aware Task Cloning"}, {"paperId": "d7998a6ef5e5ff8e9573b0000d6f69861f5872ab", "title": "Progress-based Container Scheduling for Short-lived Applications in a Kubernetes Cluster"}]}

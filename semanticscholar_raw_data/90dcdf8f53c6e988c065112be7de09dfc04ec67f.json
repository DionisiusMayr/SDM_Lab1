{"paperId": "90dcdf8f53c6e988c065112be7de09dfc04ec67f", "publicationVenue": {"id": "a0edb93b-1e95-4128-a295-6b1659149cef", "name": "Knowledge Discovery and Data Mining", "type": "conference", "alternate_names": ["KDD", "Knowl Discov Data Min"], "url": "http://www.acm.org/sigkdd/"}, "title": "Practical Lossless Federated Singular Vector Decomposition over Billion-Scale Data", "abstract": "With the enactment of privacy-preserving regulations, e.g., GDPR, federated SVD is proposed to enable SVD-based applications over different data sources without revealing the original data. However, many SVD-based applications cannot be well supported by existing federated SVD solutions. The crux is that these solutions, adopting either differential privacy (DP) or homomorphic encryption (HE), suffer from accuracy loss caused by unremovable noise or degraded efficiency due to inflated data. In this paper, we propose FedSVD, a practical lossless federated SVD method over billion-scale data, which can simultaneously achieve lossless accuracy and high efficiency. At the heart of FedSVD is a lossless matrix masking scheme delicately designed for SVD: 1) While adopting the masks to protect private data, FedSVD completely removes them from the final results of SVD to achieve lossless accuracy; and 2) As the masks do not inflate the data, FedSVD avoids extra computation and communication overhead during the factorization to maintain high efficiency. Experiments with real-world datasets show that FedSVD is over 10000x faster than the HE-based method and has 10 orders of magnitude smaller error than the DP-based solution (\u03b5=0.1, \u03b4=0.1) on SVD tasks. We further build and evaluate FedSVD over three real-world applications: principal components analysis (PCA), linear regression (LR), and latent semantic analysis (LSA), to show its superior performance in practice. On federated LR tasks, compared with two state-of-the-art solutions: FATE [17] and SecureML [19], FedSVD-LR is 100x faster than SecureML and 10x faster than FATE.", "venue": "Knowledge Discovery and Data Mining", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2021-05-19", "journal": {"name": "Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"}, "authors": [{"authorId": "2064208321", "name": "Di Chai"}, {"authorId": "2143500842", "name": "Leye Wang"}, {"authorId": "1908497", "name": "Junxue Zhang"}, {"authorId": "2145494870", "name": "Liu Yang"}, {"authorId": "2169936209", "name": "Shuowei Cai"}, {"authorId": "2157740727", "name": "Kai Chen"}, {"authorId": "144286907", "name": "Qian Yang"}], "citations": [{"paperId": "f3451c588b778aea8c0f51aec3db9ba780116fbe", "title": "COLA: Cross-city Mobility Transformer for Human Trajectory Simulation"}, {"paperId": "389e1de6c6a266509b89ac00c36a4cb56dee78e5", "title": "P3LS: Partial Least Squares under Privacy Preservation"}, {"paperId": "d37f0b42715cd7ff1f10412b903fbc92ff757d82", "title": "Fed-mSSA: A Federated Approach for Spatio-Temporal Data Modeling Using Multivariate Singular Spectrum Analysis"}, {"paperId": "ab76cea2cac5d0a308c438260f134c014f6cdb7b", "title": "Efficient federated item similarity model for privacy-preserving recommendation"}, {"paperId": "7e555856fc97b669379b0989a8c50097e4f607ed", "title": "A Survey for Federated Learning Evaluations: Goals and Measures"}, {"paperId": "67fcf6d8ccfa5234d5d0ba53ca70f9df2fbe22b7", "title": "Privacy Matters: Vertical Federated Linear Contextual Bandits for Privacy Protected Recommendation"}, {"paperId": "22f82344819b6a8da453a23e3e20f759002cfb02", "title": "Communication Efficient Secret Sharing with Dynamic Communication-Computation Conversion"}, {"paperId": "c133816f3ead6e4b0f17cfb946bddd05a3f389e5", "title": "Vertical Federated Knowledge Transfer via Representation Distillation for Healthcare Collaboration Networks"}, {"paperId": "725e713842392d9db55a4dd7ab9f575a083d0a27", "title": "Federated Analytics: A survey"}, {"paperId": "f13f014f51dd425661e3202067c5ef5052fe4d6a", "title": "Vertical Federated Learning"}, {"paperId": "4aea3aa7c1f9b926a72e9242dab83db85f199e14", "title": "Vertical Federated Linear Contextual Bandits"}, {"paperId": "e467ad57b7872a48b5210af756f5260dad8a5ab4", "title": "A Survey on Heterogeneous Federated Learning"}, {"paperId": "56470596bc37d953704a15f6424399ebba2c452d", "title": "Federated singular value decomposition for high dimensional data"}, {"paperId": "1ca46e1445e85cf097117dfe9eeaf9577c82e5ca", "title": "FedPower: Privacy-Preserving Distributed Eigenspace Estimation"}, {"paperId": "58a5dd40251bafa062e19a27f2341fb52704a813", "title": "Seeking Consensus on Subspaces in Federated Principal Component Analysis"}, {"paperId": "a4260807cf0147f608451feb153ec72f625e0a49", "title": "FedEval: A Holistic Evaluation Framework for Federated Learning"}, {"paperId": "b88ca6706af822cb8f4e569b63711b7f75bb48d6", "title": "Federated Supervised Principal Component Analysis"}, {"paperId": "a5e985829a7830b1f669568f31c96f13c3b09a24", "title": "FLASH: Towards a High-performance Hardware Acceleration Architecture for Cross-silo Federated Learning"}, {"paperId": "5b63d4afab7d9503f684e3c1925b68b750e7f887", "title": "Accelerating Secure Collaborative Machine Learning with Protocol-Aware RDMA"}, {"paperId": "37df8888ea3faf6b12546204f6e3ac0e4fb595fb", "title": "This paper is"}]}

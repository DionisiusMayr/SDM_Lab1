{"paperId": "af42ed7b612835820720d0820bf1e886edb1c312", "publicationVenue": {"id": "fb4e379d-815b-45bd-af66-cfd34c2cc48f", "name": "Workshop on Abusive Language Online", "type": "conference", "alternate_names": ["ALW", "Workshop Abus Lang Online"]}, "title": "Towards a Comprehensive Taxonomy and Large-Scale Annotated Corpus for Online Slur Usage", "abstract": "Abusive language classifiers have been shown to exhibit bias against women and racial minorities. Since these models are trained on data that is collected using keywords, they tend to exhibit a high sensitivity towards pejoratives. As a result, comments written by victims of abuse are frequently labelled as hateful, even if they discuss or reclaim slurs. Any attempt to address bias in keyword-based corpora requires a better understanding of pejorative language, as well as an equitable representation of targeted users in data collection. We make two main contributions to this end. First, we provide an annotation guide that outlines 4 main categories of online slur usage, which we further divide into a total of 12 sub-categories. Second, we present a publicly available corpus based on our taxonomy, with 39.8k human annotated comments extracted from Reddit. This corpus was annotated by a diverse cohort of coders, with Shannon equitability indices of 0.90, 0.92, and 0.87 across sexuality, ethnicity, and gender. Taken together, our taxonomy and corpus allow researchers to evaluate classifiers on a wider range of speech containing slurs.", "venue": "Workshop on Abusive Language Online", "year": 2020, "fieldsOfStudy": ["Psychology", "Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-11-01", "journal": {"pages": "138-149"}, "authors": [{"authorId": "2008180785", "name": "Jana Kurrek"}, {"authorId": "3403180", "name": "Haji Mohammad Saleem"}, {"authorId": "4881881", "name": "D. Ruths"}], "citations": [{"paperId": "65445dfd0100850618361f0f3ddfacff4bcc5453", "title": "Spanning the Spectrum of Hatred Detection: A Persian Multi-Label Hate Speech Dataset with Annotator Rationales"}, {"paperId": "c70b8ac00c8832be0a5cdd495af5d5a82fa2e3c1", "title": "Text Detoxification as Style Transfer in English and Hindi"}, {"paperId": "5c3bed9da03933d5e6efe28b4ed5ca8885882ddb", "title": "MetaHate: A Dataset for Unifying Efforts on Hate Speech Detection"}, {"paperId": "b46878347e6b5faadd2102a33a260a4daab412e6", "title": "A Sentiment Analysis Benchmark for Automated Machine Learning Applications"}, {"paperId": "a07a724406994bbed62269c9fea8e61621764be9", "title": "NDDSM: Novel Deep Decision-Support Model for Hate Speech Detection"}, {"paperId": "af92ff18f5165ce0eb73290e26f5d227e1129866", "title": "Latent Feature-based Data Splits to Improve Generalisation Evaluation: A Hate Speech Detection Case Study"}, {"paperId": "4db0463c862a8d01c996a0f70bd364716fe6441f", "title": "On the Challenges of Building Datasets for Hate Speech Detection"}, {"paperId": "6a618a8ace70a1f4475e048b3cf33e1c3f10d28e", "title": "A Supervised Classification Approach for Detecting Hate Speech in English Tweets"}, {"paperId": "6ef559d4c0bebbd21bf88ee9717c408525c40474", "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media"}, {"paperId": "49f1fa0d609ff06564b46270cbc022b7d9d195f4", "title": "Assessing Language Model Deployment with Risk Cards"}, {"paperId": "afeb41a8b517241b8876641c259f0047931c0325", "title": "Qualitative Analysis of a Graph Transformer Approach to Addressing Hate Speech: Adapting to Dynamically Changing Content"}, {"paperId": "e24b89132eae2bd8b8380b2b727ee0001aa1baff", "title": "TERF: \u00bfInsulto o meme?"}, {"paperId": "c79f7942f117358d4e12844e8ff7332fb840034f", "title": "Pradvis vac: A socio-demographic dataset for determining the level of hatred severity in a low-resource Hinglish language"}, {"paperId": "a0449cb688e65967a8ec21d4d37fed3ea08d93e3", "title": "CoRAL: a Context-aware Croatian Abusive Language Dataset"}, {"paperId": "d8cabee352313ba80a1bf1caa45a6cda321973ba", "title": "Identifying key challenges and needs in digital mental health moderation practices supporting users exhibiting risk behaviours to develop responsible AI tools: the case study of Kooth"}, {"paperId": "47565b408e5d08a97923e4e901f586877c1e3a6a", "title": "Which One Is More Toxic? Findings from Jigsaw Rate Severity of Toxic Comments"}, {"paperId": "4b7ed4bc605467b59807bbce46a570691819f35f", "title": "Multilingual HateCheck: Functional Tests for Multilingual Hate Speech Detection Models"}, {"paperId": "d1ccf9309bb456b9c6a4c5305fd7418c275ba57a", "title": "Enriching Abusive Language Detection with Community Context"}, {"paperId": "22f27d1576cf72bcd833785076d9d32675ebd18b", "title": "Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation"}, {"paperId": "75482397a162a8897677d2e918a9ef0f429e3315", "title": "Investigating the role of swear words in abusive language detection tasks"}, {"paperId": "2d2a5b42a4cb11dbfbe3d3ab6e42533ed36aa30c", "title": "Identifying vulgarity in Bengali social media textual content"}, {"paperId": "d323f4f5a1c596e0bb172a8c50ae75911f131674", "title": "Introducing an Abusive Language Classification Framework for Telegram to Investigate the German Hater Community"}, {"paperId": "112bf9794471c0a0a0cb01eca4826386c279da8f", "title": "Bias and comparison framework for abusive language datasets"}, {"paperId": "353c88c231ce156d604e074af276422422fc73f7", "title": "A Survey of Race, Racism, and Anti-Racism in NLP"}, {"paperId": "ad8f0170bde61a8c1ca56507bf624f9392bb59b7", "title": "Ruddit: Norms of Offensiveness for English Reddit Comments"}, {"paperId": "6de4dc0bb66971071ced5201e37ed8f3ccd5e062", "title": "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection"}, {"paperId": "2b4929707e20e37a3a6351036ac48c20b5466a6d", "title": "HateCheck: Functional Tests for Hate Speech Detection Models"}, {"paperId": "f2bb83781e16212ff86551becd570631a062aa5b", "title": "DCU at SemEval-2023 Task 10: A Comparative Analysis of Encoder-only and Decoder-only Language Models with Insights into Interpretability"}, {"paperId": "8fde04e0eea75b68e437dc804766b9b83f36e756", "title": "The subtle language of exclusion: Identifying the Toxic Speech of Trans-exclusionary Radical Feminists"}, {"paperId": "b936eab7c6eefb78c6d2c840f82688dac5e6be2e", "title": "Misogyny and Aggressiveness Tend to Come Together and Together We Address Them"}, {"paperId": "f799f680756ece4097806ee28819b54d49c9e319", "title": "Exploiting Emojis for Abusive Language Detection"}, {"paperId": "d113e7cf8adf596e4d7c692b6d9d23179a243b78", "title": "Crowdsourcing of Parallel Corpora: the Case of Style Transfer for Detoxification"}]}

{"paperId": "84adc377933eb09289304f63644ce546de9a4a2b", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?", "abstract": "Coaxing out desired behavior from pretrained models, while avoiding undesirable ones, has redefined NLP and is reshaping how we interact with computers. What was once a scientific engineering discipline-in which building blocks are stacked one on top of the other-is arguably already a complex systems science, in which emergent behaviors are sought out to support previously unimagined use cases. Despite the ever increasing number of benchmarks that measure task performance, we lack explanations of what behaviors language models exhibit that allow them to complete these tasks in the first place. We argue for a systematic effort to decompose language model behavior into categories that explain cross-task performance, to guide mechanistic explanations and help future-proof analytic research.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-07-31", "journal": {"name": "ArXiv", "volume": "abs/2308.00189"}, "authors": [{"authorId": "14487640", "name": "Ari Holtzman"}, {"authorId": "119659229", "name": "Peter West"}, {"authorId": "1982950", "name": "Luke Zettlemoyer"}], "citations": [{"paperId": "a816817423d4ab4e02c307b5a8f54e374d80caac", "title": "Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models"}, {"paperId": "7cebf3afab09d990a2322ea053d0de96f31f2971", "title": "Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?"}, {"paperId": "798feda076ad710df65d509a7884bd15937c8056", "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs"}, {"paperId": "4b3b7ab69cbf6b02087836810772799e9213bcb9", "title": "Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation"}, {"paperId": "71491b7e8913f24d7d0f01bfd0a9814dc72f4675", "title": "Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review"}, {"paperId": "1a3f7e23ef8f0bf06d0efa0dc174e4e361226ead", "title": "Paloma: A Benchmark for Evaluating Language Model Fit"}, {"paperId": "c0d9a48547d728dd320b453b01a0ab1ce2f96098", "title": "Circuit Component Reuse Across Tasks in Transformer Language Models"}, {"paperId": "9ebf47129c15f61f4b77bbfe305c522480c20347", "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models"}]}

{"paperId": "bed5ac98a8e189f38823b21651c759d7d569e86e", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning", "abstract": "Join order selection (JOS) is the problem of ordering join operations to minimize total query execution cost and it is the core NP-hard combinatorial optimization problem of query optimization. In this paper, we present JoinGym, a lightweight and easy-to-use query optimization environment for reinforcement learning (RL) that captures both the left-deep and bushy variants of the JOS problem. Compared to existing query optimization environments, the key advantages of JoinGym are usability and significantly higher throughput which we accomplish by simulating query executions entirely offline. Under the hood, JoinGym simulates a query plan's cost by looking up intermediate result cardinalities from a pre-computed dataset. We release a novel cardinality dataset for $3300$ SQL queries based on real IMDb workloads which may be of independent interest, e.g., for cardinality estimation. Finally, we extensively benchmark four RL algorithms and find that their cost distributions are heavy-tailed, which motivates future work in risk-sensitive RL. In sum, JoinGym enables users to rapidly prototype RL algorithms on realistic database problems without needing to setup and run live systems.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-07-21", "journal": {"name": "ArXiv", "volume": "abs/2307.11704"}, "authors": [{"authorId": "2148352172", "name": "Kaiwen Wang"}, {"authorId": "2110248299", "name": "Junxiong Wang"}, {"authorId": "2181747709", "name": "Yueying Li"}, {"authorId": "3174388", "name": "Nathan Kallus"}, {"authorId": "2636156", "name": "Immanuel Trummer"}, {"authorId": "144426657", "name": "Wen Sun"}], "citations": []}

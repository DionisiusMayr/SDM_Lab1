{"paperId": "53780b4eeb51f8cde06c7e76008d5c8b3260a88c", "publicationVenue": {"id": "deedf64a-dd5c-4b33-b345-ff83bfb93d71", "name": "International Symposium on Computer Architecture", "type": "conference", "alternate_names": ["Int Symp Comput Archit", "ISCA"], "url": "http://www.cs.wisc.edu/~arch/www/"}, "title": "Accelerating Personalized Recommendation with Cross-level Near-Memory Processing", "abstract": "The memory-intensive embedding layers of the personalized recommendation systems are the performance bottleneck as they demand large memory bandwidth and exhibit irregular and sparse memory access patterns. Recent studies propose near memory processing (NMP) to accelerate memory-bound embedding operations. However, due to the load imbalance caused by the skewed access frequency of the embedding data, existing NMP solutions that exploit fine-grained memory parallelism fail to translate the increasingly massive internal bandwidth to performance improvements, leading to resource underutilization and hardware overhead. We propose an efficient yet practical fine-grained NMP accelerator for embedding operations. We architect ReCross, a cross-level NMP architecture that exploits rank, bank-group, and subarray-level memory parallelism in a unified DIMM-based memory system by supporting rank, bank-group, and bank-level NMP to accommodate various bandwidth requirements of embedding data. In addition, we present a novel embedding partitioning technique to quantify the bandwidth requirements of embedding tables and allocate them to appropriate NMP levels. ReCross innovatively collaborates the data and architecture characteristics for the NMP embedding layer acceleration, achieving high resource utilization and performance. Our evaluation shows that ReCross outperforms a state-of-the-art bank-group level NMP solution, TRiM-G, by 2.5\u00d7 with nearly the same area overhead and bank-level NMP solution, TRiM-B, by 1.8\u00d7 with an area overhead reduction of 4\u00d7.", "venue": "International Symposium on Computer Architecture", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2023-06-17", "journal": {"name": "Proceedings of the 50th Annual International Symposium on Computer Architecture"}, "authors": [{"authorId": "2177399757", "name": "Haifeng Liu"}, {"authorId": "9135861", "name": "Long Zheng"}, {"authorId": "2108860901", "name": "Yu Huang"}, {"authorId": "2152505362", "name": "Chao Liu"}, {"authorId": "2147245034", "name": "Xiangyu Ye"}, {"authorId": "2165688103", "name": "Jingrui Yuan"}, {"authorId": "144925807", "name": "Xiaofei Liao"}, {"authorId": "145914251", "name": "Hai Jin"}, {"authorId": "2220174", "name": "Jingling Xue"}], "citations": [{"paperId": "505641490f56e0a0b67757a1f3a157bf5a62e97d", "title": "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing"}]}

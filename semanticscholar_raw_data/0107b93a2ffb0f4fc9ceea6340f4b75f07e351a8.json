{"paperId": "0107b93a2ffb0f4fc9ceea6340f4b75f07e351a8", "publicationVenue": {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e", "name": "IEEE International Conference on Data Engineering", "type": "conference", "alternate_names": ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng", "International Conference on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"}, "title": "FLBooster: A Unified and Efficient Platform for Federated Learning Acceleration", "abstract": "Federated learning (FL) has emerged as a paradigm to train a global machine learning model in a distributed manner while taking privacy concerns and data protection regulations into consideration. Although a variety of FL algorithms have been proposed, the training efficiency of FL remains challenging due to massive mathematical computations and expensive client-server communication costs. However, existing FL-acceleration studies are limited as they can only solve the computation and communication overheads separately, which is suboptimal and constrains their acceleration ability. Moreover, previous studies are typically designed for specific FL scenarios and can support only one or two FL models, thus exhibiting poor generality.To fill these critical voids, we propose FLBooster, which provides unified and efficient acceleration capacity for a broad range of FL models. This is the first proposal to solve the computation and communication overheads simultaneously. Specifically, we utilize GPUs to boost the computation-intensive homomorphic encryption (HE) operations in a parallel manner, which significantly reduces the computation costs. On the other hand, a simple but efficient compression method is designed to lighten the exchange of data volumes between client and server. Extensive experiments using four standard FL models on three datasets show that FLBooster acquires superior speed-up gains (i.e., 14.3\u00d7 \u2013 138\u00d7) over state-of-the-art acceleration systems. Finally, we integrate FLBooster into the open-source FL benchmark FATE and offer user-friendly APIs for development.", "venue": "IEEE International Conference on Data Engineering", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-04-01", "journal": {"name": "2023 IEEE 39th International Conference on Data Engineering (ICDE)", "pages": "3140-3153"}, "authors": [{"authorId": "2192246915", "name": "Zhihao Zeng"}, {"authorId": "151480027", "name": "Yuntao Du"}, {"authorId": "1726018749", "name": "Ziquan Fang"}, {"authorId": "2115384591", "name": "Lu Chen"}, {"authorId": "3290437", "name": "Shiliang Pu"}, {"authorId": "2224888708", "name": "Guodong Chen"}, {"authorId": "2359832", "name": "Hongya Wang"}, {"authorId": "1409828392", "name": "Yunjun Gao"}], "citations": [{"paperId": "a1f2b0cc6c4ab9306c96c97c9ba7b27ca03dcfd8", "title": "Secure and Verifiable Data Collaboration with Low-Cost Zero-Knowledge Proofs"}, {"paperId": "fd60796e583c041235635fa8ebc5b97f570c7974", "title": "UniFL: Accelerating Federated Learning Using Heterogeneous Hardware Under a Unified Framework"}]}

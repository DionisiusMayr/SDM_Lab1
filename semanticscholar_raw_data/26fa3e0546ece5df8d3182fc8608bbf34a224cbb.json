{"paperId": "26fa3e0546ece5df8d3182fc8608bbf34a224cbb", "publicationVenue": {"id": "7c9d091e-015e-4e5d-a11f-9bc369fcf414", "name": "IEEE Transactions on Parallel and Distributed Systems", "type": "journal", "alternate_names": ["IEEE Trans Parallel Distrib Syst"], "issn": "1045-9219", "url": "http://www.computer.org/tpds", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=71"]}, "title": "SEIZE: Runtime Inspection for Parallel Dataflow Systems", "abstract": "Many Data-Intensive Scalable Computing (DISC) Systems provide easy-to-use functional APIs, and efficient scheduling and execution strategies allowing users to build concise data-parallel programs. In these systems, data transformations are concealed by exposed APIs, and intermediate execution states are masked under dataflow transitions. Consequently, many crucial features and optimizations (e.g., debugging, data provenance, runtime skew detection), which require runtime datafow states, are not well-supported. Inspired by our experience in implementing features and optimizations over DISC systems, we present <inline-formula><tex-math notation=\"LaTeX\">$\\mathsf {SEIZE}$</tex-math><alternatives><mml:math><mml:mi mathvariant=\"sans-serif\">SEIZE</mml:mi></mml:math><inline-graphic xlink:href=\"li-ieq1-3035170.gif\"/></alternatives></inline-formula>, a unified framework that enables dataflow inspection\u2014wiretapping the data-path with listening logic\u2014in MapReduce-style programming model. We generalize our lessons learned by providing a set of primitives defining dataflow inspection, orchestration options for different inspection granularities, and operator decomposition and dataflow punctuation strategy for dataflow intervention. We demonstrate the generality and flexibility of the approach by deploying <inline-formula><tex-math notation=\"LaTeX\">$\\mathsf {SEIZE}$</tex-math><alternatives><mml:math><mml:mi mathvariant=\"sans-serif\">SEIZE</mml:mi></mml:math><inline-graphic xlink:href=\"li-ieq2-3035170.gif\"/></alternatives></inline-formula> in both Apache Spark and Apache Flink, and by implementing a prototype runtime query optimizer for Spark. Our experiments show that, the overhead introduced by the inspection logic is most of the time negligible (less than 5 percent in Spark and 10 percent in Flink).", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2021-04-01", "journal": {"name": "IEEE Transactions on Parallel and Distributed Systems", "pages": "842-854", "volume": "32"}, "authors": [{"authorId": "2024664573", "name": "Youfu Li"}, {"authorId": "2192580", "name": "Matteo Interlandi"}, {"authorId": "2493657", "name": "Fotis Psallidas"}, {"authorId": "2158625463", "name": "Wei Wang"}, {"authorId": "1712630", "name": "C. Zaniolo"}], "citations": [{"paperId": "96b38fa4aba41db8f0c1af6a3f0b1fa718bab3df", "title": "A resource occupancy ratio-oriented load balancing task scheduling mechanism for Flink"}]}

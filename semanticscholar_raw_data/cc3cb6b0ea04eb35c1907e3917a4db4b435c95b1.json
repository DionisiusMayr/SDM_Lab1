{"paperId": "cc3cb6b0ea04eb35c1907e3917a4db4b435c95b1", "publicationVenue": {"id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd", "name": "Neural Information Processing Systems", "type": "conference", "alternate_names": ["Neural Inf Process Syst", "NeurIPS", "NIPS"], "url": "http://neurips.cc/"}, "title": "FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning", "abstract": "Finance is a particularly difficult playground for deep reinforcement learning. However, establishing high-quality market environments and benchmarks for financial reinforcement learning is challenging due to three major factors, namely, low signal-to-noise ratio of financial data, survivorship bias of historical data, and model overfitting in the backtesting stage. In this paper, we present an openly accessible FinRL-Meta library that has been actively maintained by the AI4Finance community. First, following a DataOps paradigm, we will provide hundreds of market environments through an automatic pipeline that collects dynamic datasets from real-world markets and processes them into gym-style market environments. Second, we reproduce popular papers as stepping stones for users to design new trading strategies. We also deploy the library on cloud platforms so that users can visualize their own results and assess the relative performance via community-wise competitions. Third, FinRL-Meta provides tens of Jupyter/Python demos organized into a curriculum and a documentation website to serve the rapidly growing community. FinRL-Meta is available at: https://github.com/AI4Finance-Foundation/FinRL-Meta", "venue": "Neural Information Processing Systems", "year": 2022, "fieldsOfStudy": ["Economics", "Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-11-06", "journal": {"name": "SSRN Electronic Journal"}, "authors": [{"authorId": "4029028", "name": "Xiao-Yang Liu"}, {"authorId": "2186589721", "name": "Ziyi Xia"}, {"authorId": "2145151658", "name": "Jingyang Rui"}, {"authorId": "1505808706", "name": "Jiechao Gao"}, {"authorId": "1504453822", "name": "Hongyang Yang"}, {"authorId": "2152184398", "name": "Ming Zhu"}, {"authorId": "2118324724", "name": "Chris Wang"}, {"authorId": "50218397", "name": "Zhaoran Wang"}, {"authorId": "2148900809", "name": "Jian Guo"}], "citations": [{"paperId": "50e1054243139b67b0ccf169abb6121a0fa0cd94", "title": "Deep Limit Order Book Forecasting"}, {"paperId": "af90eb921ece93b4703b5d4f844c370ded1f06fe", "title": "From Factor Models to Deep Learning: Machine Learning in Reshaping Empirical Asset Pricing"}, {"paperId": "d2073b0947a1634fcad2417c89ffe3fa5881a1cb", "title": "Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization"}, {"paperId": "401aeac7beabe15fc1410f87d4d4ce466c24e565", "title": "The FinBen: An Holistic Financial Benchmark for Large Language Models"}, {"paperId": "037252f3b144b0219f2c7337084770e836102834", "title": "CNN-DRL with Shuffled Features in Finance"}, {"paperId": "64be9786303a8aba460618bae4272dc68c4804c2", "title": "CNN-DRL for Scalable Actions in Finance"}, {"paperId": "f9b326aaef54c786d4504583c9fdfdbf1c869122", "title": "Learning RL policies for anticipative assistive robots by simulating human-robot interactions in real scenarios using egocentric videos"}, {"paperId": "a2f3d6c64dd684eb1584fcd7bebbfa116e19c486", "title": "Margin Trader: A Reinforcement Learning Framework for Portfolio Management with Margin and Constraints"}, {"paperId": "eb34bd715e3a7c68477ec0824ebb171b948b80c2", "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design"}, {"paperId": "82cc7aef83d7fd3200a3ef12a2d6696fd3fe4430", "title": "Logic-guided Deep Reinforcement Learning for Stock Trading"}, {"paperId": "bd09391fbd124dc0c0a6be5d0ab2eb5d9c43fbac", "title": "FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets"}, {"paperId": "99954ac70d8bab6a1ba52a55c75678fe6325ab5e", "title": "GraphSAGE with deep reinforcement learning for financial portfolio optimization"}, {"paperId": "362b153f7138148b394e5d54149ce0ef91227fef", "title": "POE: A General Portfolio Optimization Environment for FinRL"}, {"paperId": "508a69c1d63525502eaf07790363f8bb3b3fc256", "title": "Efficient Continuous Space Policy Optimization for High-frequency Trading"}, {"paperId": "c6be432e065caf9aa079199dea2a9171b4c38f08", "title": "An Ensemble Method of Deep Reinforcement Learning for Automated Cryptocurrency Trading"}, {"paperId": "bed5ac98a8e189f38823b21651c759d7d569e86e", "title": "JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning"}, {"paperId": "6121fb3e393597e02481a516f0035f06ec9a5836", "title": "FinGPT: Democratizing Internet-scale Data for Financial Large Language Models"}, {"paperId": "83eb79318ea3e10f96c7b5a1dd264c38402b71ac", "title": "LOB-Based Deep Learning Models for Stock Price Trend Prediction: A Benchmark Study"}, {"paperId": "5dea206e2a36e672f197252bdd27d156d058f48c", "title": "FinGPT: Open-Source Financial Large Language Models"}, {"paperId": "2032aa3ea996e32b45890e9d5bfae4638af2b3cc", "title": "Dynamic Datasets and Market Environments for Financial Reinforcement Learning"}, {"paperId": "98b7b5b9693419e6d96ed295cf40225d9c23d17d", "title": "Smart Robotic Strategies and Advice for Stock Trading Using Deep Transformer Reinforcement Learning"}, {"paperId": "3416dd98d0875c52f07c649200960958b3e14b8c", "title": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical Approach to Address Backtest Overfitting"}, {"paperId": "f8ff28c02b5d1aa27803330ee1676a0a7d93176b", "title": "Recent advances in reinforcement learning in finance"}, {"paperId": "fb69015150bf3431c832b251c706526bfb894fa1", "title": "Cross-Domain Disentanglement: A Novel Approach to Financial Market Prediction"}]}

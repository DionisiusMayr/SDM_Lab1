{"paperId": "e827a686216beadd08a5d2840c24ed470e521a94", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System", "abstract": "Training machine learning (ML) algorithms is a computationally intensive process, which is frequently memory-bound due to repeatedly accessing large training datasets. As a result, processor-centric systems (e.g., CPU, GPU) suffer from costly data movement between memory units and processing units, which consumes large amounts of energy and execution cycles. Memory-centric computing systems, i.e., with processing-in-memory (PIM) capabilities, can alleviate this data movement bottleneck. Our goal is to understand the potential of modern general-purpose PIM architectures to accelerate ML training. To do so, we (1) implement several representative classic ML algorithms (namely, linear regression, logistic regression, decision tree, K-Means clustering) on a real-world general-purpose PIM architecture, (2) rigorously evaluate and characterize them in terms of accuracy, performance and scaling, and (3) compare to their counterpart implementations on CPU and GPU. Our evaluation on a real memory-centric computing system with more than 2500 PIM cores shows that general-purpose PIM architectures can greatly accelerate memory-bound ML workloads, when the necessary operations and datatypes are natively supported by PIM hardware. For example, our PIM implementation of decision tree is $27\\times$ faster than a state-of-the-art CPU version on an 8-core Intel Xeon, and $1.34\\times$ faster than a state-of-the-art GPU version on an NVIDIA A100. Our K-Means clustering on PIM is $2.8\\times$ and $3.2\\times$ than state-of-the-art CPU and GPU versions, respectively. To our knowledge, our work is the first one to evaluate ML training on a real-world PIM architecture. We conclude with key observations, takeaways, and recommendations that can inspire users of ML workloads, programmers of PIM architectures, and hardware designers&architects of future memory-centric computing systems.", "venue": "arXiv.org", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-07-16", "journal": {"name": "ArXiv", "volume": "abs/2207.07886"}, "authors": [{"authorId": "2167029308", "name": "Juan G'omez-Luna"}, {"authorId": "100927332", "name": "Yu-Yin Guo"}, {"authorId": "32584839", "name": "Sylvan Brocard"}, {"authorId": "2672798", "name": "Julien Legriel"}, {"authorId": "2024853708", "name": "Remy Cimadomo"}, {"authorId": "2173743", "name": "Geraldo F. Oliveira"}, {"authorId": "2117029302", "name": "Gagandeep Singh"}, {"authorId": "145929920", "name": "O. Mutlu"}], "citations": [{"paperId": "c75daf38ec84d306179277d08904101bc5f68d60", "title": "Swordfish: A Framework for Evaluating Deep Neural Network-based Basecalling using Computation-In-Memory with Non-Ideal Memristors"}, {"paperId": "711910e69879e512fde3f591eca5447a46625e00", "title": "SimplePIM: A Software Framework for Productive and Efficient Processing-in-Memory"}, {"paperId": "4e268759f57e64f59febafb0250071dee4a8cffe", "title": "Evaluating Homomorphic Operations on a Real-World Processing-In-Memory System"}, {"paperId": "ef0638c10bba5e53bf348cd3e64c2954dc903d57", "title": "Pathfinding Future PIM Architectures by Demystifying a Commercial PIM Technology"}, {"paperId": "06444c5756a513124b35300d1374f0e34df12990", "title": "Evaluating Machine LearningWorkloads on Memory-Centric Computing Systems"}, {"paperId": "036f2336db908986ba83082641423ad1da234b9d", "title": "Machine Learning Training on a Real Processing-in-Memory System"}, {"paperId": "7bb6015f45457fdbe3bb39e17dc9cb0786ecd688", "title": "A Modern Primer on Processing in Memory"}]}

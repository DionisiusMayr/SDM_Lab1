{"paperId": "dd890da11f2a96f39e35cc29ee002ffe6cf8a532", "publicationVenue": {"id": "87884a6c-bedc-4aa9-bf6d-f9a8f937438d", "name": "International Symposium on Memory Systems", "type": "conference", "alternate_names": ["MEMSYS", "Int Symp Mem Syst"]}, "title": "Writeback Modeling: Theory and Application to Zipfian Workloads", "abstract": "As per-core CPU performance plateaus and data-bound applications like graph analytics and key-value stores become more prevalent, understanding memory performance is more important than ever. Many existing techniques to predict and measure cache performance on a given workload involve either static analysis or tracing, but programs like key-value stores can easily have billions of memory accesses in a trace and have access patterns driven by non-statically observable phenomena such as user behavior. Past analytical solutions focus on modeling cache hits, but the rise of non-volatile memory (NVM) like Intel\u2019s Optane with asymmetric read/write latencies, bandwidths, and power consumption means that writes and writebacks are now critical performance considerations as well, especially in the context of large-scale software caches. We introduce two novel analytical cache writeback models that function for workloads with general frequency distributions; in addition we provide closed-form instantiations for Zipfian workloads, one of the most ubiquitous frequency distribution types in data-bound applications. The models have different use cases and asymptotic runtimes, making them suited for use in different circumstances, but both are fully analytical; cache writeback statistics are computed with no tracing or sampling required. We demonstrate that these models are extremely accurate and fast: the first model, for infinitely large level-two (L2) software cache, averaged 5.0% relative error from ground truth and achieved a minimum speedup over a state-of-the-art trace analysis technique (AET) of 515x to generate writeback information for a single cache size. The second model, which is fully general with respect to L1 and L2 sizes but slower, averaged 3.0% relative error from ground truth and achieved a minimum speedup over AET of 105x for a single cache size.", "venue": "International Symposium on Memory Systems", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2021-09-27", "journal": {"name": "Proceedings of the International Symposium on Memory Systems"}, "authors": [{"authorId": "2108980028", "name": "Wesley Smith"}, {"authorId": "2057276442", "name": "Daniel Byrne"}, {"authorId": "48493240", "name": "C. Ding"}], "citations": []}

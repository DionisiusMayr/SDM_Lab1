{"paperId": "d2c2f9f33d433cc77a9b753f44cc51fa459e3521", "publicationVenue": {"id": "764e3630-ddac-4c21-af4b-9d32ffef082e", "name": "IEEE International Conference on Data Engineering", "type": "conference", "alternate_names": ["ICDE", "Int Conf Data Eng", "IEEE Int Conf Data Eng", "International Conference on Data Engineering"], "url": "http://www.wikicfp.com/cfp/program?id=1331"}, "title": "S/C: Speeding up Data Materialization with Bounded Memory", "abstract": "With data pipeline tools and the expressiveness of SQL, managing interdependent materialized views (MVs) are becoming increasingly easy. These MVs are updated repeatedly upon new data ingestion (e.g., daily), from which database admins can observe performance metrics (e.g., refresh time of each MV, size on disk) in a consistent way for different types of updates (full vs. incremental) and for different systems (single node, distributed, cloud-hosted). One missed opportunity is that existing data systems treat those MV updates as independent SQL statements without fully exploiting their dependency information and performance metrics. However, if we know that the result of a SQL statement will be consumed immediately after for subsequent operations, those subsequent operations do not have to wait until the early results are fully materialized on storage because the results are already readily available in memory. Of course, this may come at a cost because keeping those results in memory (even temporarily) will reduce the amount of available memory; thus, our decision should be careful.In this paper, we introduce a new system, called S/C, which tackles this problem through efficient creation and update of a set of MVs with acyclic dependencies among them. S/C judiciously uses bounded memory to reduce the end-to-end MV refresh time by short-circuiting expensive reads and writes; S/C\u2019s objective function accurately estimates the time savings from keeping intermediate data in memory for particular periods. Our solution jointly optimizes an MV refresh order, what data to keep in memory, and when to release the data from memory. At a high level, S/C still materializes all data exactly as defined in MV definitions; thus, it does not impact any service-level agreements. In our experiments with TPC-DS datasets (up to 1TB), we show that S/C's optimization can speedup end-to-end runtime by 1.04\u00d7\u20135.08\u00d7 with (only) 1.6GB memory.", "venue": "IEEE International Conference on Data Engineering", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-03-17", "journal": {"name": "2023 IEEE 39th International Conference on Data Engineering (ICDE)", "pages": "1981-1994"}, "authors": [{"authorId": "2040810002", "name": "Zhaoheng Li"}, {"authorId": "121946942", "name": "Xinyu Pi"}, {"authorId": "40155297", "name": "Yongjoo Park"}], "citations": [{"paperId": "2aa4f898e28e4cdea16f6c7baa403a7db5d91eb5", "title": "ElasticNotebook: Enabling Live Migration for Computational Notebooks (Technical Report)"}, {"paperId": "35383850bc203178b43e6e0b43b57197488db506", "title": "Transactional Python for Durable Machine Learning: Vision, Challenges, and Feasibility"}, {"paperId": "023fbffad88fd923d33c1e3ac33262b396123065", "title": "A Step Toward Deep Online Aggregation"}]}

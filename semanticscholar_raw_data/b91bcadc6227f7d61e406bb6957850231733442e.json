{"paperId": "b91bcadc6227f7d61e406bb6957850231733442e", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Factuality Challenges in the Era of Large Language Models", "abstract": "The emergence of tools based on Large Language Models (LLMs), such as OpenAI's ChatGPT, Microsoft's Bing Chat, and Google's Bard, has garnered immense public attention. These incredibly useful, natural-sounding tools mark significant advances in natural language generation, yet they exhibit a propensity to generate false, erroneous, or misleading content -- commonly referred to as\"hallucinations.\"Moreover, LLMs can be exploited for malicious applications, such as generating false but credible-sounding content and profiles at scale. This poses a significant challenge to society in terms of the potential deception of users and the increasing dissemination of inaccurate information. In light of these risks, we explore the kinds of technological innovations, regulatory reforms, and AI literacy initiatives needed from fact-checkers, news organizations, and the broader research and policy communities. By identifying the risks, the imminent threats, and some viable solutions, we seek to shed light on navigating various aspects of veracity in the era of generative AI.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-08", "journal": {"name": "ArXiv", "volume": "abs/2310.05189"}, "authors": [{"authorId": "2256988818", "name": "Isabelle Augenstein"}, {"authorId": "2256987318", "name": "Timothy Baldwin"}, {"authorId": "2284591948", "name": "Meeyoung Cha"}, {"authorId": "2256999352", "name": "Tanmoy Chakraborty"}, {"authorId": "1683012", "name": "Giovanni Luca Ciampaglia"}, {"authorId": "2256993500", "name": "David Corney"}, {"authorId": "2256999256", "name": "Renee DiResta"}, {"authorId": "2256999148", "name": "Emilio Ferrara"}, {"authorId": "2256997151", "name": "Scott Hale"}, {"authorId": "1770962", "name": "A. Halevy"}, {"authorId": "2256998951", "name": "Eduard H. Hovy"}, {"authorId": "2257003221", "name": "Heng Ji"}, {"authorId": "2268194233", "name": "Filippo Menczer"}, {"authorId": "31329752", "name": "Rub\u00e9n M\u00edguez"}, {"authorId": "2026545715", "name": "Preslav Nakov"}, {"authorId": "2994143", "name": "Dietram A. Scheufele"}, {"authorId": "1491627343", "name": "Shivam Sharma"}, {"authorId": "2256998588", "name": "Giovanni Zagni"}], "citations": [{"paperId": "3c632184a105d2a639f8d7e66a7e4999142b6a63", "title": "Correcting misinformation on social media with a large language model"}, {"paperId": "88ee6398a970acbb1cab592cbd07c944d8b59b4e", "title": "Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models"}, {"paperId": "7198c0d9e81b273f9fcf9e6c0577641041f4f518", "title": "Generative-AI in E-Commerce: Use-Cases and Implementations"}, {"paperId": "4adfef112d0b7868743dfb06a2ff375c9fa276df", "title": "I Am Not Them: Fluid Identities and Persistent Out-group Bias in Large Language Models"}, {"paperId": "24a56d41df2c939c3223bde7bf26050302c3dea7", "title": "AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls"}, {"paperId": "866009d74c7a553c073c777c8c016c672da21872", "title": "Evaluating the efficacy of leading large language models in the Japanese national dental hygienist examination: A comparative analysis of ChatGPT, Bard, and Bing Chat"}, {"paperId": "0251bb95be75d472c8d5b873751615e7fe2feb1d", "title": "A Comprehensive Study of Knowledge Editing for Large Language Models"}, {"paperId": "03eeaad27db9a967b0e204d40c005c21388cb09e", "title": "Decoding Concerns: Multi-label Classification of Vaccine Sentiments in Social Media"}, {"paperId": "d1fc253c083687bda6d19e4d67c652871ff8ad37", "title": "Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation"}]}

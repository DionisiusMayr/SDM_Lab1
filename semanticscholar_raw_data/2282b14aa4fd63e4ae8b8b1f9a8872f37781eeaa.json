{"paperId": "2282b14aa4fd63e4ae8b8b1f9a8872f37781eeaa", "publicationVenue": {"id": "8270cfe1-3713-4325-a7bd-c6a87eed889e", "name": "Entropy", "type": "journal", "issn": "1099-4300", "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-155606", "alternate_urls": ["http://www.mdpi.com/journal/entropy/", "http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:ch:bel-155606", "https://www.mdpi.com/journal/entropy"]}, "title": "Storage Space Allocation Strategy for Digital Data with Message Importance", "abstract": "This paper mainly focuses on the problem of lossy compression storage based on the data value that represents the subjective assessment of users when the storage size is still not enough after the conventional lossless data compression. To this end, we transform this problem to an optimization, which pursues the least importance-weighted reconstruction error in data reconstruction within limited total storage size, where the importance is adopted to characterize the data value from the viewpoint of users. Based on it, this paper puts forward an optimal allocation strategy in the storage of digital data by the exponential distortion measurement, which can make rational use of all the storage space. In fact, the theoretical results show that it is a kind of restrictive water-filling. It also characterizes the trade-off between the relative weighted reconstruction error and the available storage size. Consequently, if a relatively small part of total data value is allowed to lose, this strategy will improve the performance of data compression. Furthermore, this paper also presents that both the users\u2019 preferences and the special characteristics of data distribution can trigger the small-probability event scenarios where only a fraction of data can cover the vast majority of users\u2019 interests. Whether it is for one of the reasons above, the data with highly clustered message importance is beneficial to compression storage. In contrast, from the perspective of optimal storage space allocation based on data value, the data with a uniform information distribution is incompressible, which is consistent with that in the information theory.", "venue": "Entropy", "year": 2020, "fieldsOfStudy": ["Computer Science", "Medicine", "Mathematics"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-02-20", "journal": {"name": "Entropy", "volume": "22"}, "authors": [{"authorId": "3127248", "name": "Shanyun Liu"}, {"authorId": "1978166", "name": "R. She"}, {"authorId": "153225408", "name": "Zheqi Zhu"}, {"authorId": "7469995", "name": "Pingyi Fan"}], "citations": [{"paperId": "3ef68be5c6ab290b020f86fd6beae08466b4dd62", "title": "Jeffreys Divergence and Generalized Fisher Information Measures on Fokker\u2013Planck Space\u2013Time Random Field"}, {"paperId": "0b16f6a4b1ce1c66ebaf069d8fe84de594694f71", "title": "Entropy Measures for Data Analysis II: Theory, Algorithms and Applications"}]}

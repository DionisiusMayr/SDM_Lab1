{"paperId": "dda5728ddca81df3721744f1441ee8302c075456", "publicationVenue": {"id": "130f7aa7-1552-45e2-a924-46e8efee92d5", "name": "IEEE Micro", "type": "journal", "issn": "0272-1732", "url": "http://www.computer.org/micro/", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=40"]}, "title": "Accelerating Neural Network Inference With Processing-in-DRAM: From the Edge to the Cloud", "abstract": "Neural networks (NNs) are growing in importance and complexity. An NN\u2019s performance (and energy efficiency) can be bound either by computation or memory resources. The processing-in-memory (PIM) paradigm, where computation is placed near or within memory arrays, is a viable solution to accelerate memory-bound NNs. However, PIM architectures vary in form, where different PIM approaches lead to different tradeoffs. Our goal is to analyze, discuss, and contrast dynamic random-access memory (DRAM)-based PIM architectures for NN performance and energy efficiency. To do so, we analyze three state-of-the-art PIM architectures: 1) UPMEM, which integrates processors and DRAM arrays into a single 2-D chip, 2) Mensa, a 3-D-stacking-based PIM architecture tailored for edge devices, and 3) SIMDRAM, which uses the analog principles of DRAM to execute bit-serial operations. Our analysis reveals that PIM greatly benefits memory-bound NNs: 1) UPMEM provides 23\u00d7 the performance of a high-end graphics processing unit (GPU) when the GPU requires memory oversubscription for a general matrix\u2013vector multiplication kernel, 2) Mensa improves energy efficiency and throughput by 3.0\u00d7 and 3.1\u00d7 over the baseline Edge tensor processing unit for 24 Google edge NN models, and 3) SIMDRAM outperforms a central processing unit/graphics processing unit by 16.7\u00d7/1.4\u00d7 for three binary NNs. We conclude that the ideal PIM architecture for NN models depends on a model's distinct attributes, due to the inherent architectural design choices.", "venue": "IEEE Micro", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-09-19", "journal": {"name": "IEEE Micro", "pages": "25-38", "volume": "42"}, "authors": [{"authorId": "2173743", "name": "Geraldo F. Oliveira"}, {"authorId": "1388812849", "name": "Juan G\u00f3mez-Luna"}, {"authorId": "33801185", "name": "Saugata Ghose"}, {"authorId": "2675748", "name": "Amirali Boroumand"}, {"authorId": "145929920", "name": "O. Mutlu"}], "citations": [{"paperId": "c9ae624dfce78b72c4c01ff3941f06440f385ae3", "title": "Balanced Data Placement for GEMV Acceleration with Processing-In-Memory"}, {"paperId": "c9edf92c1f762c52a90cc0cb45eb06d4eed82110", "title": "MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Computing"}, {"paperId": "505641490f56e0a0b67757a1f3a157bf5a62e97d", "title": "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing"}, {"paperId": "d5f2e95be45d3e003655a9a84e0adda9468b0838", "title": "MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient and Programmer-Transparent Multiple-Instruction Multiple-Data Processing"}, {"paperId": "8c5ef03e9118253ec019965bf142d1be7998a453", "title": "Functionally-Complete Boolean Logic in Real DRAM Chips: Experimental Characterization and Analysis"}, {"paperId": "aef4ee743e6e61aec316ceaa301515f048020921", "title": "Just-in-time Quantization with Processing-In-Memory for Efficient ML Training"}, {"paperId": "7d1e2ba4f60cb29500c7c02337d41c45042ee696", "title": "A full spectrum of computing-in-memory technologies"}, {"paperId": "4e268759f57e64f59febafb0250071dee4a8cffe", "title": "Evaluating Homomorphic Operations on a Real-World Processing-In-Memory System"}, {"paperId": "ef0638c10bba5e53bf348cd3e64c2954dc903d57", "title": "Pathfinding Future PIM Architectures by Demystifying a Commercial PIM Technology"}, {"paperId": "7a210280d4775b1dfb36401a1007ac57602ab1e5", "title": "pLUTo: Enabling Massively Parallel Computation in DRAM via Lookup Tables"}]}

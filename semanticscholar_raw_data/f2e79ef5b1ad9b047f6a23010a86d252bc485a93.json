{"paperId": "f2e79ef5b1ad9b047f6a23010a86d252bc485a93", "publicationVenue": {"id": "73e316c6-3e72-4c26-82ab-47e8da044b15", "name": "Symposium on Field Programmable Gate Arrays", "type": "conference", "alternate_names": ["Field Program Gate Array", "Symp Field Program Gate Array", "Field Programmable Gate Arrays", "FPGA"], "url": "http://www.wikicfp.com/cfp/program?id=1082"}, "title": "MOCHA: Multinode Cost Optimization in Heterogeneous Clouds with Accelerators", "abstract": "FPGAs have been widely deployed in public clouds, e.g., Amazon Web Services (AWS) and Huawei Cloud. However, simply offloading accelerated kernels from CPU hosts to PCIe-based FPGAs does not guarantee out-of-pocket cost savings in a pay-as-you-go public cloud. Taking Genome Analysis Toolkit (GATK) applications as case studies, although the adoption of FPGAs reduces the overall execution time, it introduces 2.56\u00d7 extra cost, due to insufficient application-level speedup by Amdahl's law. To optimize the out-of-pocket cost while keeping high speedup and throughput, we propose Mocha framework as a distributed runtime system to fully utilize the accelerator resource by accelerator sharing and CPU-FPGA partial task offloading. Evaluation results on Haplotype Caller (HTC) and Mutect2 in GATK show that on AWS, Mocha saves on the application cost by 2.82x for HTC, 1.06x for Mutect2 and on Huawei Cloud by 1.22x, 1.52x respectively than straightforward CPU-FPGA integration solution with less than 5.1% performance overhead.", "venue": "Symposium on Field Programmable Gate Arrays", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2021-02-17", "journal": {"name": "The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays"}, "authors": [{"authorId": "39399815", "name": "Peipei Zhou"}, {"authorId": "1865099", "name": "Jiayi Sheng"}, {"authorId": "17813719", "name": "Cody Hao Yu"}, {"authorId": "144537862", "name": "Peng Wei"}, {"authorId": "2146041652", "name": "Jie Wang"}, {"authorId": null, "name": "Di Wu"}, {"authorId": "2259796", "name": "J. Cong"}], "citations": [{"paperId": "f9b6ea589be1a8681ffb91c4e5f1bc465a190a1e", "title": "Towards Carbon Modeling of Cloud Servers with Accelerators"}, {"paperId": "504eb27743731d0594a7ceb4c6f596e19eb1f61e", "title": "REFRESH FPGAs: Sustainable FPGA Chiplet Architectures"}, {"paperId": "666925feadef6139dbea4bcbafe6e5fd63e8fee8", "title": "Resource Provisioning for CPU-FPGA Environments with Adaptive HLS-Versioning and DVFS"}, {"paperId": "717feb33598258ae72a4394556e8dc198b2893ef", "title": "Mimir: Finding Cost-efficient Storage Configurations in the Public Cloud"}, {"paperId": "476e5be97ea72accfbb845e029fa3f001135c602", "title": "Energy-aware fully-adaptive resource provisioning in collaborative CPU-FPGA cloud environments"}, {"paperId": "a7a0eac1ca927cf613751457369151859e71a0d2", "title": "CHARM: Composing Heterogeneous AcceleRators for Matrix Multiply on Versal ACAP Architecture"}, {"paperId": "8ec4ed52eaadf72ea01c50b77b165d029dbeb001", "title": "FPGA sharing in the cloud: a comprehensive analysis"}, {"paperId": "a2694d1f56f53bf92dccb4f678a445639373385e", "title": "Kairos: Building Cost-Efficient Machine Learning Inference Systems with Heterogeneous Cloud Resources"}, {"paperId": "e9ab2f65db81f5698b518b380c38ed407a4aa153", "title": "An FPGA Accelerator for Genome Variant Calling"}, {"paperId": "7fde8fdbf666fb2a42a9ce4c579dd4cd1236e183", "title": "RIBBON: Cost-Effective and QoS-Aware Deep Learning Model Inference using a Diverse Pool of Cloud Computing Instances"}, {"paperId": "77fc7be5a0cdc0141462a9cc00451e73329a13d7", "title": "Building Heterogeneous Cloud System for Machine Learning Inference"}]}

{"paperId": "20aa90187af7dd6508fa32ab438ea243fee0f5fa", "publicationVenue": null, "title": "PACE: Poisoning Attacks on Learned Cardinality Estimation", "abstract": "Cardinality estimation (CE) plays a crucial role in database optimizer. We have witnessed the emergence of numerous learned CE models recently which can outperform traditional methods such as histograms and samplings. However, learned models also bring many security risks. For example, a query-driven learned CE model learns a query-to-cardinality mapping based on the historical workload. Such a learned model could be attacked by poisoning queries, which are crafted by malicious attackers and woven into the historical workload, leading to performance degradation of CE.\n In this paper, we explore the potential security risks in learned CE and study a new problem of poisoning attacks on learned CE in a black-box setting. There are three challenges. First, the interior details of the CE model are hidden in the black-box setting, making it difficult to attack the model. Second, the attacked CE model's parameters will be updated with the poisoning queries, i.e., a variable varying with the optimization variable, so the problem cannot be modeled as a univariate optimization problem and thus is hard to solve by an efficient algorithm. Third, to make an imperceptible attack, it requires to generate poisoning queries that follow a similar distribution to historical workload. We propose a poisoning attack system, PACE, to address these challenges. To tackle the first challenge, we propose a method of speculating and training a surrogate model, which transforms the black-box attack into a near-white-box attack. To address the second challenge, we model the poisoning problem as a bivariate optimization problem, and design an effective and efficient algorithm to solve it. To overcome the third challenge, we propose an adversarial approach to train a poisoning query generator alongside an anomaly detector, ensuring that the poisoning queries follow similar distribution to historical workload. Experiments show that PACE reduces the accuracy of the learned CE models by 178\u00d7, leading to a 10\u00d7 decrease in the end-to-end performance of the target database.", "venue": "Proceedings of the ACM on Management of Data", "year": 2024, "fieldsOfStudy": null, "publicationTypes": ["JournalArticle"], "publicationDate": "2024-03-12", "journal": {"name": "Proceedings of the ACM on Management of Data"}, "authors": [{"authorId": "2294006464", "name": "Jintao Zhang"}, {"authorId": "2293932677", "name": "Chao Zhang"}, {"authorId": "2242412700", "name": "Guoliang Li"}, {"authorId": "1720852203", "name": "Chengliang Chai"}], "citations": []}

{"paperId": "15be954fe1d8b591be64ff7c0fc7eaa2ace0e32a", "publicationVenue": null, "title": "A Comparative Evaluation of Deep Reinforcement Learning Frameworks", "abstract": "In recent years, deep reinforcement learning (DRL) has emerged as a powerful and general approach for a variety of sequential decision making tasks. While early research has been mainly limited to controlled environments like complex video games and scoped robotic tasks, recent works have shown large potential in applying DRL approaches for everyday tasks in computer systems. A large number of frameworks providing reference implementations of common deep reinforcement learning algorithms makes it possible nowadays for the researchers and developers to quickly prototype new ideas for DRL applications. However, due to the heterogeneous nature of these solutions and absence of formal guidelines, choosing a framework that fits the particular use case of a developer and some given system requirements may be challenging. Therefore, in this research we conduct the first comparative evaluation of several state-ofthe-art DRL frameworks in an attempt to improve researchers\u2019 and developers\u2019 awareness of a wide range of existing solutions, and how they compare. In particular, in this work, we provide an evaluation platform, using it to analyze key components and features of such representative frameworks as the research-oriented and lightweight Dopamine library, the end-to-end Horizon platform for large-scale production systems, and the Ray RLlib framework, which is optimized to enhance learning in a distributed setting. By varying numerous parameters in the frameworks\u2019 configurations, we simulate several scenarios and report framework performance both in terms of runtime and in the stability of the learning process. Empirical results obtained for a traditional CartPole and real-world Query Optimizer environments indicate that Ray RLlib\u2019s parallel abstract components provide the best performance both on CPU and GPU. Although Horizon agents failed to achieve the optimal performance for the chosen common configuration and network architecture, this framework offers numerous features valuable in a production setting where access to the environment might be restricted. Dopamine, on the other hand, managed to provide both a compact implementation and satisfying performance across a number of experiments. While by no means exhaustive, our research provides a comprehensible overview of existing DRL solutions and highlights the main differences in their design and purposes. By sharing our flexible evaluation platform, we encourage the scientific community to contribute to our study by implementing new experiments for already integrated frameworks and other promising solutions.", "venue": "", "year": 2019, "fieldsOfStudy": null, "publicationTypes": ["Review"], "publicationDate": null, "journal": null, "authors": [{"authorId": "2096708540", "name": "P. Shevchenko"}, {"authorId": "1746173", "name": "G. Saake"}, {"authorId": "3236596", "name": "Christian R\u00f6ssl"}], "citations": []}

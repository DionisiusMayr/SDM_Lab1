{"paperId": "30d8e9602ea5ac4104331dfe78c0a3832ff5f72b", "publicationVenue": {"id": "22c9862f-a25e-40cd-9d31-d09e68a293e6", "name": "Machine-mediated learning", "type": "journal", "alternate_names": ["Mach learn", "Machine Learning", "Mach Learn"], "issn": "0732-6718", "alternate_issns": ["0885-6125"], "url": "http://www.springer.com/computer/artificial/journal/10994", "alternate_urls": ["https://link.springer.com/journal/10994", "http://www.springer.com/west/home/computer/artificial?SGWID=4-147-70-35726603-0"]}, "title": "Dealing with multiple experts and non-stationarity in inverse reinforcement learning: an application to real-life problems", "abstract": null, "venue": "Machine-mediated learning", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2021-03-14", "journal": {"name": "Machine Learning", "pages": "2541 - 2576", "volume": "110"}, "authors": [{"authorId": "1396459632", "name": "Amarildo Likmeta"}, {"authorId": "24717227", "name": "Alberto Maria Metelli"}, {"authorId": "144763838", "name": "Giorgia Ramponi"}, {"authorId": "46188113", "name": "Andrea Tirinzoni"}, {"authorId": "47340819", "name": "M. Giuliani"}, {"authorId": "1792167", "name": "Marcello Restelli"}], "citations": [{"paperId": "03a631ec943a91d6e95275e2e2216ca54b58f0de", "title": "Inverse Reinforcement Learning with Sub-optimal Experts"}, {"paperId": "a1d5ee777646b5420ec61e41a1a301dac10892ba", "title": "Multi-intention Inverse Q-learning for Interpretable Behavior Representation"}, {"paperId": "006d5ff1dbeb3465f6901dc38a267ab9c2636ac2", "title": "Towards Theoretical Understanding of Inverse Reinforcement Learning"}, {"paperId": "8aa66115a81e192fdb7219867cc301992499a4b1", "title": "Bankruptcy-evolutionary games based solution for the multi-agent credit assignment problem"}, {"paperId": "a6edc97c4cb8af13bb593c6c27610ce2eb8e7b20", "title": "Inverse Reinforcement Learning as the Algorithmic Basis for Theory of Mind: Current Methods and Open Problems"}, {"paperId": "50b7baed2365f292b67cf95470b5cec170a69715", "title": "Tight Performance Guarantees of Imitator Policies with Continuous Actions"}, {"paperId": "cc9a1a1808a542c92978e76fa196a35f76cc5f49", "title": "Model-free inverse reinforcement learning with multi-intention, unlabeled, and overlapping demonstrations"}, {"paperId": "b09fca07015809a7b9e3f6ef9ef510bf8352edac", "title": "Online Learning Human Behavior for a Class of Human-in-the-Loop Systems via Adaptive Inverse Optimal Control"}, {"paperId": "947d7814a4631c101ef896cb564a67cac65eb93a", "title": "First, do no harm - Missing data treatment to support lake ecological condition assessment"}, {"paperId": "b5876b4940c37fc05b661a16d8262e42721f6aa7", "title": "Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning"}, {"paperId": "6d0adac188152fbaa45a88ba4da788926ed8144a", "title": "Reinforcement Learning in Practice: Opportunities and Challenges"}, {"paperId": "9b969e22973b4d3ead02d69a678c5dfd2e83b560", "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time"}, {"paperId": "368f02cbb95213b5e13b10a6696abab944e39a59", "title": "Forming Real-World Human-Robot Cooperation for Tasks With General Goal"}, {"paperId": "7575b6eae80cc22b522c5ae6381cb689454fd645", "title": "Option Compatible Reward Inverse Reinforcement Learning"}, {"paperId": "50317d1f6e460fe90406074c0545acf65a1fe5f9", "title": "A Tutorial on Internet of Behaviors: Concept, Architecture, Technology, Applications, and Challenges"}, {"paperId": "dd82df889ca3ddab1c60d943293441284cce98a0", "title": "Balancing Sample Efficiency and Suboptimality in Inverse Reinforcement Learning"}, {"paperId": "61fff1deebd649264dcfac407c70d1f0db87adea", "title": "Dynamic Inverse Reinforcement Learning for Characterizing Animal Behavior"}, {"paperId": "cba09b6ea79d4b45fa4b93b4b7a60896d6b21390", "title": "Provably Efficient Learning of Transferable Rewards"}]}

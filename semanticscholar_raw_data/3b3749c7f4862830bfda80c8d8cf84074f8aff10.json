{"paperId": "3b3749c7f4862830bfda80c8d8cf84074f8aff10", "publicationVenue": null, "title": "TCUDB: Accelerating Database with Tensor Processors", "abstract": "The emergence of novel hardware accelerators has powered the tremendous growth of machine learning in recent years. These accelerators deliver incomparable performance gains in processing high-volume matrix operators, particularly matrix multiplication, a core component of neural network training and inference. In this work, we explored opportunities of accelerating database systems using NVIDIA's Tensor Core Units (TCUs). We present TCUDB, a TCU-accelerated query engine processing a set of query operators including natural joins and group-by aggregates as matrix operators within TCUs. Matrix multiplication was considered inefficient in the past; however, this strategy has remained largely unexplored in conventional GPU-based databases, which primarily rely on vector or scalar processing. We demonstrate the significant performance gain of TCUDB in a range of real-world applications including entity matching, graph query processing, and matrix-based data analytics. TCUDB achieves up to 288x speedup compared to a baseline GPU-based query engine.", "venue": "SIGMOD Conference", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle", "Conference"], "publicationDate": "2021-12-14", "journal": {"name": "Proceedings of the 2022 International Conference on Management of Data"}, "authors": [{"authorId": "115512247", "name": "Yu-Ching Hu"}, {"authorId": "47001493", "name": "Yuliang Li"}, {"authorId": "2653363", "name": "Hung-Wei Tseng"}], "citations": [{"paperId": "df3e456ed971931a5840a777106d184481f94a3c", "title": "Efficiently Processing Large Relational Joins on GPUs"}, {"paperId": "3adca9d49eab1a4db6538a995af3636d10e120c3", "title": "BladeDISC: Optimizing Dynamic Shape Machine Learning Workloads via Compiler Approach"}, {"paperId": "839e997bd3ff92e095b73a42bbd493f329a04853", "title": "MAD MAcce: Supporting Multiply-Add Operations for Democratizing Matrix-Multiplication Accelerators"}, {"paperId": "478247d1e7526ce6fa94dbc710d49a01a6327c7a", "title": "Exploiting the Potential of Flexible Processing Units"}, {"paperId": "aaa732b3f8215fb3edf16bee1205f5056c0f2201", "title": "TensorCV: Accelerating Inference-Adjacent Computation Using Tensor Processors"}, {"paperId": "751ddace56889adfda1153a0fda7781619e32d70", "title": "JoinBoost: Grow Trees Over Normalized Data Using Only SQL"}, {"paperId": "6ae19fb6eae020951aeccbed884e04f3824bf518", "title": "Accelerating Machine Learning Queries with Linear Algebra Query Processing"}, {"paperId": "3f975d7daa17a25f88aee309cb9781ecdaa958ce", "title": "rNdN: Fast Query Compilation for NVIDIA GPUs"}, {"paperId": "c909aaf29267c8a4cd31d8de2a82dbfba351257a", "title": "Optimizing Tensor Computations: From Applications to Compilation and Runtime Techniques"}, {"paperId": "49ca8424856fec72b395b833c83801b9ab0927fd", "title": "AMULET: Adaptive Matrix-Multiplication-Like Tasks"}, {"paperId": "f13612cafb71f3617cb8d29a8b8363d2756e292d", "title": "An Empirical Performance Comparison between Matrix Multiplication Join and Hash Join on GPUs"}, {"paperId": "6581a666f0f47df9cda7f0c398fe00c0d27c56a9", "title": "ADAMANT: A Query Executor with Plug-In Interfaces for Easy Co-processor Integration"}, {"paperId": "f9e0a938f9fa75d2a2c96691d4812516a1ecc388", "title": "Density-optimized Intersection-free Mapping and Matrix Multiplication for Join-Project Operations"}, {"paperId": "489f6c0e46fc72ee91a06e99cfb48d969acd654e", "title": "Amalur: Data Integration Meets Machine Learning"}, {"paperId": "6af0c985f4761c48f8a68d52da1a8c0807fb14e1", "title": "SIMD2: a generalized matrix instruction set for accelerating tensor computation beyond GEMM"}, {"paperId": "300823792f3854a857c452259455fe4b162c3104", "title": "Query Processing on Tensor Computation Runtimes"}, {"paperId": "7d449b130b547b1519c6e5902cc6888416f91b36", "title": "Trinity: In-Database Near-Data Machine Learning Acceleration Platform for Advanced Data Analytics"}]}

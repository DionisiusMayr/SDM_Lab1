{"paperId": "e12a970a0069ae11b99616694cfb715a01c29f6e", "publicationVenue": null, "title": "Detect, Distill and Update: Learned DB Systems Facing Out of Distribution Data", "abstract": "Machine Learning (ML) is changing DBs as many DB components are being replaced by ML models. One open problem in this setting is how to update such ML models in the presence of data updates. We start this investigation focusing on data insertions (dominating updates in analytical DBs). We study how to update neural network (NN) models when new data follows a different distribution (a.k.a. it is \"out-of-distribution\" -- OOD), rendering previously-trained NNs inaccurate. A requirement in our problem setting is that learned DB components should ensure high accuracy for tasks on old and new data (e.g., for approximate query processing (AQP), cardinality estimation (CE), synthetic data generation (DG), etc.). This paper proposes a novel updatability framework (DDUp). DDUp can provide updatability for different learned DB system components, even based on different NNs, without the high costs to retrain the NNs from scratch. DDUp entails two components: First, a novel, efficient, and principled statistical-testing approach to detect OOD data. Second, a novel model updating approach, grounded on the principles of transfer learning with knowledge distillation, to update learned models efficiently, while still ensuring high accuracy. We develop and showcase DDUp's applicability for three different learned DB components, AQP, CE, and DG, each employing a different type of NN. Detailed experimental evaluation using real and benchmark datasets for AQP, CE, and DG detail DDUp's performance advantages.", "venue": "Proc. ACM Manag. Data", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2022-10-11", "journal": {"name": "Proceedings of the ACM on Management of Data", "pages": "1 - 27", "volume": "1"}, "authors": [{"authorId": "151499040", "name": "M. Kurmanji"}, {"authorId": "1732298", "name": "P. Triantafillou"}], "citations": [{"paperId": "49a5aadfceac5d5ed9e224bc777f4f616de1daae", "title": "Modeling Shifting Workloads for Learned Database Systems"}, {"paperId": "20aa90187af7dd6508fa32ab438ea243fee0f5fa", "title": "PACE: Poisoning Attacks on Learned Cardinality Estimation"}, {"paperId": "cb05ef87cf3c8616626e3648f6a4146199acf57f", "title": "Machine Unlearning in Learned Databases: An Experimental Analysis"}, {"paperId": "8731e01cba81f6b9bfa79430f3c2d23ff36e5bf6", "title": "Deep Learning-Based Bloom Filter for Efficient Multi-key Membership Testing"}, {"paperId": "ffbcb2112645d3c82eb0027de0c2c6caac991810", "title": "ML-Powered Index Tuning: An Overview of Recent Progress and Open Challenges"}, {"paperId": "b062366d9bcf3284c2a38be0b95765b1aac683bf", "title": "Eraser: Eliminating Performance Regression on Learned Query Optimizer"}, {"paperId": "afbd24227a90a13c30876c905643b68171e5e1bc", "title": "On Nonlinear Learned String Indexing"}]}

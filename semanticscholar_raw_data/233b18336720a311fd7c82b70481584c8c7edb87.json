{"paperId": "233b18336720a311fd7c82b70481584c8c7edb87", "publicationVenue": {"id": "cdc83875-a82d-445c-b097-cbe91afe99a8", "name": "Conference on Fairness, Accountability and Transparency", "type": "conference", "alternate_names": ["FAccT", "Conf Fairness Account Transpar"], "url": "https://facctconference.org/"}, "title": "\u201cI\u2019m fully who I am\u201d: Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation", "abstract": "Warning: This paper contains examples of gender non-affirmative language which could be offensive, upsetting, and/or triggering. Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization of TGNB persons contributes to and persists within Open Language Generation (OLG). This social knowledge serves as a guide for evaluating popular large language models (LLMs) on two key aspects: (1) misgendering and (2) harmful responses to gender disclosure. To do this, we introduce TANGO, a dataset of template-based real-world text curated from a TGNB-oriented community. We discover a dominance of binary gender norms reflected by the models; LLMs least misgendered subjects in generated text when triggered by prompts whose subjects used binary pronouns. Meanwhile, misgendering was most prevalent when triggering generation with singular they and neopronouns. When prompted with gender disclosures, TGNB disclosure generated the most stigmatizing language and scored most toxic, on average. Our findings warrant further research on how TGNB harms manifest in LLMs and serve as a broader case study toward concretely grounding the design of gender-inclusive AI in community voices and interdisciplinary literature.", "venue": "Conference on Fairness, Accountability and Transparency", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["Book", "JournalArticle"], "publicationDate": "2023-05-17", "journal": {"name": "Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency"}, "authors": [{"authorId": "51494507", "name": "Anaelia Ovalle"}, {"authorId": "3436466", "name": "Palash Goyal"}, {"authorId": "3475586", "name": "J. Dhamala"}, {"authorId": "20742874", "name": "Zachary Jaggers"}, {"authorId": "2110821190", "name": "Kai Wei Chang"}, {"authorId": "143728483", "name": "A. Galstyan"}, {"authorId": "1804104", "name": "R. Zemel"}, {"authorId": "2139538015", "name": "Rahul Gupta"}], "citations": [{"paperId": "7169ead14cdf1a7d86c89e930d195bdb328ea936", "title": "Robust Pronoun Use Fidelity with English LLMs: Are they Reasoning, Repeating, or Just Biased?"}, {"paperId": "8c323eca1406bd4020c98d6b5f00ff8f2b7f3340", "title": "Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation"}, {"paperId": "7a63385cfdb5c7ecd6b78e3eadb832c4b92ba62b", "title": "Measuring Implicit Bias in Explicitly Unbiased Large Language Models"}, {"paperId": "5da06eb3a746932acfe36b81c7c640c3d969ae70", "title": "Evaluating Gender Bias in Large Language Models via Chain-of-Thought Prompting"}, {"paperId": "fe9cec220e93e1cb7fe3d49cb3458f5cde1d8b2d", "title": "Mapping the Field of Algorithm Auditing: A Systematic Literature Review Identifying Research Trends, Linguistic and Geographical Disparities"}, {"paperId": "b7e503f77773d9947c0bb5452b6905891fd52eea", "title": "The Gaps between Pre-train and Downstream Settings in Bias Evaluation and Debiasing"}, {"paperId": "a8798c4a2352a118a369678b164ab4c249004642", "title": "AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters"}, {"paperId": "910e0dbbca0fca4b066fce8834be791d3e46e9b0", "title": "Fairness Certification for Natural Language Processing and Large Language Models"}, {"paperId": "283c4236d56e970a20859b442e048c9f197d15c5", "title": "Tokenization Matters: Navigating Data-Scarce Tokenization for Gender Inclusive Language Technologies"}, {"paperId": "66a4ebd72a0a858b7cd01b9ef583055c50671f8b", "title": "Can Large Language Models Support Medical Facilitation Work? A Speculative Analysis"}, {"paperId": "02ff8161b2c93d610fcbccce96231de12790d759", "title": "Trust in Queer Human-Robot Interaction"}, {"paperId": "b930342321b0e3e63e6ce6f90680130d7b5b4a97", "title": "Test Suites Task: Evaluation of Gender Fairness in MT with MuST-SHE and INES"}, {"paperId": "f1269db14771485d06e64940a05c5d95e4eb36ce", "title": "Impact of Stricter Content Moderation on Parler's Users' Discourse"}, {"paperId": "ce157cea880c9ab64de64f11a531202f5348fa05", "title": "\"Kelly is a Warm Person, Joseph is a Role Model\": Gender Biases in LLM-Generated Reference Letters"}, {"paperId": "e36128e4cc6ac3e7a99b487403537e869f0b518d", "title": "Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus"}, {"paperId": "02006613484021c6c0a49fe6351bc7f20f823a62", "title": "Queering the ethics of AI"}, {"paperId": "a4d543cc77a0a643a271988f5b4b6699f421c85c", "title": "Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms"}, {"paperId": "225a242405d1629b18b7c4367a3101509c9274bb", "title": "Scaling Laws Do Not Scale"}, {"paperId": "cfd2145fa17d2fcd7f1dba27bd713eaa4e798c1f", "title": "Sociodemographic Bias in Language Models: A Survey and Forward Path"}, {"paperId": "a80d106b4536884af8da68078babc70086b1a607", "title": "Evaluating the Social Impact of Generative AI Systems in Systems and Society"}, {"paperId": "5df8a05f298ca6a12f5042ba58a356f840b0531e", "title": "A Study on Chinese Social Perspective regarding ChatGPT for Education and Beyond"}, {"paperId": "5677b3de564fddf06f518c79429697f316d944d4", "title": "MISGENDERED: Limits of Large Language Models in Understanding Pronouns"}]}

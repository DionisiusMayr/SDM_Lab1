{"paperId": "c0082580c4b9e5c6c96cf06f1be67c0cbbafb753", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models", "abstract": "Patients often face difficulties in understanding their hospitalizations, while healthcare workers have limited resources to provide explanations. In this work, we investigate the potential of large language models to generate patient summaries based on doctors' notes and study the effect of training data on the faithfulness and quality of the generated summaries. To this end, we develop a rigorous labeling protocol for hallucinations, and have two medical experts annotate 100 real-world summaries and 100 generated summaries. We show that fine-tuning on hallucination-free data effectively reduces hallucinations from 2.60 to 1.55 per summary for Llama 2, while preserving relevant information. Although the effect is still present, it is much smaller for GPT-4 when prompted with five examples (0.70 to 0.40). We also conduct a qualitative evaluation using hallucination-free and improved training data. GPT-4 shows very good results even in the zero-shot setting. We find that common quantitative metrics do not correlate well with faithfulness and quality. Finally, we test GPT-4 for automatic hallucination detection, which yields promising results.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2024-02-23", "journal": {"name": "ArXiv", "volume": "abs/2402.15422"}, "authors": [{"authorId": "2257302522", "name": "Stefan Hegselmann"}, {"authorId": "101568984", "name": "Zejiang Shen"}, {"authorId": "2286305430", "name": "Florian Gierse"}, {"authorId": "2056898702", "name": "Monica Agrawal"}, {"authorId": "2264980099", "name": "David Sontag"}, {"authorId": "2286448733", "name": "Xiaoyi Jiang"}], "citations": []}

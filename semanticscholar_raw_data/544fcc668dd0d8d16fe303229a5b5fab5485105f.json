{"paperId": "544fcc668dd0d8d16fe303229a5b5fab5485105f", "publicationVenue": null, "title": "Near LLC versus near main memory processing", "abstract": "Emerging advanced applications, such as deep learning and graph processing, with enormous processing demand and massive memory requests call for a comprehensive processing system or advanced solutions to address these requirements. Near data processing is one of the promising structures targeting this goal. However, most recent studies have focused on processing instructions near the main memory data banks while ignoring the benefits of processing instructions near other memory hierarchy levels such as LLC. In this study, we investigate the near LLC processing structures, and compare it to the near main memory processing alternative, specifically in graphics processing units. We analyze these two structures on various applications in terms of performance and power. Results show a clear benefit of near LLC processing over near main memory processing in a class of applications. Further, we suggest an architecture, which could benefit from both near main memory and near LLC processing structures, but requiring the applications to be characterized in advance or at run time.", "venue": "GPGPU@PPoPP", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2022-04-03", "journal": {"name": "Proceedings of the 14th Workshop on General Purpose Processing Using GPU"}, "authors": [{"authorId": "2121832825", "name": "Hossein Bitalebi"}, {"authorId": "2127770954", "name": "Vahid Geraeinejad"}, {"authorId": "145273965", "name": "M. Ebrahimi"}], "citations": [{"paperId": "71da072154d65ab4f9095b25a5f79ee50dc019d1", "title": "LATOA: Load-Aware Task Offloading and Adoption in GPU"}, {"paperId": "087979a130fb1816fcc66958a33134556ef039cd", "title": "Inference Time Reduction of Deep Neural Networks on Embedded Devices: A Case Study"}]}

{"paperId": "d8ece1181a52b171143131c351e77894a689509a", "publicationVenue": {"id": "e02accb9-dacc-43fd-995e-92fe9a825cc4", "name": "Design, Automation and Test in Europe", "type": "conference", "alternate_names": ["Design, Automation, and Test in Europe", "DATE", "Des Autom Test Eur"], "issn": "1530-1591", "alternate_issns": ["1558-1101"], "url": "https://ieeexplore.ieee.org/xpl/conhome/1000198/all-proceedings", "alternate_urls": ["http://www.date-conference.com/"]}, "title": "Securing Deep Spiking Neural Networks against Adversarial Attacks through Inherent Structural Parameters", "abstract": "Deep Learning (DL) algorithms have gained popularity owing to their practical problem-solving capacity. However, they suffer from a serious integrity threat, i.e., their vulnerability to adversarial attacks. In the quest for DL trustworthiness, recent works claimed the inherent robustness of Spiking Neural Networks (SNNs) to these attacks, without considering the variability in their structural spiking parameters. This paper explores the security enhancement of SNNs through internal structural parameters. Specifically, we investigate the SNNs robustness to adversarial attacks with different values of the neuron's firing voltage thresholds and time window boundaries. We thoroughly study SNNs security under different adversarial attacks in the strong white-box setting, with different noise budgets and under variable spiking parameters. Our results show a significant impact of the structural parameters on the SNNs' security, and promising sweet spots can be reached to design trustworthy SNNs with 85% higher robustness than a traditional non-spiking DL system. To the best of our knowledge, this is the first work that investigates the impact of structural parameters on SNNs robustness to adversarial attacks. The proposed contributions and the experimental framework is available online 11https://github.com/rda-ela/SNN-Adversarial-Attacks to the community for reproducible research.", "venue": "Design, Automation and Test in Europe", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2020-12-09", "journal": {"name": "2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)", "pages": "774-779"}, "authors": [{"authorId": "2034158630", "name": "Rida El-Allami"}, {"authorId": "51486203", "name": "Alberto Marchisio"}, {"authorId": "145063983", "name": "M. Shafique"}, {"authorId": "2880991", "name": "Ihsen Alouani"}], "citations": [{"paperId": "a37c236803455afd7da3dc027e7865a0414a5697", "title": "Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack"}, {"paperId": "c0eda0c5b4314edcfd8ac734586e745b590e711f", "title": "Moving Target Defense Through Approximation for Low-Power Neuromorphic Edge Intelligence"}, {"paperId": "075ad710f548810560e2844b39f6e89147cbc34c", "title": "Adversarially Robust Spiking Neural Networks Through Conversion"}, {"paperId": "ed51f169c4b9c5794c29459784958c9f1121e30a", "title": "Towards Effective Training of Robust Spiking Recurrent Neural Networks Under General Input Noise via Provable Analysis"}, {"paperId": "9025ffd1fd220cbbf4a91aa758662d17716dd345", "title": "HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds"}, {"paperId": "23a285c721faf96ed65070ad542b1d5d159c7acb", "title": "HyperSNN: A new efficient and robust deep learning model for resource constrained control applications"}, {"paperId": "b6067c140109b5eadbee61e0d758d54f68253dd5", "title": "A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural Networks"}, {"paperId": "f8e455422ffcbc395899016d1262a47518142af8", "title": "Rate Gradient Approximation Attack Threats Deep Spiking Neural Networks"}, {"paperId": "06494c07707736770a7d9871fa332c2a5866b8f9", "title": "A regularization perspective based theoretical analysis for adversarial robustness of deep spiking neural networks"}, {"paperId": "e2cd0a85f65e085c59ef4c6ea8b9f7285744c0c7", "title": "A Comprehensive Review of Spiking Neural Networks: Interpretation, Optimization, Efficiency, and Best Practices"}, {"paperId": "ea14ef2fde967c9ca6a414cd34dc9622beadae89", "title": "Linear Leakage: Better Robustness for Spiking Neural Network"}, {"paperId": "0c3290a60188784ddc38733102bc83574044ebee", "title": "Security-Aware Approximate Spiking Neural Networks"}, {"paperId": "9d04631704209f07199ddd8aae538ce1bc02aeee", "title": "Improving Reliability of Spiking Neural Networks through Fault Aware Threshold Voltage Optimization"}, {"paperId": "7208f4a1e7da9efb2a10c95e5e322ea6c17ac215", "title": "Adversarial Defense via Neural Oscillation inspired Gradient Masking"}, {"paperId": "a10a1c4210a33fe149e13db68cae098673c27f28", "title": "Attacking the Spike: On the Transferability and Security of Spiking Neural Networks to Adversarial Examples"}, {"paperId": "4401bc479fed88233ba5a332a7c988707db4595d", "title": "Special Session: Towards an Agile Design Methodology for Efficient, Reliable, and Secure ML Systems"}, {"paperId": "009aeca83b4b15c2af1e8230693aab6e30d83c9b", "title": "Toward Robust Spiking Neural Network Against Adversarial Perturbation"}, {"paperId": "a8ae5a8ebb77b4790f4c087f57340760dbd780fa", "title": "HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep Spiking Neural Networks by Training with Crafted Input Noise"}, {"paperId": "69d5dbf25c5a9873b684beb2b70ceab6b71fd3dc", "title": "Towards Energy-Efficient and Secure Edge AI: A Cross-Layer Framework ICCAD Special Session Paper"}, {"paperId": "2e581c18688ca559491e9788582dae9ceec6b71a", "title": "DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks"}, {"paperId": "18e30e6892ffa6bb720c06573488da1eb9e1f5a1", "title": "Robuste Lernverfahren"}, {"paperId": "b39f31035b1706e64bfdd6269c8af744d8af04e1", "title": "A Comparative Study on the Performance and Security Evaluation of Spiking Neural Networks"}, {"paperId": "5a3819ade33edf557e074b4f9c6c43240ada9837", "title": "Security of Event-Based Spiking Neural Networks: Attacks and Defense Methodologies Supervisors"}]}

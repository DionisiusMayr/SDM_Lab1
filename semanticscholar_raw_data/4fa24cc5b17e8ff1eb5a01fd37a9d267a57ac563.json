{"paperId": "4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Recipes for Safety in Open-domain Chatbots", "abstract": "Models trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which include offensive or otherwise toxic behavior and unwanted biases. We investigate a variety of methods to mitigate these issues in the context of open-domain generative dialogue models. We introduce a new human-and-model-in-the-loop framework for both training safer models and for evaluating them, as well as a novel method to distill safety considerations inside generative models without the use of an external classifier at deployment time. We conduct experiments comparing these methods and find our new techniques are (i) safer than existing models as measured by automatic and human evaluations while (ii) maintaining usability metrics such as engagingness relative to the state of the art. We then discuss the limitations of this work by analyzing failure cases of our models.", "venue": "arXiv.org", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-10-14", "journal": {"name": "ArXiv", "volume": "abs/2010.07079"}, "authors": [{"authorId": "2155954521", "name": "Jing Xu"}, {"authorId": "3092435", "name": "Da Ju"}, {"authorId": "6649233", "name": "Margaret Li"}, {"authorId": "90841478", "name": "Y-Lan Boureau"}, {"authorId": "145183709", "name": "J. Weston"}, {"authorId": "31461304", "name": "Emily Dinan"}], "citations": [{"paperId": "a4fe9129afaf2ce1876057d0f33314a82a6731a4", "title": "ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors"}, {"paperId": "66478b3142aa4fc3d7e8166f19720c678caf0b71", "title": "Nevermind: Instruction Override and Moderation in Large Language Models"}, {"paperId": "6ecb6f2c4544e3c7f8dfd33a8e2f14735653b6ef", "title": "Improving Dialog Safety using Socially Aware Contrastive Learning"}, {"paperId": "b1f243b586e87fe12ff8fe1a501f11ea5fc5ad44", "title": "On Prompt-Driven Safeguarding for Large Language Models"}, {"paperId": "4fda99880cdbf8f178f01eb4c8dbdae7f959ea94", "title": "Red-Teaming for Generative AI: Silver Bullet or Security Theater?"}, {"paperId": "a6a8896dea728310d1bfe829e027e10cccdf4974", "title": "Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing Security in Large Language Models"}, {"paperId": "de4dfb773ab455081e5fb1862e08f581c58d43bc", "title": "Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems"}, {"paperId": "aac83deb068875d2dffb58b2c8fdeffc6ad2a38a", "title": "A First Look at Toxicity Injection Attacks on Open-domain Chatbots"}, {"paperId": "14e8cf5a5e6a7b35e618b08f5cf06f572b3a54e0", "title": "Tree of Attacks: Jailbreaking Black-Box LLMs Automatically"}, {"paperId": "3409a29c7287a5e0010f48f8bca42679e3b10c12", "title": "Tackling Bias in Pre-trained Language Models: Current Trends and Under-represented Societies"}, {"paperId": "d33af48af5d8f268d83dbdd0368057090808b4f1", "title": "Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models"}, {"paperId": "034c8d4eb031786925ef274e6d275c7c210c4f1d", "title": "Unveiling the Implicit Toxicity in Large Language Models"}, {"paperId": "ef7097244ee0cc2d54649e7bec121abf7c628947", "title": "A Survey of the Evolution of Language Model-Based Dialogue Systems"}, {"paperId": "c2f9b21da0ce660c09fe8e740d020d9a752e748b", "title": "Compositional Capabilities of Autoregressive Transformers: A Study on Synthetic, Interpretable Tasks"}, {"paperId": "ecdfc556828dc59d8a0009016fcbe97a06cf7e23", "title": "Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework"}, {"paperId": "c4ff1be5c254b60b96b7455eefcc4ec9583f82ed", "title": "A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily"}, {"paperId": "57d0e672040800e8d882ff0022647c087095e35f", "title": "AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications"}, {"paperId": "709af143f78bc62413c50ea1a7ee75b0702c4f59", "title": "MART: Improving LLM Safety with Multi-round Automatic Red-Teaming"}, {"paperId": "69627a301cdd6b49a905bb9a2c83d54129563376", "title": "A Framework to Assess (Dis)agreement Among Diverse Rater Groups"}, {"paperId": "a60d610a9dd0db089cffdebd1512acf7eb478eae", "title": "Unveiling Safety Vulnerabilities of Large Language Models"}, {"paperId": "34fda38263a4af9d0be684ae564ce1c3120c3314", "title": "Successor Features for Efficient Multisubject Controlled Text Generation"}, {"paperId": "e314d182fd9d35a05870b38a56ee38eb3149b47d", "title": "Attack Prompt Generation for Red Teaming and Defending Large Language Models"}, {"paperId": "9ec29a26336f043a705ac99baa04c8d7f69fe4b4", "title": "Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis"}, {"paperId": "6f542f60a5d4f540d056bb49d47f89f1035ad0cf", "title": "A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement"}, {"paperId": "dd7a74a09fc29cadcd47fafc4f7812bb8d2d7208", "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values"}, {"paperId": "2403c8e72a90d9c778970fc0812ecdcc58800c5d", "title": "Can Language Models be Instructed to Protect Personal Information?"}, {"paperId": "e9ca67b67f4b43650baaef0d03013683eeb4528e", "title": "Large Language Models Can Be Good Privacy Protection Learners"}, {"paperId": "1310d08cf967e875eb417f7be8eaf896dc680251", "title": "No Offense Taken: Eliciting Offensiveness from Language Models"}, {"paperId": "72e05fac8cf01593f70c63e16385a7bf6fd0fe09", "title": "All Languages Matter: On the Multilingual Safety of Large Language Models"}, {"paperId": "c182bcd5f37f37fea9f3dad856dc381e0f19578a", "title": "Augmenting LLMs with Knowledge: A survey on hallucination prevention"}, {"paperId": "749d59f887c8ac83fd4f5178465e8b03e463358c", "title": "Large Language Model Alignment: A Survey"}, {"paperId": "cd29c25c489562b409a60f83365f93f33ee1a0a1", "title": "Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM"}, {"paperId": "946dfe19e35cb2ded83351526a166bd63015d172", "title": "Evaluating Chatbots to Promote Users' Trust - Practices and Open Problems"}, {"paperId": "1ab91d6ac7afc1a0121487a9089fa70edc1634d4", "title": "Certifying LLM Safety against Adversarial Prompting"}, {"paperId": "bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7", "title": "Bias and Fairness in Large Language Models: A Survey"}, {"paperId": "c11dad59cbca5cc4875391ebf5360f945aec933a", "title": "Identifying and Mitigating the Security Risks of Generative AI"}, {"paperId": "8d36390a430845849b62646a8c8be4c79f2b3d62", "title": "AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models"}, {"paperId": "897940fb5dd4d739b88c4659c4565d05f48d06b8", "title": "GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher"}, {"paperId": "df4d785dcdc0e8736fc46277fa03ed2eac3d63f6", "title": "Neural Conversation Models and How to Rein Them in: A Survey of Failures and Fixes"}, {"paperId": "104b0bb1da562d53cbda87aec79ef6a2827d191a", "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"}, {"paperId": "929305892d4ddae575a0fc23227a8139f7681632", "title": "Jailbroken: How Does LLM Safety Training Fail?"}, {"paperId": "f1eeba530be0ac537bcdf633ee6c462045c97fb5", "title": "Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup"}, {"paperId": "38e4ee78d41d0f910e8a5263e58e7b35cacb87c6", "title": "Intersectionality in Conversational AI Safety: How Bayesian Multilevel Models Help Understand Diverse Perceptions of Safety"}, {"paperId": "6e30a511242cd48a1394d87ce8d2b682978014a0", "title": "DICES Dataset: Diversity in Conversational AI Evaluation for Safety"}, {"paperId": "258934fa8c76d468f1ff9fa5cd6df84b16985dee", "title": "Enhancing Offensive Language Detection with Data Augmentation and Knowledge Distillation"}, {"paperId": "fecd289505aa53960bca88fd562d517265b751d0", "title": "Developing Effective Educational Chatbots with ChatGPT prompts: Insights from Preliminary Tests in a Case Study on Social Media Literacy"}, {"paperId": "4bd35d344c635b05f97f4d749741d196ff541bf3", "title": "A Primer on Seq2Seq Models for Generative Chatbots"}, {"paperId": "ff04b7e24337b06ff6be1e45c0933fbf2cce289f", "title": "Safety and Fairness for Content Moderation in Generative Models"}, {"paperId": "0b6edce3dde7e502c6b7c6d83bac0230ec912482", "title": "Improving Open Language Models by Learning from Organic Interactions"}, {"paperId": "b3f272d644fe580d18f635be4d6ac4c520ef0d0f", "title": "Preference-grounded Token-level Guidance for Language Model Fine-tuning"}, {"paperId": "cc3bfea86ed457079363598ae38af11dd3b00e47", "title": "Query-Efficient Black-Box Red Teaming via Bayesian Optimization"}, {"paperId": "0dadcbfc9b8d5d8b36ec8b98bf69ffe677ae5a79", "title": "Model-Based Simulation for Optimising Smart Reply"}, {"paperId": "969559ec5fcdb98dc5690640b2560d8df6fa9591", "title": "Reducing Sensitivity on Speaker Names for Text Generation from Dialogues"}, {"paperId": "27f9b6d984496b78998facd7c9ea53927d899c4a", "title": "ReSeTOX: Re-learning attention weights for toxicity mitigation in machine translation"}, {"paperId": "9379d519b8ddfa194ef6f575127451e5016e1803", "title": "Mirages: On Anthropomorphism in Dialogue Systems"}, {"paperId": "9ada8fa11b1cdece31f253acae50b62df8d5f823", "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation"}, {"paperId": "700da3f3758e053c379f905bebee261ba69f1073", "title": "Prompted LLMs as Chatbot Modules for Long Open-domain Conversation"}, {"paperId": "f7a7f9a66712a1a344533de693d4ff47aab8da3a", "title": "Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training"}, {"paperId": "9364720b2ab9ac67bc08e2b0b49aadded3d4e2e5", "title": "Appropriateness is all you need!"}, {"paperId": "3c24ac9fcc14c716208cc784a39bda847056c7f0", "title": "Towards Explainable and Safe Conversational Agents for Mental Health: A Survey"}, {"paperId": "7e0b582f10af855c7a2e2a6320939bd7dd82ef62", "title": "Learn What NOT to Learn: Towards Generative Safety in Chatbots"}, {"paperId": "59fc49dfd81b92661437eaf7e339c0792ccd8755", "title": "Safety Assessment of Chinese Large Language Models"}, {"paperId": "79e1324fc74dfd45ea8a7ca7b9fd0a12c1e09218", "title": "Safer Conversational AI as a Source of User Delight"}, {"paperId": "ffd53613590f434a08fbdbdf9c13ef067256f82e", "title": "Learn What Is Possible, Then Choose What Is Best: Disentangling One-To-Many Relations in Language Through Text-based Games"}, {"paperId": "fa07e26cb328188264fb7bba4e39320d5aed28d0", "title": "Those Aren't Your Memories, They're Somebody Else's: Seeding Misinformation in Chat Bot Memories"}, {"paperId": "a7c462a72df491a7514fbc096871a4ce6720406b", "title": "Unit Scaling: Out-of-the-Box Low-Precision Training"}, {"paperId": "851893ca18d52c77d60f79228fdf3e61eaf23fd1", "title": "Rewarding Chatbots for Real-World Engagement with Millions of Users"}, {"paperId": "da5fcb26c830663b79c9aa1c550ae62e7725fcad", "title": "Systematic Rectification of Language Models via Dead-end Analysis"}, {"paperId": "7cfaec8004c6d9f4fb5cf10287d15513c35b0a63", "title": "Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements"}, {"paperId": "c5120b546f1bd99df5bd2e2bf44db5c7c46d1545", "title": "Pretraining Language Models with Human Preferences"}, {"paperId": "1d75f8de31bf47ec46fa5586056420ec8bc97e86", "title": "Using In-Context Learning to Improve Dialogue Safety"}, {"paperId": "7c0013dff50fe4dbc6af3677324a5852716f121a", "title": "Mephisto: A Framework for Portable, Reproducible, and Iterative Crowdsourcing"}, {"paperId": "5784a10804c122d09349ff4e215cd12d8b72b6aa", "title": "MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Moral Discussions"}, {"paperId": "8616da9215843353f2169916766054dfbd50a671", "title": "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines"}, {"paperId": "a640cdafc10181517b7694ab589db515595b3490", "title": "Evaluating Human-Language Model Interaction"}, {"paperId": "9e3d35bd060dfe7dd962080eea94ea33840dadc3", "title": "On Safe and Usable Chatbots for Promoting Voter Participation"}, {"paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654", "title": "Constitutional AI: Harmlessness from AI Feedback"}, {"paperId": "ef3b5106b0af18ebb9e7a4ed8901351061315227", "title": "Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation"}, {"paperId": "4e53b481beabba42aac027e5a8c69fed26ab4062", "title": "RHO ($\u03c1$): Reducing Hallucination in Open-domain Dialogues with Knowledge Grounding"}, {"paperId": "f9575af71832d0d14aaea2dbf7485dd518239c29", "title": "An Exploratory Study on Chatbots"}, {"paperId": "8c5dfc418b937ba78e481ca46a5f43ac61863059", "title": "Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems"}, {"paperId": "44e02c4735e2e6cce3214e30bba1e30a92804bdd", "title": "Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey"}, {"paperId": "9c36c8f398a074801d6098287c4353bcf87a1d6c", "title": "Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values"}, {"paperId": "e085bd71d3cc53a6eba3aa7e6940171a3a5d1086", "title": "Risk-graded Safety for Handling Medical Queries in Conversational AI"}, {"paperId": "ab27a41e10d2362a58db2465073f2b8a4a29312a", "title": "Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling"}, {"paperId": "089c3a879253d730e98eaed7b945fa6c4113ca1f", "title": "Why So Toxic?: Measuring and Triggering Toxic Behavior in Open-Domain Chatbots"}, {"paperId": "a3076ecfed0571fbbb5217a5cc6b4b6f24f6f7dd", "title": "BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage"}, {"paperId": "1bff5af76552f6d3c881ab051275d037f26f66be", "title": "Learning from data in the mixed adversarial non-adversarial case: Finding the helpers and ignoring the trolls"}, {"paperId": "a4a111c37e42c84805051b1b0740ec1c7e683992", "title": "Investigating Debiasing Effects on Classification and Explainability"}, {"paperId": "1c25b49fb6a2789597320a9e3591a6e51f1ed6ed", "title": "Neural Generation Meets Real People: Building a Social, Informative Open-Domain Dialogue Agent"}, {"paperId": "242a463cdecee18efd9d1e8471d3695a413fba86", "title": "Improving Bot Response Contradiction Detection via Utterance Rewriting"}, {"paperId": "6d994b4f5a46cd14e8f09f1e9e49120546b15e31", "title": "CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning"}, {"paperId": "017cfe49fce1cb77bda2e1791f7203f5ebac0ac7", "title": "Director: Generator-Classifiers For Supervised Language Modeling"}, {"paperId": "b05f8f3e48227b452384d2b9527cc6fcc0db68b3", "title": "Resolving the Human Subjects Status of Machine Learning's Crowdworkers"}, {"paperId": "36c50e6638dddc8324eef9bfa064bfcab80cbef4", "title": "ProsocialDialog: A Prosocial Backbone for Conversational Agents"}, {"paperId": "cf18a9f5a334e574f1d1f6ffdd64b6dac11fe9be", "title": "RL with KL penalties is better viewed as Bayesian inference"}, {"paperId": "e2c16d93bca8822b571dd388af4e309069d1a373", "title": "Target-Guided Dialogue Response Generation Using Commonsense and Data Augmentation"}, {"paperId": "ee5a743129e5785b92aff156a947ca8c6beabbbc", "title": "Robust Conversational Agents against Imperceptible Toxicity Triggers"}, {"paperId": "13a0d8bb38f739990c8cd65a44061c6534f17221", "title": "OPT: Open Pre-trained Transformer Language Models"}, {"paperId": "0286b2736a114198b25fb5553c671c33aed5d477", "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"}, {"paperId": "db16bfde275a298b8de87b9710fd80a851db65ef", "title": "Korean Online Hate Speech Dataset for Multilabel Classification: How Can Social Science Improve Dataset on Hate Speech?"}, {"paperId": "3a8679d59143f1262ddf706b39e79b7d6421ebf2", "title": "Using Pre-Trained Language Models for Producing Counter Narratives Against Hate Speech: a Comparative Study"}, {"paperId": "4ae200e3e33045130f7abd1d38a82a8355dc6273", "title": "PANGUBOT: Efficient Generative Dialogue Pre-training from Pre-trained Language Model"}, {"paperId": "f8292d4ddf7a6dfe240eeaa9685f5d18eed9a3f6", "title": "Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion"}, {"paperId": "2613734d0fcff478915ea61e702160cfe88311d8", "title": "EVA2.0: Investigating Open-domain Chinese Dialogue Systems with Large-scale Pre-training"}, {"paperId": "d795901e67de0c1eb512dc6323a5e8997e288aa7", "title": "Beyond Plain Toxic: Detection of Inappropriate Statements on Flammable Topics for the Russian Language"}, {"paperId": "d766bffc357127e0dc86dd69561d5aeb520d6f4c", "title": "Training language models to follow instructions with human feedback"}, {"paperId": "de4635e95259118a545fdc0682407f416c16086a", "title": "AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation"}, {"paperId": "64acb0084c9dd8f454421ccc9289c1e389d7fcb8", "title": "Towards Identifying Social Bias in Dialog Systems: Framework, Dataset, and Benchmark"}, {"paperId": "37ddb9305c8c9120c21a2fae5a851ce8e4384a9c", "title": "Data Scaling Laws in NMT: The Effect of Noise and Architecture"}, {"paperId": "b3848d32f7294ec708627897833c4097eb4d8778", "title": "LaMDA: Language Models for Dialog Applications"}, {"paperId": "3664cceee40f91c75d1ee2d2e17a050e846e52bb", "title": "COLD: A Benchmark for Chinese Offensive Language Detection"}, {"paperId": "94f02394a8f019d7ece7eb9612e96253ba97f30c", "title": "Human Evaluation of Conversations is an Open Problem: comparing the sensitivity of various methods for evaluating dialogue agents"}, {"paperId": "8492aa1b0b799e19f7f0eb054c7adaba7bd5d866", "title": "There is no rose without a thorn: Finding weaknesses on BlenderBot 2.0 in terms of Model, Data and User-Centric Approach"}, {"paperId": "b90c090f7928a78d85d952737488be1ef8587ae5", "title": "A Literature Survey of Recent Advances in Chatbots"}, {"paperId": "5cf42d26583d2b083262451e9005e6ed273badca", "title": "Automatic Evaluation and Moderation of Open-domain Dialogue Systems"}, {"paperId": "35eb6755b63c45ff44d05ace8ea1b3b8c8db9eee", "title": "On the Safety of Conversational Models: Taxonomy, Dataset, and Benchmark"}, {"paperId": "5182b649f4c00784dd64e6f976021b1704a01d72", "title": "Analyzing Dynamic Adversarial Training Data in the Limit"}, {"paperId": "dc59b104f41d41d555c5b1a1fda7d69a5e080c53", "title": "Investigating Robustness of Dialog Models to Popular Figurative Language Constructs"}, {"paperId": "93df98bf527e97f3876dfefb8b167a221b37e638", "title": "ConvAbuse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in Conversational AI"}, {"paperId": "d64e57b9780f30f5b49bf620fdfb8584651b7f85", "title": "Challenges in Detoxifying Language Models"}, {"paperId": "697cb0d25869e83b8304b3feb7a9e5dbce85b182", "title": "Automatically Exposing Problems with Neural Dialog Models"}, {"paperId": "77d956cdab4508d569ae5741549b78e715fd0749", "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"}, {"paperId": "063183d95a249d94c95d12e7e9462e0aa84b6d85", "title": "Hi, my name is Martha: Using names to measure and mitigate bias in generative dialogue models"}, {"paperId": "9f54b02d32835a6dc977a335444df707494763ec", "title": "Proto: A Neural Cocktail for Generating Appealing Conversations"}, {"paperId": "718339cbafd0b4613d3389cc2c22592764b92c62", "title": "Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation"}, {"paperId": "f56cda7ee6b3cfa427d045b6cc754ec68349c511", "title": "Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts"}, {"paperId": "6be402b8568d58c916d303bc1b72258506e1de9a", "title": "Viola: A Topic Agnostic Generate-and-Rank Dialogue System"}, {"paperId": "917c63f2186119166b3379f5d2816bb1a2f39b09", "title": "DEMix Layers: Disentangling Domains for Modular Language Modeling"}, {"paperId": "3f2690d8d55ec7562e5779f5ee30aea8355f7473", "title": "Did chatbots miss their \u201cApollo Moment\u201d? Potential, gaps, and lessons from using collaboration assistants during COVID-19"}, {"paperId": "de549c1592a62c129b8d49c8c0137aa6859b103f", "title": "Internet-Augmented Dialogue Generation"}, {"paperId": "88064de690af282dbdf222774f03ff070b9df22b", "title": "Beyond Goldfish Memory: Long-Term Open-Domain Conversation"}, {"paperId": "2ef4ab54d00203f9ac610213ac3abc8e1fe541b4", "title": "Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling"}, {"paperId": "6eb042e98091ce96af92ea400e43212ccb982ad3", "title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning"}, {"paperId": "d624bc273821c871f899d8256a34be40c09fc3cd", "title": "Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets"}, {"paperId": "d1290807d6089713a6710285ac115904c39c311d", "title": "Assessing Political Prudence of Open-domain Chatbots"}, {"paperId": "3772194d7638ee3ef98ab306e1ea9260273610b9", "title": "Chatbots: Security, privacy, data protection, and social aspects"}, {"paperId": "828ace8bc78f6ab0636d5c7183e773a0e49d367c", "title": "How Robust are Fact Checking Systems on Colloquial Claims?"}, {"paperId": "a80eca1bf659fcac949a1d7e9196b42b023d3e36", "title": "A Unified Pre-training Framework for Conversational AI"}, {"paperId": "4ae632b89089b38ce41d307a6cda4727e42aaab3", "title": "Detoxifying Language Models Risks Marginalizing Minority Voices"}, {"paperId": "c0e6cd2ec3bc9eb46c7d45bb708854da3327339e", "title": "A Survey on Bias in Deep NLP"}, {"paperId": "6f8e6079b99b764d9044477349caa113f55ae122", "title": "Did Chatbots Miss Their 'Apollo Moment'? A Survey of the Potential, Gaps and Lessons from Using Collaboration Assistants During COVID-19"}, {"paperId": "6de4dc0bb66971071ced5201e37ed8f3ccd5e062", "title": "Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection"}, {"paperId": "d77c78c9439422ed88e754f776a642d43a8acb66", "title": "Reducing Conversational Agents\u2019 Overconfidence Through Linguistic Calibration"}, {"paperId": "2cf2d1491f72f198ae9990971cf2846e9fe51141", "title": "Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective"}, {"paperId": "cf58cbdaf475109da7c528e6d5d390ed97fba6b2", "title": "Multi-Modal Open-Domain Dialogue"}, {"paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6", "title": "GeDi: Generative Discriminator Guided Sequence Generation"}, {"paperId": "2ae108f21571ad13bd7dc4a43ae263025dce4879", "title": "SafeConv: Explaining and Correcting Conversational Unsafe Behavior"}, {"paperId": "e0d3a34ea616d181eedae9e56126e86daefdd2c8", "title": "Enhancing Dialogue Generation with Conversational Concept Flows"}, {"paperId": "269cea351c93c5c20e61ea8634da8f2dffe9b1ae", "title": "Re3Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training"}, {"paperId": "9310a82992cec877c372eb5c9ef8e6ea64c6d8e3", "title": "Controlling Toxicity using Backpacks"}, {"paperId": "582c059e43da5b25f92388b125bf7bef2609e48c", "title": "\u57fa\u4e8eRoBERTa\u7684\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u4fa6\u6d4b\u65b9\u6cd5\u7814\u7a76(Chinese Hate Speech detection method Based on RoBERTa-WWM)"}, {"paperId": "3607b92705cd1fba04eaf295f57be4b085791063", "title": "Dialogue Distillery: Crafting Interpolable, Interpretable, and Introspectable Dialogue from LLMs"}, {"paperId": "738852940591ecf864abf402878ecf66e2945267", "title": "Visual Adversarial Examples Jailbreak Large Language Models"}, {"paperId": "c3aba0f3185989768b22a29f8f431d80a5710171", "title": "Chatbots & Dialogue Systems"}, {"paperId": "cb0335107f12d331ace2cbf220eb3c7bdcf653c5", "title": "Mitigating Societal Harms in Large Language Models"}, {"paperId": "f139e9c24dc1f7b6a046dd4b81c3a8a72f2dec33", "title": "InstructSafety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning"}, {"paperId": "08f7aeca8f94bedbeb425bef1f0b3fcd9361f785", "title": "SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems"}, {"paperId": "6626dadc76d1af9d19fc4c2a4fa3a4cf414e62e0", "title": "Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and Benchmarks"}, {"paperId": "39061cead45e4aea31e5710519879717fe4db7bb", "title": "Guiding the Release of Safer E2E Conversational AI through Value Sensitive Design"}, {"paperId": "5fa273f7db53ef98d3789b26a8f2dcf3b71fe005", "title": "Empirical study on BlenderBot 2.0\u2019s Errors Analysis in terms of Model, Data and User-Centric Approach"}, {"paperId": "25eba922c7076e1a8a0a86fd0eed2bfcdbe0bbc3", "title": "AugESC: Large-scale Data Augmentation for Emotional Support Conversation with Pre-trained Language Models"}, {"paperId": "96ebc81050b403dc7d69c8ce99551609b1b4159e", "title": "Improving Multi-label Malevolence Detection in Dialogues through Multi-faceted Label Correlation Enhancement"}, {"paperId": "bd280228effa8faf51f6c1dd1492daa619b9e103", "title": "Korean Online Hate Speech Dataset for Multilabel Classification - How Can Social Science Aid Developing Better Hate Speech Dataset? TaeYoung"}, {"paperId": "eb1ac44bbc0fe07c5f31f459c7199211239e90b8", "title": "Open-domain Dialogue Generation: What We Can Do, Cannot Do, And Should Do Next"}, {"paperId": "fdbd1350e14171eaebd82eb2b11ee9141b0963c2", "title": "The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications"}, {"paperId": "64a8effea41797ad725f865c0bea9fc7d6869910", "title": "On Controlling Fallback Responses for Grounded Dialogue Generation"}, {"paperId": "4e5ffe64df98dcc1cc0715c550fad8854436543e", "title": "AI Ethics: Assessing and Correcting Conversational Bias in Machine-Learning based Chatbots"}, {"paperId": "31c7bfb0daf0c958d28ff1cd142ea00b26f1037a", "title": "Towards an open-domain chatbot for language practice"}, {"paperId": "24615e613d4551f7aaa0557befa0a8bc403f39cd", "title": "Stateful Memory-Augmented Transformers for Dialogue Modeling"}, {"paperId": "53f0a4b27ee6ff182cae970e45faac048dbefae4", "title": "MoralDial: A Framework to Train and Evaluate Moral Dialogue Systems via Constructing Moral Discussions"}, {"paperId": "315320de0c8e8c30a5758ba7966c8fe5c935b82a", "title": "Automating Counterspeech in Dialogue Systems"}, {"paperId": "d5789c54cb35b2cea39553f5794dc0f0e5a7e8b9", "title": "QaDialMoE: Question-answering Dialogue based Fact Verification with Mixture of Experts"}, {"paperId": "378d987bb204dc230f5e20cbe7bc90acb21730d9", "title": "BiasAsker: Testing Social Biases in Dialog Systems"}, {"paperId": "d3230937c11e7bf5ab10b91775dfc4c3339025a9", "title": "Unaware of Reality: Inconsistent Grounding in Conversational AI Anonymous"}, {"paperId": "20fa4f23d98b053bb86ac966dc6cbca197dba160", "title": "DIPARTIMENTO DI FILOLOGIA, LETTERATURA E LINGUISTICA CORSO DI LAUREA IN INFORMATICA UMANISTICA MAGISTRALE TESI DI LAUREA FairShades-Fairness Auditing in Abusive Language Detection Systems"}, {"paperId": "9eae922928b13ef6111da6d60e855e71c3848396", "title": "S AFETY B ENCH : Identifying Safety-Sensitive Situations for Open-domain Conversational Systems"}, {"paperId": "b1999b5ede6820e7a17a5567009f4aadb3649f64", "title": "A Human-machine Collaborative Framework for Evaluating Malevolence in Dialogues"}, {"paperId": "118e031a2d52091da61d70067cfa317a57f7b832", "title": "Fundamental Exploration of Evaluation Metrics for Persona Characteristics of Text Utterances"}, {"paperId": "5d67168e92f571dcc5a738ebd59570d047f14cce", "title": "Evaluation of a Virtual Agent in Guiding Users from the Non-Clinical Population in Self-Attachment Intervention"}, {"paperId": "ca7570353bab859f515e9599bc38defc6ec40e98", "title": "Less is more : An Empirical Analysis of Model Compression for Dialogue"}, {"paperId": "465fda29d247ac148af5ea3b70db56918d086edc", "title": "GeDi: Generative Discriminator Guided Decoding for Faster Controllable Sequence Generation"}, {"paperId": "aa56123a816226be7f7bd25b74784c8a2b2f5e8b", "title": "Linguistic calibration through metacognition: aligning dialogue agent responses with expected correctness"}, {"paperId": "bb661d76c3ff444be4a8c55865b1d0c08e4a3b07", "title": "Neural network architecture specification and design"}]}

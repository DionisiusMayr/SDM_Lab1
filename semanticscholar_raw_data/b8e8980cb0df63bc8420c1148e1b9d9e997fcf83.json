{"paperId": "b8e8980cb0df63bc8420c1148e1b9d9e997fcf83", "publicationVenue": {"id": "d13e941e-4cac-4f1d-bdca-77d927e31f1b", "name": "ACM Symposium on Cloud Computing", "type": "conference", "alternate_names": ["System-on-Chip Conference", "ACM Symp Cloud Comput", "Syst Conf", "Symp Cloud Comput", "Annual IEEE International System-on-Chip Conference", "Symposium on Cloud Computing", "Annu IEEE Int Syst Conf", "SoCC"], "url": "http://www.ieee-socc.org/"}, "title": "Llama: A Heterogeneous & Serverless Framework for Auto-Tuning Video Analytics Pipelines", "abstract": "The proliferation of camera-enabled devices and large video repositories has led to a diverse set of video analytics applications. These applications rely on video pipelines, represented as DAGs of operations, to transform videos, process extracted metadata, and answer questions like, \"Is this intersection congested?\" The latency and resource efficiency of pipelines can be optimized using configurable knobs for each operation (e.g., sampling rate, batch size, or type of hardware used). However, determining efficient configurations is challenging because (a) the configuration search space is exponentially large, and (b) the optimal configuration depends on users' desired latency and cost targets, (c) input video contents may exercise different paths in the DAG and produce a variable amount intermediate results. Existing video analytics and processing systems leave it to the users to manually configure operations and select hardware resources. We present Llama: a heterogeneous and serverless framework for auto-tuning video pipelines. Given an end-to-end latency target, Llama optimizes for cost efficiency by (a) calculating a latency target for each operation invocation, and (b) dynamically running a cost-based optimizer to assign configurations across heterogeneous hardware that best meet the calculated per-invocation latency target. This makes the problem of auto-tuning large video pipelines tractable and allows us to handle input-dependent behavior, conditional branches in the DAG, and execution variability. We describe the algorithms in Llama and evaluate it on a cloud platform using serverless CPU and GPU resources. We show that compared to state-of-the-art cluster and serverless video analytics and processing systems, Llama achieves 7.8x lower latency and 16x cost reduction on average.", "venue": "ACM Symposium on Cloud Computing", "year": 2021, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book"], "publicationDate": "2021-02-03", "journal": {"name": "Proceedings of the ACM Symposium on Cloud Computing"}, "authors": [{"authorId": "103852091", "name": "Francisco Romero"}, {"authorId": "48886419", "name": "Mark Zhao"}, {"authorId": "2397000", "name": "N. Yadwadkar"}, {"authorId": "117272782", "name": "Christos Kozyrakis"}], "citations": [{"paperId": "2bc83301600ff07acebc27eaa710d1ad231581ed", "title": "Joint Optimization of Parallelism and Resource Configuration for Serverless Function Steps"}, {"paperId": "faac3315d8f7c9b64412bbb653d6b25e1cf56665", "title": "Sponge: Inference Serving with Dynamic SLOs Using In-Place Vertical Scaling"}, {"paperId": "413021d23a97a603abdca274949c35bf9da15b90", "title": "Jiagu: Optimizing Serverless Computing Resource Utilization with Harmonized Efficiency and Practicability"}, {"paperId": "594a53ffd5ff194c1e33b15cf67dd7496be93204", "title": "Inference serving with end-to-end latency SLOs over dynamic edge networks"}, {"paperId": "1a2955b4bc88132fc676ad831c221d726248b8c1", "title": "Adaptive Auto-Tuning Framework for Global Exploration of Stencil Optimization on GPUs"}, {"paperId": "dd615ebe688ae4fd127e19bb248717f25157b90e", "title": "DAGit: A Platform For Enabling Serverless Applications"}, {"paperId": "82c2f784dc35fd930594a24a7354832d23876446", "title": "Graft: Efficient Inference Serving for Hybrid Deep Learning With SLO Guarantees via DNN Re-Alignment"}, {"paperId": "3465516f76ea93ff8349cdfd944f9e348838ca6e", "title": "Towards Serverless Optimization with In-place Scaling"}, {"paperId": "9b9a84719a4b1763c5c0deb800573c68bda56dde", "title": "Optimizing Resource Management for Shared Microservices: A Scalable System Design"}, {"paperId": "4057dac4f2369ee4b072854e219c71364c9d0d87", "title": "VQPy: An Object-Oriented Approach to Modern Video Analytics"}, {"paperId": "ec25a1a0561d28cf2fa48de85a65b8d267bad6de", "title": "Memento: Architectural Support for Ephemeral Memory Management in Serverless Environments"}, {"paperId": "8e8cf6cbd4a68bffe722dc54b7143983cb4a7d82", "title": "Expedited Data Transfers for Serverless Clouds"}, {"paperId": "2776cf55518b51a11ab129660eaab91eb4187837", "title": "Energy Efficient Scheduling for Serverless Systems"}, {"paperId": "b61fafdeaee3694693b982fa79e2042cce7f09c5", "title": "IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency"}, {"paperId": "f10cc66ecc90a9d6dd2d8704e0faa941fbb6348d", "title": "Symphony: Optimized DNN Model Serving using Deferred Batch Scheduling"}, {"paperId": "dda9e433ac572636b57d05c1a1bf529fb4df2973", "title": "FaST-GShare: Enabling Efficient Spatio-Temporal GPU Sharing in Serverless Computing for Deep Learning Inference"}, {"paperId": "7034d45160c8cac0afb8e3a3c99ac3d8fec74145", "title": "Towards Timely Edge-assisted Video Analytics Services"}, {"paperId": "b6af2e3b142fbef48e0a84c77068232bcd595856", "title": "Darly: Deep Reinforcement Learning for QoS-aware scheduling under resource heterogeneity Optimizing serverless video analytics"}, {"paperId": "9c196709ee1e628edee548afaa43822a365dff0b", "title": "Edge-Assisted Adaptive Configuration for Serverless-Based Video Analytics"}, {"paperId": "2592a6397ef41786b27bee8ebf94f326e04e034a", "title": "A Low Cost Cross-Platform Video/Image Process Framework Empowers Heterogeneous Edge Application"}, {"paperId": "48028d71d0d808650ce437da8ea1faaf394ff87f", "title": "EAVS: Edge-assisted Adaptive Video Streaming with Fine-grained Serverless Pipelines"}, {"paperId": "97e8e9ad3862629bacb28b994f2d5d52a2371c00", "title": "Extract-Transform-Load for Video Streams"}, {"paperId": "e26b43bac071c9c5fd7b31df4cfed4add6ff8d76", "title": "Clover: Toward Sustainable AI with Carbon-Aware Machine Learning Inference Service"}, {"paperId": "ff70b57466ca768b2c70bb8459eda4f3f78af4b6", "title": "In-Storage Domain-Specific Acceleration for Serverless Computing"}, {"paperId": "70e3fac68959e2175184bdc60e2986cf47df0071", "title": "EQUI-VOCAL: Synthesizing Queries for Compositional Video Events from Limited User Interactions"}, {"paperId": "ad020c3b49bc7cb1999815f7fe5f2b33fe0b0c48", "title": "Multitask Scheduling of Computer Vision Workload on Edge Graphical Processing Units"}, {"paperId": "9e9c4f691bb830bac30cf7f624ebc82f63b101c1", "title": "VaBUS: Edge-Cloud Real-Time Video Analytics via Background Understanding and Subtraction"}, {"paperId": "eb0505d28e743e10927baa06e2bc63e15e0dbbe0", "title": "Erms: Efficient Resource Management for Shared Microservices with SLA Guarantees"}, {"paperId": "585b1eacd2b269e7de556e2f4a891428f450ee5f", "title": "Profiling-free Configuration Adaptation and Latency-Aware Resource Scheduling for Video Analytics"}, {"paperId": "0611000abe5ce90554e13830c5df7e7df375dda6", "title": "CAMDNN: Content-Aware Mapping of a Network of Deep Neural Networks on Edge MPSoCs"}, {"paperId": "9a8691280e9b22876e8f3e9ee69be3d4692012f7", "title": "Jellyfish: Timely Inference Serving for Dynamic Edge Networks"}, {"paperId": "d202d2936b7495b1c493d94a744f3f4653f6f447", "title": "Edge Video Analytics: A Survey on Applications, Systems and Enabling Techniques"}, {"paperId": "a372c5620683ebc2c87ae1abe2e44088c2ed21fe", "title": "The power of prediction: microservice auto scaling via workload learning"}, {"paperId": "cd8399c8f147d90984f5f42590b1c7da55ae3daa", "title": "Slice-Tune: a system for high performance DNN autotuning"}, {"paperId": "1add047298154e27d8ef732e6c73c2f1c91eba23", "title": "Optimizing Video Analytics with Declarative Model Relationships"}, {"paperId": "a2694d1f56f53bf92dccb4f678a445639373385e", "title": "Kairos: Building Cost-Efficient Machine Learning Inference Systems with Heterogeneous Cloud Resources"}, {"paperId": "24065abf28f18aa05cec8272069122e2e0ca3b74", "title": "Sequence Clock: A Dynamic Resource Orchestrator for Serverless Architectures"}, {"paperId": "1b454103614b5a4147c1157e6748fd54cfc88526", "title": "AMESoS: a scalable and elastic framework for latency sensitive streaming pipelines"}, {"paperId": "047ef38cde96dc443875ddca078d2b49fa6e42aa", "title": "WISEFUSE"}, {"paperId": "b9b8f753ae32654d46e396a11ea2a88a0312c1a8", "title": "Serving and Optimizing Machine Learning Workflows on Heterogeneous Infrastructures"}, {"paperId": "5709cb7d75604410cff84cc3aaff452227d82a8a", "title": "StepConf: SLO-Aware Dynamic Resource Configuration for Serverless Function Workflows"}, {"paperId": "b78a31d7afa2622d210919e69b5c4c616d0c7d24", "title": "FA2: Fast, Accurate Autoscaling for Serving Deep Learning Inference with SLA Guarantees"}, {"paperId": "1be610975a1afe352f94796220a96303be8969b3", "title": "FuncPipe: A Pipelined Serverless Framework for Fast and Cost-Efficient Training of Deep Learning Models"}, {"paperId": "768d9b64682ce5bde6e0d6e33a34b9ff8e488487", "title": "Microservice-based Edge Device Architecture for Video Analytics"}, {"paperId": "e5ac8208cd08027eec4daf14cf026bb32bcba8be", "title": "Better Never Than Late: Timely Edge Video Analytics Over the Air"}, {"paperId": "90b2c3b6a7189065fcba078eff5684176fdccce0", "title": "Scrooge: A Cost-Effective Deep Learning Inference System"}, {"paperId": "0697791b674f77ec094d7f56786e078229dc3454", "title": "Efficiency in the serverless cloud paradigm: A survey on the reusing and approximation aspects"}, {"paperId": "6607309be6bdeafcc3691fd1cc18ecffe0da1b8e", "title": "Faa$T: A Transparent Auto-Scaling Cache for Serverless Applications"}, {"paperId": "11689e94fb70058769675d23634628c491461f56", "title": "Interference-Aware Scheduling for Inference Serving"}, {"paperId": "99c89b36852b039f963ea02c09e1ec7c0e5139f5", "title": "Serverless Computing: A Survey of Opportunities, Challenges, and Applications"}, {"paperId": "1e14c45a3d4f7d2af452ea0d362d8955849e354c", "title": "SPSC : Stream Processing Framework atop Serverless Computing for Industrial Big Data"}, {"paperId": "f63291b893b5052f808d177067642f2f9b189404", "title": "Green Carbon Footprint for Model Inference Serving via Exploiting Mixed-Quality Models and GPU Partitioning"}, {"paperId": "7bc07012b9a9ae8150c1e66e91168cfa6603b8f5", "title": "VIVA: An End-to-End System for Interactive Video Analytics"}, {"paperId": "77fc7be5a0cdc0141462a9cc00451e73329a13d7", "title": "Building Heterogeneous Cloud System for Machine Learning Inference"}, {"paperId": "85106fc0a68a575166f0f18456fa755b7a2660a3", "title": "Deep Learning-Driven Edge Video Analytics: A Survey"}, {"paperId": "2e2f8a92074958abca7fe7b6a1690d46048b4c10", "title": "Efficiency in the Serverless Cloud Computing Paradigm: A Survey Study"}, {"paperId": "96b5e90a87418aac6ca26e201088dece8dc87513", "title": "This paper is included in the Proceedings of the 17th USENIX Symposium on Operating Systems Design and Implementation."}]}

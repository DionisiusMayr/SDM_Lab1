{"paperId": "0a56fc83bac9739ac31259e44f4a59271f3a6fee", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "No Love Among Haters: Negative Interactions Reduce Hate Community Engagement", "abstract": "While online hate groups pose significant risks to the health of online platforms and safety of marginalized groups, little is known about what causes users to become active in hate groups and the effect of social interactions on furthering their engagement. We address this gap by first developing tools to find hate communities within Reddit, and then augment 11 subreddits extracted with 14 known hateful subreddits (25 in total). Using causal inference methods, we evaluate the effect of replies on engagement in hateful subreddits by comparing users who receive replies to their first comment (the treatment) to equivalent control users who do not. We find users who receive replies are less likely to become engaged in hateful subreddits than users who do not, while the opposite effect is observed for a matched sample of similar-sized non-hateful subreddits. Using the Google Perspective API and VADER, we discover that hateful community first-repliers are more toxic, negative, and attack the posters more often than non-hateful first-repliers. In addition, we uncover a negative correlation between engagement and attacks or toxicity of first-repliers. We simulate the cumulative engagement of hateful and non-hateful subreddits under the contra-positive scenario of friendly first-replies, finding that attacks dramatically reduce engagement in hateful subreddits. These results counter-intuitively imply that, although under-moderated communities allow hate to fester, the resulting environment is such that direct social interaction does not encourage further participation, thus endogenously constraining the harmful role that these communities could play as recruitment venues for antisocial beliefs.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-03-23", "journal": {"name": "ArXiv", "volume": "abs/2303.13641"}, "authors": [{"authorId": "119523645", "name": "Daniel Hickey"}, {"authorId": "2133452483", "name": "Matheus Schmitz"}, {"authorId": "144227945", "name": "D. Fessler"}, {"authorId": "1700820", "name": "P. Smaldino"}, {"authorId": "2138610191", "name": "Goran Muric"}, {"authorId": "37936069", "name": "K. Burghardt"}], "citations": [{"paperId": "888795b54ce655f5a0125ca507db69583e53dee3", "title": "Collective moderation of hate, toxicity, and extremity in online discussions"}]}

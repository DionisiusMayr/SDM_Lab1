{"paperId": "66e7edf09589527ebb58418632418758cee668cd", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models", "abstract": "Big models have achieved revolutionary breakthroughs in the field of AI, but they might also pose potential concerns. Addressing such concerns, alignment technologies were introduced to make these models conform to human preferences and values. Despite considerable advancements in the past year, various challenges lie in establishing the optimal alignment strategy, such as data cost and scalable oversight, and how to align remains an open question. In this survey paper, we comprehensively investigate value alignment approaches. We first unpack the historical context of alignment tracing back to the 1920s (where it comes from), then delve into the mathematical essence of alignment (what it is), shedding light on the inherent challenges. Following this foundation, we provide a detailed examination of existing alignment methods, which fall into three categories: Reinforcement Learning, Supervised Fine-Tuning, and In-context Learning, and demonstrate their intrinsic connections, strengths, and limitations, helping readers better understand this research area. In addition, two emerging topics, personal alignment, and multimodal alignment, are also discussed as novel frontiers in this field. Looking forward, we discuss potential alignment paradigms and how they could handle remaining challenges, prospecting where future alignment will go.", "venue": "arXiv.org", "year": 2024, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2024-03-07", "journal": {"name": "ArXiv", "volume": "abs/2403.04204"}, "authors": [{"authorId": "2261242175", "name": "Xinpeng Wang"}, {"authorId": "2258959896", "name": "Shitong Duan"}, {"authorId": "2258961742", "name": "Xiaoyuan Yi"}, {"authorId": "2237129499", "name": "Jing Yao"}, {"authorId": "2111056408", "name": "Shanlin Zhou"}, {"authorId": "2261095215", "name": "Zhihua Wei"}, {"authorId": "2290178596", "name": "Peng Zhang"}, {"authorId": "2269692885", "name": "Dongkuan Xu"}, {"authorId": "2290466289", "name": "Maosong Sun"}, {"authorId": "2289847313", "name": "Xing Xie"}], "citations": [{"paperId": "e59689af068b7402a5d0349e2075dd6c3a721eca", "title": "Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security"}, {"paperId": "8e6124739e03c9d7ea4903de00c3370d2f1a8387", "title": "Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback"}]}

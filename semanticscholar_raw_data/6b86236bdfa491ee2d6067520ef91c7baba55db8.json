{"paperId": "6b86236bdfa491ee2d6067520ef91c7baba55db8", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Optimizing Privacy, Utility and Efficiency in Constrained Multi-Objective Federated Learning", "abstract": "Conventionally, federated learning aims to optimize a single objective, typically the utility. However, for a federated learning system to be trustworthy, it needs to simultaneously satisfy multiple/many objectives, such as maximizing model performance, minimizing privacy leakage and training cost, and being robust to malicious attacks. Multi-Objective Optimization (MOO) aiming to optimize multiple conflicting objectives at the same time is quite suitable for solving the optimization problem of Trustworthy Federated Learning (TFL). In this paper, we unify MOO and TFL by formulating the problem of constrained multi-objective federated learning (CMOFL). Under this formulation, existing MOO algorithms can be adapted to TFL straightforwardly. Different from existing CMOFL works focusing on utility, efficiency, fairness, and robustness, we consider optimizing privacy leakage along with utility loss and training cost, the three primary objectives of a TFL system. We develop two improved CMOFL algorithms based on NSGA-II and PSL, respectively, for effectively and efficiently finding Pareto optimal solutions, and we provide theoretical analysis on their convergence. We design specific measurements of privacy leakage, utility loss, and training cost for three privacy protection mechanisms: Randomization, BatchCrypt (An efficient version of homomorphic encryption), and Sparsification. Empirical experiments conducted under each of the three protection mechanisms demonstrate the effectiveness of our proposed algorithms.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-04-29", "journal": {"name": "ArXiv", "volume": "abs/2305.00312"}, "authors": [{"authorId": "1505828520", "name": "Yan Kang"}, {"authorId": "2064783785", "name": "Hanlin Gu"}, {"authorId": "2192532889", "name": "Xingxing Tang"}, {"authorId": "2145050945", "name": "Yuanqin He"}, {"authorId": "2108353945", "name": "Yuzhu Zhang"}, {"authorId": "2215861642", "name": "Jinnan He"}, {"authorId": "1878783812", "name": "Yuxing Han"}, {"authorId": "2087083369", "name": "Lixin Fan"}, {"authorId": "2166949653", "name": "Qiang Yang"}], "citations": [{"paperId": "d68ff1fdba49d5cd6888794f6216c72f98072c6e", "title": "Hyperparameter Optimization for SecureBoost via Constrained Multi-Objective Federated Learning"}, {"paperId": "76d1910516e944c7584347886c3a998da2822974", "title": "Evaluating Membership Inference Attacks and Defenses in Federated Learning"}, {"paperId": "911c120315388b340fd20bd15c174111f5e0ef96", "title": "Federated Continual Learning via Knowledge Fusion: A Survey"}, {"paperId": "8ed9c9f9397e6d8dd97b120ea533e61073e796ed", "title": "A Theoretical Analysis of Efficiency Constrained Utility-Privacy Bi-Objective Optimization in Federated Learning"}, {"paperId": "f416c5574c9741e14f0fd728112178bcda382c21", "title": "Grounding Foundation Models through Federated Transfer Learning: A General Framework"}, {"paperId": "13e0f74fdb458b8e2312b149831f3299c2352c7c", "title": "Federated Learning Integration in O- RAN: A Concise Review"}, {"paperId": "2b1ab5326f39f26a05ab433b30434276bc04f2d0", "title": "SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning"}, {"paperId": "34ccb3300da9fbbf59517a18eb0ccdd2baa1df4f", "title": "A Meta-learning Framework for Tuning Parameters of Protection Mechanisms in Trustworthy Federated Learning"}, {"paperId": "f13f014f51dd425661e3202067c5ef5052fe4d6a", "title": "Vertical Federated Learning"}]}

{"paperId": "0efdd284df4ae7c75b5055999a207f68b360f228", "publicationVenue": null, "title": "Towards reducing the time needed for load testing", "abstract": "The performance of large\u2010scale systems must be thoroughly tested under various levels of workload, as load\u2010related issues can have a disastrous impact on the system. However, load testing often requires a large amount of time, running from hours to even days. In our prior work, we reduced the execution time of a load test by detecting repetitiveness in individual performance metric values, such as CPU utilization, that are observed during the test. However, as we explain in this paper, disregarding combinations of performance metrics may miss important information about the load\u2010related behavior of a system. In this paper we revisit our prior approach, by proposing an approach that reduces the execution time of a load test by detecting whether a test no longer exercises new combinations of the observed performance metrics. We study three open source systems, in which we use our new and prior approaches to reduce the execution time of a 24\u2010hour load test. We show that our new approach is capable of reducing the execution time of the test to less than 8.5 hours, while preserving a coverage of at least 95% of the combinations that are observed between the performance metrics during the 24\u2010hour tests.", "venue": "J. Softw. Evol. Process.", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-07-16", "journal": {"name": "Journal of Software: Evolution and Process", "volume": "35"}, "authors": [{"authorId": "52384767", "name": "Hammam M. AlGhamdi"}, {"authorId": "1755660", "name": "C. Bezemer"}, {"authorId": "39724619", "name": "Weiyi Shang"}, {"authorId": "144890499", "name": "A. Hassan"}, {"authorId": "1793275", "name": "P. Flora"}], "citations": [{"paperId": "f87738ca1cd7614816da3afeb6b7c1ec273dad18", "title": "Video game performance analysis on selected operating systems"}, {"paperId": "76cf0fab441f8332549fc83291a280c0f54deb64", "title": "Scalability Testing of Land Forest Fire Patrol Information Systems"}, {"paperId": "51846c78d14b485ba37d6c4ac8422e606e6b0d4c", "title": "Automated Generation and Evaluation of JMH Microbenchmark Suites From Unit Tests"}, {"paperId": "fde0535d71e2e9e9273e09d3b4e3bc0591e1607e", "title": "Using Microbenchmark Suites to Detect Application Performance Changes"}, {"paperId": "13374de64aa511567867d9f8e2fb8f1010ee019a", "title": "Towards effective assessment of steady state performance in Java software: are we there yet?"}, {"paperId": "759785be6da465bf63527bfefdd2eb469fe2a912", "title": "Machine learning aplicado al an\u00e1lisis del rendimiento de desarrollos de software"}, {"paperId": "2f65e60dfd8a05f6dfeec8a237507b029386b1eb", "title": "Performance Testing for Cloud Computing with Dependent Data Bootstrapping"}, {"paperId": "25a6a38bb83c26fe0f26ec106af53e32735dc296", "title": "Applying test case prioritization to software microbenchmarks"}, {"paperId": "26acbf461e61cf95255ed858e98b11bf928f26b0", "title": "Predicting unstable software benchmarks using static source code features"}, {"paperId": "060680fbeffbef60b4a730a578622579f7597bb2", "title": "Using application benchmark call graphs to quantify and improve the practical relevance of microbenchmark suites"}]}

{"paperId": "a278412a5c1a97f0e94631841a09cdc467493cae", "publicationVenue": {"id": "99e98681-158c-48ca-8f86-386d75770b50", "name": "IEEE/ACM International Symposium on Modeling, Analysis, and Simulation On Computer and Telecommunication Systems", "type": "conference", "alternate_names": ["IEEE/ACM Int Symp Model Anal Simul Comput Telecommun Syst", "Model Anal Simul Comput Telecommun Syst", "Modeling, Analysis, and Simulation On Computer and Telecommunication Systems", "MASCOTS"], "url": "http://www.mascots-conference.org/"}, "title": "TrimTuner: Efficient Optimization of Machine Learning Jobs in the Cloud via Sub-Sampling", "abstract": "This work introduces TrimTuner, the first system for optimizing machine learning jobs in the cloud to exploit sub-sampling techniques to reduce the cost of the optimization process, while keeping into account user-specified constraints. TrimTuner jointly optimizes the cloud and application-specific parameters and, unlike state of the art works for cloud optimization, eschews the need to train the model with the full training set every time a new configuration is sampled. Indeed, by leveraging sub-sampling techniques and data-sets that are up to 60 x smaller than the original one, we show that TrimTuner can reduce the cost of the optimization process by up to 50 x. Further, TrimTuner speeds-up the recommendation process by 65 x with respect to state of the art techniques for hyperparameter optimization that use sub-sampling techniques. The reasons for this improvement are twofold: i) a novel domain specific heuristic that reduces the number of configurations for which the acquisition function has to be evaluated; ii) the adoption of an ensemble of decision trees that enables boosting the speed of the recommendation process by one additional order of magnitude.", "venue": "IEEE/ACM International Symposium on Modeling, Analysis, and Simulation On Computer and Telecommunication Systems", "year": 2020, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2020-11-09", "journal": {"name": "2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)", "pages": "1-8"}, "authors": [{"authorId": "122535582", "name": "Pedro Mendes"}, {"authorId": "2062797649", "name": "Maria Casimiro"}, {"authorId": "145850527", "name": "P. Romano"}, {"authorId": "145307943", "name": "D. Garlan"}], "citations": [{"paperId": "55139914c166a9ddf62922a01078ce73975c03ed", "title": "Adapting Multi-objectivized Software Configuration Tuning"}, {"paperId": "9ce7d0b3a4e15a0cd92d86d8c4231c6ed045afd8", "title": "SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems"}, {"paperId": "7fbb73f3e61ed9ab1f18d0290082729a46ca36cd", "title": "Towards a Peer-to-Peer Data Distribution Layer for Efficient and Collaborative Resource Optimization of Distributed Dataflow Applications"}, {"paperId": "0f3b97eb980a9d4f07d606d5f483055e1ca178bd", "title": "Karasu: A Collaborative Approach to Efficient Cluster Configuration for Big Data Analytics"}, {"paperId": "47d229dcbdedd684ec446c56d4f571116cdd6742", "title": "Hyper-parameter Tuning for Adversarially Robust Models"}, {"paperId": "6a9bfc08af212ca74c6546e3fa57efa7a0bd8d43", "title": "Perona: Robust Infrastructure Fingerprinting for Resource-Efficient Big Data Analytics"}, {"paperId": "5fb68a006229af5a6f44444ad9f31dc51f97956c", "title": "Batch Multi-Fidelity Active Learning with Budget Constraints"}, {"paperId": "6596e9ec088a73f3ddb8bdf962fd2cebad048e81", "title": "Planning Landscape Analysis for Self-Adaptive Systems"}, {"paperId": "0d58d85814a57eef7cb6ae73833a3d742119ea11", "title": "Supervising the Multi-Fidelity Race of Hyperparameter Configurations"}, {"paperId": "53904e77b999f6bdb505539d527686ad712dfc0b", "title": "Lifelong Dynamic Optimization for Self-Adaptive Systems: Fact or Fiction?"}, {"paperId": "a74d42ba1f15ba0002f7485ac4f0514bb8b4675c", "title": "MMO: Meta Multi-Objectivization for Software Configuration Tuning"}, {"paperId": "3d4c258cc3ba14c7252914349f91bd21f2801684", "title": "HyperJump: Accelerating HyperBand via Risk Modelling"}, {"paperId": "5e242f1ebb868127121fdca15f4dcc642f3d9ef7", "title": "Multi-objectivizing software configuration tuning"}, {"paperId": "57bafcf99a2982db2dbf7da42ff8e7d00ac3727f", "title": "Self-Adaptation for Machine Learning Based Systems"}, {"paperId": "131eba8d6bf54fb0347a822f5d2d04a50385ff14", "title": "Hyper-Parameter Tuning using Bayesian Optimization"}]}

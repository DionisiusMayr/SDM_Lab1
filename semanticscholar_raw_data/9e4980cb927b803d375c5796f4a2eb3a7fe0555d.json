{"paperId": "9e4980cb927b803d375c5796f4a2eb3a7fe0555d", "publicationVenue": {"id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd", "name": "Neural Information Processing Systems", "type": "conference", "alternate_names": ["Neural Inf Process Syst", "NeurIPS", "NIPS"], "url": "http://neurips.cc/"}, "title": "The Quantization Model of Neural Scaling", "abstract": "We propose the Quantization Model of neural scaling laws, explaining both the observed power law dropoff of loss with model and data size, and also the sudden emergence of new capabilities with scale. We derive this model from what we call the Quantization Hypothesis, where network knowledge and skills are\"quantized\"into discrete chunks ($\\textbf{quanta}$). We show that when quanta are learned in order of decreasing use frequency, then a power law in use frequencies explains observed power law scaling of loss. We validate this prediction on toy datasets, then study how scaling curves decompose for large language models. Using language model gradients, we automatically decompose model behavior into a diverse set of skills (quanta). We tentatively find that the frequency at which these quanta are used in the training distribution roughly follows a power law corresponding with the empirical scaling exponent for language models, a prediction of our theory.", "venue": "Neural Information Processing Systems", "year": 2023, "fieldsOfStudy": ["Computer Science", "Physics"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-03-23", "journal": {"name": "ArXiv", "volume": "abs/2303.13506"}, "authors": [{"authorId": "2064378938", "name": "Eric J. Michaud"}, {"authorId": "2145253202", "name": "Ziming Liu"}, {"authorId": "2212525703", "name": "Uzay Girit"}, {"authorId": "2011933", "name": "Max Tegmark"}], "citations": [{"paperId": "f29b21d60b8440afe50cb709bbe801315eff1e55", "title": "Token-Efficient Leverage Learning in Large Language Models"}, {"paperId": "b8f280d8bf685f8da7c83068e73f000528072d6b", "title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models"}, {"paperId": "c231dcc7f85e52c2a0e225022a4b755d472b65bb", "title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance"}, {"paperId": "cf36c0c47e1f1a9bb5285c638bdd77244113bbae", "title": "Dissociating language and thought in large language models"}, {"paperId": "94223e2ef04af94f7971264a2c101d49ebff7079", "title": "Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models"}, {"paperId": "7d417465bdf254f8b4491c0e4adbace8f49010ab", "title": "Unified View of Grokking, Double Descent and Emergent Abilities: A Perspective from Circuits Competition"}, {"paperId": "debcb86e9d230807b3967227342c9b3747c27f3b", "title": "Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective"}, {"paperId": "837b55eefbeee72e580e97a7b3c7136e714134b4", "title": "A Tale of Tails: Model Collapse as a Change of Scaling Laws"}, {"paperId": "0dda8952b94af0cf52515d89ebeda1d6644c86c6", "title": "A Resource Model For Neural Scaling Law"}, {"paperId": "e1a280f346b575c85cde4ad4ba0e10dc6df93105", "title": "On monitorability of AI"}, {"paperId": "ad9bac9b786f65f0a832b11ba7e83639c90da415", "title": "A Dynamical Model of Neural Scaling Laws"}, {"paperId": "efd0aa60187d3c9ab80d3343e4ae4561edc90a48", "title": "The Information of Large Language Model Geometry"}, {"paperId": "df1b124fd695eb0e205c642c353d614243948a1a", "title": "Deriving a Power-Law Model for Aggregating Data with Head Based Clustering"}, {"paperId": "af365d54e237fb213d980b2dc0c2ef1a4280bbd7", "title": "In-Context Learning Dynamics with Random Binary Sequences"}, {"paperId": "0195b0c4f01b120e0b6a55f6f4f072f6c6a00506", "title": "A Survey of Metrics to Enhance Training Dependability in Large Language Models"}, {"paperId": "f73cd1c9eba950c04fbd81e1f024392978059d59", "title": "Scaling Laws for Associative Memories"}, {"paperId": "c5c2870e05eae948fc58287447def73b6b192332", "title": "A Neural Scaling Law from Lottery Ticket Ensembling"}, {"paperId": "740c783ac07039cf30b6d8a8f95e775b3297c79e", "title": "Language Models Represent Space and Time"}, {"paperId": "e63bc54f59bba688a5d2d79d842367c59465aeb1", "title": "Breaking through the learning plateaus of in-context learning in Transformer"}, {"paperId": "3aba2e1d4532bab1ebc8caa616f21960e4afb2bc", "title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck"}, {"paperId": "77b603850094ff749c9040772f8169a75145d506", "title": "Explaining grokking through circuit efficiency"}, {"paperId": "4b474c1f42eefbf14ca85c951f2a22ce031b6cb7", "title": "Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models"}, {"paperId": "d96454e89f1228bc7cdbaad211f3779574aa2b2c", "title": "The semantic landscape paradigm for neural networks"}, {"paperId": "d62c4d00b277e948956b6610ce2644e88fe1577b", "title": "Large Language Models"}, {"paperId": "a72ba8dc49a6a842f69c312ac9a037a0f33b74f5", "title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks"}, {"paperId": "f8029060e91209f048b3f9882f2cdd3607785ccd", "title": "Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability"}, {"paperId": "12910786da7a34c9ee26798fd81b0ed7b0e38789", "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"}, {"paperId": "29c7f009df21d0112c48dec254ff80cc45fac3af", "title": "Are Emergent Abilities of Large Language Models a Mirage?"}, {"paperId": "85167930a692f52c60c8456c83ef64365128de5f", "title": "Associative Memories with Heavy-Tailed Data"}]}

{"paperId": "c7492913370b5726eaa6ced163a60de6c9d4bb7f", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics", "abstract": "The utilization of large language models (LLMs) in the Healthcare domain has generated both excitement and concern due to their ability to effectively respond to freetext queries with certain professional knowledge. This survey outlines the capabilities of the currently developed LLMs for Healthcare and explicates their development process, with the aim of providing an overview of the development roadmap from traditional Pretrained Language Models (PLMs) to LLMs. Specifically, we first explore the potential of LLMs to enhance the efficiency and effectiveness of various Healthcare applications highlighting both the strengths and limitations. Secondly, we conduct a comparison between the previous PLMs and the latest LLMs, as well as comparing various LLMs with each other. Then we summarize related Healthcare training data, training methods, optimization strategies, and usage. Finally, the unique concerns associated with deploying LLMs in Healthcare settings are investigated, particularly regarding fairness, accountability, transparency and ethics. Our survey provide a comprehensive investigation from perspectives of both computer science and Healthcare specialty. Besides the discussion about Healthcare concerns, we supports the computer science community by compiling a collection of open source resources, such as accessible datasets, the latest methodologies, code implementations, and evaluation benchmarks in the Github. Summarily, we contend that a significant paradigm shift is underway, transitioning from PLMs to LLMs. This shift encompasses a move from discriminative AI approaches to generative AI approaches, as well as a shift from model-centered methodologies to datacentered methodologies.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-10-09", "journal": {"name": "ArXiv", "volume": "abs/2310.05694"}, "authors": [{"authorId": "2256984070", "name": "Kai He"}, {"authorId": "2106694812", "name": "Rui Mao"}, {"authorId": "144562160", "name": "Qika Lin"}, {"authorId": "2256993165", "name": "Yucheng Ruan"}, {"authorId": "2056436683", "name": "Xiang Lan"}, {"authorId": "2256985757", "name": "Mengling Feng"}, {"authorId": "2256994507", "name": "Erik Cambria"}], "citations": [{"paperId": "3cf3f50cb5379099f8fc98c9dd429944fef47f94", "title": "RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain"}, {"paperId": "b810f3a5e49fb23c789015f756d35aef21f924ad", "title": "On Prompt Sensitivity of ChatGPT in Affective Computing"}, {"paperId": "9be02ecf206ad7494bb9531aed9491af203a3c3d", "title": "LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction"}, {"paperId": "9433efc73dc22a786eebce80502a8ef8b5fb265b", "title": "Evaluation Ethics of LLMs in Legal Domain"}, {"paperId": "589a3f34fcf839c279106c5b30a3b980c7b68bfc", "title": "Vision-Language Models for Medical Report Generation and Visual Question Answering: A Review"}, {"paperId": "d66282661e999660d76414b2cc689c14e8c3b4ae", "title": "To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering"}, {"paperId": "26a35eefcbf2d0598e5d9b020030d9dd48d572eb", "title": "Enhancing Mental Health Condition Detection on Social Media through Multi-Task Learning"}, {"paperId": "e692672bc299848a1c35d953bc025091f371e070", "title": "Adaptation of Biomedical and Clinical Pretrained Models to French Long Documents: A Comparative Study"}, {"paperId": "46b8f29c23b29dc9b62c9292481d54e03939bf3b", "title": "Healthcare Copilot: Eliciting the Power of General LLMs for Medical Consultation"}, {"paperId": "0a1b6d53f66733b584c95885564bfd6aacf22529", "title": "InMD-X: Large Language Models for Internal Medicine Doctors"}, {"paperId": "12f224bdbd5f7b43ed4c8b69d309c78450b22461", "title": "RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning"}, {"paperId": "13b8934468665ecb586f491d7f9f6c460cb095e5", "title": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains"}, {"paperId": "fed3376de52d70ba83050182e79466dddde45746", "title": "On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities"}, {"paperId": "b28ad67a90bea98eafefe6259b888c1d75b2ccbb", "title": "T-RAG: Lessons from the LLM Trenches"}, {"paperId": "db54979e005b5e3fd0a9b9c0444b014488bd47a9", "title": "Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset"}, {"paperId": "512c3a8b0d5462fe8a98a1713a02d1a3186e3aae", "title": "Are LLMs Ready for Real-World Materials Discovery?"}, {"paperId": "d39c0bbd523c19812fe00467c321a7f446cdb81d", "title": "Leveraging Large Language Models for Hybrid Workplace Decision Support"}, {"paperId": "59f4322ff656c81e9767c78e8599dabccebb5b5c", "title": "Are Generative AI systems Capable of Supporting Information Needs of Patients?"}, {"paperId": "3a6d34a21e9c7344c564dc502e117b6769f10c47", "title": "Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data"}, {"paperId": "dabf7edde0efb9b1e092aa27847a547cf2961192", "title": "Integrating Physician Diagnostic Logic into Large Language Models: Preference Learning from Process Feedback"}, {"paperId": "93886752191db25efd096a65af7b09df5c0a64e0", "title": "Data-Centric Foundation Models in Computational Healthcare: A Survey"}, {"paperId": "a1c04034df40cbe6f0d0004d456fdab807ae63ec", "title": "Generalist embedding models are better at short-context clinical semantic search than specialized embedding models"}, {"paperId": "c9e59fa464bfb2c2f696ffdf62b4125aac8a7782", "title": "BioLLMBench: A Comprehensive Benchmarking of Large Language Models in Bioinformatics"}, {"paperId": "d9403061e3a3392652d037138532fab111c845c1", "title": "Large language models in healthcare and medical domain: A review"}, {"paperId": "73788e8afc7c377805b0a94234810c8722f71377", "title": "From Text to Tables: A Local Privacy Preserving Large Language Model for Structured Information Retrieval from Medical Documents"}, {"paperId": "d5688d5154f934b232ddb7f899b31adf8a08fc2b", "title": "Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects"}, {"paperId": "cde42399a756854ad0997ac39f9f84231533efdc", "title": "Ascle: A Python Natural Language Processing Toolkit for Medical Text Generation"}, {"paperId": "bca0bbd01ea917b7a9fe369288ea3ba03d3b1ff3", "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge"}, {"paperId": "ee5e79a83b019d5a7e3ad55e6e39696aff67a5f2", "title": "Combating Misinformation in the Age of LLMs: Opportunities and Challenges"}, {"paperId": "8d2709ed1788a67e64425fb410bb49f3ee49e088", "title": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review"}, {"paperId": "affcda0a52e6b37535e8ba2c7ac05f5ec94bb1ac", "title": "Bias in Emotion Recognition with ChatGPT"}, {"paperId": "eaf52a96efd77675130196b32ca3ae25e03b0d35", "title": "Evaluating the Cybersecurity Robustness of Commercial LLMs against Adversarial Prompts: A PromptBench Analysis"}, {"paperId": "a1c16eb47c6ae88beb7a2287c75e38fd5832536b", "title": "Explainable AI for Stress and Depression Detection in the Cyberspace and Beyond"}]}

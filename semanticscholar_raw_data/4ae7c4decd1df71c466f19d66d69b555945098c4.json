{"paperId": "4ae7c4decd1df71c466f19d66d69b555945098c4", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Beyond Text: A Deep Dive into Large Language Models' Ability on Understanding Graph Data", "abstract": "Large language models (LLMs) have achieved impressive performance on many natural language processing tasks. However, their capabilities on graph-structured data remain relatively unexplored. In this paper, we conduct a series of experiments benchmarking leading LLMs on diverse graph prediction tasks spanning node, edge, and graph levels. We aim to assess whether LLMs can effectively process graph data and leverage topological structures to enhance performance, compared to specialized graph neural networks. Through varied prompt formatting and task/dataset selection, we analyze how well LLMs can interpret and utilize graph structures. By comparing LLMs' performance with specialized graph models, we offer insights into the strengths and limitations of employing LLMs for graph analytics. Our findings provide insights into LLMs' capabilities and suggest avenues for further exploration in applying them to graph analytics.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-07", "journal": {"name": "ArXiv", "volume": "abs/2310.04944"}, "authors": [{"authorId": "2257349205", "name": "Yuntong Hu"}, {"authorId": "2021011947", "name": "Zhengwu Zhang"}, {"authorId": "2257314969", "name": "Liang Zhao"}], "citations": [{"paperId": "52f3338b8969517629097e745f66cb9eac5f99c5", "title": "Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Techniques"}, {"paperId": "eff9d7ed06f30f121d30ee13802a11f172ef66f4", "title": "Demystifying Chains, Trees, and Graphs of Thoughts"}, {"paperId": "54630cd92c0c6696a422c3b2aa986c1f75df70b3", "title": "A Survey of Graph Meets Large Language Model: Progress and Future Directions"}, {"paperId": "21510620f0c92dde08741070a00593bcd1815d8c", "title": "Can LLMs Effectively Leverage Graph Structural Information through Prompts, and Why?"}]}

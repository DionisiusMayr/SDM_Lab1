{"paperId": "9f3fd606147f4d27169a947f8deb74c56f75eecf", "publicationVenue": {"id": "fcbcaf18-8ab1-43e1-a973-604bbc7e344e", "name": "Proceedings of the VLDB Endowment", "type": "journal", "alternate_names": ["Proceedings of The Vldb Endowment", "Proc VLDB Endow", "Proc Vldb Endow"], "issn": "2150-8097", "url": "http://dl.acm.org/toc.cfm?id=J1174", "alternate_urls": ["http://portal.acm.org/toc.cfm?CFID=21632689&CFTOKEN=99329904&WantType=Affiliated%20Organizations&coll=ACM&dl=ACM&id=J1174&idx=J1174&part=affil&title=VLDB%20Endowment&type=periodical"]}, "title": "Fast and Space-Efficient Parallel Algorithms for Influence Maximization", "abstract": "\n Influence Maximization (IM) is a crucial problem in data science. The goal is to find a fixed-size set of highly influential\n seed\n vertices on a network to maximize the influence spread along the edges. While IM is NP-hard on commonly used diffusion models, a greedy algorithm can achieve (1 - 1/\n e\n )-approximation by repeatedly selecting the vertex with the highest\n marginal gain\n in influence as the seed. However, we observe two performance issues in the existing work that prevent them from scaling to today's large-scale graphs: space-inefficient memorization to estimate marginal gain, and time-inefficient seed selection process due to a lack of parallelism.\n \n \n This paper significantly improves the scalability of IM using two key techniques. The first is a\n sketch-compression\n technique for the independent cascading model on undirected graphs. It allows combining the simulation and sketching approaches to achieve a time-space tradeoff. The second technique includes new data structures for parallel seed selection. Using our new approaches, we implemented\n PaC-IM\n : Parallel and Compressed IM.\n \n \n We compare\n PaC-IM\n with state-of-the-art parallel IM systems on a 96-core machine with 1.5TB memory.\n PaC-IM\n can process the ClueWeb graph with 978M vertices and 75B edges in about 2 hours. On average, across all tested graphs, our uncompressed version is 5--18x faster and about 1.4x more space-efficient than existing parallel IM systems. Using compression further saves 3.8x space with only 70% overhead in time on average.\n", "venue": "Proceedings of the VLDB Endowment", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-01", "journal": {"name": "Proc. VLDB Endow.", "pages": "400-413", "volume": "17"}, "authors": [{"authorId": "2266421567", "name": "Letong Wang"}, {"authorId": "2266488000", "name": "Xiangyun Ding"}, {"authorId": "2266389076", "name": "Yan Gu"}, {"authorId": "2108541101", "name": "Yihan Sun"}], "citations": []}

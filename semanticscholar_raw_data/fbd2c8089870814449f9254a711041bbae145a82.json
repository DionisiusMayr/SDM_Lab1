{"paperId": "fbd2c8089870814449f9254a711041bbae145a82", "publicationVenue": {"id": "d9720b90-d60b-48bc-9df8-87a30b9a60dd", "name": "Neural Information Processing Systems", "type": "conference", "alternate_names": ["Neural Inf Process Syst", "NeurIPS", "NIPS"], "url": "http://neurips.cc/"}, "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources", "abstract": "In this work we explore recent advances in instruction-tuning language models on a range of open instruction-following datasets. Despite recent claims that open models can be on par with state-of-the-art proprietary models, these claims are often accompanied by limited evaluation, making it difficult to compare models across the board and determine the utility of various resources. We provide a large set of instruction-tuned models from 6.7B to 65B parameters in size, trained on 12 instruction datasets ranging from manually curated (e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and systematically evaluate them on their factual knowledge, reasoning, multilinguality, coding, and open-ended instruction following abilities through a collection of automatic, model-based, and human-based metrics. We further introduce T\\\"ulu, our best performing instruction-tuned model suite finetuned on a combination of high-quality open resources. Our experiments show that different instruction-tuning datasets can uncover or enhance specific skills, while no single dataset (or combination) provides the best performance across all evaluations. Interestingly, we find that model and human preference-based evaluations fail to reflect differences in model capabilities exposed by benchmark-based evaluations, suggesting the need for the type of systemic evaluation performed in this work. Our evaluations show that the best model in any given evaluation reaches on average 87% of ChatGPT performance, and 73% of GPT-4 performance, suggesting that further investment in building better base models and instruction-tuning data is required to close the gap. We release our instruction-tuned models, including a fully finetuned 65B T\\\"ulu, along with our code, data, and evaluation framework at https://github.com/allenai/open-instruct to facilitate future research.", "venue": "Neural Information Processing Systems", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-06-07", "journal": {"name": "ArXiv", "volume": "abs/2306.04751"}, "authors": [{"authorId": "1705260", "name": "Yizhong Wang"}, {"authorId": "2056776606", "name": "Hamish Ivison"}, {"authorId": "2697425", "name": "Pradeep Dasigi"}, {"authorId": "2689239", "name": "Jack Hessel"}, {"authorId": "2236429", "name": "Tushar Khot"}, {"authorId": "37619618", "name": "Khyathi Raghavi Chandu"}, {"authorId": "30051202", "name": "David Wadden"}, {"authorId": "2071601396", "name": "Kelsey MacMillan"}, {"authorId": "144365875", "name": "Noah A. Smith"}, {"authorId": "46181066", "name": "Iz Beltagy"}, {"authorId": "2548384", "name": "Hannaneh Hajishirzi"}], "citations": [{"paperId": "8dc4ac4446f787f0647e1e16a9c43b2880e04008", "title": "Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer"}, {"paperId": "de542a756ed96c360813b0293063b13653474708", "title": "Evaluating Generative Language Models in Information Extraction as Subjective Question Correction"}, {"paperId": "3fa9def5ab2ede7e66635f750062419404c5f4a8", "title": "Untangle the KNOT: Interweaving Conflicting Knowledge and Reasoning Skills in Large Language Models"}, {"paperId": "5bd151095a06398bc4c8d34f2a64c5461af8235b", "title": "Concept -- An Evaluation Protocol on Conversation Recommender Systems with System-centric and User-centric Factors"}, {"paperId": "cc5cb7520eed9f6d4afb669ea40f38c5596e8900", "title": "FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning"}, {"paperId": "b30e8ef07654aa5f52ad26f6fbb1fa5ba7f9573f", "title": "Comparing Bad Apples to Good Oranges: Aligning Large Language Models via Joint Preference Optimization"}, {"paperId": "bfc223b002401f42b44bca725da6ed6d1b953cff", "title": "Disentangling Length from Quality in Direct Preference Optimization"}, {"paperId": "60071051e176b6e2fadbededadbb08b05e125c13", "title": "Dual-Personalizing Adapter for Federated Foundation Models"}, {"paperId": "662f0841a2a8435c8b3f196a4016347ad31cd8d5", "title": "Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A Multifaceted Statistical Approach"}, {"paperId": "d5d7b26dbdf09737878644530b226a79c9f43bfb", "title": "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models"}, {"paperId": "a1228951fa61089866579aa4671bb1fb1128df69", "title": "Third-Party Language Model Performance Prediction from Instruction"}, {"paperId": "2d1adda7a9b0596d8b470c065da5a6528b364a7f", "title": "Automated Data Curation for Robust Language Model Fine-Tuning"}, {"paperId": "973814cd535facbf4f27c3de477b05bf19366030", "title": "ORPO: Monolithic Preference Optimization without Reference Model"}, {"paperId": "f282f8a64476c1ab2a05c63d6a3a0d7e4b2996d9", "title": "Electrocardiogram Instruction Tuning for Report Generation"}, {"paperId": "ae4635297ad87fcb3ec4105a51b5cbcb4075e5e2", "title": "LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error"}, {"paperId": "303b4ae0e53cca8d007076778e5c17e28116ff7e", "title": "Learning to Decode Collaboratively with Multiple Language Models"}, {"paperId": "13f44206745d20971ca271401eff6772aa80de80", "title": "SaulLM-7B: A pioneering Large Language Model for Law"}, {"paperId": "97c17683dbd3bea6972b93f5ab8ebb208b344ee6", "title": "Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs"}, {"paperId": "3352782f94354d3f3a170f497dd1888e9cd39d8a", "title": "MathScale: Scaling Instruction Tuning for Mathematical Reasoning"}, {"paperId": "cfa85c8db829dbd2384ea7f130f462e7e7f1f630", "title": "Reliable, Adaptable, and Attributable Language Models with Retrieval"}, {"paperId": "fe99095df95638b6768e1c10682034d25353ed89", "title": "MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining"}, {"paperId": "030b888709dc14ccd6f6b8151757066e9c33dc7f", "title": "FAC2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"}, {"paperId": "62863fbcff6bc411bd83dc50d3e1bcbe72f651ef", "title": "RECOST: External Knowledge Guided Data-efficient Instruction Tuning"}, {"paperId": "21b8e360ac5d7101ebd5ca2ebdd859f3d3f39b7b", "title": "Asymmetry in Low-Rank Adapters of Foundation Models"}, {"paperId": "d32764d479f338e0a1897cc3c35630f4ed0a39bf", "title": "SelectIT: Selective Instruction Tuning for Large Language Models via Uncertainty-Aware Self-Reflection"}, {"paperId": "1cba4c9ad9b7f645aeb97e6a4ac369fd0cde6490", "title": "PeriodicLoRA: Breaking the Low-Rank Bottleneck in LoRA Optimization"}, {"paperId": "33313b413695dcd396c6f558a3153cc6a572d5c1", "title": "ChatMusician: Understanding and Generating Music Intrinsically with LLM"}, {"paperId": "3b13389584c554fb5d7eb2f2ffc9b11b50385664", "title": "PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA"}, {"paperId": "c4d43fe1b7e44c5e9929d6edf7bd11de4e6d293a", "title": "Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning"}, {"paperId": "da01b426baea356687c7ee1d006c9cf986f498b5", "title": "CriticBench: Evaluating Large Language Models as Critic"}, {"paperId": "1c0b3679919cd0531973fced1a1eb49745d9332d", "title": "Instruction-tuned Language Models are Better Knowledge Learners"}, {"paperId": "241eefc1bb11e693e0fef6977a65a0a822fb8f5e", "title": "LoRA+: Efficient Low Rank Adaptation of Large Models"}, {"paperId": "7cebf3afab09d990a2322ea053d0de96f31f2971", "title": "Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?"}, {"paperId": "e710115f7251bc552e23311c69086253ddab2429", "title": "Contrastive Instruction Tuning"}, {"paperId": "a5805cca2c24c9125795c10daa87671cd5609972", "title": "Instruction Diversity Drives Generalization To Unseen Tasks"}, {"paperId": "6857a1439cfd5057d7e129eff16e5a58ab94bf14", "title": "OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models"}, {"paperId": "4d4d9da4f2c39089ea6c8d84e5031c195548d7b6", "title": "Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence"}, {"paperId": "c8b1206ef8e6fdebd3b9ad2165937256ab8b5652", "title": "Chain-of-Thought Reasoning Without Prompting"}, {"paperId": "42ee90ce864f1cb2a865f554fc3c6531d0ea34d3", "title": "ODIN: Disentangled Reward Mitigates Hacking in RLHF"}, {"paperId": "7ae48b24cbf955bf9b9498fb287bf4c5cd3b73d4", "title": "OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning"}, {"paperId": "a1f76db91c0debcf93ae9889736bce8470902113", "title": "Large Language Models: A Survey"}, {"paperId": "2565b1ae47fb8e47017bee18ef1c602d6e1f4e44", "title": "Rethinking Data Selection for Supervised Fine-Tuning"}, {"paperId": "bf40c8f88875f7c591dddc0936542918f4083b22", "title": "A Roadmap to Pluralistic Alignment"}, {"paperId": "b88b25aba67d7a391eb480563fbfd5b4a6625444", "title": "Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning"}, {"paperId": "95898b1f82cf7ad7d96fcc85b4def7f086325af5", "title": "LESS: Selecting Influential Data for Targeted Instruction Tuning"}, {"paperId": "184bfcbed3fb8dadffef665412f373cebd42ede5", "title": "Diversity Measurement and Subset Selection for Instruction Tuning Datasets"}, {"paperId": "2c2585c5098ad2309591b4a1f090bd552d3a6f30", "title": "GIRT-Model: Automated Generation of Issue Report Templates"}, {"paperId": "241c72f38b8c674ef4853852eb1cdcb3851eefa2", "title": "eXplainable Bayesian Multi-Perspective Generative Retrieval"}, {"paperId": "ac45bbf9940512d9d686cf8cd3a95969bc313570", "title": "OLMo: Accelerating the Science of Language Models"}, {"paperId": "ec9203f6c25a353325dd23ed38e5036b79d9e79b", "title": "LongAlign: A Recipe for Long Context Alignment of Large Language Models"}, {"paperId": "465f76343f5ca61a088d97623f5fe73e5ca7e630", "title": "Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks"}, {"paperId": "ed2da4a2c64c4ffdfe4fa38176b61d688a2b0d21", "title": "RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization"}, {"paperId": "8c1243e089621d09025e1e51e8e01cb2cb20eabf", "title": "Knowledge Fusion of Large Language Models"}, {"paperId": "221a0e0c798d4bbc8a057d869b7251e03f1b0790", "title": "ChatQA: Building GPT-4 Level Conversational QA Models"}, {"paperId": "5ab5ed1ee85d2adabf46ec6f86c9820120fe774c", "title": "Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models"}, {"paperId": "f6d7482bb5baf33f22b862ad4997f5c8cd13db21", "title": "Tuning Language Models by Proxy"}, {"paperId": "c6e162aedf6a5ab0135e3b991577d77ca06673f9", "title": "SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning"}, {"paperId": "e7bbfb2eb08cce711fd39f2081d116d7e760651e", "title": "Question Translation Training for Better Multilingual Reasoning"}, {"paperId": "2b9fdc60647701c9c79c3203c04fded35fe2d7ec", "title": "An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models"}, {"paperId": "028d75496e51943f52c7b2177344a3c089c18058", "title": "Fine-grained Hallucination Detection and Editing for Language Models"}, {"paperId": "b2fda33b7c122c044a7faa185d250d59ce9e4453", "title": "Investigating Data Contamination for Pre-training Language Models"}, {"paperId": "c858999fdfe11f93eb50bcb0eb6920f877e385ad", "title": "CASA: Causality-driven Argument Sufficiency Assessment"}, {"paperId": "c3d1832ed0444f75d44116fabbdda891aebc4b01", "title": "LLaMA Pro: Progressive LLaMA with Block Expansion"}, {"paperId": "90d04e5f1cb6efb12e14e388730cf58666325edb", "title": "A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators"}, {"paperId": "36c5d94a9856e9ccd86f51551b9b432fdad3b61f", "title": "Hazards from Increasingly Accessible Fine-Tuning of Downloadable Foundation Models"}, {"paperId": "ec9414654469692d8f1de8e2401a3dcbc58ee11a", "title": "Demystifying Instruction Mixing for Fine-tuning Large Language Models"}, {"paperId": "7a31971b0af439dec6fc484cca20df57f440b644", "title": "One Shot Learning as Instruction Data Prospector for Large Language Models"}, {"paperId": "e41150e2b0feeb02c3948b34a2dec9d290b9c979", "title": "diff History for Neural Language Agents"}, {"paperId": "a2b150e02306038389f5df683428f5a4659a468e", "title": "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following"}, {"paperId": "117a9f9227ebe4acc67ff8a52eb9db2ab16390c8", "title": "Data Management For Large Language Models: A Survey"}, {"paperId": "600d9287efc4703bdb99ce39b5e8b37da0baa6f6", "title": "The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning"}, {"paperId": "836b9658eb81f321de90423b6259b07a398ca79b", "title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient Way"}, {"paperId": "e3f7ad05b1652c6ada78cffbe405bceb723bc70c", "title": "MoDS: Model-oriented Data Selection for Instruction Tuning"}, {"paperId": "ea9af64a79ffe964e43121e8f78883c146894910", "title": "LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms"}, {"paperId": "d034a77636c0b155eb3f752f161203f7891135cb", "title": "Data Diversity Matters for Robust Instruction Tuning"}, {"paperId": "37680e5cb6030e01f1a44a5abe2257972196ae26", "title": "Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2"}, {"paperId": "312fed7476dd58b8a14bbc2a15f9faa00423b988", "title": "FollowEval: A Multi-Dimensional Benchmark for Assessing the Instruction-Following Capability of Large Language Models"}, {"paperId": "a8f42b2538fb99afecaddbce11eeeec5034b3141", "title": "How Well Do Large Language Models Truly Ground?"}, {"paperId": "215de09ac6e5de81187c85065b5ace8bc01f2862", "title": "Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models"}, {"paperId": "722aa3bb6e426afc40f05c42a2fc0623adb51af9", "title": "Towards Verifiable Text Generation with Symbolic References"}, {"paperId": "9c60c766d65daa5554949fb3bce2df1ef58a5a16", "title": "PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning"}, {"paperId": "bf11f01929afed0ad3ccfe1b5e0fd34d90ef2b4f", "title": "Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models"}, {"paperId": "0b0525a0fdc1e18978e9861dcb4544a90c2e70ce", "title": "Agent Lumos: Unified and Modular Training for Open-Source Language Agents"}, {"paperId": "227b5f8206b64858edeef6723b96af14133077e3", "title": "Rethinking Benchmark and Contamination for Language Models with Rephrased Samples"}, {"paperId": "578887182fcf49cfd4d99fa3b1de200e8ebb2c45", "title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection"}, {"paperId": "0b3e7b5cbef627b1ceedceadc5f58787f432163b", "title": "What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning"}, {"paperId": "c0d698950a4560fc2a63acb30a91aa2deb042ed3", "title": "Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions"}, {"paperId": "590954e15e247cc343710ee97e396ad99f52970f", "title": "Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks"}, {"paperId": "439f1aacbcb32cba6da8f75bd9b15f7ea35e9d4d", "title": "Making Large Language Models Better Data Creators"}, {"paperId": "f8f9b9e5a1b9dd67fe61bd358f1d90f6cceeb4a1", "title": "Dynamics of Instruction Tuning: Each Ability of Large Language Models Has Its Own Growth Pace"}, {"paperId": "74609184b96ee622b0ae775a3d7d86e2bfd49eb7", "title": "How do Language Models Bind Entities in Context?"}, {"paperId": "1c091ddbd2acb70056c514317586ffec2d7d2fef", "title": "OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models"}, {"paperId": "7bca28a11b7bd50dd378dd59e97f3556b16183f3", "title": "MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications"}, {"paperId": "2967ab775f6cdabc6ab59010734f352dd3ebc8d6", "title": "Instruct and Extract: Instruction Tuning for On-Demand Information Extraction"}, {"paperId": "b1d2a29860e69c6ce9987ddefbe112feb1efa16a", "title": "Large Language Models can Share Images, Too!"}, {"paperId": "06dc6e7c32480aff7085f32de22206a62f5893fc", "title": "Analyzing Multilingual Competency of LLMs in Multi-Turn Instruction Following: A Case Study of Arabic"}, {"paperId": "378a51082ddf7430f928b7dde59186c041eb4b6c", "title": "Tuna: Instruction Tuning using Feedback from Large Language Models"}, {"paperId": "46fe9ce789408b8a50fb4259e6bf0cc5855f4ed5", "title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs"}, {"paperId": "45872b94798c3125abfb185b7926689c5e767763", "title": "GraphGPT: Graph Instruction Tuning for Large Language Models"}, {"paperId": "2ccc2463e702302acdb096adba9d736da5a64af3", "title": "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective"}, {"paperId": "9bf00afb0efb02a263fa3ddea1e768677498536c", "title": "Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging"}, {"paperId": "ddbd8fe782ac98e9c64dd98710687a962195dd9b", "title": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"}, {"paperId": "d395c771f6537259610497ba218cce5b9bfc2c50", "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries"}, {"paperId": "23e5395b4c6249c2873666bff73e203821c14719", "title": "Instruction Tuning with Human Curriculum"}, {"paperId": "675c87c9fed17b6dc1d9734606e12c9d0c46c573", "title": "InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining"}, {"paperId": "d65c8066ab553d4d7ed70c567f50af2d5d875a82", "title": "Towards the Fundamental Limits of Knowledge Transfer over Finite Domains"}, {"paperId": "8147cec9245d34d13732a08e915c920a1a499bb5", "title": "Lemur: Harmonizing Natural Language and Code for Language Agents"}, {"paperId": "a32a999377d3eb14ac7652877f002f5c548d3134", "title": "Establishing Trustworthiness: Rethinking Tasks and Model Evaluation"}, {"paperId": "24df244bf7a6e8c93c5f183d3f62d39c0f773c68", "title": "SALMON: Self-Alignment with Principle-Following Reward Models"}, {"paperId": "5088a04d1a9f42b967f3dcf791145e8aa367fc54", "title": "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition"}, {"paperId": "e6776f5f293c18f4b2322b1479f083cb24d33343", "title": "SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF"}, {"paperId": "be9447ccc05a0e8a07321272778c7574173cf00e", "title": "Resprompt: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models"}, {"paperId": "0e0e706e13f160e74cac9556f28ab9a358c148d2", "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"}, {"paperId": "cddb552f6c3464a54a02b0b64b2d1af56c086606", "title": "MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning"}, {"paperId": "ad44f2392df3c6f2c45d21fe1dbd8ec17003530d", "title": "Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models"}, {"paperId": "1e0caa706e9d9fdad82d6713fa20b52975a1703b", "title": "At Which Training Stage Does Code Data Help LLMs Reasoning?"}, {"paperId": "8ec117feff6ee10e3b20a19ac101fee5c99e14d7", "title": "LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression"}, {"paperId": "844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5", "title": "Aligning Large Multimodal Models with Factually Augmented RLHF"}, {"paperId": "68838aba1cc6e20028f9703b96e3517b01972277", "title": "Large language models can accurately predict searcher preferences"}, {"paperId": "7a7128e9696dfedc24bf432c4b4c3aafa5e95a1a", "title": "An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models"}, {"paperId": "0fb61be60088e80e565b84f44e49ba30630b6126", "title": "Stabilizing RLHF through Advantage Model and Selective Rehearsal"}, {"paperId": "e56dc21699e6283fce072ffc908cb9f66321760d", "title": "Exploring the impact of low-rank adaptation on the performance, efficiency, and regularization of RLHF"}, {"paperId": "423cbdde746d691deb23263005e587ec087d2cdc", "title": "ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer"}, {"paperId": "6cdc91a8a6eaf655e0a228f3fb075d91de3a703e", "title": "Leveraging Large Language Models for Automated Dialogue Analysis"}, {"paperId": "a3dd7d33dfaa9e02e43d92e900cba01f52d8c4b9", "title": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"}, {"paperId": "74b4b993babe99bc5f5c589c27fef0f1baba606b", "title": "Making Large Language Models Better Reasoners with Alignment"}, {"paperId": "d00735241af700d21762d2f3ca00d920241a15a4", "title": "Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"}, {"paperId": "d655f652d02251b45db43181c5e3c73dfc59cd51", "title": "Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties"}, {"paperId": "b931b242f40a032b9ae7dae9d9fc10c6ab90695e", "title": "Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models"}, {"paperId": "eee548fbd0b9dd954c692fbd8880e80d5f077bd7", "title": "Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models"}, {"paperId": "f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f", "title": "Instruction Tuning for Large Language Models: A Survey"}, {"paperId": "88b0ee59d565f2e04f62e1729ac9c681e132f103", "title": "PlatoLM: Teaching LLMs via a Socratic Questioning User Simulator"}, {"paperId": "dd6a5032b61404ad6931cd28b1b5d7d9f75c9de8", "title": "Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation"}, {"paperId": "40e0b9361d88b1879891eb6d16de110b30bf6c62", "title": "OctoPack: Instruction Tuning Code Large Language Models"}, {"paperId": "dd3fb89d1201d46fa80b6a9519114599c01c11ac", "title": "#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"}, {"paperId": "c74a13b251b6af6dfce49eeb128b1c0e2ddf955d", "title": "A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment"}, {"paperId": "9fec5cf2f06e6fd8c5e6f6028226082d1ecec5b7", "title": "Extrapolating Large Language Models to Non-English by Aligning Languages"}, {"paperId": "a2cec5152e3af9d99a4a3b8128fc247885b4b1c3", "title": "In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning"}, {"paperId": "7f55ef29a6f8b2771c5435bbeba29c87264fdc88", "title": "Shepherd: A Critic for Language Model Generation"}, {"paperId": "0894585294c67193ff3190240554677b56fd79a0", "title": "From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?"}, {"paperId": "b5069352383579c6464d8e5ec34eab693c45f59a", "title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets"}, {"paperId": "3e664adb009dce373129a3563e4b2cb08731bc76", "title": "PolyLM: An Open Source Polyglot Large Language Model"}, {"paperId": "130d18d1d455336e1a5b06c85784894bb67d87ec", "title": "PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations"}, {"paperId": "f8e99be4f9a01761fab74bade2c3c18de9fc686b", "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"}, {"paperId": "da08e9f21ef361e0e1242f8849a18a4ea1a3d27e", "title": "SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions"}, {"paperId": "cde934546bbdb19094d8a53cc047d002c827f884", "title": "Large Multimodal Models: Notes on CVPR 2023 Tutorial"}, {"paperId": "a0a79dad89857a96f8f71b14238e5237cbfc4787", "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"}, {"paperId": "38d64919ba526868a850a0e5f6239d4c474b7e7e", "title": "Large Language Models are not Fair Evaluators"}, {"paperId": "9e16d8cc6096ec0d2733a4ecf41ce09d9a4bd19c", "title": "Scaling Data-Constrained Language Models"}, {"paperId": "8d9a91c4372ec4bc274d27cac52548bf35285358", "title": "Investigating Table-to-Text Generation Capabilities of LLMs in Real-World Information Seeking Scenarios"}, {"paperId": "0744580e75a74357e466a57082c85cb42f548aa9", "title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning"}, {"paperId": "9573e2025440219a1d3393664b3c80bda51ac8f4", "title": "Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning"}, {"paperId": "405b3b7f04380c87677735e471b8434616d2e229", "title": "Do prompt positions really matter?"}, {"paperId": "acbabae091bed349535537b05a9ee80467faf255", "title": "TaskWeb: Selecting Better Source Tasks for Multi-task NLP"}, {"paperId": "05bf0ea7bc89adb92e583f4fc91dc994fa77bb85", "title": "LongForm: Effective Instruction Tuning with Reverse Instructions"}, {"paperId": "807f4a368e845f7649e645f91d1d4f2ce72beee3", "title": "A Comprehensive Survey on Instruction Following"}, {"paperId": "a85ae093657f62bf13bf18b0652402026dd4186d", "title": "DialogCC: An Automated Pipeline for Creating High-Quality Multi-Modal Dialogue Dataset"}, {"paperId": "92d1ba0bf4e3823a7b691b827edd2306f408f8c5", "title": "RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization"}, {"paperId": "ac4ffaab10f6b6ad83e79ca5691f338abf5cff82", "title": "Instruction Mining: High-Quality Instruction Data Selection for Large Language Models"}, {"paperId": "ac771182d1780c863954243809d1e144433919f9", "title": "Aligning Large Language Models with Human: A Survey"}, {"paperId": "6f3562f861af68e04eb8916230eada09b07d7e1d", "title": "Granite Foundation Models"}, {"paperId": "91e7be4f080feae4773289775279a67b508e648f", "title": "Beyond Performance: Quantifying and Mitigating Label Bias in LLMs"}]}

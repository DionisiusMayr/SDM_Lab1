{"paperId": "e92232eba9abb75b6f7d3644210004416422e93c", "publicationVenue": {"id": "6b6df2de-21bc-4137-9859-3fcef46f6a21", "name": "Mobile Information Systems", "type": "journal", "alternate_names": ["Mob Inf Syst"], "issn": "1574-017X", "url": "https://www.hindawi.com/journals/misy/", "alternate_urls": ["https://www.iospress.nl/journal/mobile-information-systems/", "https://www.iospress.nl/html/1574017x.php", "http://content.iospress.com/journals/mobile-information-systems"]}, "title": "Energy Efficiency Strategy for Big Data in Cloud Environment Using Deep Reinforcement Learning", "abstract": "Big data entails massive cloud resources for data processing and analysis, which consumes more energy to run. The resources and tasks are increasing exponentially in the cloud environment for the processing of big data, which results in an increment in power consumption to run the cloud data center. So, there is always a scope for optimizing the energy utilization in cloud data centers. This paper presents a visionary architecture in a cloud environment for big data with a proposed energy-efficient strategy based on LSTM-DQN (long-short-term memory-deep Q network) using reinforcement learning (RL). The traditional techniques are not so efficient when the tasks are allocated dynamically, and the generic RL strategies are not able to store the data iterated in the last cycles of processing, so the LSTM is considered for this purpose. In the proposed model, integration of DPSO and DQN is used for better estimation and rectification of the curse of dimensionality. The proposed strategy is compared with different variants of PSO (particle swarm optimization) such as DPSO and QoS-PSO. The improvement in results through proposed model is recoded over the algorithm such as load aware (8.01%), DQN (13.36%), EA-DQN (34.16%), L-No-DEAF (15.62%), DPSO (62.68%), QoS-PSO (72.69%), FFO-EVSM (75.42%), and MIMT (76.39%) on the parameter of energy efficiency, tasks completion time, and energy consumption over the timeline. So, the proposed model is encouraging in the energy-efficient cloud environment for big data with the challenges that the technological world is facing and the emergence of deep learning as one propitious field.", "venue": "Mobile Information Systems", "year": 2022, "fieldsOfStudy": null, "publicationTypes": null, "publicationDate": "2022-08-11", "journal": {"name": "Mobile Information Systems"}, "authors": [{"authorId": "2141589692", "name": "Neeraj Kumar Pandey"}, {"authorId": "2310681", "name": "M. Diwakar"}, {"authorId": "48085624", "name": "A. Shankar"}, {"authorId": "5033115", "name": "Prabhishek Singh"}, {"authorId": "8704288", "name": "Mohammad Hossein Khosravi"}, {"authorId": "2107990070", "name": "Vivek Kumar"}], "citations": [{"paperId": "5b86897a008f06e6c5615c5ce22730e6690f3b97", "title": "Comparative analysis of cloud resources forecasting using deep learning techniques based on VM workload traces"}, {"paperId": "33aaf0e04ff499013502f2314ce8d2f497882c5d", "title": "Energy efficient task scheduling based on deep reinforcement learning in cloud environment: A specialized review"}, {"paperId": "285fee7dd1563b5d505a351a329d4a819cf2b6af", "title": "Advancing Bug Detection in Solidity Smart Contracts with the Proficiency of Deep Learning"}, {"paperId": "d3798971001f57e9e285f0eb6abdd92509a5bc10", "title": "Influence of Deepfake Terminology on Content-Emerging Threat Reduction"}, {"paperId": "7e762a8e7f8f8559be10eb9be5da286873fe4f29", "title": "An Efficient Security Solution for IoT and Cloud Security Using Lattice-Based Cryptography"}, {"paperId": "90910abedf36dce47a59975b21ceedc8cb7dd413", "title": "Soft computing in computer network security protection system with machine learning based on level protection in the cloud environment"}, {"paperId": "5e45d2551c966a39194b016ce36eeb0978ad599c", "title": "Improved Task Scheduling Strategy Using Reinforcement Learning in Cloud Environment"}]}

{"paperId": "a64067c6c4286fc60f4430829ae6b18519c088e3", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models", "abstract": "Aligned large language models (LLMs) demonstrate exceptional capabilities in task-solving, following instructions, and ensuring safety. However, the continual learning aspect of these aligned LLMs has been largely overlooked. Existing continual learning benchmarks lack sufficient challenge for leading aligned LLMs, owing to both their simplicity and the models' potential exposure during instruction tuning. In this paper, we introduce TRACE, a novel benchmark designed to evaluate continual learning in LLMs. TRACE consists of 8 distinct datasets spanning challenging tasks including domain-specific tasks, multilingual capabilities, code generation, and mathematical reasoning. All datasets are standardized into a unified format, allowing for effortless automatic evaluation of LLMs. Our experiments show that after training on TRACE, aligned LLMs exhibit significant declines in both general ability and instruction-following capabilities. For example, the accuracy of llama2-chat 13B on gsm8k dataset declined precipitously from 28.8\\% to 2\\% after training on our datasets. This highlights the challenge of finding a suitable tradeoff between achieving performance on specific tasks while preserving the original prowess of LLMs. Empirical findings suggest that tasks inherently equipped with reasoning paths contribute significantly to preserving certain capabilities of LLMs against potential declines. Motivated by this, we introduce the Reasoning-augmented Continual Learning (RCL) approach. RCL integrates task-specific cues with meta-rationales, effectively reducing catastrophic forgetting in LLMs while expediting convergence on novel tasks.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-10-10", "journal": {"name": "ArXiv", "volume": "abs/2310.06762"}, "authors": [{"authorId": "2118451107", "name": "Xiao Wang"}, {"authorId": "2213635839", "name": "Yuan Zhang"}, {"authorId": "2214644916", "name": "Tianze Chen"}, {"authorId": "2181306462", "name": "Songyang Gao"}, {"authorId": "2219131195", "name": "Senjie Jin"}, {"authorId": "2257091385", "name": "Xianjun Yang"}, {"authorId": "2218237934", "name": "Zhiheng Xi"}, {"authorId": "2058585152", "name": "Rui Zheng"}, {"authorId": "51192034", "name": "Yicheng Zou"}, {"authorId": "2067331064", "name": "Tao Gui"}, {"authorId": "2257376355", "name": "Qi Zhang"}, {"authorId": "2257129989", "name": "Xuanjing Huang"}], "citations": [{"paperId": "e198314dbbe1c98957b6e6eea3c91ab47f7decfd", "title": "CoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large Language Model"}, {"paperId": "bd0cd89337cc40d39d3a4cbe9c8709e06e877f3e", "title": "Continual Learning for Large Language Models: A Survey"}]}

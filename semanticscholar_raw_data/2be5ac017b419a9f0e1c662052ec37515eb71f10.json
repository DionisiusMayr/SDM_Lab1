{"paperId": "2be5ac017b419a9f0e1c662052ec37515eb71f10", "publicationVenue": null, "title": "Automatic Tuning of Data-Intensive Analytical Workloads", "abstract": "Modern industrial, government, and academic organizations are collecting massive amounts of data (\"Big Data\") at an unprecedented scale and pace. The ability to perform timely and cost-effective analytical processing of such large datasets in order to extract deep insights is now a key ingredient for success. These insights can drive automated processes for advertisement placement, improve customer relationship management, and lead to major scientific breakthroughs. \nExisting database systems are adapting to the new status quo while large-scale dataflow systems (like Dryad and MapReduce) are becoming popular for executing analytical workloads on Big Data. Ensuring good and robust performance automatically on such systems poses several challenges. First, workloads often analyze a hybrid mix of structured and unstructured datasets stored in nontraditional data layouts. The structure and properties of the data may not be known upfront, and will evolve over time. Complex analysis techniques and rapid development needs necessitate the use of both declarative and procedural programming languages for workload specification. Finally, the space of workload tuning choices is very large and high-dimensional, spanning configuration parameter settings, cluster resource provisioning (spurred by recent innovations in cloud computing), and data layouts. \nWe have developed a novel dynamic optimization approach that can form the basis for tuning workload performance automatically across different tuning scenarios and systems. Our solution is based on (i) collecting monitoring information in order to learn the run-time behavior of workloads, (ii) deploying appropriate models to predict the impact of hypothetical tuning choices on workload behavior, and (iii) using efficient search strategies to find tuning choices that give good workload performance. The dynamic nature enables our solution to overcome the new challenges posed by Big Data, and also makes our solution applicable to both MapReduce and Database systems. We have developed the first cost-based optimization framework for MapReduce systems for determining the cluster resources and configuration parameter settings to meet desired requirements on execution time and cost for a given analytic workload. We have also developed a novel tuning-based optimizer in Database systems to collect targeted run-time information, perform optimization, and repeat as needed to perform fine-grained tuning of SQL queries.", "venue": "", "year": 2016, "fieldsOfStudy": ["Computer Science"], "publicationTypes": null, "publicationDate": "2016-11-16", "journal": {"name": "", "volume": ""}, "authors": [{"authorId": "2013116", "name": "H. Herodotou"}], "citations": [{"paperId": "67a1780787df721f4863223c5fc1194ddf5af7c4", "title": "Towards optimizing the execution of spark scientific workflows using machine learning\u2010based parameter tuning"}, {"paperId": "915ab7b6ca3633230403d47dbb31cf74888cc5c9", "title": "A Survey on Automatic Parameter Tuning for Big Data Processing Systems"}, {"paperId": "a6b1c6a8b4cca54d9c55fcac71d8769d646e3703", "title": "Data-Intensive Workflow Management: For Clouds and Data-Intensive and Scalable Computing Environments"}, {"paperId": "1ee312df85771c0382839a7ee3b119aa6db080b0", "title": "Multiple Decisional Query Optimization in Big Data Warehouse"}, {"paperId": "db3ec8222540de5d4af682f5d40615197756c227", "title": "S2D: Shared Distributed Datasets, Storing Shared Data for Multiple and Massive Queries Optimization in a Distributed Data Warehouse"}, {"paperId": "0e65dd2de69c521db57d88d23ac13851387a0218", "title": "Modelo para estimar performance de um Cluster Hadoop"}, {"paperId": "d71d1d3dd5bdebd51dbd83dfb95d559d5db10c61", "title": "POSUM: A Generic Portfolio Scheduler for MapReduce Workloads"}, {"paperId": "c567bb2f16aab93efebce598c91378d330c34d10", "title": "HCEm model and a comparative workload analysis of Hadoop cluster"}, {"paperId": "1071feecdef5f52fe186d9f2eb206a68a9739149", "title": "Nouvelle strat\u00e9gie pour le traitement distribu\u00e9 des processus d\u00e9cisionnels massifs dans un Big Data Warehouse"}, {"paperId": "98acf8ad01025507ef7024b1311ac45c56934781", "title": "An Enhanced MapReduce Workload Allocation Tool for Spot Market Resources"}, {"paperId": "e5e12aa8ca1aebf9ca48df44a082cf3ea14f10eb", "title": "A What-if Engine for Cost-based MapReduce Optimization"}, {"paperId": "8e08ff5b1ab5889a278999772e9e8a15e5ff685c", "title": "Bulletin of the Technical Committee on Data Engineering March"}]}

{"paperId": "3abb6d7ecb4ad85e12badbe6d190a516477d67d5", "publicationVenue": {"id": "d65e8b4a-f9c2-45ae-9b87-090db7e872f1", "name": "International Conference on Parallel Architectures and Compilation Techniques", "type": "conference", "alternate_names": ["Int Conf Parallel Archit Compil Tech", "PACT", "Parallel Comput Technol", "Parallel Computing Technologies", "Pan African Conference Science, Computing and Telecommunications", "PaCT", "Pan Afr Conf Sci Comput Telecommun"], "url": "http://www.pactconf.org/", "alternate_urls": ["http://ssd.sscc.ru/en/conference"]}, "title": "Com-CAS: Effective Cache Apportioning under Compiler Guidance", "abstract": "With a growing number of cores in modern high-performance servers, effective sharing of the last level cache (LLC) is more critical than ever. The primary agenda of such systems is to maximize performance by efficiently supporting multi-tenancy of diverse workloads. However, this could be particularly challenging to achieve in practice, because modern workloads exhibit dynamic phase behaviour, which causes their cache requirements & sensitivities to vary at finer granularities during execution. Unfortunately, existing systems are oblivious to the application phase behavior, and are unable to detect and react quickly enough to these rapidly changing cache requirements, often incurring significant performance degradation. In this paper, we propose Com-CAS, a new apportioning system that provides dynamic cache allocations for co-executing applications. Com-CAS differs from the existing cache partitioning systems by adapting to the dynamic cache requirements of applications just-in-time, as opposed to reacting, without any hardware modifications. The front-end of Com-CAS consists of compiler-analysis equipped with machine learning mechanisms to predict cache requirements, while the back-end consists of proactive scheduler that dynamically apportions LLC amongst co-executing applications leveraging Intel Cache Allocation Technology (CAT). Com-CAS's partitioning scheme utilizes the compiler-generated information across finer granularities to predict the rapidly changing dynamic application behaviors, while simultaneously maintaining data locality. Our experiments show that Com-CAS improves average weighted throughput by 15% over unpartitioned cache system, and outperforms state-of-the-art partitioning system KPart [6] by 20%, while maintaining the worst individual application completion time degradation to meet various Service-Level Agreement (SLA) requirements.", "venue": "International Conference on Parallel Architectures and Compilation Techniques", "year": 2022, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Book", "Conference"], "publicationDate": "2022-10-08", "journal": {"name": "Proceedings of the International Conference on Parallel Architectures and Compilation Techniques"}, "authors": [{"authorId": "2051300911", "name": "Bodhisatwa Chatterjee"}, {"authorId": "2111267466", "name": "Sharjeel Khan"}, {"authorId": "50307172", "name": "S. Pande"}], "citations": [{"paperId": "836cebc205dc45e8a66e2a5bf1e42e74f44dc9a5", "title": "Beacons: An End-to-End Compiler Framework for Predicting and Utilizing Dynamic Loop Characteristics"}]}

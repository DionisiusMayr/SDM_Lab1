{"paperId": "416d95170cd73d00d72847b2a34c0c39f28621fe", "publicationVenue": {"id": "1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44", "name": "Annual Meeting of the Association for Computational Linguistics", "type": "conference", "alternate_names": ["Annu Meet Assoc Comput Linguistics", "Meeting of the Association for Computational Linguistics", "ACL", "Meet Assoc Comput Linguistics"], "url": "https://www.aclweb.org/anthology/venues/acl/"}, "title": "Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model", "abstract": "Natural language generation models reproduce and often amplify the biases present in their training data. Previous research explored using sequence-to-sequence rewriting models to transform biased model outputs (or original texts) into more gender-fair language by creating pseudo training data through linguistic rules. However, this approach is not practical for languages with more complex morphology than English. We hypothesise that creating training data in the reverse direction, i.e. starting from gender-fair text, is easier for morphologically complex languages and show that it matches the performance of state-of-the-art rewriting models for English. To eliminate the rule-based nature of data creation, we instead propose using machine translation models to create gender-biased text from real gender-fair text via round-trip translation. Our approach allows us to train a rewriting model for German without the need for elaborate handcrafted rules. The outputs of this model increased gender-fairness as shown in a human evaluation study.", "venue": "Annual Meeting of the Association for Computational Linguistics", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2023-05-18", "journal": {"pages": "4486-4506"}, "authors": [{"authorId": "37430735", "name": "Chantal Amrhein"}, {"authorId": "2187058204", "name": "Florian Schottmann"}, {"authorId": "2082372", "name": "Rico Sennrich"}, {"authorId": "2008684540", "name": "Samuel Laubli"}], "citations": [{"paperId": "38f94f882255732b4ad4a154777382a8bf0d0648", "title": "Fairness in Large Language Models: A Taxonomic Survey"}, {"paperId": "8a515a6510e209f1ab9e53d70c291c7e007716d5", "title": "Disclosure and Mitigation of Gender Bias in LLMs"}, {"paperId": "7394132d8d62f83b64e5466007a07e86221b7b6d", "title": "A Prompt Response to the Demand for Automatic Gender-Neutral Translation"}, {"paperId": "3409a29c7287a5e0010f48f8bca42679e3b10c12", "title": "Tackling Bias in Pre-trained Language Models: Current Trends and Under-represented Societies"}, {"paperId": "b930342321b0e3e63e6ce6f90680130d7b5b4a97", "title": "Test Suites Task: Evaluation of Gender Fairness in MT with MuST-SHE and INES"}, {"paperId": "e36128e4cc6ac3e7a99b487403537e869f0b518d", "title": "Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus"}, {"paperId": "bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7", "title": "Bias and Fairness in Large Language Models: A Survey"}, {"paperId": "03bf28df6e282a7e36e1686edeb9c624e6ffb13b", "title": "A Survey on Fairness in Large Language Models"}, {"paperId": "43c3334b259ccdb6d5d9b8db6f0fbeabc04ab53b", "title": "Building Foundations for Inclusiveness through Expert-Annotated Data"}, {"paperId": "a62f8ff093058246f2f9f5a341f7b15ce7310e87", "title": "A Rewriting Approach for Gender Inclusivity in Portuguese"}]}

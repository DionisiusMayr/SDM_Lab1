{"paperId": "6e9a5af235cfd2167f02be825138ef73af0f400d", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Neural Rankers for Code Generation via Inter-Cluster Modeling", "abstract": "Code Large Language Models (CodeLLMs) have ushered in a new era of code generation advancements. However, selecting the best solutions from among all possible CodeLLM solutions remains a challenge. Previous methods frequently overlooked the intricate functional similarities and interactions between clusters, resulting in suboptimal results. In this work, we introduce \\textit{SRank}, a novel reranking strategy for selecting the best solution from code generation that focuses on modeling inter-cluster relationship. By quantifying the functional overlap between clusters, our approach provides a better ranking strategy of code solutions. Empirical results show that our method achieves a remarkable results on pass@1 score. For instance, on the Human-Eval benchmark, we achieve 69.66\\% in pass@1 with Codex002, 75.31\\% for WizardCoder, 53.99\\% for StarCoder and 60.55\\% for CodeGen, which surpass the state-of-the-arts solution ranking methods, such as CodeT and Coder-Reviewer on the same CodeLLM with significant margin ($\\approx 6.1\\%$ improvement on average). Comparing to the random sampling method, we can achieve an average improvement of $\\approx 23.07\\%$ on Human-Eval and 17.64\\% on MBPP. Even in scenarios with limited test inputs, our approach demonstrates robustness and superiority, marking a new state-of-the-arts in code generation reranking.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle", "Review"], "publicationDate": "2023-10-16", "journal": {"name": "ArXiv", "volume": "abs/2311.03366"}, "authors": [{"authorId": "113520204", "name": "H. To"}, {"authorId": "2114752800", "name": "Minh Nguyen"}, {"authorId": "26910508", "name": "Nghi D. Q. Bui"}], "citations": [{"paperId": "a06d3e9e90008c64c45a0029d580541d5f646771", "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents"}]}

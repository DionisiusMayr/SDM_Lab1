{"paperId": "7f55ef29a6f8b2771c5435bbeba29c87264fdc88", "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "title": "Shepherd: A Critic for Language Model Generation", "abstract": "As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.", "venue": "arXiv.org", "year": 2023, "fieldsOfStudy": ["Computer Science"], "publicationTypes": ["JournalArticle"], "publicationDate": "2023-08-08", "journal": {"name": "ArXiv", "volume": "abs/2308.04592"}, "authors": [{"authorId": "1785372925", "name": "Tianlu Wang"}, {"authorId": "2114104308", "name": "Ping Yu"}, {"authorId": "46879944", "name": "Xiaoqing Tan"}, {"authorId": "2228213801", "name": "Sean O'Brien"}, {"authorId": "10721120", "name": "Ramakanth Pasunuru"}, {"authorId": "2173509991", "name": "Jane Dwivedi-Yu"}, {"authorId": "100664938", "name": "O. Yu. Golovneva"}, {"authorId": "1982950", "name": "Luke Zettlemoyer"}, {"authorId": "1399159921", "name": "Maryam Fazel-Zarandi"}, {"authorId": "1709797", "name": "Asli Celikyilmaz"}], "citations": [{"paperId": "d06e65f74715e071678bf8ccdcf9d52004a10280", "title": "CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences"}, {"paperId": "29a56e1c377ac6a4457656b57ef7631ed2bdb509", "title": "LLMCRIT: Teaching Large Language Models to Use Criteria"}, {"paperId": "978aaaeccb4e67041d7c54fc1c3f4520824d8c1a", "title": "Self-Refinement of Language Models from External Proxy Metrics Feedback"}, {"paperId": "6f24e0782300dca8a4cefcb5a3ccba94bfbb1395", "title": "CriticBench: Benchmarking LLMs for Critique-Correct Reasoning"}, {"paperId": "da01b426baea356687c7ee1d006c9cf986f498b5", "title": "CriticBench: Evaluating Large Language Models as Critic"}, {"paperId": "ee85c7c666135f4aae32336968f09584029b6a35", "title": "Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning"}, {"paperId": "0f6cd53c0cc1ee252433e0d37f419754e053b8a6", "title": "Suppressing Pink Elephants with Direct Principle Feedback"}, {"paperId": "4c98e18cf16395b95ffaaeeac3eceffa608dcf8d", "title": "\"Task Success\" is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors"}, {"paperId": "05ab4b262a2a343aa505ff3640fdf30b2530ac99", "title": "LLM-based NLG Evaluation: Current Status and Challenges"}, {"paperId": "d034845314490c8a30ce8d801f87e00c853098fc", "title": "Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study"}, {"paperId": "4b8df079495cbec21ae90d60ab84e8dd813ca7e6", "title": "Leveraging Large Language Models for NLG Evaluation: A Survey"}, {"paperId": "b39d32b7b9b11019a579b182e0fd33cd511a4003", "title": "Structsum Generation for Faster Text Comprehension"}, {"paperId": "485f8a429cf5f70c558181187f2d62e31784deaa", "title": "Reasons to Reject? Aligning Language Models with Judgments"}, {"paperId": "e88a2b613cbbaf7e20a4039e7454b0f10eab3153", "title": "Is Feedback All You Need? Leveraging Natural Language Feedback in Goal-Conditioned Reinforcement Learning"}, {"paperId": "936f7f0fa77efcd322805b93a8d74c48a4108290", "title": "ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?"}, {"paperId": "1ee2e1db7182b8d5c5904a2c2b5efb574130c562", "title": "Digital Socrates: Evaluating LLMs through explanation critiques"}, {"paperId": "de1894742b7f2e4fe02d9ff94761d6178e0a5d3c", "title": "Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision"}, {"paperId": "b039327dc59bd43a65f4a7ac7a975b875ae02f8c", "title": "The Privacy Pillar - A Conceptual Framework for Foundation Model-based Systems"}, {"paperId": "2a5593f19512b4b0cd5448d7e5ef39d801b4877e", "title": "InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models"}, {"paperId": "c085e88a0351e393609a95305afc1db792d1db0f", "title": "The History and Risks of Reinforcement Learning and Human Feedback"}, {"paperId": "9ebf47129c15f61f4b77bbfe305c522480c20347", "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models"}, {"paperId": "ad8182bfb70b3b67a60571ba720cdfc00b8e1392", "title": "Constructive Large Language Models Alignment with Diverse Feedback"}, {"paperId": "5001630bcc65e8e0e621b19625629a2689724743", "title": "Generative Judge for Evaluating Alignment"}, {"paperId": "6d4bacb69923e1e94fb4de468b939ce6db32fb51", "title": "Large Language Models Cannot Self-Correct Reasoning Yet"}, {"paperId": "4c8cc2383cec93bd9ea0758692f01b98a035215b", "title": "UltraFeedback: Boosting Language Models with High-quality Feedback"}, {"paperId": "5076bbbf831a92174c9cc1b347bd0584560435fc", "title": "Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning"}, {"paperId": "a0d83f9e15e722f23c14eb83cb2f87c1d1ea6400", "title": "EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria"}, {"paperId": "7cfaec8004c6d9f4fb5cf10287d15513c35b0a63", "title": "Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements"}]}
